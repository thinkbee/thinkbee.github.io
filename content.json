{"pages":[{"title":"Linux - update-alternatives","text":"Cheat Linux SystemGRUB 복구우분투 부트로더인 GRUB가 잘못되어 복구하려면 해당 배포본의 Live CD, Live USb 등으로 부팅해서 ‘Try Ubuntu’ 에서 터미널을 통해 복구 절차를 시작한다. https://askubuntu.com/questions/88384/how-can-i-repair-grub-how-to-get-ubuntu-back-after-installing-windows https://help.ubuntu.com/community/Grub2 https://wiki.ubuntu.com/Grub2#Recover KeyboardCapslock과 Control key 교체하기 키맵 이용해서 다음 명령:1$setxkbmap -layout us -option ctrl:nocaps 123sudo vi /etc/default/keyboardXKBOPTIONS=&quot;ctrl:nocaps&quot; 1sudo dpkg-reconfigure keyboard-configuration dd블록 크기디스크에 데이터를 쓸려면 디스크의 기본 블록 크기인 512B 보다 큰게 좋다. 또한 쓰기 속도를 증가시키기 위해서 디스크의 물리적 지형에 맞는 크기를 사용하는 것이 좋다. fdisk 같은 유틸리티로 정보를 확인할 수 있고 혹은 sysfs 정보를 확인할 수 있다. 123456/sys/block/sdX/size/sys/block/sdX/queue/physical_block_size/sys/block/sdX/queue/logical_block_size/sys/block/sdX/sdXY/alignment_offset/sys/block/sdX/sdXY/start/sys/block/sdX/sdXY/size 디스크 지우기dd에 데이터를 쓸려면 디스크의 기본 블록 크기인 512B 보다 커야 한다. 또한 쓰기 속도를 증가시키기 위해서 디스크의 물리적 지형에 맞는 크기를 사용하는 것이 좋다. 1$ sudo dd bs=8k if=/dev/urandom of=/dev/rdisk2 fdisk 정보로 확인 1234567891011$ sudo fdisk -l /dev/sdbDisk /dev/sdb: 59.6 GiB, 64021856256 bytes, 125042688 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: 441CD64A-70D1-4A40-ACA8-05CAB62C5C89Device Start End Sectors Size Type/dev/sdb1 2048 8390655 8388608 4G Linux swap/dev/sdb2 8390656 125042654 116651999 55.6G Linux LVM fdisk 결과의 Sector size는 전체 용량과 섹터 크기를 계산하면 논릭적인 섹터의 크기를 확인할 수 있다. 12echo $((64021856256/125042688))512 Sector size (logical/physical): 512 bytes / 512 bytes 에서 물리 크기를 확인할 수 있다. 성능dd 를 사용해서 1024 바이트를 1000000 블록에 걸쳐 쓰기를 수행한다 - 1GB 1$ time sudo dd bs=1024 count=1000000 if=/dev/zero of=1GB_file dd 를 사용해서 1GB 크기 파일을 1024 바이트씩 읽기를 한다. 1$ time sudo dd bs=1024 if=1GB_file of=/dev/null Verbose outputSending an INFO signal to a running dd process makes it print I/O statistics to standard error and then resume copying. In the example below, dd is run in the background to copy 10 million blocks. The kill command makes it output intermediate I/O statistics, and when dd completes normally or is killed by the SIGINT signal, it outputs the final statistics. 12345678$ dd if=/dev/zero of=/dev/null count=10MB &amp; pid=$!$ kill -s INFO $pid; wait $pid3385223+0 records in3385223+0 records out1733234176 bytes (1.7 GB) copied, 6.42173 seconds, 270 MB/s10000000+0 records in10000000+0 records out5120000000 bytes (5.1 GB) copied, 18.913 seconds, 271 MB/s On systems lacking the INFO signal dd responds to the USR1 signal instead, unless the POSIXLY_CORRECT environment variable is set. You can also try the status=progress option: 123456[~]$ dd if=/dev/zero of=/dev/null count=10MB status=progress4708234752 bytes (4.7 GB, 4.4 GiB) copied, 4 s, 1.2 GB/s10000000+0 records in10000000+0 records out5120000000 bytes (5.1 GB, 4.8 GiB) copied, 4.3516 s, 1.2 GB/s[~]$ 참조 http://askubuntu.com/questions/511467/how-can-i-completely-erase-all-data-on-a-micro-sd-card Terminal Reset실수로 바이너리 파일을 cat 하거나 하여 글자들이 깨질때.. 터미널 리셋하는 방법 12345$ reset$ tput sgr0$ setterm -reset$ setterm -initialize$ Ctrl + V, Ctrl + O System Info123cat /etc/os-release # Raspbianuname -acat /etc/issue Hardware Info123456lscpulshwlspcilsusblsblk // block deviceslspcmcia 1cat /proc/cpuinfo // BIOS안의 시스템 정보//dmidecode //memory$free -m Architecture1$cat /etc/issue Ubuntu 에서 1$subo lsb_release -a 12$ dpkg --print-architecture // armhf 123$ uname -ai686, i386은 32bit, x86_64는 64bit. armv7은 32bit, armv8은 64bit$ uname -m // machine inf $ uname -i // hw platform$ uname -p // processor $ arch // uname -m 과 동일 32bit 64bit 체크$ getconf LONG_BIT // 시스템 구성 질의 $ file /bin/lsELF 32-bit LSB executable, ARM, EABI5 version 1 .. ARMarm 7 is 32 bit.ARMv8-A, October 2011, 64-bit address space and 64-bit arithmetic 지원$ uname -m // machine infi686 // 32bitx86_64 // 64bitarmv7l // 32bitarmv8 // 64bit 설정// Time zone 1$ sudo dpkg-reconfigure tzdata rsynchttp://www.joinc.co.kr/w/Site/Tip/Rsync rsync -avzh source destination-a : 심볼릭 링크, 속성, 퍼미션, 소유권 등 보존-v : 자세한 정보출력-z : 전송시 압축-r : 하위디렉토리포함-e ssh : ssh를 이용한 rsync 동기화–stats : 결과출력 기본 옵션1rsync -av source/ destination/ include와 exclude이 옵션을 이용해서 대상 파일을 추가하거나 제외 할 수 있다. 1$ rsync -avz --exclude 'data' id@192.168.56.101:/home/backups ./ 별표(*)도 사용할 수 있다. 1$ rsync -avz --exclude '*.cache' id@192.168.56.101:/home/backups ./ 증분 백업수정/변경된 내용만 동기화한다. rsync -avzh moniwiki/ /tmp/backups/-h, –human-readable : output numbers in a human-readable format-u : –update update only (don’t overwrite newer files)–delete : 서버동기화후 원본에서 파일이 삭제되면 백업에서도 파일을 삭제–remove-source-files : 12$ rsync -av /home/ /backup/home/ # 원본 증분 백업$ rsync -av --delete /home/ /backup/home/ #원본 증분 백업, 원본 파일 삭제시 사본에서도 삭제 동기화 옵션delete 옵션목적지에 파일이나 디렉토리가 존재할 경우 삭제하고 싶을 때 --delete 옵션을 사용한다. 1rsync -avz --delete id@192.168.56.101:/home/backups ./ 원본 삭제 옵션--remove-source-files를 이용하면, 전송이 끝난 후 원본파일을 삭제한다. 1$rsync --remove-source-files -zvh backup.tar /tmp/backups/ ssh 통한 백업rsync 에는 ssh 를 이용하여 원격서버에 접속하여 동기화를 하는 기능이 있습니다. 1rsync -azrtv --delete --stats -e &quot;ssh -i /root/.ssh/개인키&quot; 원본서버계정@원본서버주소:원본경로/ /백업경로/ find와 결합1find . -type f -mtime -3 | rsync -avz --files-from=- /soucepc /data/backup faillog/var/log/faillog 는 계정의 로그인 실폐 횟수 정보를 바이너리 파일로 저장한다. 다음 C struct 구조의 정보가 바이너리로 저장되고 있다: 1234567struct faillog { short fail_cnt; short fail_max; char fail_line[12]; time_t fail_time; long fail_locktime;}; 직접 읽을 수 없기 때문에 faillog 명령을 사용한다. 123456$ faillog -u pi # pi 계정$ faillog -aLogin Failures Maximum Latest Onroot 0 0 01/01/70 00:00:00 +0000daemon 0 0 01/01/70 00:00:00 +0000 최근 3일의 로그인 실패를 찾으려면 : 1$ faillog -t 3 -u pi fsckfsck(for file system consistency check) 명령은 파일 시스템을 조사하여 손상된 파일을 출력해 주며 사용자에게 그것을 복구할 것인지를 질의fsck 수행은 시스템마다 약간의 차이가 있지만 대부분 다음과 같은 5개 항목에 대하여 검사Blocks and sizes, Pathname, Connectivity, Reference count, Free List 1$ sudo fsck –t ext2 /dev/hdb Attempt to repair damaged blocks1$ sudo fsck –a Repair damaged blocks interactively1$ sudo fsck -r &lt;drive&gt; forceForcing the checkYou can also force fsck at boot time by passing fsck.mode=force, as a kernel parameter. This will check every filesystem you have on the machine. /forcefsckCreate a file called forcefsck: 1# touch /forcefsck Now, reboot the system: 1# reboot Frce fsck on next boot using shutdown command (may not work on many modern distros) The -F option force fsck on reboot, login as root and type the following command to reboot and run fsck: 1# shutdown -rF now 링크 Changing the check frequencyBy default, fsck checks a filesystem every 30 boots (counted individually for each partition). To change the frequency of checking, run: 1$ sudo tune2fs -c 20 /dev/sda1 exFAT리눅스테어 외부 USB 디스크를 exFAT로 포맷하고 사용한다면, exfat-fuse와 exfat-utils를 설치해 준다. 1$ sudo apt install exfat-fuse exfat-utils 그리고 대부분 최신 리눅스 데스크탑은 USB 디스크를 더블클릭하면 자동마운트 해준다. 터미널에서는 123$ sudo mkdir /media/my_usb$ sudo mount -t exfat /dev/sdb1 /media/my_usb$ sudo umount /dev/sdb1 vnc serverhttps://www.digitalocean.com/community/tutorials/how-to-install-and-configure-vnc-on-ubuntu-14-04 http://www.whatwant.com/840 $ sudo apt-get install gnome-panel tightvncserver 첫 실행을 해서 기본 Config 등의 구성을 하도록 하면 되는데, sudo 없이 계정 권한으로 실행하여도 된다. 계정 권한으로 실행을 하면 해당 계정으로 환경 설정을 한다. 1$ vncserver 실행할 때에 해상도를 미리 정해줘야 한다. $ vncserver -geometry 1024x768 기본 창 관리자 변경 기본 생성된 xstartup 파일에는 내가 원하는 대로 환경 설정이 되어 있지 않다. 가장 먼저 실행된 vnc4server를 종료부터 하고 xstartup 파일을 수정하자. 1234$ vncserver -kill :1$ cp ~/.vnc/xstartup ~/.vnc/xstartup.old$ nano ~/.vnc/xstartup 참조https://wiki.archlinux.org/index.php/fsck","link":"/linux/linux-system-cheat.html"},{"title":"Linux - Cloud Drives","text":"리눅스 ( 아마 Armbian 서버에서 사용하려고 했었던 것 같다?!)에서 Cloud drive를 사용하고자 한다. Odroid C2 그리고 Orange-pi 시스템에서 사용할, 데스크탑 환경의 Armbian Xenial에서 사용하기 위해 클라우드 드라이브를 사용할 목적으로 사용했었다. Google DriveGoogle drive는 grive 패키지로 제공되고 있다. 최근 (아마 2016년 이후) Google의 REST API가 바뀌어 grive2 패키지를 사용해야 한다. 패키지 제공이 되지 않으면 소스 빌드해서 사용했다. grive2 소스 기반 설치Debian/Ubuntu/Linux Mint 에서 다음 라이브러리가 필요하다: yajl 2.x libcurl libstdc++ libgcrypt Boost (Boost filesystem, program_options, regex, unit_test_framework and system are required) expat 다음 같이 cmake 와 필요한 라이브러리를 apt로 설치한다. 12sudo apt-get install git cmake build-essential libgcrypt11-dev libyajl-dev \\ libboost-all-dev libcurl4-openssl-dev libexpat1-dev libcppunit-dev binutils-dev pkg-config 빌드소스 다운로드: 12git clone https://github.com/vitalif/grive2cd grive2 CMake 로는 다음 같이 빌드 환경을 구성한다 123mkdir buildcd buildcmake .. 그리고 Make 로 다음 같이 빌드한다: 1make -j4 그리고 설치한다: 1sudo make install Updates소스는 git pull 로 최신 소스를 얻고 다시 빌드한다: 123456cd /path/to/yourGriveSourceCodeDir/grive2git pullcd buildcmake ..make -j4sudo make install Usage인증 12345678910$ grive -a-----------------------Please go to this URL and get an authentication code:https://accounts.google.com/o/oauth2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%....client_id=22314510474.apps.googleusercontent.com-----------------------Please input the authentication code here:5/dTdVFy9xBd2cKLYvkcvJlYhwfht4IPuyJdri2Vv3sKAReading local directoriesReading remote server file list 참조 Grive2 ## OneDrive, for Linux OneDrive, for Linux를 설치해서 사용한다. 설치https://github.com/skilion/onedrive 와 같이 다운로드해서 설치하거나 apt로 unstable apt로 설치할 수 있다. source 설치git-hub 가이드에 따라, 12345sudo apt-get install libcurl-devsudo apt-get install libsqlite3-devsudo wget http://master.dl.sourceforge.net/project/d-apt/files/d-apt.list -O /etc/apt/sources.list.d/d-apt.listwget -qO - http://dlang.org/d-keyring.gpg | sudo apt-key add -sudo apt-get update &amp;&amp; sudo apt-get install dmd-bin 그런데 Armbian 에서 llibcurl-dev 패키지를 요구해서, 1234567$ sudo apt-get install libcurl-devReading state information... DonePackage libcurl-dev is a virtual package provided by: libcurl4-openssl-dev 7.38.0-4+deb8u5 libcurl4-nss-dev 7.38.0-4+deb8u5 libcurl4-gnutls-dev 7.38.0-4+deb8u5You should explicitly select one to install. 그래서 libcurl-dev을 설치했다 12$ sudo apt-get install libcurl4-openssl-dev$ sudo apt-get install libsqlite3-dev 설정1234$ cat ~/.config/onedrive/configsync_dir = &quot;~/OneDrive&quot;skip_file = &quot;.*|~*|thumbs.db|Games/*.iso&quot;skip_dir = &quot;.*|Music|Movies/FullHD&quot; 사용은 1234567$ onedrive -h Usage: onedrive [OPTION]... no option Sync and exit.-m --monitor Keep monitoring for local and remote changes. --resync Forget the last saved state, perform a full sync. -v --verbose Print more details, useful for debugging. -h --help This help information. 참조 onedrive for Linux","link":"/linux/linux-cloud-drives.html"},{"title":"Linux - update-alternatives","text":"이 글은 우분투, 리눅스 박스에서 여러버전의 도구를 관리할 수 있는 update-alternatives 를 다루고 있다. update-alternativeupdate-alternative 유틸리티로 리눅스 기본 제공 개발 환경의 gcc, cross compiler용 gcc 등 여러 버전의 gcc를 사용할 수 있게 구성할 수 있다.이들 버전의 환경을 교체해서 사용하기를 원한다. update-alternative 도구를 사용할 수 있다. update-alternative 사용여러 버전의 gcc를 update-alternative를 사용해서 선택적으로 사용할 수 있다. gcc 로 등록된 현재 버전 목록을 질의 한다. 1$ update-alternatives --query gcc 등록여기서 사용하는 여러 gcc 버전들을 설치한 후에 다음과 같은 명령어로 등록을 할 수 있다. 1update-alternatives --install &lt;link&gt; &lt;name&gt; &lt;path&gt; &lt;priority&gt; 실행파일 이름으로 /etc/alternatives/ 을 가리킨다. (예: /usr/bin/pager) 해당 링크 그룹의 대표 이름으로, 여러 가지 버전의 패키지들을 대표하는 이름으로 보면 될 것 같다.(예: pager) alternatives 로 실제 연결할 실행파일 이름으로, 시스템에 설치한 패키지의 실행파일 이름이다.(예: /usr/bin/less) automatic 모드에서 어떤 것을 자동으로 선택해서 사용할지 결정할 때 사용되는 우선순위로, 높은 수가 더 높은 우선순위이다. gcc 등록Ubuntu 14.04 최신 버전에 gcc4.7, 4.8 를 사용하려고 설치했다고 가정한다. 123sudo apt-get updatesudo apt-get install gcc-4.7 g++-4.7sudo apt-get install gcc-4.8 g++-4.8 그리고 gcc 그룹에 4.8를 우선도가 높게 50으로 준다. 1sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 50 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8 여기서 gcc를 master로 g++을 slave로 준비했다. --slave 옵션은 --install 로 지정한 master에 종속해서 여러개의 슬레이브를 마스터에 추가할 수 있고, 마스터의 링크가 바뀌면 슬레이브도 함께 바뀐다. 두번째 버전은 gcc-4.7 버전을 우선도가 40 정도로 하자. 1sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.7 50 --slave /usr/bin/g++ g++ /usr/bin/g++-4.7","link":"/linux/linux-update-alternatives.html"},{"title":"Linux - sshd","text":"SSH UsagesSsh timeoutssh를 사용시 접속 시간이 지나면 자동 끎김을 막아주는 옵션들이 있다. 운영하는 서버는 보안상 alive 메시지를 모두 막아 두었다.다만, ssh 접속시 ServerAliveInterval 을 사용해서 클라이언트가 alive 메시지를 서버에 있다. sshdsshd 데몬은 클라이언트 접속후 sshd_config에 구성한 설정데로 alive 메시지를 클라이언트에 주고 받아 접속 시간을 연장할 수 있다. 아래 그림 [^1] 1234567891011# alive 메시지 사용 결정#TCPKeepAlive yes # 기본 yes.# 클라이언트가 살아있는지 확인하는 간격.ClientAliveInterval 60 # 기본 0.# 클라이언트에서 응답이 없을 때 메시지를 보내는 횟수ClientAliveCountMax 3 # 확인 횟수# Login Prompt에서 사용자 입력을 기다리는 시간을 초 단위로 입력.LoginGraceTime 20 #( 1m: 기본 1분지정, 0은 시간제한없음) ssh 옵션ssh 사용시 /etc/ssh/ssh_config 구성 파일에 있는 ServerAliveInterval 옵션을 사용하면 ssh 접속시 alive 메시지를 서버가 클라이인트에게 주어진 시간 간격으로 보낸다. [그림. ServerAliveInterval] ssh_config 파일에 구성하거나 ssh 사용시 -o ServerAliveInterval 옵션을 사용하는 방법 두 가지가 있다. ssh -oServerAliveInterval option every time you’re connecting to a server by using the -o ServerAliveInterval= prefix as the following example; 1ssh -o ServerAliveInterval=300 user@example.com key파일 사용키파일 이용 키파일을 원하는 위치에 복사하고 퍼미션을 400으로 조정합니다. (저는 ~/Desktop/key/로 정했습니다.) 1$ chmod 400 ~/Desktop/key/keyfile.pem 터미널에서 키파일 옵션을 추가한 명령으로 ssh 접속 1$ ssh -i ~/Desktop/key/keyfile.pem ec2-user@[서버 아이피 또는 도메인] 포트가 다르다면 1$ ssh -i ~/Docments/cloud-server.pem root@220.11.11.173 -p 8888 서버 키 생성 서버에도 클라이언트와 동일하게 ssh-keygen 명령으로 비밀키와 공개키를 생성한다. 1(SERVER)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@server&quot; scp -i /Documents/ncloud-key/qkbooo-ncloud.pem ~/.ssh/id_rsa.pub root@210.89.190.173:/ -p 2525 12ssh userid@SERVER(SERVER) $ cat client.pub &gt;&gt; .ssh/authorized_keys; rm client.pub 포트변경 사용rsync 포트 사용rsync에서 다른 ssh 포트를 사용하고 있을 경우 아래와 같이 옵션을 붙여준다. 1$ rsync -e 'ssh -p 0000' 혹은 1rsnyc --rsh'=ssh -p0000' 참조 sshd_config ssh_config [^1]: How to keep your ssh connection","link":"/linux/ssh-usages.html"},{"title":"Linux - find usages","text":"find 명령에서 자주 사용하는 쓰임새를 요약했다. 2018-05: rm, i-node 내용 추가{:.right-history} find 명령find 명령 요약주어진 이름으로 찾아 화면에 출력한다. -name 은 대소문자 구분한 이름을 준다. 1find ./ -name '*.xml' -print 주어지는 이름의 패턴은 *? 를 사용할 수 있다. 찾은 결과를 받아 명령의 입력으로 실행할 수 있다. 다음은 현재 디렉토리 밑에서 .c 파일을 찾아 md5sum 으로 해시 값을 출력한다. -iname은 대소문자 구분을 하지 않는다. 12find -iname &quot;*.c&quot; -exec md5sum {} \\;d41d8cd98f00b204e9800998ecf8427e ./mycprogram.c 검색시 탐색 깊이는 -maxdepth 혹은 -mindepth를 사용할 수 있다. 1find -maxdepth 2 -iname &quot;*.c&quot; -exec md5sum {} \\; 어떤 파일을 제외한 것만 찾을 수 있다: 1find -maxdepth 1 -not -iname &quot;mycprogram.c&quot; 파일의 퍼미션으로 찾을 수 있다. 123find . -perm -g=r -type f -exec ls -l {} \\;find . -perm g=r -type f -exec ls -l {} \\;find . -perm 040 -type f -exec ls -l {} \\; 찾은 후 삭제하기: 1find ./ -name 'Debug' -exec rm -rf {} \\; find 명령으로 i-node를 통해서 지우기: 아래 처럼 특수문자로 “~” or “a b c” 등의 이상한 파일이 있을 경우 inode를 확인해 삭제에 유용하다. 1234$ ls -i$ 32471 a b c $ find . -inum 32471 -exec rm -rf {} ';'$ find . -inum 32471 -exec rm -rf {} \\; 회피문자 파일 이름 삭제하기???? 같이 지워지지 안는 파일 같은 경우도 i-node로 삭제할 수 있다. 1234567891011~$ ls -ali~$ ls -alitotal 206842467329 drwxr-xr-x 11 qkboo qkboo 4096 Jun 20 22:54 . 2 drwxr-xr-x 10 qkboo qkboo 4096 Jun 1 12:56 ..42467482 drwxr-xr-x 2 qkboo qkboo 12288 Jul 2 2016 .Picasa3Temp42598444 drwxrwxrwx 3 qkboo qkboo 4096 Mar 29 23:45 ??????42475521 drwxr-xr-x 4 qkboo qkboo 4096 Jun 20 22:52 Design_Assets42467936 drwxr-xr-x 14 qkboo qkboo 4096 Mar 4 16:39 Incoming~$ find . -inum 42598444 -exec rm {} \\; 파일 형식으로 검색옵션 -type 은 파일 형식으로 찾을 수 있다. 파일 형식은: b block special c character special d directory f regular file l symbolic link p FIFO s socket 일반 파일 1find . -type f 소켓 형식의 파일 1find . -type s 디렉토리 형식 1find . -type d 숨겨진 파일만 검색도 가능하다. 1find . -type f -name &quot;.*&quot; 역시 숨겨진 디렉토리만 찾을 수 도 있다. 1find -type d -name &quot;.*&quot; 파일 크기로 검색옵션 -size 를 사용해서 파일의 크기로 찾을 수 있다. 아래는 어떤 크기 보다 크거나, 작은 파일을 찾아 준다. 123find -size +100M # 보다 큰 파일find -size -100M # 보다 작은 파일find -size 100M # 같은 크기의 파일 다음 같이 응용해 볼 수 있다. 100MB 보다 큰 파일을 찾아 삭제한다: 1find / -type f -name *.zip -size +100M -exec rm -i {} \\; 파일의 수정된 시간을 기준모든 파일의 수정된 시간 정보를 알 수 있다. test_1.txt의 시간을 기준으로 검색해 보자. 12ls -lrt test_1.txt-rw-r--r-- 1 gtko gtko 0 2011-02-01 02:26 test_1.txt 옵션 -newer 에 대상 파일을 주면 해당 파일을 생성한 날짜 이후의 결과만을 표시하게 된다. 12345find -newer test_1.txt../dir2./dir2/file2./dir2/file3 자주 사용할 만한 find 명령유용한 find 명령들 alias로 만들어 사용하기도 한다. a.out 인 파일 지우기 1alias rmao=&quot;find . -iname a.out -exec rm {} \\;&quot; c프로그램의 core 파일 1alias rmc=&quot;find . -iname core -exec rm {} \\;&quot; 큰 파일 삭제… 1234alias rm100m=&quot;find / -type f -name *.tar -size +100M -exec rm -i {} \\;&quot;alias rm1g=&quot;find / -type f -name *.tar -size +1G -exec rm -i {} \\;&quot;alias rm2g=&quot;find / -type f -name *.tar -size +2G -exec rm -i {} \\;&quot;alias rm5g=&quot;find / -type f -name *.tar -size +5G -exec rm -i {} \\;&quot; iconv 와 결합iconv로 파일 인코딩을 변환할 수 있는데, 많은 파일을 한번에 처리하기 위해서 find와 결합해 찾은 모든 파일의 파일 인코딩을 변환할 수 있다. 다음은 .c 파일을 찾아 인코딩을 euc-kr에서 utf-8로 변환하는 명령이다. 1find ./ -name '*.c' -exec iconv -feuc-kr -tutf-8 {} -o {} \\; find 를 사용하지 않는다면, 디렉토리 안에 있는 모든 파일의 인코딩을 변환하고자 할 때는 shell 조건문과 섞어서 사용할 수 있다. 1$ for F in './*.sql'; do iconv -c -feuc-kr -tutf-8 $F -o $F; done 참조Linux find command examples","link":"/linux/linux-find.html"},{"title":"Linux - ssh-sshfs","text":"ssh 사용 팁과 sshfs 이용 방법에 대해서 정리한다. ssh터미널에서 ssh를 사용하는데 이용하는 구성과 설정을 정리했다. 비밀키 이용ssh를 사용하는 클라이언트에서 ssh-keygen 으로 비밀키와 공개키를 생성하고, 접속하는 서버 계정 밑에 클라이언트 공개키를 저장하면 ssh 접속시 비밀번호 응답 없이 처리되어 로그인 할 수 있다. 1. ssh 클라이언트클라이언트에서 개인 비밀키를 생성한다. ssh-keygen 명령은 기본적으로 비밀키와 공개키 파일을 사용자 홈디렉토리 ~/.ssh 폴더에, 기본 파일이름 id_rsa.pub, id_rsa.prb 파일로 저장한다. 1(CLIENT)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@localhost&quot; 2. ssh 서버서버에도 클라이언트와 동일하게 ssh-keygen 명령으로 비밀키와 공개키를 생성한다. 1(SERVER)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@server&quot; 서버에 공개키 배포클라이언트에 생성한 공개키 id_rsa.pub 파일을 업로드해서 ./ssh/authorized_keys 파일에 추가해야 한다. 보통 scp 명령으로 복사해서 authorized_keys 파일에 더해주면 된다. 일반적으로 scp 명령으로 복사하고, 서버에 ssh 접속해서 업로드한 공개키 파일을 authorized_keys 파일에 더해준다. 1. 클라이언트에서 복사하기: 1scp ~/.ssh/id_rsa.pub USER_ID@HOST_NAME:~/client.pub ssh로 서버에 로그인한다. 2.서버 authorized_keys 붙여넣기: 12ssh userid@SERVER(SERVER) $ cat client.pub &gt;&gt; .ssh/authorized_keys; rm client.pub 위 2 과정을 아래 명령 한 줄로 복사-&gt;붙여넣기를 동시에 할 수 있다. 클라이언트: 1cat ~/.ssh/id_rsa.pub | ssh &lt;USERNAME&gt;@&lt;IP-ADDRESS&gt; 'cat &gt;&gt; .ssh/authorized_keys' 이제 해당 서버로 로그인해 본다. ssh config 사용하기사용자를 위한 ssh 구성을 하려면 ~.ssh/config 설정 파일을 이용한다. keep alive sessionssh 접속시 옵션을 주어 세션 유지 시간을 지정할 수 있다. ServerAliveInterval 사용접속시 ServerAliveInterval=TICK를 사용하면 TICK초 마다 한번씩 ServerAliveInterval를 보낸다. 옵션을 직접 사용하거나 ~/.ssh/config 설정 파일에 지정해 둘 수 있다. ssh 접속시 -o 옵션으로 지정한다. 1ssh -o ServerAliveInterval=10 192.168.0.1 ~/.ssh/config 이용사용자의 ssh 설정 파일은 ~/.ssh/config 이다. 12345# For all hostsServerAliveInterval 20# For a selection of hostsHost 192.168.0.1 192.168.1.1 ServerAliveInterval 20 시스템 전체에 적용한다면 /etc/ssh_config 에 (혹은 데비안 계열은 /etc/ssh/ssh_config) 지정해도 된다. ## sshfs 원격 호스트에서 작업중인 소스등을 편집하는데 터미널로 접속해 vim, nano 같은 편집 도구를 이용할 수 있지만, 개발 컴퓨터에서 손에 익은 GUI 개발 도구를에서 개발하고 편집해서, 원격 호스트에서 실행하는 방법을 선호해서 sshfs를 이용하고 있다. 보통 Sublime Text, TextMate 등의 에디터에서 파이썬 등의 프로그래밍 코드를을 작성하고 sshfs를 이용해 원격 디렉토리에 저장하는 방법을 사한다. 설치Ubuntu/Debian1$sudo apt install sshfs Mac OS XMac OS X Fuse 설치 http://osxfuse.github.io sshfs 설치후 재시동 필요. Window다음 설치 파일을 받아 설치한다.https://win-sshfs.googlecode.com/files/win-sshfs-0.0.1.5-setup.exe Mac OS X 사용Mac OS X에서는 OSXFuse를 사용해서 사용자 계정에서 sshfs를 이용한다. 그래서 sudo 명령을 사용하지 않는다. 1$ sshfs USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote sudo 명령을 이용해서 마운트할 경우 마운트 포인트를 찾지 못해서 다음 같은 에러가 난다. 12$ lsls: odoomodules: No such file or directory Ubunto/Debian1sudo sshfs USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote 사용후 언마운트는 다음과 같다. 1$sudo umount /Volume/remote 마운트 고정: Mac OS Xhttps://amaral.northwestern.edu/resources/guides/mounting-remote-folder-os-x-over-ssh 파일 /etc/fstab 1sshfs#USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote DS_Store 파일OS X는 파일을 다룰 때 .DS_Store 파일로 폴더를 지저분하게 한다. 이것을 비활성화 할 수 있다.마운트할 때 noappledouble 옵션을 사용한다. 12$ mkdir ~/example$ sshfs user@host:/example ~/example -oauto_cache,reconnect,defer_permissions,negative_vncache,noappledouble,volname=Example Mounting an OSX SSH Volume using FUSE and SSHFS ssh authentication1sudo sshfs -o IdentityFile=~/.ssh/id_rsa USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote 자주사용하는 sshfs 명령12$ mkdir ~/example$ sshfs user@host:/example ~/example -oauto_cache,reconnect,defer_permissions,negative_vncache,noappledouble,volname=Example sshfs optionssshfs 구현마다 조금 다르지만 https://linux.die.net/man/1/sshfs 에서 옵션 내용을 조금 살펴보자: -o reconnect : reconnect to server -o delay_connect : delay connection to server o sshfs_sync: synchronous writes -o no_readahead: synchronous reads (no speculative readahead) -o sshfs_debug: print some debugging information -o cache=BOOL: enable caching {yes,no} (default: yes) -o cache_timeout=N: sets timeout for caches in seconds (default: 20) -o cache_X_timeout=N: sets timeout for {stat,dir,link} cache -o workaround=LIST: colon separated list of workarounds none: no workarounds enabled all: all workarounds enabled cache느린 네트워크에서는 캐시를 끄고 사용하는게 좋겠다. -o cache=YESNO: enable caching {yes,no} (default: yes) -o cache_timeout=N : sets timeout for caches in seconds (default: 20) -o cache_X_timeout=N : sets timeout for {stat,dir,link} cache 보증된 네트워크에서 암호화 없이 mount sshd 가 암호화를 지원하는 상황에서 안된다. 안전한 네트워크에서는 Ciphers, Compression 옵션을 사용 ^Blazingly fast sshfs 하면 빠른 속도를 얻을 수 있다. 1sshfs -o Ciphers=arcfour -o Compression=no server://some/folder /mnt/some_local_folder Ciphers=arcfour : 빠른 암호화 메서드, 다만 안전하지 않다. Compression : ssh 내장 압축 사용하지 않는다. rsync 에도 사용할 수 있다. 1rsync -e&quot;ssh -c arcfour -o Compression=no&quot; ...rest of rsync cmd... TCP OptimizationMTU(Maximum Transmission Unit)네트워크 인터페이스에서 세그먼트 없이 보낼수 있는 최대 데이터그램 크기 값입니다. 만약 데이터가 MTU 값 이상이라면 여러개의 패킷으로 분할이 될 것입니다. 간단하게 보자면 MTU 는 패킷이 한번에 보낼 수 있는 최대 크기라고 볼 수 있습니다. 이더넷의 MTU 값은 일반적으로 1500 바이트이며 옛날에 모뎀을 통해 접속하던 PPPoE 연결은 1492 바이트를 가지고 있습니다. MTU 는 각 패킷 프레임안에 최대 전송할 수 있는 값 MSS(Maximum segment size) 가 정의되어 있습니다. 그렇다면 MTU는 MSS + TCP/IP 헤더 크기가 될 것이고 반대로 MSS 는 MTU - 40 바이트가 됩니다. 40 바이트는 IP 와 TCP 헤더 20 바이트씩을 뜻합니다. Linux리눅스에서 MTU 값은 ifconfig 명령으로 확인할 수 있다. 123456789$ ifconfig eth0eth0 Link encap:Ethernet HWaddr b8:27:eb:c8:5f:4b inet addr:220.121.140.239 Bcast:220.121.140.255 Mask:255.255.255.0 inet6 addr: fe80::ba27:ebff:fec8:5f4b/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1633606 errors:0 dropped:44758 overruns:0 frame:0 TX packets:73808 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:85875027 (81.8 MiB) TX bytes:22615535 (21.5 MiB) 기본 MTU가 1500인데 이 값을 조정하려면 sudo ifconfig 명령으로 할 수 있다. 1$ sudo ifconfig eth0 mtu 9000 재시동 후에도 지속적으로 MTU 값을 유지하고 싶으면 /etc/network/interfaces 에 명시하면 된다. 12345auto eth0iface eth0 inet static address 192.168.0.2 netmask 255.255.255.0 mtu 9000 링크MTU SSHFS-MUXhttp://www.linux-magazine.com/Issues/2014/165/SSHFS-MUX Error에러 mount_osxfuse: the file system is not available (255) There appears to be a problem loading the KEXT installed by the regular osxfuse Homebrew package. You can use brew cask to install the official FUSE for OS X build from their own DMG: 123brew rm osxfusebrew install caskroom/cask/brew-caskbrew cask install osxfuse 참조 SSHFS – Installation and Performance SSHFS-MUX Protocol Not Supported Error Mac OS X sshfs Mounting an OSX SSH Volume using FUSE and SSHFS","link":"/linux/ssh-sshfs.html"}],"posts":[{"title":"blog.thinkbee.kr 이전 작업중입니다.","text":"지킬 기반 gitpages 으로 운영하던 블로그를 Hexo 를 사용해서 운영하려고 이전하고 있습니다. 다행이 이전 게시물은 그대로 이전이 되서 손실은 없을 것 같네요 곧 쉽게 사용하게 되면 밀린 블로그 포스팅을 계속하겠습니다. 총총 2022/2/24 2022/2/26: 사이드바 조정.","link":"/2022/02/24/hello-world/"},{"title":"AI &#x2F; Start Google TensorFlow","text":"Getting Started with TensorFlow 글을 요약 번역한다. tensorflow를 사용하기 위해서는 Python 프로그래밍 배열에 대한 이해 머신러닝에 대한 이해. TensorFlow는 여러 API를 제공하고 있다. TensorFlow Core: 가장 저수준 API 고수준 API는 TensorFlow Core 위에 구성되 있다. 고수준 API 에서 contrib- 를 포함한 메서드 이름은 개발중으로 향후 변경 가능성이 크다. TensorsTensorFlow 에서 주요 데이터 단위가 tensor 이다. tensor는 어떤 차원의 배열로 구성된 기초적인 값의 집합이다. tensor의 rank는 차원의 수이다. 여러 rank를 가진 tensors의 예: 12343 # 하나의 rank 0 tensor; 모양 [] 인 스칼라 값이다.[1. ,2., 3.] # rank 1 tensor; 모양 [3] 인 벡터이다.[[1., 2., 3.], [4., 5., 6.]] # rank 2 tensor; 모양 [2,3]인 행렬이다.[[[1., 2., 3.]], [[7., 8., 9.]]] # 모양 [2, 1, 3] 인 rank 3 tensor ### TensorFlow Core tutorial 먼저 import로 tensorflow 패키지를 가져온다. 1import tensorflow as tf 연산 그래프 Computational GraphTensorFlow Core 프로그램은 두 개의 불연속 구획으로 구성되었다고 생각할 수 있다. 연산 그래프 구성하기 그래프를 조립하는 단계 연산 그래프 실행하기 Session에서 graph 실행 예를 들어 뉴럴 네트워크를 표현하고 학습시키기 위해 구성 단계에는 graph를 만들고 실행 단계에는 graph의 훈련용 작업들(set of training ops)을 반복해서 실행합니다.[^1] 연산 그래프는 그래프 노드에 배열된 TensorFlow 작업의 급수이다. 간단한 연산 그래프를 구성해 보면, 각 노드는 0 혹은 다수의 tensor를 입력으로 가지고 tensor 하나를 출력으로 생성하게 하자. 노드 형식 중 하나는 상수인데, 모든 TensorFlow 상수 값은 입력으로 받지 않고, 초기화한 값을 사용한다. 아래 처럼 부동소수 tensor의 node1, node2 두 개를 생성해 보자 1234node1 = tf.constant(3.0, dtype = tf.float32)node2 = tf.constant(4.0) # 명시적으로 tf.float32 를 인자로 사용해도 된다.node3 = tf.add(node1, node2)print(node1, node2) 아래 같이 출력된다. 1Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32) 실제 값이 연산되려면 Session 을 생성하고 실행해야 한다. 다음 같이 세션을 만들고 node를 실행한다. 12sess = tf.Session()print(sess.run([node1, node2])) #[3.0, 4.0] Tensor 노드를 묶어 복합적인 계산을 구성할 수 있다. 노드를 더해서 새로운 노드로 만들 수 있다. 123node3 = tf.add( node1, node2)print(&quot;node3:&quot;, node3)print(&quot;sess.run(node3):&quot;, sess.run(node3)) 노드를 더하는 결과는 아래 같다. 12node3: Tensor(&quot;Add:0&quot;, shape=(), dtype=float32)sess.run(node3): 7.0 TensorFlow 는 TensorBoard 를 지원해 계산 그래프를 그림으로 표시할 수 있다. 아래는 TensorBoard로 출력한 스크립샷이다. 상수가 아닌 매개변수 형식으로 외부 입력을 받을 수 있는 placeholders{:.keyword} 를 사용하면 값을 나중에 입력받을 수 있다. 1234567a = tf.placeholder(tf.float32)b = tf.placeholder(tf.float32)adder_node = a + b # + provides a shortcut for tf.add(a, b)# 노드를 실행한다.print(sess.run(adder_node, {a: 3, b:4.5}))print(sess.run(adder_node, {a: [1,3], b: [2, 4]})) 결과는 127.5[ 3. 7.] TensorBoard 로 그려본 그래프는 다음 같다. 연산 그래프에 다른 연산을 더해 줄 수 있다. 12add_and_triple = adder_node * 3.print(sess.run(add_and_triple, {a: 3, b:4.5})) # 22.5 앞의 연산에 대한 TensorBoard에서 그래프는, 머신러닝에서 모델에 위와 같은 유효한 입력을 가지게 한다. 그리고 모델을 훈련시키기 위해서 새로운 출력을 갖도록 수정할 수 있다. Variables 는 그래프에 훈련시킬 매개변수를 더하게 해준다. 아래 같은 초기화 값이 있고, 1234W = tf.Variable([.3], dtype=tf.float32)b = tf.Variable([-.3], dtype=tf.float32)x = tf.placeholder(tf.float32)linear_model = W * x + b 상수는 tf.constant{:.keyword} 를 호출할 때 초기화 되지만 이후 값을 변경 할 수 없다. 반면 Variable은 tf.Variable{:.keyword}가 호출될 때 초기화 되지 않는다. 초기화 하려면 아래같은 암묵적인 연산을 해주어야 한다. 12init = tf.global_variables_initializer()sess.run(init) 그런데 init 의 실체는 모든 전역 변수를 초기화하는 TensorFlow sub-graph 핸들 이라는 것이다. 또한 sess.run 이 실행 될 때까지 초기화 되지 않는다.이제 x 가 placeholder{:.keyword} 이기 때문에 다음 같이 lenear_model 의 수치를 구하게 한다. 123print(sess.run(linear_model, {x:[1,2,3,4]}))# [ 0. 0.30000001 0.60000002 0.90000004] 이제 훈련 데이터로 linear_model을 평가하기 위해서 y placeholder를 준비하자. 그리고 loss 함수를 작성한다.loss 함수는 제공한 데이터와 현재 모델 사이가 얼마나 떨어져 있는지를 측정한다. 이것은 선형회귀(Linear Regression)에 대한 표준 loss model로 현제 모델과 제공한 데이터 사이의 델타의 제곱근의 합이다. linear_model - y 는 예제의 에러 델타에 대응하는 요소로 이루어진 벡터를 생성한다. tf.sqaure{:.keyword} 를 호출해서 에러에 대한 제곱근을 구한다. 12345y = tf.placeholder(tf.float32)squared_deltas = tf.square(linear_model - y)loss = tf.reduce_sum(squared_deltas)print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))# 23.66 여기서 W, b 에 최적화된 값 -1, 1을 재지정 할 수 있는데, tf.assign{:.keyword} 같은 연산으로 바꿔 줄 수 있다. 12345fixW = tf.assign(W, [-1.])fixb = tf.assign(b, [1.])sess.run([fixW, fixb])print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))# 0.0 결과 0.0 으로 W, b의 완벽한 값으 추축해 볼 수 있다. 머신러닝의 중요한 점은 자동으로 정확한 매개변수를 찾는 것이다. 다음 섹션에서 이것을 살펴볼 것이다. tf.train APITensorFlow 는 optimizers를 제공해서 loss 함수의 매개변수 순서에 따라 값을 변경할 수 있다. 간단한 최적화는 gradient optimizer 이다. 함수의 전달하는 자릿수에 따라 각 값을 바꿀 수 있다. 코드여기까지 코드는 아래와 같다: 참조 텐서플로우 문서 한글 번역본 Getting Started TensorFlow [^1]: 텐서플로우 한글 번역본-기본적인 사용법","link":"/2017/07/12/AI-2017-07-12-ai-platform-tensorflow-start/"},{"title":"AI &#x2F; Google TensorFlow Install","text":"2015년 인공지능 개발용 오픈소스 TensorFlow 를 공개했다. TensorFlowTensorFlow는 머신러닝을 위한 Research cloud로 1000 Cloud TPU로 가동하고 있다. 1000 TPU는 180Petaflops를 제공하고 있다. {: width=”650”} Ubuntu Linux, macOS X, Windows 머신에 설치할 수 있다. Ubuntu 14.04 이상에서 설치 가능하다. Install on Ubuntu Install먼저 TensorFlow 종류를 결정한다. TensorFlow CPU only support : 시스템에 NVIDI&amp;reg; GPU가 없으면 CPU 버전을 설치한다. 5~10분 정도 소요되고 쉽다. GPU가 있더라도 이 버전을 먼저 시도해 볼 것을 권한다. TensorFlow GPU only support : CPU보다 현저하게 빠르다. NVIDIA&amp;reg; GPU가 있고, 요구사항에 부합하며 성능 문제를 고려하면 이 버전을 설치한다. NVIDIA GPU에서 TensorFlow 실행시 요구조건GPU 지원 TensorFlow를 설치하려면 아래 NVIDIA 소프트웨어가 설치되야 한다: CUDA® Toolkit 8.0 : NVIDIA’s documentation. LD_LIBRARY_PATH 환경변수에 Cuda 경로 추가해준다. CUDA Toolkit 8.0 관련 The NVIDIA drivers 설치. cuDNN v5.1: NVIDIA’s documentation 참고, 설치후 CUDA_HOME 환경변수 설정. GPU card with CUDA Compute Capability 3.0 or higher. 지원하는 종류는 VIDIA documentation를 참조. libcupti-dev library: 아래 명령으로 NVIDIA CUDA Profile Tools Interface를 설치한다. 1$ sudo apt-get install libcupti-dev 시스템에 설치된 소프트웨어가 위에 명시하 패키지 보다 이전 버전이면 업그레이드가 필요하다. 아닌 경우 TensorFlow가 실행되지만 아래 작업을 해주어야 한다: TensorFlow 를 소스에서 설치한다 Installing TensorFlow from Sources. 최소 아래 NVIDIA versions으로 설치한다: CUDA toolkit 7.0 or greater cuDNN v3 or greater GPU card with CUDA Compute Capability 3.0 or higher. ### TensorFlow 설치 방법 TensorFlow는 virtualenv, “native” pip, Docker, Anaconda 에서 설치할 수 있다.virtualenv 환경을 권장한다. virtualenv 환경에서 설치여기서는 macOS에서 Python 가상 개발환경 설치 Linux에서 Python 가상 개발환경 설치 를 참조해서 virtualenv, virtualenvwrapper 를 구성해서 사용한다고 가정한다. 12$ mkvirtualenv --system-site-packages -p python3 tensorflow(tensorflow)$ 그리고 tensorflow 패키지를 설치한다 - GPU 버전을 선택적으로 설치한다. 12(tensorflow)$ pip install --upgrade tensorflow # CPU(tensorflow)$ pip install --upgrade tensorflow-gpu # GPU 위 명령으로 설치가 실패시 pip 버전이 8.1 이하일 수 있다. 업그레이드 후 재 시도한다. 혹은 다음 명령으로 TensorFlow Python package를 직접 설치한다. 1(tensorflow)$ pip install --upgrade tfBinaryURL tfBinaryURL 은 여기서 찾아서 직접 지정한다. Uninstall Tensorflow가상환경 디렉토리를 삭제하거나 12(tensorflow)$ deactivate$ rm -rf .virtualenv/tensorflow 혹은 가상환경에서 tensorflow 를 pip로 지운다. 12(tensorflow)$ pip uninstall tensorflow # CPU(tensorflow)$ pip uninstall tensorflow-gpu # GPU ### Run a short TensorFlow program python 을 실행해 REPL 환경 혹은 스크립트로 아래 코드를 입력한다: 1234import tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello)) 결과로 b'Hello, TensorFlow!' 같이 출력되면 성공적으로 실행된 것이다. 이어서 Getting Started with TensorFlow 를 따라간다. 참조[^1]: Intruducing TensorFlow Research Cloud","link":"/2017/07/12/AI-2017-07-12-ai-platform-tensorflow/"},{"title":"AI - Platform","text":"AI인공지능은 사람이 정보를 분석하고 특성을 모델링하는 머신러닝이 지지부진 하다 2012년 부터 딥러닝 기반은 기계가 스스로 수 많은 정보에서 지식을 구성해 가는 시스템이 실제 구현되며 전환기를 맞고 있다. 과거 IBM의 Deep Blue는 체스를 목적으로 한 체스 전용 소프트웨어와 하드웨어를 인공지능으로 구현되었다. 최근 딥러닝을 기반으로하는 알파고 같은 기술은 하드웨어와 소프트웨어가 범용적 특성을 가지고 있다.[^3] AI platformAI 플랫폼은[^1] 플랫폼이 갖는 주요기능에 따라 음성지능, 언어지능, 시각지능, 공간지능, 감성 지능 플랫폼으로 구분한다. 적용 대상에 따라서 일반 소비자를 대상으로 다양한 서비스 제공이 가능한 범용 AI 플랫폼과 의료, 금융, 법률 등 특정 산업영역에 특화된 전문 AI 플랫폼으로 구분 할 수 있다. 인공지능 플랫폼의 활용주요 IT기업이 “artificial intelligence as a service.” [^2] 으로 3rd party 기업/개발사 들이 앱/서비스를 만들어 가는 형태로 발전하고 있다. 개인/개발사들이 인공지능을 구현하는데 비해서 전문 플랫폼 사이의 성능 격차가 크다. 첫째로 기계학습에 제공하는 양질의 데이터는 큰 격차가 존재한다. 둘째로 비용, 시간 측면에서 기술과 경험이 부족해서 고도화된 서비스를 이용하는 면이 시간적 경제적으로 잇점이다. 범용 인공지능 플랫폼으로,Google Machine Learning Platform2016년 3월 음성인식, 이미지 분석, 번역 기능을 수행하는 인공지능 플랫폼 공개. 구글 머신러닝 플랫폼을 이용해 영상 처리를 한 결과를 이용한 서비스를 만들어 사용할 수 있다.[^3] 2015년 인공지능 개발용 오픈소스 TensorFlow 를 공개했다. Facebook 으로 정교화된 맞춤형 인공지능 플랫폼페이스북은 2013년 딥러닝 분야의 핵심 연구자인 얀 레쿤(Yann LeCun) 교수를 영입하고 뉴욕, 파리 등에 인공지능 전용 연구소를 설립해 인 공지능 핵심 기술 개발에 집중해 오고 있다. 2월에 게시물에 감정 표현 종류를 “좋아요”,”기쁨”,”슬픔” 등 6가지로 확대 세분화, 인공지능 플랫폼 ‘챗봇’은 개인 사용자 선호도를 분석해 서비스를 제공할 가능성, Amazon 실생활 플랫폼2015년 Alexa라는 대화형 인공지능 에이전트로 정보검색, 쇼핑몰 상품 주문, 결제 등의 다양한 기능 수행. 최근 가전, 전등, 스위치 등 스마트 디바이스와 연동되고 있다. 산업별 특화 인공지능 플랫폼 Vertical A.I PlatformIBM 의료 전문 인공지능 플랫폼, IBM 의료 전문 인공지능 플랫폼방대한 정보를 조합해 지식을 만들어 내는 Watson의 핵심 기술을 활용해 IBM은 의료, 금융 분야에 특화된 인공지능으로 발전시켜 가고 있다. 의료 전문 인공지능 플랫폼인 ‘Waston Health’를 운영중인 IBM은 다수의 헬스케어 서비스 기업들을 참여시키며 생태계를 만들어 가고 있다. 또한 약 4조원이 넘는 규모의 집중적인 M&amp;A를 통해 의료 분야의 역량을 빠르게 확보하고 있다. 의학 분야의 경우 IBM은 2012년 캐더링 암 센터와의 제휴를 통해 약 200만 페 이지 의료 전문 서적, 60만건 진단서, 150만건 환자 기록을 확보했다. 지난 2월 약 3조원을 들여 인수한 Truven Health Analytics 는 미 연방 정부 및 주정부 등 약 8500개 고객사에 헬스케어 서비스 제공하는 기업 으로서 막대한 양의 의료 정보를 보유한 기업이다. IBM은 데이터 확보를 위해 엄청 난 금액으로 기업들을 인수하면서 인공지능의 전문성을 높여 가고 있다. Medtronic이라는 헬스케어 디 바이스 제조 기업은 Watson을 활용해 사용자들의 디바이스에서 수집된 생체 정보를 의학적으로 분 석한다. 예를 들어 인슐린 수치를 모니터링 하는 경우 사용자의 수치를 주기적으로 측정해 Watson 에 전달하고 Watson은 이를 분석해 이상 징후가 예견되면 사용자에게 미리 경고를 하거나 당 섭취 절제 등을 권고해 위험을 사전에 방지한다. Arch Health Partners는 전문 의 료 기관임에도 불구하고 고혈압 환자 관리에 Watson을 활용한다. 전문의가 있지만 모든 환자를 상시적으로 관리할 수 없기 때문에 Watson이 그 기능을 대신한다. GE의 산업 인공지능 플랫폼항공, 에너지, 헬스케어, 제조 등 다양한 산업 분야에서 오랜 사업 경험을 갖고 있는 GE는 산업 현장에 인공지능을 적용하고 있다.2015년 Jeff Immelt(CEO)는 “GE는 지금까지는 제조 기반의 회사였지만 앞으로 글로벌 Top 10 소프트웨어 회사로 탈바 꿈 하겠다”고 선언했다. 약 1200명의 소프트웨어 개발자를 확보하고 실리콘 밸리에 소프트웨어 연구소(GE Digital)를 설립한 GE는 산업용 클라우드 플랫폼인 Predix Platform을 발표하며 산업 현장에 인공지능 플랫폼 적용을 확산시키며 4차 산업 혁 명 시대를 주도하려 한다. Predix가 기본적으로는 센서, 기계 간 통신, 데이터 분석과 같은 IoT 기술을 지원하는 클라우드 플랫폼이지만 결국 이를 넘어 인공지능이 접목될 수밖에 없음을 의미하기도 한다. 실제 Predix는 이제 단순한 기계 간 연결, 정보 수집의 단 계를 넘어서 기계들이 정보를 분석하고 상황에 따라 능동적으로 작업을 수행하는 방향으로 발전하고 있다. 국내 AI 플랫폼 [^20] 기업 플랫폼 특징 삼성 빅스비 LG 구글 어시스턴트 SKT 누구 KT 기가지니 네이버 쇼핑톡톡(아미카) SK 플래닛 바로 카카오톡 카카오톡 플러스 친구 주요 분야2016년 주요 기업의 인공지능 분야 M&amp;A [^3] 년도 인수 기업 피인수 기업 기술/사업 요약 2013 Google DNNresearch 딥러닝 및 Neutral Network 기반 이미지 검색 기술 Intel Indisys 자연어 처리 및 대화형 인공지능 서비스 기술 Yahoo IQ Engines 이미지 인식 기술 (이미지 내 객체 인식) Yahoo LookFlow 이미지 인식 및 사물의 종류 분류 기술 Yahoo SkyPhrase 자연어 인식 및 처리 기술 Google DeepMind 딥러닝 및 자가/강화 학습 기술 2014 IBM Cogenea 인공지능 기반의 가상형 비서 서비스 Twitter Madbits 딥러닝 기반의 인공지능 플랫폼 구현 Google Jetpac SNS내 사진 분석을 통한 지능형 여행 가이드 서비스 Google Deepmind Dark Blue Labs 딥러닝 기반의 자연어 처리 기술 Google Deepmind Vision Factory 딥러닝 기반의 텍스트 인식 기술 2015 Facebook Wit.ai 자연어를 통한 스마트홈 및 로봇 분야의 서비스 제어 기술 IBM AlchemyAPI 클라우드 기반의 자연어 처리 기술 (핵심 키워드 추출 및 주제 분류) Twitter Whetlab 머신러닝 최적화 기술 (속도, 성능) Apple Vocal IQ 음성 인식 처리 기술 (인간과 대화형 서비스) Amazon 영상 처리를 통한 사물 인식 기술 Intel 인지 컴퓨팅 기술 Apple 인간의 감정 변화 분석 기술 ~2016/4 NICe Systems Nexidia 비정형화 된 오디오, 비디오, 텍스트 데이터 검색 기술 Salesforce PredictionIO 오픈소스 기반의 머신러닝 서버 구축 Salesforce MetaMind 인공지능 기반의 개인 맞춤화 고객 관리 서비스 참고[^1]: 이코노믹 리뷰, “빠지는데 없는 감초 아마존 인공지능 알렉사”, 2017-1-8[^2]: IBM Watson 임원 David Jenny가 AI as a Service 시대를 예견[^3]: “인공지능 플랫폼 경쟁이 시작되고 있다.”, 이승훈, LGERI, 2016. 5. 11.[^20]: 인공지능 플랫폼 동향과 정책적 시사점, 2017-05-12","link":"/2017/07/12/AI-2017-07-12-ai-platform/"},{"title":"Jekyll Install","text":"이 글은 github pages 를 통해서 블로그를 할 수 있도록 다음 작업을 한다: 로컬에 ruby를 기반으로한 jekyll 을 설치한다. markdown 으로 작성한 문서를 github pages 에 올린다. jekylljekyllrb.com 의 가이드에 따라 github page에서 블로그로 사용하고자 한다. 설치Ruby 개발 도구가 반드시 필요한데 macOS는 Ruby 최신 버전이 제공되고 있다. Linux/Windows에서 rvm 이라는 가상 개발 환경으로 설치하는게 깔끔하다. GNU/Linux, Unix, or macOS Ruby version 2.0 or above, including all development headers RubyGems GCC and Make (in case your system doesn’t have them installed, which you can check by running gcc -v and make -v in your system’s command line interface) Only required for Jekyll 2 and earlierPermalink NodeJS, or another JavaScript runtime (for CoffeeScript support). Python 2.7 Ruby 개발 도구가 반드시 필요한데 다음 같이 rvm 이라는 가상 개발 환경으로 설치하는게 깔끔하다. Ruby 가상개발환경을 설치한다. Linux/Ubuntu먼저 필요 패키지 12$ sudo apt-get install gnupg2$ sudo apt-get install curl rvm을 설치한다. 1234$ gpg --keyserver hkp://keys.gnupg.net --recv-keys D39DC0E3$ \\curl -sSL https://get.rvm.io | bash -s stable$ source /home/vjinn/.rvm/scripts/rvm$ rvm install ruby-2.2.0 macOS12$ \\curl -sSL https://get.rvm.io | bash -s stable$ rvm requirements #rvm 필수요소를 설치합니다 $HOME/.rvm 이 bashrc 에 추가된다. 로그아웃 하거나 쉘을 열어 rvm 을 샐행해 본다. $HOME/.rvm/scripts/rvm 명령이 실행되야 한다. Install Ruby on rvmruby 를 설치한다. macOS는 기본으로 ruby가 설치되어 있다.단, armhf 인 경우는 binary가 제공되지 않아서 소스를 다운해서 빌드과정을 거친다. 12$ rvm install ruby-2 #ruby-2 최신 버전을 설치$ ruby -v rvm 명령에 대한 사용은 이 블로그를 참조한다. ### jekyll 설치 gem 으로 설치한다. 12$ gem install jekyll bundler... bundler gem은 다른 Ruby gem을 관리하는 gem으로 gem과 gem 버전, 의존성을 지키게 해준다. 12$ jekyll -vjekyll 3.4.3 다음은 jekyll 개발자 버전을 설치한다면 사용한다. #### jekyll 개발버전 git에서 다운로드 최신 개발 버전 사용하고자 한다면 github 에서 다운로드해서 사용한다. 12345$ git clone git://github.com/jekyll/jekyll.git$ cd jekyll$ script/bootstrap$ bundle exec rake build$ ls pkg/*.gem | head -n 1 | xargs gem install -l ### jekyll 사용 jekyll 명령으로 블로그 사이트를 생성, 갱신, 삭제 등이 가능하다. 12$ jekyll new my-awesome-siteRunning bundle install in /home/qkboo/Hdd/Blogs/qkboo.github... 이렇게 생성된 사이트는 아래 같은 구조를 갖는다: 1234567├── Gemfile├── Gemfile.lock├── _config.yml├── _posts│ └── 2016-12-04-welcome-to-jekyll.markdown├── about.md└── index.md 그리고 다음 같이 서버를 실행해서 config.yml 파일을 생성하게 하자. 1234567$ cd my-awesome-site$ bundle exec jekyll serveServer address: http://127.0.0.1:8080/ Server running... press ctrl-c to stop.Ctrl+C Ctrl+C 종료 시키고 my-site/_config.yml 파일에 다음 같이 외부에서 접속 가능하게 해준다. 123# deploymenthost: 0.0.0.0port: 5000 이렇게 해주어야 외부에서 브라우저로 접근할 수 있다. gem-based themes에서는 assets, _layouts, _includes, _sass 디렉토리가 테마의 gem에 있다. #### jekyll 실행 확인 서버가 4000 포트에서 대기중인지 확인 1sudo lsof -i :4000 ##### **bunlde** 명령 bundle 명령을 사용해 jekyll 을 실행할 수 있다. 또한 URL Root 위치를 –baseurl 로 변경 1$ bundle exec jekyll serve -w --baseurl '/' Port 변경 1$ bundle exec jekyll serve -w --baseurl '/' --port 4000 디버그 메시지 출력 –trace: 1$ bundle exec jekyll serve -w --trace ### RubyGem으로 jekyll 관리 RubyGem 을 사용하기 위해 gem 명령으로 사용한다: 1$ jekyll --version 설치한 지킬 또는 gem 패키지 목록은 다음의 명령으로 확인할 수 있다. 123$ gem listor$ gem list jekyll # jekyll 목록 RubyGems 으로 gem 버전을 찾을 수 있다. 1$ gem search jekyll --remote 지킬 특정 버전을 사용하고 싶다면 아래와 같은 옵션을 주면 된다. (예, 1.5.1) 1$ gem install jekyll -v 1.5.1 지킬 삭제는 아래와 같다. 1$ sudo gem uninstall jekyll 특정 버전 삭제는 아래와 같다. (예, 1.5.1) 1$ gem uninstall jekyll -v 1.5.1 다양한 지킬 버전이 설치되어 있을 때 최신 버전 제외 모두 삭제는 아래와 같다. 1$ sudo gem cleanup jekyll 지킬 버전 업데이트는 아래와 같다. gem update를 사용하는 것이 좋다. 123$ sudo gem updateor$ sudo gem update jekyll 위의 내용들은 아래의 명령을 통해 도움을 얻을 수 있다. 1$ gem help ### MathJax LaTex 같은 수학 수식을 지원하려면 _include/head.html 같은 위치에 MathJax 를 포함한다. 1234&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; ## 참조 Jekyll Installation 리눅스에서 지킬 설치] Jekyll extras","link":"/2017/05/06/jekyll-2017-05-06-jekyll-install/"},{"title":"Jekyll Usages","text":"jekyll 기본 사용 지킬 사이트의 테마 이용 전역 설정 글쓰기 사이트 변환 New sitenew 명령을 jekyll의 gem-based themes 를 사용하게 구성해 준다.혹은 빈 폴더에서 새롭게 구성할 수 있다. jekyll newjekyll new로 생성되는 사이트는 gem-based theme를 사용한 jekyll project bootstrapped 로 생성된다. jekyll new SITE_NAME 으로 생성 1$ jekyll new myblog 아래 같은 템플릿 파일로 구성되다. 1234567GemfileGemfile.lock_config.yml_posts/_site/about.mdindex.md 중요한 구성 파일은, 파일 설명 _config.yml 설정 파일 _drafts 발행하지 않은 준비중인 포스트. _includes 재사용 가능한 조각 파일로, _post, _layouts에서 사용 _layouts 포스팅 글의 배치를 할 수 있다. 빈 사이트 만들기1$ jekyll new myblog --blank 디렉토리 구조만 생성된다. 1234_draft/_layout/_posts/index.html _config.yml jekyll configuration 참조 jekyll 설정 참조 1234markdown: kramdownhighlighter: pygmentspermalink: prettyrelative_permalinks: false Jekyll 실행 환경을 지정할 수 있다. 예를 들어 디버깅, 개발, 운영 환경으로 구분한다면 코드에 다음 같이 넣을 수 있다: 123{% if jekyll.environment == &quot;production&quot; %} {% include disqus_comments.html %}{% endif %} jekyll을 실행시 JEKYLL_ENV에 값을 지정해 줄 수 있다. 기본 값은 development 이다. 12$ JEKYLL_ENV=production bundle exec jekyll build$ JEKYLL_ENV=production jekyll build 지킬의 포스트 등에서 사용하는 변수는 https://jekyllrb.com/docs/variables/ 에서 확인할 수 있다. github 지원 config items아래는 GitHub에서 기본으로 제공하는 설정으로 사용자가 원하는 대로 변경이 가능한 설정. 123456789101112131415github: [metadata]kramdown: input: GFM hard_wrap: falsegems: - jekyll-coffeescript - jekyll-paginatelsi: falsesafe: truesource: [your repo's top level directory]incremental: falsehighlighter: rougegist: noscript: false lsi : 관련 포스트글에 대한 인덱스를 생성. safe : 사용자 플러그인을 비활성화 하고, 심볼릭 링크(symbolic links)를 무시. source : Jekyll이 읽을 파일의 위치를 변경. incremental : 수정 변경한 포스트만 다시 빌드하는 옵션. highlighter : rough highlighter 지정 gist : GitHub gist 사용 설정. post포스트는 _posts 폴더에 저장한다. yyyy-mm-dd-파일명.markup( md 또는 markdown 또는 textile) 형식으로 포스트 파일명을 만들어야 한다. 파일 내용은 다음 같이 구성된다. Front matterBODY Front matter 는 다음 같이 구성되고, Front Matter, **머리말**를 참조한다. YAML 머리말 블록을 가진 모든 파일을 특별한 파일로 인식하여 처리하고, 머리말은 반드시 올바른 YAML 형식으로 작성되어야 하며, 대시문자 3개(—)로 감싸서 파일의 맨 첫 부분과 끝 부분에 위치한다. BODY 내용은 마크다운, 기타 문법 형식으로 작성하면 된다. []다른 포맷 지원](http://jekyllrb-ko.github.io/docs/plugins/#converters-1) Front Matter 머릿말세 개의 대쉬 라인(—) 사이에 메타 정보를 넣는다. 123456---layout: posttitle: &quot;Welcome to Jekyll!&quot;date: 2017-05-03 18:53:47 +0900categories: jekyll update--- 빈 메타 정보는 빈 두개의 — 로 둔다. Front matter 에 사용할 수 있는 내장된 변수는 다음 같다: 변수 설명 layout 사용할 레이아웃 파일을 지정한다. 레이아웃 파일명에서 확장자를 제외한 나머지 부분만 입력한다. 레이아웃 파일은 반드시 _layouts 디렉토리에 존재해야 한다. permalink 생성된 블로그 포스트 URL 을 사이트 전역 스타일 (디폴트 설정: /year/month/day/title.html)이 아닌 다른 스타일로 만드려면, 이 변수를 사용하여 최종 URL 을 설정하면 된다. published 사이트가 생성되었을 때 특정 포스트가 나타나지 않게 하려면 false 로 설정하라. category,categories 포스트를 특정 폴더에 넣지 않고, 포스트가 속해야 하는 카테고리를 하나 또는 그 이상 지정할 수 있다. 사이트가 생성될 때, 포스트는 그냥 평범하게 이 카테고리들에 속한 것처럼 동작한다. 두 개 이상의 카테고리들을 지정할 때에는 YAML 리스트 또는 쉼표로 구분된 문자열을 사용한다. tags 카테고리와 유사하게, 하나 이상의 태그를 포스트에 추가할 수 있다. 또 카테고리와 동일하게, YAML 리스트 또는 쉼표로 구분된 문자열로 지정할 수도 있다. 외부 자원이미지, 다운로드 파일 등을 사용할 때는 루트 디렉토리의 images, assets, downloads 라는 디렉토리를 만들고 그곳에 둔다. 그리고 해당 자원의 참조를 / 경로를 기준으로 삼으면 된다. 1![친절한 스크린샷](/screenshot.jpg) site.url 변수 1![친절한 스크린샷]({{ site.url }}/assets/screenshot.jpg) 1… PDF 를 직접 [다운로드]({{ site.url }}/assets/mydoc.pdf)할 수 있습니다. Build실제 웹 사이트에는 html 파일로 제공되야 한다. 그러기 위해서 serve 혹은 build 명령으로 마크다운 파일을 변환해야 한다. jekyll serve 명령은 지킬 사이트 디렉터리 안으로 접근하여 실행해야 한다. serve 명령으로 빌드한 html과 파일은 _site 폴더에 생성된다. ### Theme Jekyll은 기본 테마로 Minima라 불리는 gem-based theme를 사용한다. 이 테마를 구성하는 파일은 jekyll new 명령으로 위치에 다음 같이 구성된다. Minima 테마는 assets, _layouts, _includes, and _sass 디렉토리를 실제 Minima theme gem 디렉토리에 위치하고 있고 아래 같은 구성으로 사이트가 생성된다. 1234567├── Gemfile├── Gemfile.lock├── _config.yml├── _posts│ └── 2016-12-04-welcome-to-jekyll.markdown├── about.md└── index.md 다른 Theme gem을 사용하려면 bundle update를 실행하거나 bundle update &lt;THEME&gt; 로 사용할 를 지정한다. jekyll은 사이트 접근시 처음에 컨텐츠를 아래 폴더 안에서 찾는다. /assets /_layouts /_includes /_sass 예를 들어 post 레이아웃을 사용하고 있다면 _layouts 폴더에 _layouts/page.html 테마 파일을 생성해 변경할 수 있다. 처음부터 생성하는 것 보다 기본 테마 파일을 이용하는 것이 빠르다. #### 기본테마 Manima Minima 테마의 기본 폴더는 bundle show minima 명령으로 확인이 가능하다. 기본테마 디렉토리는 아래 같이 구성되어 있다. 테마 정의에 필요한 _includes/, _layouts/, _sass/, assets/ 폴더이다. 1234567891011121314151617181920212223├── _includes│ ├── disqus_comments.html│ ├── footer.html│ ├── google-analytics.html│ ├── head.html│ ├── header.html│ ├── icon-github.html│ ├── icon-github.svg│ ├── icon-twitter.html│ └── icon-twitter.svg├── _layouts│ ├── default.html│ ├── home.html│ ├── page.html│ └── post.html├── _sass│ ├── minima│ │ ├── _base.scss│ │ ├── _layout.scss│ │ └── _syntax-highlighting.scss│ └── minima.scss└── assets└── main.scss 기본 테마 재정의 하기Jekyll theme는 기본 layouts, includes, stylesheets를 지정하는데, 이것을 사이트 콘텐트에 맞게 재정의할 수 있다. Minima 테마의 기본 폴더는 bundle show minima 명령으로 확인이 가능하다. 그리고 아래 같이 찾아서 열어 볼 수 있다. 먼저 macOS 는 1open $(bundle show minima) Windows 에서는 1explorer /usr/local/lib/ruby/gems/2.3.0/gems/minima-2.1.0 기본 테마 디렉토리 구조를 복사해 와서 작업하겠다. 12$ cd `bundle show minima`~minima-2.1.1$ cp -r _includes _layouts _sass assets ~/mysite/ 각각의 테마 요소를 알아보자. Layout컨텐츠의 구성은 _layouts 폴더에 넣는다. 이렇게 구성해 보자 123default.html| ├&lt;-- post.html ├&lt;-- page.html ### sass _sass 디렉토리에 .sass 파일을 두면 sass 컴파일러가 컴파일 한다. fonts외부 폰트, ttf, otf 등의 폰트를 _assets/fonts 같은 폴더에 다운로드하고 css로 불러와 사용한다. 그리고 _sass/main.scss 등의 css 파일에 다음 같이 폰트를 선언한다. 123456789@font-face { font-family: &quot;NotoSansCJKkr-Regular&quot;; src: url(&quot;../_assets/fonts/NotoSansCJKkr-Regular.otf&quot;) format(&quot;opentype&quot;);}@font-face { font-family: &quot;NotoSansCJKkr-Bold&quot;; src: url(&quot;../_assets/fonts/NotoSansCJKkr-Bold.otf&quot;) format(&quot;opentype&quot;); font-style: bold;} 그리고 html 혹은 css 에서 font-family 이름을 사용하면 된다. 1234h1,h2 { font-family: &quot;NotoSansCJKkr-Bold&quot;;} ### Disqus disqus.com 에서 새 사이트를 구성하고, Jekyll 을 선택하면 Universal code 를 얻을 수 있다. #### Disqus Universal Code 설치 comments 변수 comments 변수를 YAML Front Matter에 추가하기 위해, Jekyll의 manima 테마에서 _layouts/post.html 에 변수를 추가해 준다. 1234---layout: defaultcomments: true--- Universal code `{% if page.comments %}` 와 `{% endif %}` 태그 사이에 Universal Embeded Code를 추가해 준다. manima 테마의 \\_includes/disqus_comments.html 파일에 구성되어 있다. 코드에서production을 developement로 바꿔서 테스트 해보자. 댓글 수 표시 태그 전에 아래 스크립트를 원하는 위치에 둔다. 12345{% if page.comments %} &lt;!-- Disqus comment count --&gt; &lt;script id=&quot;dsq-count-scr&quot; src=&quot;//{{ site.disqus.shortname }}.disqus.com/count.js&quot; async&gt;&lt;/script&gt;{% endif %} href 속성에 #disqus_thread 를 추가하기 위해서, _layouts/post.html 템플릿에 다음을 추가한다. 123456{% if page.author %}• &lt;span itemprop=&quot;author&quot; itemscope itemtype=&quot;http://schema.org/Person&quot;&gt;&lt;span itemprop=&quot;name&quot;&gt;{{ page.author }}&lt;/span&gt;&lt;/span&gt;{% endif %}{% if page.comments %} • &lt;a href=&quot;{{ site.url }}{{ page.url }}#disqus_thread&quot;&gt;Comments&lt;/a&gt;{% endif %} 이제 제목 밑에 disqus 링크가 표시된다. {:width=”400”} 조건에 page.conmments 를 참조하면 post 에 comments: true 가 정의되면 되고, layout 전체를 담당하려면 아래 같은 layout.comments 를 비교한다: 123{% if layout.comments %} • &lt;a href=&quot;{{ site.url }}{{ page.url }}#disqus_thread&quot;&gt;Comments&lt;/a&gt;{% endif %} ### Google Analytics jekyll new 로 새 사이트를 설치하면 __includes/google-analytics.html 이 포함되어 있다. Google Analytics에서 Tracking ID를 발급받아 사용하면 된다. #### Tracking ID Google account가 있으면 손쉽게 만들수 있다.여기 에서 로그인해서 Admin &gt; Property &gt; Tracking Info &gt; Tracking Code 에서 찾을 수 있다. {:width=”400”} #### 설정 파일 __includes/google-analytics.html 안의 {{ site.google_analytics }}에 Tracking ID가 치환 되는데, 이것은 _config.yml 파일 google_analytics: 항목에 본인의 Tracking ID를 입력한다. 12# Google servicesgoogle_analytics: UA—XXXXXXXX-X #### default.html 이 파일을 _includes/head.html 파일에는 production 모드에서 analytics가 적용이 된다. 123{% if jekyll.environment == 'production' and site.google_analytics %}{% include google-analytics.html %}{% endif %} 운영모드인 production 은 github 에 업로드시 자동으로 적용된다. 만약 다른 사이트에 업로드하려면 빌드를 한다.$ JEKYLL_ENV=production bundle exec jekyll build Pagenation지킬에서 jekyll-paginate gem 을 추가하면 페이지 구분을 추가할 수 있다. https://jekyllrb.com/docs/pagination/ Gemfile과 _config.ymlGemfile에 추가. 123group :jekyll_plugins do gem &quot;jekyll-feed&quot;, &quot;~&gt; 0.6&quot; gem &quot;jekyll-paginate&quot; config.yml에서 활성화: 12345678gems: - jekyll-feed - jekyll-paginate#페이지 활성화paginate: 6 Custom Domaingithub page를 github.io 서브도메인 대신 본인의 도메인에 등록하려면 두 가지를 한다: 깃헙 페이지의 설정에서 custom domain 을 추가한다. DNS에 CNAME을 등록한다. Custom domain 추가github 에서 github page 저장소의 Settings 에서 Custom Domain에 사용할 도메인 이름을 저장한다. CNAME 등록DNS에 CNAME 을 github의 USER_NAME.github.io 에 연결해 준다.제대로 등록됐는지 dig 명령으로 확인한다. 12345$ dig docs.example.com +nostats +nocomments +nocmd;docs.example.com. IN Adocs.example.com. 3592 IN CNAME YOUR-USERNAME.github.io.YOUR-USERNAME.github.io. 43192 IN CNAME &lt; GITHUB-PAGES-SERVER &gt;. &lt; GITHUB-PAGES-SERVER &gt;. 22 IN A 199.27.XX.XXX 참조: https://help.github.com/articles/setting-up-a-custom-subdomain/","link":"/2017/05/07/jekyll-2017-05-07-jekyll-usages/"},{"title":"Jekyll - Bootstrap 4","text":"jekyll에서 Bootstrap 4 사용하기bootstrap4 는 2017-6월 현재 alpha 버전으로 jekyll 과 github page에 적용하기 위해서 몇가지 구성과 설정을 해주어야 한다. bootstrap 4 gem 추가bootstrap4는 sass를 지원하고, 실제 sass 파일을 추가하거나 gem으로 설치하는 두 가지 방법으로 설치한다. (1) sass 소스 파일 추가 (2) Gem 으로 설치 만약 bootstrap 3를 사용한다면 Bootstrap 3은 Less로 작성되었고, Jekyll은 Sass를 지원한다.[^3] 여기서는 Bootstrap Ruby gem 으로 설치한다 bootstrap gem을 설치하고 설정을 한 후에 github page에서 사용하기 위해 마지막 섹션에 설명한 것 처럼 bootstrap scss 파일을 복사하는 과정을 거친다. GemfilesGemfile 파일을 열고 bootstrap, autoprefixer-rails, jekyll-assets gem을 추가한다. [^2]. 또한 Gemfile 에서 minima 테마 gem을 막는다. 1234567# gem &quot;minima&quot;, &quot;~&gt; 2.0&quot;group :jekyll_plugins do gem &quot;jekyll-feed&quot;, &quot;~&gt; 0.6&quot; gem 'bootstrap', '~&gt; 4.0.0.alpha4' gem 'autoprefixer-rails' gem 'jekyll-assets' autoprefixer-rails: Autoprefixer for Ruby and Ruby on Rails jekyll-assets: Jekyll을 위한 Sprockets 3 사용한 Asset pipelines. _config.yml_config.yml 을 열고, minima 사용을 막는다. 123456#theme: minimagems: - jekyll-feed - bootstrap - autoprefixer-rails - jekyll-assets 새로 추가한 bootstrap gem을 bundle 명령으로 설치한다. 1$ bundle install assets/main.scssassets/main.scss 파일에 minima를 사용하지 않고, bootstrap에서 사용할 scss 파일을_sass/ 폴더에 작성한다. 12345//@import &quot;minima&quot;;@import &quot;bootstrap&quot;;@import &quot;_custom&quot;; // before 'main', variables for bootstrap@import &quot;main&quot;;@import &quot;blog&quot;; @import “bootstrap” 은 bootstrap gem을 통해 scss 소스를 읽어 온다. 여기서는 _custom.scss 파일은 bootstraps 변수, blog.scss 파일은 블로그 테마를 구성하도록 추가해서 구성했다. _sass/custom.sass 파일이 파일은 bootstrap4 scss _variables 에 있는 변수를 다시 정의한다. 다음 같다 [^2] 12345678910111213141516171819202122232425262728// Bootstrap overrides// Options$enable-flex: true;$enable-rounded: false;$enable-shadows: false;$enable-gradients: false;$enable-transitions: true;// Typography@font-face { font-family: &quot;NotoSansCJKkr-Regular&quot;; src: url( '../assets/fonts/NotoSansCJKkr-Regular.otf') format( 'opentype');}@font-face { font-family: &quot;NotoSansCJKkr-Bold&quot;; src: url( '../assets/fonts/NotoSansCJKkr-Bold.otf') format( 'opentype'); font-style: bold;}@font-face { font-family: &quot;NotoSansCJKkr-Light&quot;; src: url( '../assets/fonts/NotoSansCJKkr-Light.otf') format( 'opentype');}$base-font-family: &quot;NotoSansCJKkr-Regular&quot;, &quot;Helvetica Neue&quot;, Arial, sans-serif !default;$font-family-sans-serif: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, &quot;Helvetica Neue&quot;, Arial, sans-serif;$font-family-base: $font-family-sans-serif; _sass/main.scss 파일여기서 main.scss 에서는 TAG에 대한 전체적인 구성을 했다. minima 에서 가져온 코드등이 혼재한다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/* * Globals */@media (min-width: 48em) { html { font-size: 18px; }}@mixin media-query($device) { @media screen and (max-width: $device) { @content; }}@mixin relative-font-size($ratio) { font-size: $font-size-base * $ratio;}// Width of the content area$on-palm: 600px !default;$on-laptop: 800px !default;$background-color: #fdfdfd !default;$spacing-unit: 30px !default;$footer-height: 4.5rem;$small-font-size: $font-size-base * 0.875 !default;$base-line-height: 1.5 !default;$my-body-font: &quot;NotoSansCJKkr-Regular&quot;, &quot;Helvetica Neue&quot;, Arial, sans-serif !default;/* * TAG */html { position: relative; min-height: 100%;}body { font: $font-weight-base #{$font-size-base}/#{$base-line-height} $my-body-font; color: #111; background-color: $background-color;}h1, .h1,h2, .h2,h3, .h3,h4, .h4,h5, .h5,h6, .h6 { font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-weight: normal; color: #333;}table, td, th { border: 1px solid #003300;}table { border-collapse: collapse; border-spacing: 0;}th { border: 2px solid black;}td { padding: 1px 2px;}/* * Syntaxhighliting from minima */%vertical-rhythm { margin-bottom: $spacing-unit / 2;}// Import partials from minima@import &quot;minima/syntax-highlighting&quot;; 마지막엔 아직 다른 syntaxhighter를 설치 안하고 기존 minima에서 사용하던 syntaxhighliter 를 사용하게 했다. layout 파일 the post page layouts _include/head.html 파일12345&lt;link rel=&quot;stylesheet&quot; href=&quot;{{ &quot;/assets/main.css&quot; | relative_url }}&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css&quot;/&gt; _layout/default.html 파일footer.html 구문 밑에 bootstrap 관련 스크립을 추가한다. 1234567891011121314151617181920{% include header.html %}&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt;{{ content }}&lt;/div&gt;&lt;/div&gt;{% include footer.html %}&lt;!-- JavaScript --&gt;&lt;script src=&quot;https://code.jquery.com/jquery-3.1.1.slim.min.js&quot; integrity=&quot;sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js&quot; integrity=&quot;sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; header.htmlheader.html 을 bootstrap navbar 형태로 다음 같이 변경한다. 123456789101112131415161718192021222324252627&lt;nav class=&quot;navbar navbar-toggleable-sm navbar-inverse bg-inverse bg-faded fixed-top&quot;&gt; {% assign default_paths = site.pages | map: &quot;path&quot; %} {% assign page_paths = site.header_pages | default: default_paths %} &lt;button class=&quot;navbar-toggler navbar-toggler-right&quot; type=&quot;button&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#nav-content&quot; aria-controls=&quot;nav-content&quot; aria-expanded=&quot;false&quot; aria-label=&quot;Toggle navigation&quot;&gt; &lt;span class=&quot;navbar-toggler-icon&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;{{ &quot;/&quot; | relative_url }}&quot;&gt;{{ site.title | escape }}&lt;/a&gt; {% if page_paths %} &lt;div class=&quot;collapse navbar-collapse justify-content-end&quot; id=&quot;nav-content&quot;&gt; &lt;ul class=&quot;navbar-nav&quot;&gt; {% for my_page in site.pages %} {% if my_page.title %} &lt;li class=&quot;nav-item&quot;&gt; &lt;a class=&quot;nav-link&quot; href=&quot;{{ my_page.url | prepend: full_base_url }}&quot;&gt;{{ my_page.title | escape }}&lt;/a&gt; &lt;/li&gt; {% endif %} {% endfor %} &lt;/ul&gt; &lt;/div&gt; {% endif %}&lt;/nav&gt; navbar에서 참조한 구현 사례는 여기 샘플을 참조한다. footer.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;footer class=&quot;footer&quot;&gt; &lt;h3&gt;{{ site.title | escape }}&lt;/h3&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-3 footer-col&quot;&gt; &lt;ul class=&quot;contact-list&quot;&gt; &lt;li&gt; {% if site.author %} {{ site.author | escape }} {% else %} {{ site.title | escape }} {% endif %} &lt;/li&gt; {% if site.email %} {% comment %}&lt;li&gt;&lt;a href=&quot;mailto:{{ site.email }}&quot;&gt;{{ // site.email }}&lt;/a&gt;&lt;/li&gt;{% endcomment %} {% endif %} &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;col-md-3 footer-col&quot;&gt; &lt;ul class=&quot;social-media-list&quot;&gt; {% if site.github_username %} &lt;li&gt; {% include icon-github.html username=site.github_username %} &lt;/li&gt; {% endif %} {% if site.twitter_username %} &lt;li&gt; {% include icon-twitter.html username=site.twitter_username %} &lt;/li&gt; {% endif %} &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;col-md-5 footer-col&quot;&gt; &lt;p&gt;{{ site.description | escape }}&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/footer&gt;{% if page.comments %} &lt;!-- Disqus comment count --&gt; &lt;script id=&quot;dsq-count-scr&quot; src=&quot;//{{ site.disqus.shortname }}.disqus.com/count.js&quot; async&gt;&lt;/script&gt;{% endif %} {% raw %} ### \\_layouts 파일 bootstrap 클래스로 감싼다. 12&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt; home.html 파일, {% raw %} 123456789101112131415161718192021222324&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;h1 class=&quot;page-heading&quot;&gt;Posts&lt;/h1&gt; {{ content }} &lt;ul class=&quot;post-list&quot;&gt; {% for post in site.posts %} &lt;li&gt; {% assign date_format = site.minima.date_format | default: &quot;%b %-d, %Y&quot; %} &lt;span class=&quot;post-meta&quot;&gt;{{ post.date | date: date_format }}&lt;/span&gt; &lt;h2&gt; &lt;a class=&quot;post-link&quot; href=&quot;{{ post.url | relative_url }}&quot;&gt;{{ post.title | escape }}&lt;/a&gt; &lt;/h2&gt; &lt;/li&gt; {% endfor %} &lt;/ul&gt; &lt;p class=&quot;rss-subscribe&quot;&gt;subscribe &lt;a href=&quot;{{ &quot;/feed.xml&quot; | relative_url }}&quot;&gt;via RSS&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt; {% endraw %} bootstrap gem과 github pagesgithub page에 올리기 위해서 gem 설치한 bootstrap themem 파일이 필요하다. 로컬에서는 bootstrap gem 으로 bootstrap의 scss 소스를 사용하지만 github page에서는 실제 scss 파일이 함께 저장소에 있어야 한다. 먼저 다음 같이 bootstrap gem 위치로 이동한다. 12$ cd `bundle show bootstrap`/usr/local/lib/ruby/gems/2.4.0/gems/bootstrap-4.0.0.alpha6 $ 스타일 시트 파일을 로컬 _scss 폴더 밑으로 복사한다. 12$ cd assets/stylesheets$ cp -r * ~/work-blog/qkboo-github-work/_sass/ Gemfile, _config.ymlbootstrap gem 사용을 막는다. mamima 테마 삭제minima 테마를 사용하지 않으므로 관련 파일이 있으면 삭제한다. deleted: _sass/minima.scss deleted: _sass/minima/_base.scss deleted: _sass/minima/_layout.scss 단, _sass/minima/_syntax-highlighting.scss 는 일단 유지하자. github page update 문제jekyll 등에서 작업한 내용을 push 했지만 github page 내용이 변경되지 않는 경우, scss 파일 등에 에러가 있을 수 있다. 해당 페이지 프로젝트의 Settings -&gt; Github pages 섹션에 에러가 표시된다. {: width=”500”} 참조[^1]: Bootstrap for Sass[^2]: Bootstrap 4 + Jekyll[^3]: Using Bootstrap CSS with Jekyll","link":"/2017/06/28/jekyll-2017-06-28-jekyll-bootstrap4/"},{"title":"macOS에서 Jekyll 설치와 Minimalmistake Theme","text":"이 글은 github pages 를 통해서 블로그를 할 수 있도록 다음 작업을 한다: 로컬에 ruby를 기반으로한 jekyll 을 설치한다. github pages 와 연동한다. markdown 으로 작성한 문서를 github pages 에 올린다. jekylljekyllrb.com 의 가이드에 따라 github page에서 블로그로 사용하고자 한다. 설치Ruby 개발 도구가 반드시 필요 - 여기서 macOS 에서 블로그 작업을 한다고 가정한다. macOS는 Ruby 최신 버전이 제공되고 있다. 여기선 Homebrew 로 루비를 설치하고 사용한다. Ruby 환경Ruby 개발 도구가 반드시 필요한데 다음 같이 rbenv 이라는 가상 개발 환경으로 설치하는게 깔끔하다. Ruby 가상개발환경을 설치한다. Install HomebrewHomebrew 를 설치한다. 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Homebrew 를 통해 ruby 최신 버전을 설치한다. 2020년 3월 현재 2.7.0 을 설치하겠다. 그리고 환경변수 PATH 에 추가해 준다. 1echo 'export PATH=&quot;/usr/local/opt/ruby/bin:$PATH&quot;' &gt;&gt; ~/.bash_profile ruby 버전을 확인한다. 12$ ruby -vruby 2.7.0p0 (2019-12-25 revision 647ee6f091) [x86_64-darwin19] jekyll 설치Jekyll 을 설치시 시스템의 ruby gem 의 로컬 혹은 글로벌 설치를 선택해야 한다. 가능하면 로컬 설치를 권장하므로 여기서 로컬 설치만 다룬다. 글로벌 설치는 여기 Global Install을 참조한다. 로컬 설치bundler gem은 다른 Ruby gem을 관리하는 gem으로 gem과 gem 버전, 의존성을 지키게 해준다. gem 으로 설치한다. 1234567$ gem install --user-install bundler jekyllFetching bundler-2.1.4.gemWARNING: You don't have /Users/qkboo/.gem/ruby/2.7.0/bin in your PATH, gem executables will not run.Successfully installed bundler-2.1.4... 현재 루비 버전을 확인후 버전의 앞 두자리 숫자를 아래 경로에 XX 에 추가한다. 12$ ruby -vruby 2.7.0p0 (2019-12-25 revision 647ee6f091) [x86_64-darwin19] 루비 버전 앞 두 자리를 아래 경로 X.X 에 입력해 실행한다. 1$ echo 'export PATH=&quot;$HOME/.gem/ruby/X.X.0/bin:$PATH&quot;' &gt;&gt; ~/.bash_profile 쉘을 다시 시작한 후 홈 디렉토리에서 gem 경로를 확인한다. 1$ gem env 설치한 jekyll 버전을 확인한다. 12$ jekyll -vjekyll 4.0.0 which jekyll1/Users/qkboo/.gem/ruby/2.7.0/bin/jekyll jekyll 사용jekyll 명령으로 블로그 사이트를 생성, 갱신, 삭제 등이 가능하다. https://jekyllrb.com/docs/#instructions 새 사이트를 구성한다. 123$ jekyll new my-siteRunning bundle install in /home/qkboo/ 이렇게 생성된 사이트는 아래 같은 구조를 갖는다: 12345678my-site/ ├── Gemfile ├── Gemfile.lock ├── _config.yml ├── _posts │ └── 2016-12-04-welcome-to-jekyll.markdown ├── about.md └── index.md 여기에 bundle로 Gem을 설치한다. 12$ cd my-site$ bundle install 그리고 다음 같이 서버를 실행하면 블로그를 구성할 수 있는 config.yml 파일을 생성한다. 123456$ bundle exec jekyll serveServer address: http://127.0.0.1:8080/ Server running... press ctrl-c to stop.Ctrl+C Ctrl+C 종료 시키고 my-site/_config.yml 파일에 다음 같이 외부에서 접속 가능하게 해준다. 123# deploymenthost: 0.0.0.0port: 5000 이렇게 해주어야 외부에서 브라우저로 접근할 수 있다. 1$ bundle exec jekyll serve macOS에서 jekyll로 실행한 서버가 4000 포트에서 대기중인지 확인 1$ sudo lsof -i :4000 bundle 명령bundle 명령을 사용해 jekyll 을 실행할 수 있다. 또한 URL Root 위치를 –baseurl 로 변경 1$ bundle exec jekyll serve -w --baseurl '/' Port 변경 1$ bundle exec jekyll serve -w --baseurl '/' --port 4000 디버그 메시지 출력 –trace: 1$ bundle exec jekyll serve -w --trace gem list jekyll RubyGem으로 jekyll 관리RubyGem 을 사용하기 위해 gem 명령으로 사용한다: 1$ jekyll --version 설치한 지킬 또는 gem 패키지 목록은 다음의 명령으로 확인할 수 있다. 123$ gem listor$ gem list jekyll # jekyll 목록 RubyGems 으로 gem 버전을 찾을 수 있다. 1$ gem search jekyll --remote 지킬 특정 버전을 사용하고 싶다면 아래와 같은 옵션을 주면 된다. (예, 1.5.1) 1$ gem install jekyll -v 1.5.1 지킬 삭제는 아래와 같다. 1$ sudo gem uninstall jekyll 특정 버전 삭제는 아래와 같다. (예, 1.5.1) 1$ gem uninstall jekyll -v 1.5.1 다양한 지킬 버전이 설치되어 있을 때 최신 버전 제외 모두 삭제는 아래와 같다. 1$ sudo gem cleanup jekyll 지킬 버전 업데이트는 아래와 같다. gem update를 사용하는 것이 좋다. 123$ sudo gem updateor$ sudo gem update jekyll 위의 내용들은 아래의 명령을 통해 도움을 얻을 수 있다. 1$ gem help gem-based themes에서는 assets, _layouts, _includes, _sass 디렉토리가 테마의 gem에 있다. MathJaxLaTex 같은 수학 수식을 지원하려면 _include/head.html 같은 위치에 MathJax 를 포함한다. 1234&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; git-pages 연동하기참조 Jekyll Installation:macOS Jekyll Quickstart","link":"/2020/03/06/jekyll-2020-03-06-jekyll-mmtheme-macos/"},{"title":"NodeJS &#x2F; nvm 기반 개발환경 설치","text":"Node.js를 설치하고 관리할 수 있는 Node Version Manager를 사용한 개발환경 구성에 대해 살펴본다. 2018-6 npm i 관련 설명 추가{:.right-history} 버전관리자를 통한 Node.js 개발환경Node.js는 커뮤니티 개발을 위주로 업그레이드가 자주 된다. 개발중인 관련 모듈이 업그레이드를 따라가지 못할 경우가 자주 발생할 수 있다. 그래서 실제 개발하는 경우에 Node.js 버전의 변경을 자유롭게 하기 위해서 버전관리자(Node Version Manager) 환경에서 개발을 권장한다. 주요한 버전관리자에는 Nvm, Nodist 등 여러 종류가 있는데, 대부분 리눅스와 맥에서 사용 가능하다. 그리고 윈도우 환경에서는 nvm-windows, nodist를 사용할 수 있다. Linux/macOS: https://github.com/creationix/nvm Windows: https://github.com/marcelklehr/nodist 버전관리자를 설치후 사용 방법은 대동소이 하다. 여기서는 nvm을 다룬다. Shell 은 쉘 프롬프트로 사용자 권한 및 현재 위치를 표시하는데 보통 권한별로 아래 기호를 사용한다. $ : 사용자 프롬프트 # : root 프롬프트 ~ : 사용자 홈 디렉토리 / : 루트 디렉토리 . : 현재 디렉토리 .. : 이전 디렉토리 nvm 설치Linux / MacOS는 다음 쉘 스크립을 실행해 설치한다. curl 이용: 1curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.4/install.sh | bash wget 이용: 1wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.4/install.sh | bash install.sh 스크립이 설치하는 nvm은 사용자 홈디렉토리 ~/.nvm 에 설치된다. (이후 $NVM_HOME이라 하겠다) $NVM_HOME/install.sh 를 실행하면 업그레이드가 진행된다. 설치후 ~/.bash_profile, ~/.profile 등의 프로파일에 nvm.sh 가 실행되도록 아래 스크립이 추가된다. 12export NVM_DIR=&quot;$HOME/.nvm&quot;[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; . &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm Node.js 설치원격 저장소의 node 목록 12nvm ls-remotenvm ls-remote v6 #v6.x 버전만 검색 nvm install 은 해당 node version를 다운로드하고 설치한다. 1nvm install v5 # node version v5.x 버전중 최종버전 nvm ls 설치된 node 버전을 확인한다 12345$ nvm ls v0.9.12 v0.11.0 v6.9.1current: v6.9.1 nvm use로 사용할 node version을 지정한다 - 이것은 사용자의 $PATH 환경변수에 node 경로를 추가해준다. 12nvm use 6.9.1 #v6 버전을 사용한다.nvm use v7 #v7 버전중 최종 버번을 선택한다. node 경로를 제거하려면, 1nvm deactivate 로그인후 기본 node 환경으로 지정하려면 1nvm alias default 6.9.1 lts 버전Node.js 는 가용 버전이 장기지원을 위해서 LTS(Long Term Support) 프로그램을 진행하고 있다. 실제 운영 서버는 이런 LTS 버전을 중심으로 가동될 것이다. nvm 도 lts 만을 선별해서 설치하고 관리할 수 있다. 현재 LTS 버전중 최신버전만을 출력하려면, 1nvm ls-remote --lts |grep Latest 전역 패키지 통합nvm에서 새로운 node 버전을 설치하면서 기존 node 버전에서 사용중인 패키지를 통합해서 설치 할 수 있다. 예를 들어 최신 8 버전을 설치하며 사용중인 기존 6버전 패키지를 함께 설치하려면, 1nvm install v8 --reinstall-packages-from=v8.0.1 Default alias 잘 못 된 경우새로 로그인 혹은 버전 변경시 다음 메시지 출력, 1N/A: version &quot;N/A -&gt; N/A&quot; is not yet installed. 이 경우 가능성은 제거한 버전이 default 로 지정되서 그런듯 하다, 아래의 경우 default가 v8.7 인데 삭제해서 없기 때문이다. 12345678910$ nvm ls-&gt; v6.11.5 v7.10.1default -&gt; v8.7.0 (-&gt; N/A)node -&gt; stable (-&gt; v7.10.1) (default)stable -&gt; 7.10 (-&gt; v7.10.1) (default)iojs -&gt; N/A (default)lts/* -&gt; lts/boron (-&gt; v6.11.5)lts/argon -&gt; v4.8.5 (-&gt; N/A)lts/boron -&gt; v6.11.5 그래서 default 를 설치된 버전으로 변경해서 지정해 주면 위 메시지가 나오지 않는다. ### nodist Nodist 는 윈도우즈 환경에서 Nvm과 비슷하게 nodejs의 버전을 관리할 수 있다. https://github.com/marcelklehr/nodist 윈도우즈 인스톨러로 다운로드 가능. git 혹은 zip 으로 다운로드 가능. 인스톨러로 설치시nodist releases 에서 nodist 인스톨러를 다운받아 설치한다. git으로 설치윈도우즈 git으로 clone을 해오고, 윈도우의 환경설정 변수를 설정한다. 123C:\\&gt;git clone git://github.com/marcelklehr/nodist.gitC:\\&gt;setx /M PATH &quot;C:\\users\\thinkbee\\nodist\\bin;%PATH%&quot;C:\\&gt;setx /M NODIST_PREFIX &quot;C:\\users\\thinkbee\\nodist&quot; 이제 cmd에서 nodist의 업데이트를 실행해주고 사용한다. 1C:\\&gt;nodist selfupdate 기타 다른 환경에서 설치 및 사용법은 nodist 에서 확인한다. npmnpm 은 nodejs 패키지 관리자로 선택한 모듈을 설치, 갱신 및 삭제할 수 있고, 스크립팅을 통해 프로세스 관리까지 할 수 있다. npm init1npm init -y[--yes] 이렇게 생성된 package.json 은, 1234567891011{ &quot;name&quot;: &quot;myproject&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;} npm 으로 추가하는 모듈은 package.json에 의존성을 추가할 수 있다. npm install --save 별도의 플래그를 사용한다. 그리고 --dev 플래그를 주면 developer dependency에 추가해 준다. savenpm &lt; 5 이하 버전은 -S 혹은 --save 옵션으로 모듈 의존성을 package.json 에 추가한다. node를 설치후 npm을 업그레이드 해준다. npm 자체는 다음 같이 업그레이드 한다. 12npm i -g npmnpm install npm@latest -g Outdated module현재 package.json 에 설치된 버전과 명시된 버전 그리고 최신 버전과 차이를 알 수 있다. 1234npm outdatedPackage Current Wanted Latest Locationbody-parser 1.15.2 1.15.2 1.18.2 application-namedebug 0.7.4 0.7.4 3.1.0 application-name 최신 버전으로 설치를 하려면 package.json을 버전코드로 변경하고 업데이트를 진행한다. 모든 패키지를 업데이트할 수 있다. 123npm update+ mongoose@4.13.1added 1 package, removed 4 packages and updated 2 packages in 32.975s 특정 모듈만 업데이트하려면 패키지를 명시하면 된다. 1npm update debug npm upgradenode를 설치후 npm을 업그레이드 해준다. npm 자체는 다음 같이 업그레이드 한다. 12npm i -g npmnpm install npm@latest -g Outdated module현재 package.json 에 설치된 버전과 명시된 버전 그리고 최신 버전과 차이를 알 수 있다. 1234npm outdatedPackage Current Wanted Latest Locationbody-parser 1.15.2 1.15.2 1.18.2 application-namedebug 0.7.4 0.7.4 3.1.0 application-name 최신 버전으로 설치를 하려면 package.json을 버전코드로 변경하고 업데이트를 진행한다.혹은 모든 패키지를 업데이트할 수 있다. 123npm update+ mongoose@4.13.1added 1 package, removed 4 packages and updated 2 packages in 32.975s npm in vs. npm upinstall 과 update는 package.json 에 명시된 버전에 대응해 실행된다. npm install installs all modules that are listed on package.json file and their dependencies. npm update updates all packages in the node_modules directory and their dependencies. npm install express installs only the express module and its dependencies. npm update express updates the express module and its dependencies. stackoverflow: npm install vs update 에 따르면 버전 관리에 따른 차이를 보인다. 개별 모듈만 업그레이드 하려면 install @latest 같이 사용한다. 다음 같이 npm outdated 로 프로젝트 버전 상태를 확인해 보면 12345678910111213141516171819$ npm outdatedPackage Current Wanted Latest Locationagenda 0.9.0 0.9.1 1.0.3 www_appbody-parser 1.15.2 1.15.2 1.18.2 www_appcharset 1.0.0 1.0.1 1.0.1 www_appcheerio 0.22.0 0.22.0 1.0.0-rc.2 www_appcookie-parser 1.3.5 1.3.5 1.4.3 www_appdebug 2.2.0 2.2.0 3.1.0 www_appejs 2.5.7 2.5.8 2.5.8 www_appexpress 4.14.1 4.14.1 4.16.3 www_appiconv 2.2.1 2.3.0 2.3.0 www_appmongoose 4.13.2 4.13.12 5.0.13 www_appmorgan 1.7.0 1.7.0 1.9.0 www_appmulter 1.2.0 1.3.0 1.3.0 www_apppassport 0.2.2 0.2.2 0.4.0 www_apppassport-local-mongoose 1.3.0 1.3.0 5.0.0 www_apppug 2.0.0-rc.4 2.0.3 2.0.3 www_apprequest 2.83.0 2.85.0 2.85.0 www_appserve-favicon 2.3.0 2.3.2 2.5.0 www_app i 명령으로 현재 package.json에 명시된 버전이 설치된다. 123$ npm i mongoose+ mongoose@4.13.12updated 7 packages in 17.037s @latest 제한자로 최신 버전으로 업그레이드 할 수 있다. 12$ npm i mongoose@latest+ mongoose@5.0.13 어쨌든 버전 갱신을 목적으로 하면 npm i 를 일반적으로 써도 무방하다. Process management다음 글로 좀더 깊은 내용으로 옮겼다.","link":"/2017/04/01/nodejs-2017-04-01-nodejs-install-nvm/"},{"title":"Angular 개발환경","text":"Angular모바일, 데스크탑 웹 앱 구축을 지원하는 UI Framework 이다. Version History Angular 2: Initial Release 14.09.2016 Angular 4: Release on 23.03.2017 2017년 3월에 기존 2.x 버전에 호환하는 Angular 4.0.0이 출시되었다. [^1] Angular 5: Currently in beta 4 release 16.08.2017 Angular Changelog 에서 최신 정보를 얻을 수 있다. Angular4 특징기존 Angular 2에 비해 새로운게 많이 추가되었다. 작고 빠르게Angular 4 앱은 이전 버전에 비해 더 작은 공간이 소모되고 빠른 실행이 된다. View engine개선된 *nglf 와 *ngFor템플릿 바인딩이 변겨오디었는데 if/else 문법을 사용하고 관찰할 대상에 대해 변수를 대입할 수 있다. 123456789&lt;div *ngIf=&quot;userList | async as users; else loading&quot;&gt; &lt;user-profile *ngFor=&quot;let user of users; count as count; index as i&quot; [user]=&quot;user&quot; &gt; User {{i}} of {{count}} &lt;/user-profile&gt;&lt;/div&gt;&lt;ng-template #loading&gt;Loading...&lt;/ng-template&gt; Angular Universal커뮤니티 안에서 개발되던 것을 angular team에서 받아들여, Universal 은 서버에서 Angular를 실행할 수 있게 해준다. @angular/platform-server 에 포함되어 있다. Angular Universal 를 배우려면 먼저 @angular/platform-server 안의 renderModuleFactory 메서드를 살펴보고, Rob Wormald’s Demo Repository 를 살펴보라. TypeScript 2.1, 2.2 호환최신 버전의 TypeScript 를 적용했다. 그러므로 ngc 스피드를 향샹 시켰고, 앱에서 형 점검을 더 좋게 했다. 템플릿을 위한 소스 맵템플릿에서 어떤 에러가 발생하면 소스 맵을 생성해서 원래 템플릿에서 의미있는 내용을 보여준다. Flat ESM / FESM펼친 모듈을 배보한다. 예제 파일 참조. ES2015 빌드우리 패키지를 the ES2015 Flat ESM format 형식으로 배포하고 있다. 이것은 실험적인 선택사항이다. 이 패키지와 합친 경우 7% 번들 크기가 줄어드는 것으로 복되고 있다. 4.0으로 업그레이드Angular 의존성을 4.0.0으로 업그레이드는 쉽다. Linux/Mac1npm install @angular/{common,compiler,compiler-cli,core,forms,http,platform-browser,platform-browser-dynamic,platform-server,router,animations}@latest typescript@latest --save Windows1npm install @angular/common@latest @angular/compiler@latest @angular/compiler-cli@latest @angular/core@latest @angular/forms@latest @angular/http@latest @angular/platform-browser@latest @angular/platform-browser-dynamic@latest @angular/platform-server@latest @angular/router@latest @angular/animations@latest typescript@latest --save Angular Update guide 참조.","link":"/2017/09/02/nodejs-2017-09-02-angular-0start/"},{"title":"Typescript &#x2F; Gulp","text":"자바스크립트 개발자 또는 경험자를 위한 typescriptlang.org 의 Tutorials 를 정리했다. 5분에 끝내는 TypeScript Gulp Migrating from Javascript React &amp; Webpack GulpGulp 와 함께 TypeScript 를 빌드할 수 있고 Gulp pipeline에 Browserify, uglify, or Watchify 를 추가할 수 있다. 여기서 Babelify를 사용한 Babel 함수화에 대한 함수화를 추가할 것이다. Node.js와 npm을 다룰 수 있다고 가정한다. 프로젝트새로운 프로젝트 디렉토리 proj 를 만들고, 1234mkdir projcd projmkdir srcmkdir dist 이 프로젝트 아래 src,dist 를 추가한다. 123proj/ ├─ src/ └─ dist/ 그리고 package.json 파일을 만들기 위해 초기화 한다. 1npm init 여러가지를 묻는데 그 중 시작점을 ./dist/main.js로 지정한다. 의존성 설치gulp-cli 를 글로벌로 설치한다. 1npm install -g gulp-cli 이어서 typescript, gulp, gulp-typescript 를 설치하고 dev 의존성으로 저장한다. 1npm install --save-dev typescript gulp gulp-typescript 간단한 예제src 폴더에 main.ts 를 작성하자. 1234function hello(compiler: string) { console.log(`Hello from ${compiler}`);}hello(&quot;TypeScript&quot;); proj 폴더의 루트에 tsconfig.json을 작성한다. 1234567{ &quot;files&quot;: [&quot;src/main.ts&quot;], &quot;compilerOptions&quot;: { &quot;noImplicitAny&quot;: true, &quot;target&quot;: &quot;es5&quot; }} proj 폴더 루트에 gulpfile.js 를 작성한다. 1234567var gulp = require(&quot;gulp&quot;);var ts = require(&quot;gulp-typescript&quot;);var tsProject = ts.createProject(&quot;tsconfig.json&quot;);gulp.task(&quot;default&quot;, function () { return tsProject.src().pipe(tsProject()).js.pipe(gulp.dest(&quot;dist&quot;));}); 빌드하고 node로 실행한다. 12gulpnode dist/main.js 모듈을 추가한다모듈을 추가해 보자, src/greet.ts 소스를 작성한다. 123export function sayHello(name: string) { return `Hello from ${name}`;} export 는 함숭름 sayHello를 외부에서 사용할 수 있게 해준다. 이 모듈을 src/main.tx 에서 import 로 들여와서 사용한다. ES2015 모듈 문법을 사용하는데 Typescript은 CommonJS 모듈을 이어받아 사용한다. 123import { sayHello } from &quot;./greet&quot;;console.log(sayHello(&quot;TypeScript&quot;)); 모듈은 tsconfig.json 에 등록해주어야 한다. 1234567{ &quot;files&quot;: [ &quot;src/main.ts&quot;, &quot;src/greet.ts&quot; ], ...} 빌드하고 node로 실행한다. 12gulpnode dist/main.js Browserify이제 Node 앱을 브라우저로 이전해 보자. 우리 모든 번들을 자바스크립으로 무꺼어야 한다. 이것은 Browserify가 수행해 준다. 이 모듈도 또한 CommonJS 모듈시스템을 사용한다. 그러므로 TypeScript과 Node.js 설정을 쉽고 변경없이 이전이 가능하다. 먼저 tsify와 vinyl-source-stream 을 설치한다. tsify 는 Browserify 플러그인으로 타입스크립트 컴파일러에 접근하게 해준다. vinyl-source-stream은 browserify의 결과 파일을 gulp가 이해하는 vinyl 형식으로 호환해준다. 1npm install --save-dev browserify tsify vinyl-source-stream 페이지 생성src에 index.html 파일을 만든다. 1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p id=&quot;greeting&quot;&gt;Loading ...&lt;/p&gt; &lt;script src=&quot;bundle.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; main.ts 를 페이지에 접근할 수 있게 갱신한다. 12345678import { sayHello } from &quot;./greet&quot;;function showHello(divName: string, name: string) { const elt = document.getElementById(divName); elt.innerText = sayHello(name);}showHello(&quot;greeting&quot;, &quot;TypeScript&quot;); 그리고 gulfile.js 를 변경한다. 12345678910111213141516171819202122232425var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var tsify = require(&quot;tsify&quot;);var paths = { pages: [&quot;src/*.html&quot;],};gulp.task(&quot;copy-html&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});gulp.task(&quot;default&quot;, [&quot;copy-html&quot;], function () { return browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }) .plugin(tsify) .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}); 기본 의존성으로 copy-html 태스크를 추가한다: 가장먼저 copy=html 이 실행된다. Browserify를 호출해서 gulp-typescript 대신 tsify 플러그인을 사용한다. bundle()이 호출되고 vinyl-source-stream을 사용해 bundle.js 로 소스를 모은다. Notice that we specified debug: true to Browserify. This causes tsify to emit source maps inside the bundled JavaScript file. Source maps let you debug your original TypeScript code in the browser instead of the bundled JavaScript. You can test that source maps are working by opening the debugger for your browser and putting a breakpoint inside main.ts. When you refresh the page the breakpoint should pause the page and let you debug greet.ts. 마지막으로 gulp 로 빌드하고 dist/index.html을 브라우저에서 실행해 보자. Watchify, Babel, UglifyBrowserify로 코드를 묶었다. 다음 Browserify 플러그인으로 더 확장된 빌드를 구현할 수 있다. Watchify: gulp 를 시작하고 증분 컴파일을 할 수 있다. 수정-저장-갱신 사이클을 브라우저에서 유지할 수 있다. Babel: ES2015 와 ES5, ES3 으로 변환할 수 있는 컴파일러 이다. Typescript 이 지우너하지 않는 사용자화 변경과 확장을 추가할 수 있다. Uglify: 다운로드 시간을 줄일 수 있도록 코드를 압축한다. Watchify다음 같이 설치한다. 1npm install --save-dev watchify gulp-util gulpfile.js 를 watchify 와 gulp-util 을 사용하게 변경한다. 12345678910111213141516171819202122232425262728293031323334var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var watchify = require(&quot;watchify&quot;);var tsify = require(&quot;tsify&quot;);var gutil = require(&quot;gulp-util&quot;);var paths = { pages: [&quot;src/*.html&quot;],};var watchedBrowserify = watchify( browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }).plugin(tsify));gulp.task(&quot;copy-html&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});function bundle() { return watchedBrowserify .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}gulp.task(&quot;default&quot;, [&quot;copy-html&quot;], bundle);watchedBrowserify.on(&quot;update&quot;, bundle);watchedBrowserify.on(&quot;log&quot;, gutil.log); We wrapped our browserify instance in a call to watchify, and then held on to the result. We called watchedBrowserify.on(“update”, bundle); so that Browserify will run the bundle function every time one of your TypeScript files changes. We called watchedBrowserify.on(“log”, gutil.log); to log to the console. 이제 gulp 를 실행하며 watchify에 의해 소스 변경을 점검하고 변경시 컴파일을 한다. 1234567$ gulp[04:39:43] Using gulpfile ~/Works/typescript/proj/gulpfile.js[04:39:43] Starting 'copy-html'...[04:39:43] Finished 'copy-html' after 105 ms[04:39:43] Starting 'default'...[04:39:52] 3199 bytes written (0.38 seconds)[04:39:52] Finished 'default' after 8.66 s Uglifyuglify 는 코드를 난독화 시키고, 용량을 줄여 준다. 1npm install --save-dev gulp-uglify vinyl-buffer gulp-sourcemaps gulpfile.js에 추가한다. 1234567891011121314151617181920212223242526272829303132var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var tsify = require(&quot;tsify&quot;);var uglify = require(&quot;gulp-uglify&quot;);var sourcemaps = require(&quot;gulp-sourcemaps&quot;);var buffer = require(&quot;vinyl-buffer&quot;);var paths = { pages: [&quot;src/*.html&quot;],};gulp.task(&quot;copy-html&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});gulp.task(&quot;default&quot;, [&quot;copy-html&quot;], function () { return browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }) .plugin(tsify) .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(buffer()) .pipe(sourcemaps.init({ loadMaps: true })) .pipe(uglify()) .pipe(sourcemaps.write(&quot;./&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}); uglify 는 한번 호출하는데 - sourcemaps를 유지하기 위해 버퍼링하고 소스맵을 하기 위해 호출한다. 이것으로 분리된 소스맵 파일을 생성한다. gulp를 실행해 bundle.js 를 통해 최소화된 파일로 출력되는지 점검할 수 있다. 12gulpcat dist/bundle.js BabelBabel과 Bebel preset ES2015를 설치한다. 기본 설정으로 Uglify 같이 코드를 난독화 한다. 역시 vinyl-buffer, gulp-sourcemaps 가 필요하다. 파일 확장자 .js, .es, .es6 and .jsx 에 대해서만 다룬다. 그러므로 .ts 확장자도 추가할 필요가 있다. 1npm install --save-dev babelify babel-preset-es2015 vinyl-buffer gulp-sourcemaps gulpfile.js 를 12345678910111213141516171819202122232425262728293031323334var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var tsify = require(&quot;tsify&quot;);var sourcemaps = require(&quot;gulp-sourcemaps&quot;);var buffer = require(&quot;vinyl-buffer&quot;);var paths = { pages: [&quot;src/*.html&quot;],};gulp.task(&quot;copyHtml&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});gulp.task(&quot;default&quot;, [&quot;copyHtml&quot;], function () { return browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }) .plugin(tsify) .transform(&quot;babelify&quot;, { presets: [&quot;es2015&quot;], extensions: [&quot;.ts&quot;], }) .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(buffer()) .pipe(sourcemaps.init({ loadMaps: true })) .pipe(sourcemaps.write(&quot;./&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}); 그리고 tsconfig.js에 typescript 의 대상을 *”target”: “es5”*에서 ES2015로 명시해 준다.Babel’s ES5 output should be very similar to TypeScript’s output for such a simple script.","link":"/2017/09/01/nodejs-2017-09-01-typescript-2gulp/"},{"title":"Typescript &#x2F; 5min in Typescript","text":"자바스크립트 개발자 또는 경험자를 위한 typescriptlang.org 의 Tutorials 를 정리했다. 5분에 끝내는 TypeScript Gulp Migrating from Javascript React &amp; Webpack 5분에 끝내는 TypeScript자바스크립트 개발자 또는 경험자가 알아야할 내용을 정리한 TypeScript in 5min을 정리했다. 설치TypeScript는 Node.js를 사용하며, npm으로 typescript 지원 도구를 설치한다. 1npm install -g typescript 개발자용 nightly build도 설치 할 수 있다. 1npm install -g typescript@next tsc 컴파일러TypeScript 소스를 tsc 컴파일러로 컴파일하고, 결과는 Javascript로 생성된다. 12$ tsc -VVersion 2.5.2 최신버전 갱신은 Typscript blog 를 참조한다. 첫번째 TypeScript 파일보통 Typescript 소스 확장자는 .ts 로 저장하고 tsc 컴파일러로 컴파일한다. .ts 파일을 컴파일 하면 .js 자바스크립트 소스파일이 생성된다. 예를 들어 아래 자바스크립트로 구성된 코드를 greeter.ts 파일에 입력한다. 1234567function greeter(person) { return &quot;Hello, &quot; + person;}var user = &quot;Jone James&quot;;document.body.innerHTML = greeter(user); 그리고 컴파일 하면 자바스크립트 소스 greeter.js 가 생성된다. 1$ tsc greeter.ts greeter.ts 소스와 컴파일 결과 greeter.js 소스는 일치한다. Type annotationsTypeScript에서 형(Types) 표기는 함수 혹은 변수에 의미를 부여하기 위한 방법으로, 아래 코드의 greeter 함수에 전달하는 인자가 string 형 이라고 의도하기 위해서, 변수 다음 :으로 오른쪽에 형을 지정(annotation)해 선언한다 - 즉, 문자열로 전달할 거야 하는 의도를 선언한다고 이해하면 된다. 123456function greeter(person: string) { return &quot;Hello, &quot; + person;}var user = [&quot;My&quot;, 1, 2, 3];greeter(user); 이제 tsc 로 컴파일을 실행하면 아래 같이 형 지정 에러를 표시한다. 비슷하게 greeter() 함수의 매개변수를 모두 지우고 컴파일해도 비슷한 결과를 보여준다. 12$ tsc greeter.tsgreeter_2.ts(7,9): error TS2345: Argument of type '(string | number)[]' is not assignable to parameter of type 'string'. Typescript의 형 지정은 코드와 주어진 형 지정자를 기반으로 정적 분석을 제공한다. 이렇게 컴파일 에러는 발생하지만 .js 자바스크립트는 생성되는 것을 확인 할 수 있다. 코드에 에러가 있어도 TypeScript을 사용할 수 있다, 다만 원래 의도데로 실행되지는 않는다는 것을 경고해 준다. Interfaces추상화를 위해 interface 를 사용해서 속성을 가진 개체를 선언 할 수 있다. 아래 Person 인터페이스는 firstName, lastName 속성으로 선언하고 있다. TypeScript에서는 내부 구조가 호환하면 두 객체는 호횐 된다고 한다. 이것은 명시적으로 implements 절을 사용하지 않고도 인터페이스가 요구하는 형태를 가지면 인터페이스에 동일하게 구현이 가능하다고 한다. 이제 greeter 함수를 인터페이스 Person 형으로 다음 같이 선언할 수 있다. 123456789101112interface Person { firstName: string; lastName: string;}function greeter(person: Person) { return &quot;Hello, &quot; + person.firstName + &quot; &quot; + person.lastName;}var user = { firstName: &quot;Jane&quot;, lastName: &quot;User&quot; };document.body.innerHTML = greeter(user); 이 소스를 tsc 로 컴파일 해도 형이 일치한다고 판단해서 경고가 없고 결과 자바스크립트를 HTML로 코딩해서 결과를 확인해 보자, 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;TypeScript Greeter&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=&quot;greeter_3interface.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; Classes자바스크립에는 없는 클래스 기반의 객체지향 프로그래밍을 지원한다. class 키워드로 선언하고 속성과 메서드를 가진다. 또한 생성자 constructor() 에 public 접근제한자를 지정해서 추상화 단계를 결정하게 하고, 생성자의 public 지정자는 해당 이름으로 자동으로 속성을 생성하게 해준다. 이것은 클래스가 인터페이스와 잘 결합되게 해준다. 1234567891011121314151617181920212223class Student { fullName: string; constructor( public firstName: string, public middleInitial: string, public lastName: string ) { this.fullName = firstName + &quot; &quot; + middleInitial + &quot; &quot; + lastName; }}interface Person { firstName: string; lastName: string;}function greeter(person: Person) { return &quot;Hello, &quot; + person.firstName + &quot; &quot; + person.lastName;}var user = new Student(&quot;Jane&quot;, &quot;M.&quot;, &quot;User&quot;);document.body.innerHTML = greeter(user); Person 인터페이스를 요구받는 greeter()에 Student class의 생성자에 호혼한다. 그래서 tsc로 컴파일해도 아무 문제 없다. 다만, 클래스의 생성자 매개변수가 인자 수, 형 같이 다르면 다음 같이 에러를 발생한다. 1greeter_4classes.ts(18,12): error TS2554: Expected 3 arguments, but got 2. 컴파일한 자바스크립은 HTML에서 실행할 수 있다. 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;TypeScript Greeter&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=&quot;greeter.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 실제 실행하면 Person 객체는 세번째 매개변수가 없기 때문에 undefined 로 나타난다. Hello, Jane undefined TypeScript에서 클래스 기반의 코드를 컴파일해서 자바스크립트 생성된 결과를 보면, 클래스는 자바스크립트의 프로토타입 기반의 객체지향 방법의 축약형이다. 123456789var Student = /** @class */ (function () { function Student(firstName, middleInitial, lastName) { this.firstName = firstName; this.middleInitial = middleInitial; this.lastName = lastName; this.fullName = firstName + &quot; &quot; + middleInitial + &quot; &quot; + lastName; } return Student;})(); 참조Typescript in 5 min","link":"/2017/09/01/nodejs-2017-09-01-typescript-1quickstart/"},{"title":"Angular 개발환경","text":"Angular4 CLI2017년 3월에 기존 2.x 버전에 호환하는 Angular 4.0.0이 출시되었다. [^1] ### CLI Quick Start Angular CLI는 명령행 인터페이스로 프로젝트를 생성, 파일 추가 그리고 개발 태스크 - 테스트, 번들, 개발에 대한 기능을 제공하고 있다.여기서 Angular CLI로 TypeScript 에서 앱을 개발하는 과정을 Style Guide가 권장하는데 맞게 진행해 보자 예제 다운로드 개발환경 설정node.js와 npm에 대해 사용이 가능해야 하고 구성해야 한다. Angular CLI를 전역환경에 설치한다. 시간이 소요된다. 1npm install -g @angular/cli ng 명령을 사용할 수 있다. 1ng -v CLI에서 새 프로젝트 생성ng new 명령으로 프로젝트를 생성한다 - 생성으로 관련 npm 패키지를 설치하는 과정이 길다. [^2] 1ng new my-app 새로 생성한 프로젝트 디렉토리로 이동해서 서비스를 실행한다. ng serve 명령은 서버를 실행하고, 파일을 12cd my-appng serve --open #### Angular QuickStart Source Angular Quickstart Source 를 사용해서 CLI 없이 Angular 4를 시작할 수 있다. – 여러 의존성 문제가 발생한다. node v4.x.x 와 npm 3.x.x 이상을 필요로한다. To use the Angular 2 Quickstart, you run: 12$ git clone https://github.com/angular/quickstart.git my-proj$ cd my-proj Quickstart source 에 푸시하지 않으려면 .git 폴더를 삭제해도 무방하다. 12rm -rf .git # OS/X (bash)rd .git /S/Q # windows 또한 테스트와 저장소 유지를 위해 사용하는 non-essential을 삭제해도 된다. Linux (bash) 123xargs rm -rf &lt; non-essential-files.txtrm src/app/*.spec*.tsrm non-essential-files.txt OS/X (bash) 123xargs rm -rf &lt; non-essential-files.osx.txtrm src/app/*.spec*.tsrm non-essential-files.osx.txt Windows 123for /f %i in (non-essential-files.txt) do del %i /F /S /Qrd .git /s /qrd e2e /s /q 패키지를 설치한다. 1npm install 이제 최신 angular4 패키지를 설치하고 package.json 에 저장한다. To upgrade, paste (Mac only): 1npm install @angular/{common,compiler,compiler-cli,core,forms,http,platform-browser,platform-browser-dynamic,platform-server,router,animations}@next --save 1npm install @angular/common@next @angular/compiler@next @angular/compiler-cli@next @angular/core@next @angular/forms@next @angular/http@next @angular/platform-browser@next @angular/platform-browser-dynamic@next @angular/platform-server@next @angular/router@next @angular/animations@next --save npm install @angular/core @angular/http –save Typescript 이 설치되어 있지 않다면 역시 설치해 준다. 1npm install typescript@2.3 --save 시작 1npm start 앱 프로젝트 살펴보기Angular component 수정app-root 로 불리는 _ ./src/app/app.component.ts._ 콤포넌트를 수정해 보자. 에디터에서 열고 title 속성을 수정해 보자. 12345678910import { Component } from &quot;@angular/core&quot;;@Component({ selector: &quot;app-root&quot;, templateUrl: &quot;./app.component.html&quot;, styleUrls: [&quot;./app.component.css&quot;],})export class AppComponent { title = &quot;안녕하세요. Angular App&quot;;} ./app.component.css 스타일시트 파일을 수정해 보자. css 수정src/app/app.component.css 에서 스타일을 수정해 보자. 12345h1 { color: #369; font-family: Arial, Helvetica, sans-serif; font-size: 250%;} 프로젝트 구성src 폴더는 Angular components, templates, styles, images 등을 포함하고 있다. 파일 설명 app/app.component.{ts,html,css,spec.ts} AppComponent를 HTML 템플릿, CSS 스타일, 단위 테스트와 함게 선언한다. 이것은 앱에 관련한 계층적인 콤포넌트 트리가 되는 root 콤로넌트다. ng 기본 명령ng serve 로 서버를 제공한다. 기본 http://localhost:4200/ 에서 확인한다. 그리고 변경된 내용은 자동으로 서버에 적용된다. 서비스 포트와 호스트는 기본 포트는 4200번으로 .angular-cli.json 파일에 defaults 섹션에 선언할 수 있다. 12345678910{ &quot;defaults&quot;: { &quot;styleExt&quot;: &quot;css&quot;, &quot;component&quot;: {}, &quot;serve&quot;: { &quot;port&quot;: 4201, &quot;host&quot;: 127.0.0.1 } }} Code 발판새로운 콤포넌트를 추가하려면 ng generate component component-name 명령을 실행하면 새로운 모듈이 추가된다. ng generate 명령 1ng generate directive|pipe|service|class|guard|interface|enum|module BuildRun ng build 명령은 프로젝트를 빌드한다. 빌드 결과물은 dist/ 디렉토리에 저장된다. -prod 옵션을 사용하면 완성본을 구성할 수 있다. Running unit tests단위 테스트를 수행할 수 있는데, ng test 는 Karma를 통해서 단위테스트를 수행한다. Running end-to-end testsRun ng e2e to execute the end-to-end tests via Protractor.Before running the tests make sure you are serving the app via ng serve. 참조CLI 없이 Angular 4를 시작 [^1]: Angular 4.0.0 Now Available[^2]: Angular 4 Quick Start","link":"/2017/09/02/nodejs-2017-09-02-angular-cli/"},{"title":"Angular4 Tutorial for Beginner -- (1)","text":"Angular 이용에 대한 튜토리얼은 Angular Tutorial for beginners to Professionals 를 요약하고 있다. Angular App여기서는 angular cli를 사용해서 angular project를 생성하고 다루는데, 링크 Angular Cli Usages 에서 새 프로젝트 실행에 대해 살펴볼 수 있다. Anguar 의 개발 환경은 Create Angular2 를 참조한다. 프로젝트 생성ng new 명령으로 프로젝트를 생성한다. 1ng new myproducts 새로 생성한 프로젝트 디렉토리로 이동해서 서비스를 실행한다. ng serve 명령은 서버를 실행 12cd myproductsng serve 브라우저로 localhost:4200 으로 접속 디렉토리 구성ng new 생성하는 템플릿은 이렇게 구성되 있다. Root 폴더 Angular-cli.json: Angular CLI를 위한 구성 파일..editorconfig: 에디터 설정 파일. http://editorconfig.org 참고..gitignore: git 소스 제어를 하지 않는 설정 파일. karma.conf.js: karma test runner 설정 파일. package.json: npm 패키지 목록 설정 파일 protractor.conf.js: The Configuration file for protractor end to end test runner. README.md tsconfig.json: TypeScript compiler configuration for your IDE to pick up and give you helpful tooling. tslint.json: tslint is a static code analysis tool used in software development for checking Typescript code quality. To check if TypeScript source code complies with coding rules. TSLint checks your TypeScript code for readability, maintainability, and functionality errors typings.d.ts: Typescript type definition file e2e 폴더 protractor 가 엔드투엔드 테스트하는데 필요한 파일을 포함한다. Protractor는 실제 브라우저에 대비해 앱을 테스트할 수 있게 한다. 여기서 자세한 것은 배울 수 있다. 콤포넌트 분석Angular CLI로 생성한 프로젝트는 여러 콤포넌트로 구성되어 있다. src/app/ 밑에 콤포넌트 소스가 있다. app.component.ts앱의 뷰를 표현하고, 뷰는 화면의 한 부분이다. 3개로 구성되어 있다. class, class decorator, import statement 12345678910import { Component } from &quot;@angular/core&quot;;@Component({ selector: &quot;app-root&quot;, templateUrl: &quot;./app.component.html&quot;, styleUrls: [&quot;./app.component.css&quot;],})export class AppComponent { title = &quot;app&quot;;} export 키워드로 AppComponent class는 다른 콤포넌트에서 사용할 수 있다. 이런 콤포넌트 클래스는 속성과 메서드를 가질 수 있다. @Component decorator는 클래스 데코레이터로 이 콤포넌트에 대한 메타데이터를 제공한다. 이 메타데이터를 사용해서 Angular가 뷰를 생성한다. templateUrl: styleUrl: selector: angular에게 템플릿을 표시할 곳을 말한다. 이 콤포넌트에서 app-root 셀렉터는 index.html에서 사용한다. import 구문 외부 라이브러리를 콤포넌트에서 사용하고자 할 때 사용. 여기서 @angular/core 라이브러리에서 Component 데코레이터를 가져왔다. Root 모듈angular 앱은 모듈로 구성된다. app.module.ts 소스를 루트 모듈(root module)로 부른다. 123456789101112import { BrowserModule } from &quot;@angular/platform-browser&quot;;import { NgModule } from &quot;@angular/core&quot;;import { AppComponent } from &quot;./app.component&quot;;@NgModule({ declarations: [AppComponent], imports: [BrowserModule], providers: [], bootstrap: [AppComponent],})export class AppModule {} Angular 모듈의 구조는 콤포넌트 클래스와 비슷하다. class, class decorator, import Module class 는 콤포넌트와 비슷하게 export로 외부 모듈에서 사용할 수 있다. 1export class AppModule {} Angular 모듈은 @NgModule 데코레이터를 필요로 한다. 이 데코레이터로 모듈에 관련한 메타데이터를 전달한다. 소스에서 @NgModule은 declarations, imports, providers, bootstrap 네 가지 필드를 선언하고 있다. imports: 이 모듈에서 사용하는 모듈을 선언한다. Declarations: 이 모듈에 관련한 콤포넌트, 디렉티브, 파이프를 선언한다. Providers: 서비스를 선언하면 다른 콤포넌트가 사용할 수 있다. Bootstrap: 메타 데이터는 루트 콤포넌트를 식별한다. Import 구문AppModuel 에서 요구하는 외부 라이브러리를 들여오는데 사용한다. 또한 원하는 AppComponent를 들여오기 위해서 AppComponent가 필요하다. 부트스트래핑루트 모듈을 부트스트랩 해보자. 먼저 화면에 보이기 위해서 템플릿 파일인 app.component.html 이 있다. 이것은 AppComponent에 바인딩 된다. 결국 AppComponent 가 AppModule이 로드될 때 부트스트랩된다고 알 수 있다. 그래서 앱이 올라올 때 Angular에게 AppModule을 적재하자고 묻는데 이것은 src/main.ts 파일에서 완성된다. 12345678910111213import { enableProdMode } from &quot;@angular/core&quot;;import { platformBrowserDynamic } from &quot;@angular/platform-browser-dynamic&quot;;import { AppModule } from &quot;./app/app.module&quot;;import { environment } from &quot;./environments/environment&quot;;if (environment.production) { enableProdMode();}platformBrowserDynamic() .bootstrapModule(AppModule) .catch((err) =&gt; console.log(err)); platformBrowserDynamic 콤포넌트: angular 앱에서 부트스트랩을 위해 필요한 모든 함수들. enableProdMode: 기본적으로 개발자 모드로 실행하게 한다. environment: environment.ts 는 개발자 모드 환경이 있다. 개발자 환경에서 environments.ts 파일을 사용한다. 실제 상업 모드에서는 environments.prod.ts 가 사용된다. env 맵의 목록에서 어떤 파일이 사용되는지 확인할 수 있는데 angular-cli.json 파일에 있다. index.html앱의 메인 페이지이다. 셀렉터가 콤포넌트를 태그 처럼 사용하게 한다. app.component.ts에 선언한데로 이 셀렉터에 템플릿이 표시된다. 다른 파일app 폴더 밑에 다른 파일을 살펴보자. Assets 폴더이미지 혹은 앱을 빌드하는데 필요한 자원을 넣어 두는 곳. polyfills.ts웹 표준을 다르게 구현/지원하는 여러 브라우저를 위해 일반화를 해준다. 브라우저 지원 가이드에 따라서 core-js, zone.js 로 관리한다. styles.css전역에 지원하는 스타일을 선언한다. test.ts단위 테스트를 위한 관문. tsconfig.{applspec}.json타입스크립 컴파일러 구성 과 테스트 구성파일. ng 명령ng new, init, ng new 명령1ng new &lt;project-name&gt; [Options] –dry-run, -d: 시험 실행, 실제 프로젝트 파일은 만들지 않고 출력 파일만 생성한다. –verbose, -v: –skip : 프로젝트 생성 후에 npm 명령 실행 못한다. –skip-git: 이 프로젝트에는 git repository 생성 못한다. – : 새 프로젝트를 생성할 부모 디렉토리. 참조 https://www.tektutorialshub.com/create-first-angular-2-application/","link":"/2017/09/05/nodejs-2017-09-05-angular-tour-1/"},{"title":"NodeJS - mongoose middleware","text":"Middleware이 글은 mongoose middleware를 한글로 요약 정리한 것이다. 실제 본문을 요약하여 번역해 정리했으므로 이해가 안되는 부분은 위 링크의 내용을 참조하기 바란다. mongoose middlewarepre, post hook 이라고 불리는 mongoose middleware는 비동기 함수의 실행중 제어권을 다룰 수 있다. 미들웨어는 스키마 수순에서 사용고 plugins 를 작성하는데 유용하다. Mongoose 4.x 은 4종류의 미들웨어를 지원한다: document middleware model middleware aggregate middleware query middleware Document middleware는 아래 도큐멘트 함수를 지원한다. 도큐멘트 미들웨어에서 this 는 도큐멘트를 가르킨다. init validate save remove Query middleware 는 아래 모델과 쿼리 함수를 지원한다. 쿼리 미들웨어 함수에서 this 는 쿼리를 가르킨다. count find findOne findOneAndRemove findOneAndUpdate update Aggregate middleware 는 MyModel.aggregate() 를 위한것이다. Aggregate middleware는 aggregate 객체에서 exec() 를 호출할 때 실행된다.. 여기서 this 는 aggregation object를 가르킨다. aggregate Model middleware 는 아래 모델 함수에 대해 지원한다. 여기서 this는 모델을 가르킨다. insertMany Note: There is no query hook for remove(), only for documents. If you set a ‘remove’ hook, it will be fired when you call myDoc.remove(), not when you call MyModel.remove(). Note: The create() function fires save() hooks. 모든 미들웨어 형식은 pre와 post 훅(hook)을 지원한다. ### Pre middleware Serial과 parallel 이라는 두가지 pre 훅이 있다. #### Serial Serial middleware는 각 미들웨어가 next()를 호출하면 하나 다음 다른 하나를 실행한다. 12345var schema = new Schema(..);schema.pre('save', function(next) { // do stuff next();}); 그렇지만 next() 함수가 미들웨어의 다음 코드 실행을 멈추지 않기 때문에 return 패턴을 사용해서 코드 진행을 멈추면 된다. 123456789var schema = new Schema(..);schema.pre('save', function(next) { if (foo()) { console.log('calling next!'); // `return next();` will make sure the rest of this function doesn't run return next(); } console.log('after next');}); #### Parallel Parallel middleware는 제어를 더욱 정밀하게 할 수 있다. 아래는 Pre 훅에 true 인자를 전달해 parallel 미들웨어를 사용하게 하고, 이것은 save 인 경우 각 미들웨어에서 done 호출 전까지 실행하지 않는다는 의미이다. 12345678var schema = new Schema(..);// `true`: parallel middleware.schema.pre('save', true, function(next, done) { // calling next kicks off the next middleware in parallel next(); setTimeout(done, 100);}); #### Use Cases 미들웨어는 원자화 모델과 비동기 코드의 중첩을 회피하는데 유용한다. 아래 같은 사례: 복합 유효성 확인 의존하는 문서 삭제 (사용자에 관련한 모든 문서를 삭제) asynchronous defaults asynchronous tasks that a certain action triggers triggering custom events notifications #### 에러 처리 미들웨어에서 Error 형식 매개변수로 next(), done() 을 호출할 때 에러로 처리가 가로채지면 콜백 함수에 에러가 전달된다. 아래 같이 에러 발생시 new Error()를 생성해야 다음 next() 가 호출되지 않는다. 123456789schema.pre(&quot;save&quot;, function (next) { var err = new Error(&quot;something went wrong&quot;); next(err);});// later...myDoc.save(function (err) { console.log(err.message); // something went wrong}); ### Post middleware post middleware 는 pre middle 웨어가 완료되어 훅 메서드가 처리된 뒤에 실행된다. post 는 제어를 직접 하지 못한다. 예를 들어 next(), done() callback이 전달되면 post 훅은 이들 메서드를 이벤트 리스너에 등록하는 방법이다. 123456789101112schema.post(&quot;init&quot;, function (doc) { console.log(&quot;%s has been initialized from the db&quot;, doc._id);});schema.post(&quot;validate&quot;, function (doc) { console.log(&quot;%s has been validated (but not saved yet)&quot;, doc._id);});schema.post(&quot;save&quot;, function (doc) { console.log(&quot;%s has been saved&quot;, doc._id);});schema.post(&quot;remove&quot;, function (doc) { console.log(&quot;%s has been removed&quot;, doc._id);}); #### Asynchronous Post Hooks post가 선언된 순서에 따라 post hook이 비동기 적으로 실행되는데, callback function에 두 개의 인자를 전달하면 mongoose는 두번째를 next() 로 가정하고 순서에 따라 next를 트리거 호출한다. 1234567891011121314// Takes 2 parameters: this is an asynchronous post hookschema.post(&quot;save&quot;, function (doc, next) { setTimeout(function () { console.log(&quot;post1&quot;); // Kick off the second post hook next(); }, 10);});// Will not execute until the first middleware calls `next()`schema.post(&quot;save&quot;, function (doc, next) { console.log(&quot;post2&quot;); next();}); #### Save/Validate Hooks The save() 함수는 validate() hook을 유발하는데 이것은 pre('save') hook이 호출되면서 pre('validate') 와 post('validate') hook이 호출된다는 것이다. 123456789101112schema.pre(&quot;validate&quot;, function () { console.log(&quot;this gets printed first&quot;);});schema.post(&quot;validate&quot;, function () { console.log(&quot;this gets printed second&quot;);});schema.pre(&quot;save&quot;, function () { console.log(&quot;this gets printed third&quot;);});schema.post(&quot;save&quot;, function () { console.log(&quot;this gets printed fourth&quot;);}); #### Notes on findAndUpdate() and Query Middleware Pre 와 post save() hook은 update(), findOneAndUpdate() 등에서 호출되지 않는다. Mongoose 4.0 은 이들 함수에 다른 훅을 가지고 있다. 123456789101112schema.pre(&quot;find&quot;, function () { console.log(this instanceof mongoose.Query); // true this.start = Date.now();});schema.post(&quot;find&quot;, function (result) { console.log(this instanceof mongoose.Query); // true // prints returned documents console.log(&quot;find() returned &quot; + JSON.stringify(result)); // prints number of milliseconds the query took console.log(&quot;find() took &quot; + (Date.now() - this.start) + &quot; millis&quot;);}); document middleware에서 this 는 갱신하는 도큐멘트를 가르킨다. 그래서 update() 에 타임스탬프를 추가하고자 하면 아래 pre hook을 사용한다. 123schema.pre(&quot;update&quot;, function () { this.update({}, { $set: { updatedAt: new Date() } });}); Error Handling Middleware New in 4.5.0 일반적으로 next() 호출시 첫번째 error에서 멈추는데 특별한 post middleware로 “error handling middleware” 가 있다.Error handling middleware는 부가적으로 콜백 함수의 매개변수에 error가 전달되는데, 첫번째 인자로 error 를 전달한다. 123456789101112131415161718192021var schema = new Schema({ name: { type: String, // Will trigger a MongoError with code 11000 when // you save a duplicate unique: true, },});// Handler **must** take 3 parameters: the error that occurred, the document// in question, and the `next()` functionschema.post(&quot;save&quot;, function (error, doc, next) { if (error.name === &quot;MongoError&quot; &amp;&amp; error.code === 11000) { next(new Error(&quot;There was a duplicate key error&quot;)); } else { next(error); }});// Will trigger the `post('save')` error handlerPerson.create([{ name: &quot;Axl Rose&quot; }, { name: &quot;Axl Rose&quot; }]); Error handling middleware는 query middleware와도 동작한다. 예를 들어 update() 호출시 키 중철 에러를 처리하는 훅를 고려하면: 12345678910111213141516171819202122// The same E11000 error can occur when you call `update()`// This function **must** take 3 parameters. If you use the// `passRawResult` function, this function **must** take 4// parametersschema.post(&quot;update&quot;, function (error, res, next) { if (error.name === &quot;MongoError&quot; &amp;&amp; error.code === 11000) { next(new Error(&quot;There was a duplicate key error&quot;)); } else { next(error); }});var people = [{ name: &quot;Axl Rose&quot; }, { name: &quot;Slash&quot; }];Person.create(people, function (error) { Person.update( { name: &quot;Slash&quot; }, { $set: { name: &quot;Axl Rose&quot; } }, function (error) { // `error.message` will be &quot;There was a duplicate key error&quot; } );}); ## 참조 mongoose middleware plugins","link":"/2017/12/20/nodejs-2017-12-20-mongodb-mongoose-middleware/"},{"title":"Open API Web Token","text":"Open api keyAPI keys는 사용자 인증, 요청 API 호출을 위해 필요하다. 보통 RESTFull API 호출시 API keys 와 인증 스킴을 사용한다. 주요 차이는: API keys : 앱 혹은 사이트 호출을 식별해서 API 호출을 만다. Auth tokens : 앱 혹은 사이트 사용자를 식별한다. 이런 인증에 두가지 방식을 사용한다. Session-based Authentication Token-based Authentication Token based Authentication토큰 기반 인증은 Stateless Authentication 이 큰 이유이다. 클라이언트 측 로컬 스토리지 (혹은 세션, 쿠키 가능)에 저장된다. 좋은 예는 싱글 페이지 앱, Web ApIs, IoT가 있다 앱이 확장성이 있고 분리되야 한다면, Token 기반이 좋은 사례가 된다. Stateless Authentication: 인증에 대해 서버측이 인증 정보를 보존하지 않는다. JWTJWT(JSON Web Tokens)는 REST API를 사용한 간단하고 보안이 적용된 인증 전략이다. 웹 인증을 위한 표준이고 JSON token 요청을 기반으로 한다. 인증 서버에서 발급한 토큰을 클라이언트가 요청시 마다 헤더에 토큰을 넣어 요구해야 한다. MEAN 스택 앱에 빠르게 인증을 추가하는 것은 JSON Web Token 을 사용할 수 있다. How JWT Works?Node Js JWT Authentication Tutorial From Scratch JSON Web Token is the token; we need to put the header in every request to verify the client. The Architecture of JWT Authentication is pretty darn simple. First user attempt to login with their credentials. After server verifies the credentials, it sends JSON Web Token to the client. A client then saves that token in local storage or any other storage mechanism. Again if a client wants to request a protected route or resource, then it sends JWT in a request header. The server verifies that JWT and if it is correct then return a 200 response with the information, client needs. If the JWT is invalid, then it gives unauthorized access or any other restricted message. Node js JWT Authentication In this tutorial, we are not using any front-end framework. We will use POSTMAN to request the server. We will check the auth using token. So let us get started. Step 1: Install node js dependencies.Create one project folder and go into that folder. Type the following command. 1npm init Now, install the following dependencies. 1npm install express jsonwebtoken mongoose body-parser --save It will install the express web framework, jsonwebtoken package to authenticate the user, mongoose schema model, and body-parser middleware. Also, we need to install the nodemon development server to prevent the stop and restart the server process. So let us do that first. 1npm install nodemon --save-dev Rest dependencies we will install as our project grows. Step 2: Configure the Node Server.In the package.json file, change this object to the following. 123&quot;scripts&quot;: { &quot;start&quot;: &quot;nodemon server&quot;}, So in the terminal when we type npm start command, we bootstrap the server.js file.In the root folder, make one file called server.js. Configure the node server. 1234567891011// server.jsconst express = require(&quot;express&quot;);const app = express();const bodyParser = require(&quot;body-parser&quot;);const PORT = 3000;app.listen(PORT, function () { console.log(&quot;Server is running on Port&quot;, PORT);}); Now, go to terminal and hit the following instruction. 1npm start It will start the server, you can see it on a console. So it is ready to consume any request, either web or API. Step 3: Send a request to node server via Postman.First, we define one route and send the JSON response to the client. 1234567// server.jsapp.get(&quot;/checking&quot;, function (req, res) { res.json({ Tutorial: &quot;Welcome to the Node express JWT Tutorial&quot;, });}); Open the Postman and send the get request to http://localhost:3000/checking. Postman Tutorial Step 4: Configure the MongoDB Database.Write the following code to connect the Node.js application to the MongoDB database. if below mongoose 3.x, 123// server.jsconst mongoose = require(&quot;mongoose&quot;);mongoose.connect(&quot;mongodb://localhost/jwtauth&quot;); Then use above mongoose 4.x, prepare Promise and connect(). 123456// Mongodbmongoose.Promise = global.Promise;mongoose.connect(&quot;mongodb://student:PW@localhost/students&quot;, { useMongoClient: true,}); Also, write the body-parser middleware to the application. 1234// server.jsapp.use(bodyParser.urlencoded({ extended: false }));app.use(bodyParser.json()); Step 5: Create a User model.Create one new folder inside root called models. In that, create one file called user.model.js file. 1234567891011// user.model.js&quot;use strict&quot;;const mongoose = require(&quot;mongoose&quot;);const user = mongoose.Schema({ //_id: mongoose.Schema.Types.ObjectId, email: { type: String, required: true }, password: { type: String, required: true },});module.exports = mongoose.model(&quot;User&quot;, user); We have defined the schema for the User collection. Step 6: Create the routes for users.In the root, make one folder called routes. In that folder, create one file called user.route.js. Now we need to sign the user up for our application. So let us define the post route to signup the user. We also need a bcrypt module to hash the password. We can not store the plain password. So let us install bcrypt module first. 1npm i bcrypt Next, write the following code into the user.route.js file. 123456789101112131415161718192021222324252627282930313233343536373839// user.route.jsconst express = require(&quot;express&quot;);const router = express.Router();const mongoose = require(&quot;mongoose&quot;);const bcrypt = require(&quot;bcrypt&quot;);const User = require(&quot;../models/user.model&quot;);router.post(&quot;/signup&quot;, function (req, res) { bcrypt.hash(req.body.password, 10, function (err, hash) { if (err) { return res.status(500).json({ error: err, }); } else { // const user = new User(req.body); const user = new User({ // _id: new mongoose.Types.ObjectId(), email: req.body.email, password: hash, }); user .save() .then(function (result) { console.log(result); res.status(200).json({ success: &quot;New user has been created&quot;, }); }) .catch((error) =&gt; { res.status(500).json({ error: err, }); }); } });});module.exports = router; What it does is that it tries to hash the incoming request’s password property. If it fails to do so then returns a response with an error in json format. If it successes then it will create a new user and add that to the MongoDB database. Now include this user.route.js file in the server.js file. I am writing the whole file now. 1234567891011121314151617181920212223242526// server.jsconst express = require(&quot;express&quot;);const app = express();const bodyParser = require(&quot;body-parser&quot;);const user = require(&quot;./routes/user.route&quot;);const mongoose = require(&quot;mongoose&quot;);mongoose.connect(&quot;mongodb://localhost/jwtauth&quot;);const PORT = 3000;app.use(bodyParser.urlencoded({ extended: false }));app.use(bodyParser.json());app.get(&quot;/checking&quot;, function (req, res) { res.json({ Tutorial: &quot;Welcome to the Node express JWT Tutorial&quot;, });});app.use(&quot;/user&quot;, user);app.listen(PORT, function () { console.log(&quot;Server is running on Port&quot;, PORT);}); Step 7: Send a post request from the Postman.postman 에서 POST 방식으로 새 사용자를 추가해 보자, POST에서 Body를 Raw 이고 형식은 json(application/json) 를 선택하고 작성한다. 123456{ &quot;firstName&quot;: &quot;&quot;, &quot;lastName&quot;: &quot;&quot;, &quot;email&quot;: &quot;&quot;, &quot;password&quot;: &quot;&quot;} {:width=”500”} [그림. Postman에서 JSON 포스트] You can see here, I have created user successfully. Now, I am using Studio 3T for MongoDB. So here is the newly created user in the database. 이제 실제 암호화된 비밀번호로 생성된 사용자 정보를 확인할 수 있다. {:width=”500”} [그림. 새 사용자 정보] MongoDB Tutorial With An Example Step 8: Sign In the User.사용자가 생성되고 비밀번호로 bcryp로 비밀번호가 생성되면 bcrypt.compare() 를 사용해 사용자 비밀번호를 인증할 수 있다. 12345678910111213141516171819202122232425262728// user.route.jsrouter.post(&quot;/signin&quot;, function (req, res) { User.findOne({ email: req.body.email }) .exec() .then(function (user) { bcrypt.compare(req.body.password, user.password, function (err, result) { if (err) { return res.status(401).json({ failed: &quot;Unauthorized Access&quot;, }); } if (result) { return res.status(200).json({ success: &quot;Welcome to the JWT Auth&quot;, }); } return res.status(401).json({ failed: &quot;Unauthorized Access&quot;, }); }); }) .catch((error) =&gt; { res.status(500).json({ error: error, }); });}); 사용자 이메일로 허가된 사용자인지 인증하는데, 이메일이 존재하지 않으면 401 unauthorized access 에러를 출력한다. {:width=”500”} [그림. Postman에서 Sign 포스트] First, I have checked if the user’s email exists or not. If not then return 401 unauthorized access. If email is there then check the password with bcrypted database password if match found then welcome to the JWT auth else 401 unauthorized access. 이메일로 사용자 검색이 되고 비밀번호 인증이 되면 환영 JWT auth를 반환하고 아니면 401 unauthorized access 를 반환하게 한다. Step 9: Return the JWT, if auth attempt successful.사용자 증명인 이메일과 패스워드가 유효하면 JWT token을 반환하도록 하자, jwt.sign() 함수는 기본으로 HMAC SHA256 해시 코드를 발생한다. 1234jwt.sign({ email: user.email, _id: user._id} 다른 알고리즘이 필요하면 algorighm 속성을 제시해 준다. 12345jwt.sign({ email: user.email, _id: user._id, { algorithm: 'RS256'}} If the user’s credentials email and password are valid then in response, we need to return a JWT token. So let us generate the token and return to the user. 1234567891011121314151617181920// user.route.jsconst jwt = require(&quot;jsonwebtoken&quot;);if (result) { const JWTToken = jwt.sign( { email: user.email, _id: user._id, }, &quot;secret&quot;, { expiresIn: &quot;2h&quot;, } ); return res.status(200).json({ success: &quot;Welcome to the JWT Auth&quot;, token: JWTToken, });} JWT Token의 형식은 HEADER, PAYLOAD, SECRETKEY 조합으로 아래 같다: The format of JWT Token is as following. HEADER: ALGORITHM &amp; TOKEN TYPE 1234{“alg”: “HS256”,“typ”: “JWT”} PAYLOAD:DATA 123456{“email”: “krunallathiya10@gmail.com”,“_id”: “5a7c9bd8fc3e501c94aa6035”,“iat”: 1518120124,“exp”: 1518127324} VERIFY SIGNATURE 12345HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 조합으로 생성한 JWT는 아래 같은 JWT Token을 반환한다. So it is a combination of header, payload, and secretkey, we are providing. Remember, You need to define your secret key in your environment variable file. I have just shown here for the demo purpose. So it will produce the following JWT token. 1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImtydW5hbGxhdGhpeWExMEBnbWFpbC5jb20iLCJfaWQiOiI1YTdjOWJkOGZjM2U1MDFjOTRhYTYwMzUiLCJpYXQiOjE1MTgxMjAxMjQsImV4cCI6MTUxODEyNzMyNH0._6qVGQV_KYlonawnaTHG-OhOJLV4tgD-Eob5iRz89AM 이 토큰을 제한된 자원에 접근하는 앱에 사용할 수 있다. Now use this token to access the protected resources to your application and we are done here. So this is how you can generate the JWT Auth Token. JWT Token verifyingjwt.verify()를 사용해 발급한 토큰이 허용되는지 검증할 수 있다. jwt.verify(token, secretOrPublicKey, [options, callback]) token: 발행된 Json Web Token secretOrPublicKey: 토큰 발행시 제공한 시크릿 키 1234567891011router.post(&quot;/verify&quot;, function (req, res) { const user = User.findOne({ email: req.body.email }); // check expired? jwt.verify(req.body.token, user.secret_key, function (err, decoded) { if (err) { console.log(err); return res.status(200).json(err); } });}); 참조 npm:JSONWebToken Node Js JWT Authentication Tutorial From Scratch Why and When to Use API Keys https://appdividend.com/2018/02/07/node-js-jwt-authentication-tutorial-scratch/ Securing Node.js RESTful APIs with JSON Web Tokens","link":"/2018/06/02/nodejs-2018-06-02-restfull-openapi-jwt-token/"},{"title":"Linux - X Forwarding","text":"SBC 보드 (raspberry pi, odroid c2 등)를 Terminal 기반으로 사용하려고 할 때 GUI에서 Programming을 확인해야 할 경우 X11, VNC 등을 이용할 수 있다. 여기서는 X Forwarding 기법을 정리하고 있다. [^1]: Single Board Computer X11 ForwardingX11은 유닉스/리눅스의 전통적 데스크탑 프로토콜로 GUI 데스크탑 환경을 X11 Protocol을 사용해서 로컬 혹은 원격지 컴퓨터에서 이용할 수 있게 설계되어 있다. X Windows: X ming윈도우즈에서 X ming 환경을 구축하면 X window system을 사용할 수 있다. X client: MobaXterm윈도우 플랫폼은 다양한 X window 제품들이 있다. 최근 재미있게 사용해본 것으로 MobaXterm이 있는데, 이 제품은 유료 제품으로 Trial 을 제공하고 있다. 특징적으로 Xserver와 SSH client를 내장하고 있어서 손쉽게 리눅스 제품과 연결해 사용할 수 있다. [그림. MobaXterm 이미지] ssh를 이용해 X server에 접속하는 것 만으로도 X client 동작을 수행하고, 탭으로 구분한 ssh client 관리가 장점이며, sftp 를 이용해 서버측 파일을 브라우징 할 수 있는 장점이 있다. 단, 기업용은 유료이므로 주의가 필요하다. ### macOS/Linux 데스크탑 X Window를 지원하는 리눅스 데스크탑 혹은 맥오에스에서 ssh로 X11 Forwarding 사용할 수 있다. [그림. SSH와 X11 Tunnel 구조] X forwarding을 활성화 해서 ssh를 연결하려면 ssh -X 옵션을 추가해서 접속한다. Mac에서 X11설정Mac OS X는 OX X 10.5 이후 부터 X11을 포함하고 있지 않는다. Apple은 OS X의 X11을 더 개발하고 지원하기 위한 조직적인 노력으로 XQuartz 프로젝트를 만들었습니다. https://support.apple.com/ko-kr/HT201341 http://xquartz.macosforge.org XQuartz 를 설치해서 지원을 받아야 한다. xquartz 사이트에서 다운받아 설치한다. [그림. macOS X: Download Xquartz] 설치후 맥에서 로그아웃후 로그인 하면 X11 관련 설정과 응용프로그램을 XQuartz 기반으로 사용할 수 있다. X11 Forwarding 설정맥에서는 sshd 설정이 /private/etc/ssh/sshd_config 파일에 있다. 여기에 X11 client 요청을 허용하도록 X11Forwarding을 허용해야 한다. 1user@mac~$ sudo vi /private/etc/sshd_config 내용중에서 X11Forwarding를 찾아 다음 같이 허용으로 저장한다 1X11Forwarding yes 마지막으로 Mac에서 외부에서 요청한 X11 연결을 허용해 준다. 12user@mac~$ xhost +access control disabled, clients can connect from any host X11 이용이제 리눅스/맥 클라이언트에서 원격 서버에 -X 옵션을 이용해서 로그인 한다. 1user@mac~$ ssh -X pi@192.168.1.10 이제 원격지에서 X11 응용 프로그램을 실행해 보겠습니다. 다음은 X11 terminal 프로그램을 실행하면 Mac의 화면에 X11 terminal이 실행됩니다. 123pi@raspberrypi ~ $ netsurf-gtk ORpi@raspberrypi ~ $ lxterminal 라즈베리파이의 xterminal 프로그램이 Mac 실행됩니다. [그림. Ssh와 X Forwarding] 만약 다음 에러를 만나면 접속을 종료하고 Mac의 xhost 접속 허용을 다시 해주어야 한다. (lxterminal:20700): Gtk-WARNING **: cannot open display: localhost:10.0 혹은 원격 서버에 로그인 없이 직접 실행할 수 있습니다 12user@mac~$ ssh -X -f pi@192.168.1.205 lxterminalpi@192.168.1.205's password: 기타 X11 Appxterminal 이외의 X11 앱을 사용하려면 다음 패키지를 설치해 준다. 12~ $ sudo apt install libnss3~ $ sudo apt install x11-apps","link":"/2016/02/10/linux-2016-02-10-linux-x-forwarding/"},{"title":"Linux LVM2","text":"2018-09-19 when umount, device busy!2018-06-23 mount 명령{: history-right} LVM2Odorid C2에 USB Memory를 사용해서 리눅스의 LVM을 이용하고 있다. 여기서는 LVM 설정에 대해서만 다루고 있다. Single board computer 종류의 보드는 주 디스크로 SD Card, eMMC 를 사용하고, USB 메모리 등은 디바이스 장치로 /dev/sd* 이름으로 접근할 수 있다. 디스크 파티션시스템에 사용할 디스크 파티션을 생성한다. 그리고 사용할 디스크 파티션 종류 LVM으로 해야 한다. parted 혹은 fdisk 를 사용해서 디스크 볼륨을 생성하고 사용한다. parted대상 디스크 목록을 통해 디스크의 크기 정보를 확인한다. 1sudo parted -l parted로 lvm 볼륨 잡기 12345678910111213sudo parted /dev/sdb(parted) mklabel gptWarning: The existing disk label on /dev/sda will be destroyed and all data onthis disk will be lost. Do you want to continue?Yes/No? y(parted) unit GB(parted) mkpart primary 0 32.0GB #디스크 크기 입력(parted) set 1 lvm on(parted) printNumber Start End Size File system Name Flags 1 0.00GB 32.0GB 32.0GB primary lvm fdisk 사용대상 디스크 목록을 통해 디스크의 크기 정보를 확인한다. 1sudo fdisk -l fdisk로 파티션을 시작한다. 123456789# fdisk /dev/sdaCommand (m for help): pCommand (m for help): gCommand (m for help): nLast sector, +sectors or +size{K,M,G,T,P} (2048-125042654, default 125042654): +4GCommand (m for help): tHex code (type L to list all codes): 30Changed type of partition 'Linux filesystem' to 'Linux LVM'.Command (m for help): w 이제 새로운 파티션 ‘/dev/sda1’ 이 생성됐다. LVM 생성하기 LVM 종류로 파티션한 볼륨으로 Pysical volume 을 생성한다. Pysical volume을 Volume Group으로 등록한다. 실제 사용할 크기 만큼 Logical Volume으로 나눠 생성한다. 파일 시스템을 생성하고 마운트 한다. 시스템에 lvm2 를 설치한다. 1$ sudo apt install lvm2 Pysical Volume 만들기파티션을 Pysical volume으로 만든다. 12345$ sudo -s# pvcreate /dev/sda1 /run/lvm/lvmetad.socket: connect failed: No such file or directory WARNING: Failed to connect to lvmetad. Falling back to internal scanning. Physical volume &quot;/dev/sda1&quot; successfully created 이제 물리볼륨을 로지컬 볼륨 그룹으로 나누고 1234# vgcreate vg_usb /dev/sdb1 Volume group &quot;vg_usb&quot; successfully created# vgdisplay 볼륨그룹 지우기 12# vgremove vg_usb Volume group &quot;vg_usb&quot; successfully removed Logical Volume 만들기로지컬 볼륨을 만든다. 용량은 -L 과 -l 옵션을 사용 -L [GB/KB/B..] 단위 용량 -l PE PE 용량 단위 - vgdisplay 에 표시되는 PE 개수 여기서 두개의 로지컬 볼륨을 만든다고 가정한다. 1234# lvcreate -L +20G -n dbvol vg_usb Logical volume &quot;dbvol&quot; created.# lvcreate -L +9GB -n workvol vg_usb Logical volume &quot;workvol&quot; created. 생성한 로지컬보륨은 lvdisplay로 자세한 정보를 확인할 수 있다. 로지컬 볼륨을 지우려면 lvremove로 볼륨그룹 밑에 있는 로지컬보륨을 삭제한다. 1# lvremove /dev/vg_usb/dbvol 이제 로지컬볼륨이 준비됐고, 실제 파일 시스템을 생성한다. 파일시스템 생성mkfs 명령으로 파일 시스템을 생성한다. 12# mkfs.ext4 /dev/vg_usb/dbvol# mkfs.ext4 /dev/vg_usb/workvol 부팅시 항상 마운트하기 위해서 fstab에 등록해야 하는데, fstab에 아운트 지점을 지정하는 방법은 디바이스 드라이브의 경로 혹은 UUID를 명시하는 것이다. LVM도 다르지 않는데 먼저 fstab에 등록해서 마운트 하기 위해서 lvdisplay 명령으로 LV path 를 확인한다. 123456# lvdisplay --- Logical volume --- LV Path /dev/vg_usb/dbvol --- Logical volume --- LV Path /dev/vg_usb/workvol /etc/fstab에 LV Path 경로를 추가 한다. 12/dev/vg_usb/dbvol /data ext4 defaults 0 1/dev/vg_usb/workvol /home/pi/work ext4 defaults 0 1 UUID를 사용하려면 위에 찾은 LV Path에 해당하는 UUID를 찾아야 한다.^1 먼저 LV path 경로를 보면 12$ ll /dev/vg_usb/dbvollrwxrwxrwx 1 root root 7 May 2 18:18 /dev/vg_usb/dbvol -&gt; ../dm-0 같이 링크로 나온다. 이 링크 파일의 UUID를 찾으면 된다. 12$ ls -l /dev/disk/by-uuid/lrwxrwxrwx 1 root root 10 May 2 18:18 a7bb8085-0e50-845a-b65b-a6b7e8c86dc9 -&gt; ../../dm-0 찾은 UUID를 fstab에 마운트 지점과 함께 기록한다. 1UUID=a7bb8085-0e50-845a-b65b-a6b7e8c86dc9 /data ext4 defaults 0 0 UUID=”680C0FE30C0FAAE0” /jgdata ntfs user,auto,rw 0 0 LVM 사이즈 키우기1# lvextend -L +10M /dev/um_vg/xfs_lv -r ### LVM 을 새 시스템에 장착하기 LVM으로 생성한 볼륨그룹을 다른 시스템에서 사용하려면 Volume group을 이용한다. volume group 비활성화 volume group 추출 새 시스템에서 volume group 가져오기 새 시스템에서 volume group 활성화 새 시스템에서 마운트 1. vgscan으로 확인123# vgscan Reading all physical volumes. This may take a while... Found volume group &quot;vg_usb&quot; using metadata type lvm2 2. vg 추출12# vgexport vg_usb Volume group &quot;vg_usb&quot; successfully exported 이제 새 시스템에서 추출한 volume group을 활성화 한다. 3. PV 파티션 확인pvscan으로 파티션을 확인한다. 비활성화하고 추출한 파티션을 확인할 수 있다. 123# pvscan PV /dev/sda2 is in exported VG vg_usb [55.62 GiB / 25.62 GiB free] Total: 1 [55.62 GiB] / in use: 1 [55.62 GiB] / in no VG: 0 [0 ] vbimport 로 volume group을 가져온다. 12# vgimport vg_usb Volume group &quot;vg_usb&quot; successfully imported 4. VG 활성화12# vgchange -ay vg_usb 1 logical volume(s) in volume group &quot;vg_usb&quot; now active 마운트 하기 위해서 볼륨그룹은 장치는 dev 밑에 보륨그룹 이름 /dev/vg_usb 같이 생성되므로 ls 명령으로 확인 가능 12# ls /dev/vg_usb/mongovol workvol 혹은 lvdisplay 명령으로 LV path 를 확인한다. 1234567891011121314151617# lvdisplay --- Logical volume --- LV Path /dev/vg_usb/dbvol LV Name dbvol VG Name vg_usb LV UUID hTnMaP-6rgM-ePOi-HXs4-X0Ia-h4mP-gpT1JM LV Write Access read/write LV Creation host, time odroid64, 2016-12-02 15:05:45 +0900 LV Status available # open 0 LV Size 30.00 GiB Current LE 7680 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 mount 명령으로 LV path를 마운트 한다. 12345# mount /dev/vg_usb/dbvol mongodata/...# mount.../dev/mapper/vg_usb-dbvol on /data type ext4 (rw,relatime,data=ordered) 재시동 후 마운트를 유지하기 위해 마운트한 경로를 /etc/fstab에 추가한다. LVM error기존 LVM 디스크를 사용하던 OS에 타 시스템에서 생성한 LVM을 옮겨와 사용하려면 다음 같이 lvmetad 에러가 난다. /run/lvm/lvmetad.socket: connect failed: No such file or directory lvm2 서비스를 활성화하고 시작해 주면 된다. 1234sudo systemctl enable lvm2-lvmetad.servicesudo systemctl enable lvm2-lvmetad.socketsudo systemctl start lvm2-lvmetad.servicesudo systemctl start lvm2-lvmetad.socket ### Unmount - It's busy LVM 볼륨을 사용중 마운트를 해제하려고 할 때 다음 같은 경고가 난다. 1234sudo umount /dataumount: /data: target is busy (In some cases useful info about processes that use the device is found by lsof(8) or fuser(1).) fuser 명령 lsof 명령으로 해당 디렉토리를 사용중인 파일, 프로세스를 확인할 수 있다. 1234$ sudo fuser -vm /data USER PID ACCESS COMMAND/data: root kernel swap /data/.swap4G root kernel mount /data lsof로 어떤 프로세스가 디렉토리를 사용하는지 출력해 볼 수 있다. 123$ sudo lsof +D /dataCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbash 23617 qkboo cwd DIR 179,1 4096 129793 . xfs 파일시스템 주의: USB 메모리를 사용한 디스크에서 mongodb에 사용하기 위해서 시작했는데, 최신 mongodb의 storage engine인 WiredTiger는 xfs를 요구한다. 다만 Odroid C2 의 Ubuntu, Ambian 에서 xfsprogs 설치후 xfs 파일 시스템 생성시 문제가 있다. 1# apt install xfsprogs 디스크 볼륨을 xfs file system 생성한다. 1# mkfs.xfs /dev/usb64_vg/db_xfs ## 참조 Create xfs filesystem based LVM [LVM Resize](&gt; https://www.rootusers.com/lvm-resize-how-to-decrease-an-lvm-partition/)","link":"/2017/04/03/linux-2017-04-03-odroid-lvm2/"},{"title":"Odroid - Install Linux","text":"2018-07-10: UART 정보 추가2017-07-24: exFAT 추가{:.right-history} Odroid C2 - Install Armbian{: width=”600”} [그림. armv8 Odroid C2] 다음은 Odroid C2에 Ubuntu 16.04 minimal 버전, 그리고 Ambian Jessie를 설치하고, 처음 설정에 대한 것이다. Odroid에서 제공하는 64bit Ubuntu 설치 Ambian 64bit Debian jessi 설치 sudoer 사용자 사용 hostname 설정 swap 사용 Ambian for OdroidArmbian에서 데스크탑 버전으로 Ubuntu 와 서버 버전으로 Debian Jessie를 다운로드 가능하다. {: width=”600”} 여기서는 Debian Jessie 버전을 사용한다. 준비사항Micro SD Card를 사용하면 가능하면 UHX-1 Class 10 를 사용하도록 한다. Odroid C2는 Micro SD Card 혹은 eMMC Card로 부팅 디스크를 구성할 수 있다. Micro SD Card: UHX-1 Class 10 이상 SDHX Class 8에서 사용중인데, 큰 문제는 없지만 SD Card에 영향을 받는 듯 하다. DownloadAmbian Download 에서 Odroid C2 이미지 에서 Debian server를 다운 받는다. 서버는 7z 파일로 되어 있어서 Windows에서는 7-Zip 프로그램, macOS에서는 Keka Linux에서 7z linux 7z은 apt-get install p7zip-full 으로 설치한다. 모든 플랫폼에서 사용 가능한 저수준 이미지 쓰기 프로그램 **Etcher**도 권장한다. Etcher 사용모든 플랫폼에서 이미지 쓰기가 가능한 Etcher 사용을 권장한다. 다운로드한 Debian_jessie_default.7z 이미지 파일을 선택하고 선택한 SD Card에 이미지를 쓴다. {: width=”600”} dd 사용다운로드한 Debian_jessie_default.7z 이미지를 압축 해제하고, SD Card를 슬롯에 넣고, SD Card의 디스크 번호를 확인하고, 마운트를 해제한다. 여기서 macOS를 사용하고 Disk Utility 를 이용한다. 12$ diskutil list #디스크 번호 확인$ diskutil unmountDisk /dev/disk1 #마운트 해제 dd를 사용해 오에스이미지를 쓴다. 1$ sudo dd if=Debian_jessie_default.img of=/dev/rdisk1 bs=1M conv=fsync Verifying the burned image with Linux오에스 이미지 파일의 md5 값과 디스크에 쓴 이미지의 해시 값을 비교할 수 있다. 1234567891011$ sudo dd if=&lt;/dev/path/of/card&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.153662 s, 559 MB/s9b085251a00ad7ae16fe42fbfb25c042 -$$ dd if=&lt;my/odroid/image.img&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.140843 s, 610 MB/s9b085251a00ad7ae16fe42fbfb25c042 - 두 값이 일치해야 한다. OS를 쓴 SD Card 로 부팅하고 시스템 구성과 설정을 할 수 있다. 사용자 인터페이스로 사용하기 위해 HDMI, Keyboard 그리고 마우스가 필요하다. 만약 GUI 인터페이스 사용이 여의치 않으면 다음 같이 Serial Console을 이용해 접근할 수 있다. Serial Console 이용Odroid C2는 아래 같이 Serial Port 를 제공하고 있다. ^1 {: width=”6400”} [그림. Odroid C2 의 UART (그림. wiki.odroid.com)] 시스템 설정기본 아이디 root / 1234 로 로그인 가능하고 즉시 비밀번호를 변경해야 한다. 또한 사용자 계정을 만들어 사용해야 한다. 1234567891011121314151617181920212223242526272829303132333435Welcome to ARMBIAN Ubuntu 16.04 LTS 3.4.112-sun8iSystem load: 1.17 Up time: 2 minIP: 192.168.11.122CPU temp: 51°CUsage of /: 17% of 7.3GChanging password for root.(current) UNIX password:Enter new UNIX password:Retype new UNIX password:Thank you for choosing Armbian! Support: www.armbian.comCreating new account. Please provide a username (eg. your forename): qkbooAdding user `qkboo' ...Adding new group `qkboo' (1000) ...Adding new user `qkboo' (1000) with group `qkboo' ...Creating home directory `/home/qkboo' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for qkbooEnter the new value, or press ENTER for the default Full Name []: Qkboo Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] yDear Qkboo, your account qkboo has been created and is sudo enabled.Please use this account for your daily work from now on. upgrade1# apt update &amp;&amp; apt dist-upgrade &amp;&amp; apt upgrade 업그레이드 중 1The following packages have been kept back: linux-image-c2 기존 리눅스 이미지를 지우고 업그리이드 중 에러가 나서 이미지 업그레이드가 안되었으므로, 이전 버전 이미지를 찾아 삭제해 주면 다시 업그레이드가 된다. 1234567# apt --installed list |grep linuxlinux-image-3.14.65-73/unknown,now 20160802 arm64 [installed,automatic]linux-image-3.14.79-94/unknown,now 20161121 arm64 [installed,automatic]linux-image-c2/now 73-1 arm64 [installed,upgradable to: 94-1]linux-libc-dev/xenial-updates,xenial-security,now 4.4.0-51.72 arm64 [installed]util-linux/xenial-updates,now 2.27.1-6ubuntu3.1 arm64 [installed] 이전 버전 이미지를 지운다. 업그레이드 후 uname 확인 12345678root@odroid64:~# apt autoremove linux-image-3.14.65-73...Preparing to unpack .../linux-image-c2_94-1_arm64.deb ...Unpacking linux-image-c2 (94-1) over (73-1) ...Setting up linux-image-c2 (94-1) ...# uname -aLinux odroid64 3.14.79-94 #1 SMP PREEMPT Mon Nov 21 17:13:27 BRST 2016 aarch64 aarch64 aarch64 GNU/Linux hostnamedebian 계열에서 hostname을 변경하려면 hostnamectl 을 사용한다. 1234567891011121314$ sudo -s# hostnamectl set-hostname dlp# show settingsroot@debian:~# hostnamectl Static hostname: dlp Icon name: computer-vm Chassis: vm Machine ID: 5f47b11299ed4689a48a7f78197e452a Boot ID: bdeed3b6c079405bb45d79eff3e870a5 Virtualization: vmware Operating System: Debian GNU/Linux 8 (jessie) Kernel: Linux 3.16.0-4-amd64 Architecture: x86-64 Timezone1# dpkg-reconfigure tzdata bash-completionminimal 버전에는 bash-completion 을 다시 설치해 준다. 1$ sudo apt install bash-completion --reinstall Swap 추가여유 디스크에 swap을 추가하려면 123$ sudo mkswap /dev/sda1$ sudo swapon /dev/sda1$ sudo swapon -s swap 파일로 만들려면 12345$ sudo dd if=/dev/zero of=/data/swap4G bs=1G count=4$ sudo chmod 600 /swapfile$ sudo mkswap /swapfile$ sudo swapon /swapfile$ sudo swapon -s swapoffswap 을 지우려면 12swapoff /swapfilerm /swapfile ## Ubuntu 16.04 설치 Micro SD Card를 사용하면 가능하면 UHX-1 Class 10 를 사용하도록 한다. 준비사항Odroid C2는 Micro SD Card 혹은 eMMC Card로 부팅 디스크를 구성할 수 있다. Micro SD Card: UHX-1 Class 10 이상 SDHX Class 8에서 사용중인데, 큰 문제는 없지만 SD Card에 영향을 받는 듯 하다. 다운로드 사이트에서 Download 한다. Write a imagemacOS를 사용하고 있어서 macOS의 diskutil 명령을 사용해 SD Card에 접근했다. 1diskutil list # 디스크 목록에서 SD Card의 디바이스 파일 찾는다. 그리고 쓸려는 SD Card를 Unmount 해준다. 1diskutil unmountDisk /dev/disk1 다운받은 xz 파일을 dd 명령으로 SD Card 메모리 디스크에 쓴다. 1xzcat ubuntu64-16.04-minimal-odroid-c2-20160815.img.xz | sudo dd of=/dev/rdisk1 bs=1M conv=fsync macOS는 /dev/disk[1,2..] 의 디바이스 파일과 /dev/rdisk[1,2…]의 raw disk 디바이스 파일이 있다. 실제 쓸때 rdisk 파일을 사용하도록 권장하고 있다. Verifying the burned image with Linux12345678910$ sudo dd if=&lt;/dev/path/of/card&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.153662 s, 559 MB/s9b085251a00ad7ae16fe42fbfb25c042 -$ dd if=&lt;my/odroid/image.img&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.140843 s, 610 MB/s9b085251a00ad7ae16fe42fbfb25c042 - 첫번째 부팅기본 유저는 root/odroid 로 설정되어 있다. root의 기본 패스워드를 변경하고, sudo 사용자를 추가해 사용하도록 하자. upgradeupgrade시 dist-upgrade 는 꼭 해주도록 하자. kernel 관련 업그레이드를 완성시켜 준다. 1# apt update &amp;&amp; apt dist-upgrade &amp;&amp; apt upgrade 업그레이드 하는 도중 아래 같은 에러가 발생하면, The following packages have been kept back: linux-image-c2 기존 리눅스 이미지를 지우고 업그리이드 중 에러가 나서 이미지 업그레이드가 중단되어서 그렇다. 이전 버전 이미지를 찾아 삭제해 주면 다시 업그레이드가 된다. 1234567# apt --installed list |grep linuxlinux-image-3.14.65-73/unknown,now 20160802 arm64 [installed,automatic]linux-image-3.14.79-94/unknown,now 20161121 arm64 [installed,automatic]linux-image-c2/now 73-1 arm64 [installed,upgradable to: 94-1]linux-libc-dev/xenial-updates,xenial-security,now 4.4.0-51.72 arm64 [installed]util-linux/xenial-updates,now 2.27.1-6ubuntu3.1 arm64 [installed] 이전 버전 이미지를 지운다. 업그레이드 후 uname 확인 12345678root@odroid64:~# apt autoremove linux-image-3.14.65-73...Preparing to unpack .../linux-image-c2_94-1_arm64.deb ...Unpacking linux-image-c2 (94-1) over (73-1) ...Setting up linux-image-c2 (94-1) ...# uname -aLinux odroid64 3.14.79-94 #1 SMP PREEMPT Mon Nov 21 17:13:27 BRST 2016 aarch64 aarch64 aarch64 GNU/Linux Odroid의 Ubuntu는 root 계정을 기본으로 제공하고 있다. 일반 사용자를 등록해 sudoer로 사용하도록 한다. sudo 새 사용자 등록sudo 사용자를 추가해서 사용하려면, adduser 혹은 useradd 명령을 사용해서 사용자를 등록 할 수 있다. 새 사용자 등록먼저 adduser는 추가할 사용자에 대한 정보를 하나씩 물어 가며 등록이 진행되고, 사용자 홈을 생성해 준다. 1234567891011121314151617$ sudo adduser qkbooAdding user `qkboo' ...Adding new group `qkboo' (1000) ...Adding new user `qkboo' (1000) with group `qkboo' ...Creating home directory `/home/qkboo' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for qkbooEnter the new value, or press ENTER for the default Full Name []: Gangtai Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] y useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. http://www.tecmint.com/add-users-in-linux/ ‘useradd‘ 명령은 크게 두가지 일을 한다: 추가한 사용자에 대한 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 편집 사용자 홈 디렉토리 생성 1$sudo useradd -m qkboo 그리고 패스워드를 등록한다. 1234$ sudo passwd qkbooNew password:Retype new password:passwd: password updated successfully sudoer 등록처음 로그인후 새로운 사용자 등록하고 suders에 직접 권한을 줄 수 있다.새로 등록한 혹은 사용자를 sudo 그룹에 등록해 둔다. 1# usermod -aG sudo USERNAME 혹은 visudo 명령으로 sudoers 파일을 편집할 수 있습니다. sudoer에 있는 root는 제외하고 사용자로 등록한다. 1234$ sudo visudo# User privilege specificationroot ALL=(ALL:ALL) ALLpi ALL=(ALL:ALL) ALL 기본 에디터 변경odroid의 ubuntu 16.04는 기본에디터로 joe가 설치되어 있다. vim 으로 변경한다. 1234567891011121314# update-alternatives --config editorThere are 6 choices for the alternative editor (providing /usr/bin/editor). Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/joe 70 auto mode 1 /usr/bin/jmacs 50 manual mode 2 /usr/bin/joe 70 manual mode 3 /usr/bin/jpico 50 manual mode 4 /usr/bin/jstar 50 manual mode 5 /usr/bin/rjoe 25 manual mode 6 /usr/bin/vim.tiny 10 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 6 exFAT리눅스테어 외부 USB 디스크를 exFAT로 포맷하고 사용한다면, exfat-fuse와 exfat-utils를 설치해 준다. 1$ sudo apt install exfat-fuse exfat-utils 그리고 대부분 최신 리눅스 데스크탑은 USB 디스크를 더블클릭하면 자동마운트 해준다. 터미널에서는 123$ sudo mkdir /media/my_usb$ sudo mount -t exfat /dev/sdb1 /media/my_usb$ sudo umount /dev/sdb1 VNC server1sudo apt install tightvncserver 그리고 vncserver 명령으로 기본 패스워드를 생성한다. 1vncserver grc터미널 컬러 처리 https://github.com/garabik/grc 참조 [sudo user create](&gt; https://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-ubuntu-quickstart) armbian docs","link":"/2017/04/02/linux-2017-04-02-odroid-install-linux/"},{"title":"UFW Firewall on Ubuntu&#x2F;Debian","text":"일반적인 리눅스 배포본의 방화벽인 ufw` 를 사용해서 리눅스에 방화벽을 구축하는 방법을 기술하고 있다. 2019-12-10: 정리 2017-09-10: Log, export 추가서{:.right-history} 여기서 사용, 테스트한 리눅스 배포본은 Ubuntu 14.04, 15.04, 16.04 계열에서 동작하리라 믿는다. 실제 Raspbian Weezy, Jessie, Armbian Ubuntu 16.04, Debian Jessie 에서 사용중이다. UFW - Uncomplicated FirewallUbuntu의 기본 방화벽 두고는 UFW이다. 데스크탑을 위한 GUI 버전 Gufw 도 있다. [^2] ufw 설치다음 같이 ufw 패키지를 설치한다. 내부에서 서버로 운영중인 ARM 계열의 SBC 컴퓨터인 Raspberry Pi, Odroid, OrangePi 등의 배포본에는 ufw가 빠져 있다. 1$ sudo apt install ufw 1234$ sudo systemctl status ufw* ufw.service - Uncomplicated firewall Loaded: loaded (/lib/systemd/system/ufw.service; enabled; vendor preset: enabled) Active: inactive (dead) 방화벽 서비스를 시작한다. 1234567891011$ sudo systemctl start ufw$ sudo systemctl status ufw* ufw.service - Uncomplicated firewall Loaded: loaded (/lib/systemd/system/ufw.service; enabled; vendor preset: enabled) Active: active (exited) since Tue 2019-12-10 02:21:19 UTC; 1s ago Docs: man:ufw(8) Process: 2750 ExecStart=/lib/ufw/ufw-init start quiet (code=exited, status=0/SUCCESS) Main PID: 2750 (code=exited, status=0/SUCCESS)Dec 10 02:21:19 rock64 systemd[1]: Starting Uncomplicated firewall...Dec 10 02:21:19 rock64 systemd[1]: Started Uncomplicated firewall. 이제 ufw 를 활성화 하고 구성 내용을 설정해야 한다. 방화벽 구성 설정방화벽은 다음 같이 설정한다 기본 규칙 프로토콜, 포트 규칙 추가 방화벽 활성화 방화벽 기본 설정기본 정책을 설정 한다 - (들어오는 패킷은 차단, 나가는 패킷은 허용) 12$ sudo ufw default deny incoming$ sudo ufw default allow outgoing 현재 방화벽 기본 정책을 확인한다. 1$ sudo ufw status 설정한 규칙과 이에 따른 액션을 확인해 보려면 다음과 같이 입력한다. 12345$ sudo ufw status verboseStatus: activeLogging: on (low)Default: deny (incoming), allow (outgoing)New profiles: skip Default 부분이 방화벽의 기본 규칙으로 현재 들어오는 것은 막고, 나가는 것은 열어 놓은 상태이다. iptables 명령의 상태를 확인하려면 status raw 를 사용한다. 1$ sudo ufw show raw 먼저 ufw를 활성화하고 규칙을 추가한다. UFW 활성화방화벽은 커널 수준에서 패킷을 다루기 때문에 아래 같이 활성화 명령을 통해 네트워크 패킷을 ufw가 다룰 수 있게 해준다. ufw 활성화 상태를 확인하고 inactive 상태면 활성화 한다. 12345$ sudo ufw statusStatus: inactive$ sudo ufw enableFirewall is active and enabled on system startup 방화벽을 끌 때는 아래와 같은 명령어를 입력한다 1$ sudo ufw disable 방화벽 규칙 허용서비스, 포트, 프로토콜, 프로그램등에 예외 규칙을 적용할 액션을 추가한다. ufw [allow,deny] /&lt;optional: protocal&gt; 혹은 서비스 이름으로 가능하다 ufw [allow,deny] ssh, http, https 허용ssh 포트를 변경해서 사용한다면 반드시 직접 포트를 입력하자 123$ sudo ufw allow ssh$ sudo ufw allow http$ sudo ufw allow https 새로운 설정을 적용하려면 disable &gt; enable 해도 좋고 아래와 같이 reload 가 가능하다 1$ sudo ufw reload 포트포트를 변경해 사용하거나 특정 포트를 허용 할 수 있다. ssh 프로토콜은 tcp 22번 포트를 사용한다. 12$ sudo ufw allow 8080$ sudo ufw allow 22 규칙과 액션 상태를 확인한다. 12345678910$ sudo ufw status verboseStatus: activeLogging: on (low)Default: deny (incoming), allow (outgoing)New profiles: skipTo Action From-- ------ ----22 LIMIT IN Anywhere22 LIMIT IN Anywhere (v6) ssh 허용sh 허용 123$ sudo ufw allow sshor$ sudo ufw allow 22 ssh를 특정 IP 주소에만 접속을 허용한다 1sudo ufw allow from 192.168.0.100 to any port 22 1sudo ufw allow from 192.168.0.100 to any port 22 proto tcp limitufw는 Brute-force Attack 방어를 도와주는 Brute-force Attack을 방어하기 위한다면 다음과 같이 실행한다. 1$ sudo ufw limit ssh samba 허용12$ sudo ufw allow Samba$ sudo ufw allow from 192.168.0.0/16 to any app Samba 이렇게 설정하고 실제 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 12345678910111213$ netstat -tlnp(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 5034/python3tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN -tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN -tcp 0 0 0.0.0.0:1883 0.0.0.0:* LISTEN -tcp6 0 0 ::1:8080 :::* LISTEN 5034/python3tcp6 0 0 :::22 :::* LISTEN -tcp6 0 0 ::1:25 :::* LISTEN -tcp6 0 0 :::1883 :::* LISTEN - IP 주소 제어특정 IP 대역에서 허용/거부 하기 ufw [allow,deny] from 특정 IP만 허용할 경우 1$ sudo ufw allow from 192.168.0.100 특정 ip 또는 특정 ip 대역에 대해 특정 포트 허용/거부하기 ufw [allow,deny] from to port 123$ sudo ufw allow from 192.168.0.100 to any port 22$ sudo ufw allow from 192.168.0.100 to any port 22 proto tcp$ sudo ufw allow from 192.168.0.100 to any port 8080 특정 IP 혹은 IP 범위에 대한 접근 제어도 가능하다. ufw allow from to port ufw allow from to port proto 포트의 범위를 규칙으로 사용할 경우 1$ sudo ufw allow 9200:9300/tcp 특정 아이피에만 일정 범위의 포트를 tcp 패킷만 허용할 경우 1$ sudo ufw allow from 192.168.0.101 to any port 9200:9300 proto tcp 서브넷을 특정 포트에 허용할 경우 1$ sudo ufw allow from 192.168.0.0/24 to any port 27017 proto tcp ping (icmp) 허용/거부UFW 기본설정은 ping 요청을 허용하도록 되어있다. 이것은 /etc/ufw/before.rules 파일에 정의되어 있는데 여기서 icmp 프로토콜 관련한 항목을 DROP으로 처리하거나 삭제하면 ping을 방지할 수 있다. 123456 # ok icmp codes-A ufw-before-input -p icmp --icmp-type destination-unreachable -j ACCEPT-A ufw-before-input -p icmp --icmp-type source-quench -j ACCEPT-A ufw-before-input -p icmp --icmp-type time-exceeded -j ACCEPT-A ufw-before-input -p icmp --icmp-type parameter-problem -j ACCEPT-A ufw-before-input -p icmp --icmp-type echo-request -j ACCEPT 방화벽 규칙 삭제등록된 규칙을 삭제할 때는 2가지 방법이 있다. 첫번째는 등록 시 사용한 규칙을 그대로 입력하는 방법 12$ sudo ufw delete allow ssh$ sudo ufw delete allow 8080 22/tcp 설정이 되어있다고 가정하고, 해당 포트/포로토콜을 삭제한다. 1$ sudo ufw delete deny 22/tcp 두번째는 각 규칙의 번호를 확인하고 번호로 지우는 방법으로 status numbered 명령으로 규칙 번호를 확인한다. 1234567891011$ sudo ufw status numberedStatus: active To Action From -- ------ ----[ 1] 22 ALLOW IN Anywhere[ 2] 80/tcp ALLOW IN Anywhere[ 3] 443/tcp ALLOW IN Anywhere[ 4] 22 (v6) ALLOW IN Anywhere (v6)[ 5] 80/tcp (v6) ALLOW IN Anywhere (v6)[ 6] 443/tcp (v6) ALLOW IN Anywhere (v6) 등록된 규칙의 번호는 줄 맨앞에 있는 [숫자]로 이 숫자를 delete 명령에 준다. 2번 규칙 80/tcp 를 지우려면 1$ sudo ufw delete 2 UFW 설정 파일/etc/ufw/ 밑에 before.rule, before6.rule 파일이 있다. 기본적으로 ufw 시작시 before.rules, that allows loopback, ping, and DHCP을 활성화 하고 또한 ufw 명령이 실행된 후에 추가되는 룰이 after.rule, IPv6용 after6.rule 파일이 있다. 그리고 /etc/default/ufw 파일은 IPv6 를 활성화 하거나 비활서화 한다. Logging12$ sudo ufw logging onLogging enabled 로그 수준은 ufw logging low|medium|high 로 지정한다. 기록되는 로그는 /var/logs/ufw 에 위치한다. 1Sep 16 15:08:14 &lt;hostname&gt; kernel: [UFW BLOCK] IN=eth0 OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:00:00 SRC=123.45.67.89 DST=987.65.43.21 LEN=40 TOS=0x00 PREC=0x00 TTL=249 ID=8475 PROTO=TCP SPT=48247 DPT=22 WINDOW=1024 RES=0x00 SYN URGP=0 UFW BLOCK: This location is where the description of the logged event will be located. In this instance, it blocked a connection. IN: If this contains a value, then the event was incoming OUT: If this contain a value, then the event was outgoing MAC: A combination of the destination and source MAC addresses SRC: The IP of the packet source DST: The IP of the packet destination LEN: Packet length TTL: The packet TTL, or time to live. How long it will bounce between routers until it expires, if no destination is found. PROTO: The packet’s protocol SPT: The source port of the package DPT: The destination port of the package WINDOW: The size of the packet the sender can receive SYN URGP: Indicated if a three-way handshake is required. 0 means it is not. 참조How to configure ufw - Ubuntu 14.04 IP address from mac address [^2]: UFW Help[^3]: Check blocked IP in iptables","link":"/2017/04/03/linux-2017-04-03-ubuntu-firewall/"},{"title":"Nginx - HTTPS and Certificate SSL","text":"Nginx를 HTTPS를 사용할 수 있도록 사설 인증서와 그리고 공인 인증서를 이용해 SSL을 활성화 하는 과정을 정리했다. Nginx 설치와 서버, 프락시 등의 사용 방법에 대해서는 Nginx on Ubuntu/Debian 문서를 참조한다. TLSTLS는 SSL의 새로운 이름이다. SSL(Secure Socket Layer)는 대칭키 혹은 공개키 방식의 인증을 이룬후 암호화된 통신이 가능하다. TLS에 대해서는 다음 블로그에 자세히 설명되어 있다. HTTPS, SSL 설명 Nginx HTTPSNginx 에서 HTTPS를 상용하려면 인증기관을 통해 발급받은 SSL인증서가 필요하다. 여기서는 사용자 개인용 사설 인증서를 만들어 사용한다. 공인 서버 인증서에 대해서는 별도로 다룬다. [^2] 를 참조하면 사설 인증서와 공인 인증서에 대한 설명이 있다. 사설 인증서 설정SSL Certificate 파일을 생성하고 저장해 둔다. [^4] 12$ sudo mkdir /etc/nginx/ssl$ cd /etc/nginx/ssl OpenSSL을 사용해서 SSL Certificate를 생성한다. 12$ sudo openssl genrsa -out privkey.pem 2048$ sudo openssl req -new -x509 -key privkey.pem -out cacert.pem -days 1095 Generate DH params - 시간이 소요된다 (armv7 1Ghz 에서 30분 이상) 1$ sudo openssl dhparam 2048 &gt; /etc/nginx/ssl/dhparam.pem Nginx 설정에 SSL 활성화/etc/nginx/site-available/yoursite.com 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 80번 요청을 모두 443 SSL 서버로 바꾼다.server { listen 80 default_server; listen [::]:80 default_server; add_header Strict-Transport-Security max-age=2592000; rewrite ^/.*$ https://$host$request_uri? permanent;}# SSL을 이용한 444번 포트 사용 사이트 정의server { listen 443 default; server_name my-site.localhost; ssl on; ssl_certificate /etc/nginx/ssl/cacert.pem; ssl_certificate_key /etc/nginx/ssl/privkey.pem; ssl_session_timeout 5m; ssl_session_cache shared:SSL:5m; # Diffie-Hellman parameter for DHE ciphersuites, recommended 2048 bits ssl_dhparam /etc/nginx/ssl/dhparam.pem; # secure settings (A+ at SSL Labs ssltest at time of writing) # see https://wiki.mozilla.org/Security/Server_Side_TLS#Nginx ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-CAMELLIA256-SHA:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-SEED-SHA:DHE-RSA-CAMELLIA128-SHA:HIGH:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS'; ssl_prefer_server_ciphers on; proxy_set_header X-Forwarded-For $remote_addr; add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot;; proxy_buffers 16 64k; proxy_buffer_size 128k; server_tokens off; root /var/www/html; index index.html index.htm index.nginx-debian.html; location / { try_files $uri $uri/ =404; client_max_body_size 0; }} 설정 파일이 제대로 구성됐는지 테스트해본다.[^1] 1sudo nginx -t Certified SSL 작업: macbook pro의 thinkbee@ ~/Documents/SslCert$ https://jetmirshatri.com/build-nginx-with-openssl-1-1-0-on-ubuntu-16-04/ Lets’ EncryptLets’ Encrypt는 HTTPS를 사용하기 위해 SSL을 구매해야 하는 부분이 HTTPS 보급에 방해된다고 생각해서 SSL을 무료로 제공해서 HTTPS를 보급하기 위해 작년 말에 만들어졌다. 초기에는 Mozilla, Cisco, Akamai, EFF, id entrust 등이 모여서 ISRG(Internet Security Research Group)라는 새로운 SSL 인증기관을 만들어서 올해 SSL을 무료로 제공하겠다고 발표했다. 지금은 이 Lets’ Encrypt에 Facebook, 워드프레스를 만드는 Automattic, shopify 등 많은 회사가 스폰서로 참여하고 있다 https://www.nginx.com/blog/free-certificates-lets-encrypt-and-nginx/ Lets’ Ecrypt 발급Lets’ Ecrypt는 Shell 기반의 발급 방법을 권장한다. 웹을 통한 발급은 인증된 도메인 등록지에서 가능하다고 한다. 쉘 기반 발급을 위해서 ACME protocol client를 사용한다. 정식 클라이언트는 Certbot 을 사용한다. Certbot을 설치할 수 없는 상황에서는 호환 클라이언트를 사용할 수 있다. getssl1./getssl -c yourdomain.com 1234~/.getssl~/.getssl/getssl.cfg~/.getssl/yourdomain.com~/.getssl/yourdomain.com/getssl.cfg ~/.getssl/getssl.cfg 를 필요시 수정한다. ~/.getssl/yourdomain.com/getssl.cfg 을 수정한다. Recommended: Certbothttps://letsencrypt.org/docs/client-options/ 여기서 getssl bash 스크립트를 사용해 본다. openssl req -new -sha256 -key domain.key -subj “/“ -reqexts SAN -config &lt;(cat /etc/ssl/openssl.cnf &lt;(printf “[SAN]\\nsubjectAltName=DNS:thinkbee.kr,DNS:www.thinkbee.kr,DNS:blog.thinkbee.kr&quot;)) Certbot-autohttps://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-14-04 https://www.nginx.com/blog/free-certificates-lets-encrypt-and-nginx/ 참고 TLS/SSL에 대해 알아보아요 [^2]: SSL 인증서 종류[^3]: Enabling Https with Nginx[^4]: Create Self signed SSL","link":"/2017/11/01/linux-2017-04-04-ubuntu-nginx-ssl/"},{"title":"Nginx - Install, WebDAV, Proxy on Ubuntu&#x2F;Debian","text":"nginx를 사용해서 일반 웹 서비스, SSL, WebDav 서비스와 다른 외부 웹 서비스와 연동하는 설정을 해보자. 여기서 node.js 애플리케이션을 연동한다. ## Nginx 설치와 구성 우분투/데비안 계열에서 apt-get install 명령으로 설치한다. Nginx 설치1$ sudo apt-get install nginx 우분투/데비안 계열은 /etc/nginx 밑에 nginx 설정 파일이 위치한다. 123456789nginx/├── conf.d/├── htpasswd├── nginx.conf├── sites-available/│ └── default├── sites-enabled/│ └── default -&gt; /etc/nginx/sites-available/default└── ssl/ htpasswd: apache-utils의 htpasswd 유틸리티로 생성한 Basic auth 계정 파일 ssl/ : SSL 인증서 파일 nginx.conf : nginx의 전역 설정 파일, 사이트 설정 및 가상 호스트 설정은 sites-available 에 선언. sits-available: 웹 사이트 설정 파일 sites-enabled: 새 사이트 정의가장 좋은 방법은 기존 default 설정 파일을 복사해 수정한 후 사용한다. 12$ cd /etc/nginx/$ cp site-available/default cp site-available/my-site my-site가상 호스트 파일을 /etc/nginx/sites-available/ 폴더에 추가하고 site-enabled에 링크를 해주면 된다. 아래 내용으로 /etc/nginx/sites-available/my-site 파일을 다음 같이 추가해 준다. 1234567891011121314server { listen 80 default_server; listen [::]:80 default_server; root /home/qkboo/my-site; index index.html index.htm index.nginx-debian.html; server_name my-site.localhost; location / { try_files $uri $uri/ =404; }} 사이트 활성화는 /etc/nginx/site-enabled 폴더에 소프트 링크를 걸어준ㄷ. 12$ sudo ln -s /etc/nginx/sites-available/my-site /etc/nginx/sites-enabled/my-site$ sudo service nginx reload # 설정 다시 가져오기 Debian, Ubuntu 계열은 Ubuntu 15.x, Debian Wizzy 이후? 시스템 서비스를 systemd 로 다룬다. nginx도 systemd 스크립트로 관리할 수 있다. systemd 관련 내용 참조 - [^6] 12$ sudo systemctl reload nginx.service$ sudo systemctl status nginx.service 만약 설정 파일에 문제가 있으면 systemctl status nginx.service 결과에 어느 줄에서 문제가 있는지 확인할 수 있다. Nginx for Node.jsNginx를 메인 웹 서버로 사용하고 여기에 연결되는 URL, Location에 따라 nginx 외부의 다른 서비스에서 처리하게 하는 방법을 proxy 를 연결하는 것이다. 즉, nginx에서 Node.js, Django, Tomcat 같은 웹 서비스의 통로로 사용한다. http://www.albertauyeung.com/post/setup-jupyter-nginx-supervisor/ proxy1234567891011121314151617181920212223242526server { listen 80; server_name test.example.com; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:52222/; proxy_redirect off; } log_not_found off; gzip on; gzip_comp_level 2; gzip_proxied any; gzip_min_length 1000; gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript text/x-js; } 설정 파일이 제대로 구성됐는지 테스트해본다. sudo nginx -t [^1] ## WebDAV Nginx에서 WebDAV는 nginx-extras 패키지를 설치한다. 123$ sudo apt-get install nginx nginx-extras$ sudo mkdir /home/qkboo/WebDav$ sudo chown www-data /home/qkboo/WebDav 혹은 chgrp로 그룹만 변경할 수 있다. 1$ chgrp www-data /home/qkboo/WebDav Basic AuthHTTP Auth 는 htpasswd 유틸리티로 사용자 이름과 아이디를 등록해서 사용한다. [^5] 12$ sudo apt-get install apache2-utils$ sudo htpasswd -c /etc/nginx/htpasswd exampleuser WebDav용 설정위에서 사용한 my-site 설정에 다음 같이 WebDav 디렉토리 위치를 추가한다. 123456789101112131415161718192021222324252627282930313233343536server { # SSL configuration listen 443 ssl http2 default_server; listen [::]:443 ssl http2 default_server; ssl on; #... 생략 # WebDav directory and URL location /myfiles { alias /home/qkboo/WebDav; #root /home/qkboo/; #client_body_temp_path /var/dav/temp; dav_methods PUT DELETE MKCOL COPY MOVE; dav_ext_methods PROPFIND OPTIONS; create_full_put_path on; dav_access user:rw group:rw all:rw; autoindex on; # Basic auth auth_basic &quot;restricted&quot;; auth_basic_user_file /etc/nginx/htpasswd; send_timeout 36000s; proxy_connect_timeout 36000s; proxy_read_timeout 36000s; proxy_send_timeout 36000s; # large file uploads proxy_request_buffering off; }} more configureshttp://nginx.org/en/docs/http 에 있는 세부 설정중 사용한 것. Upload sizePOST로 multi-part 업로드시에 다음 에러가 보이면 nginx의 기본 업로드 크기를 2M 이하로 설정되어 그렇다. 1[error] 31354#0: *10899 client intended to send too large body: 1198151 bytes, client: &lt;IP address&gt;, server: example.com, request: “POST /wp-admin/async-upload.php HTTP/1.1”, host: “example.com”, referrer: “http://example.com/wp-admin/post.php?post=&lt;post id&gt;&amp;action=edit” client_max_body_size 속성을 server, location 에 설정해 준다: 1client_max_body_size 20M; limit_ratelimit_rate, limit_rate_after 는 함께 사용 12345location /flv/ { flv; limit_rate_after 500k; limit_rate 50k;} ## 참조 [^1]: nginx command[^5]: Http Auth[^6]: 서버 프로세스 관리에 대해","link":"/2017/04/03/linux-2017-04-03-ubuntu-nginx/"},{"title":"Ubuntu&#x2F;Debian ARM Cross compile 환경","text":"이 글은 우분투, 리눅스 박스에서 GNU ARM Cross compiler 를 설치하고 관리하는 방법을 다루고 있다. 2018-05-17: sidebar.nav/linux 사용{: .right-history} ARM Cross compiler 설치우분투/데비안 리눅스에서 제공하는 ARM Toolchain 환경은 Linaro 툴체인을 바탕으로 만들어져 있어서 두가지 버전으로 제공된다. Hard Float을 지원하는 버전과 그렇지 않은 버전이다.[^1] (1) gcc-arm-linux-gnueabi 이 툴체인은 EABI가 gcc의 -mfloat-abi=soft 혹은 -mfloat-abi=softfp 옵션으로 생성한다는 의미이다. (2) gcc-arm-linux-gnueabihf 이 툴체인은 EABI가 gcc -mfloat-abi=hard 옵션으로 생성한다는 의미이다. 이 의미는 Function Calling Convention이 double, float 사용시 FPU 레지스터에 올려서 전달하고 반환도 FPU 레지스터를 사용하게 된다는 것이다. update-alternatives플랫폼에 따른 gcc 환경을 변경하는 것은 update-alternatives을 사용한다. 링크 update-alternatives에서 설명을 볼 수 있다. ARM toolchain 설치Ubuntu 14.04 에서 테스트했다. 그 이상 버전도 충분히 가능하다. 아래 도구를 설치하면 각 플랫폼에 대한 binutils–arm-linux-, gcc-arm-linux-, g++-arm-linux-, cpp-arm-linux- 도구가 설치된다. Ubuntu14.04 에서 arm toolchain 설치Coretex ARM 12sudo apt-get install gcc-arm-linux-gnueabihfsudo apt-get install g++-arm-linux-gnueabihf ARM 12$ sudo apt-get install gcc-arm-linux-gnueabi$ sudo apt-get install g++-arm-linux-gnueabi Bare metal ARM 12$ sudo apt-get install gcc-arm-none-eabi$ sudo apt-get install g++-arm-none-eabi 필요하면 gfortran-arm-linux-, gobjc++-arm-linux- 등의 도구를 설치한다. 툴 체인 등록여러 개발 보드의 cross compiler를 사용하기 위해서 해당 버전의 접두어를 사용해 보자. arm 을 사용하는 보드는 arm-linux-gnueabi[hf] 명칭을 사용한다. 1$ update-alternatives --list arm-linux-gnueabihf 새로운 arm-linux-gnueabihf- 를 등록하자. arm-linux-gnueabihf 등록하기arm-linux-gnueabihf-gcc-4.8 관련 도구를 gcc 그룹에 등록하기 12sudo update-alternatives --install /usr/bin/arm-linux-gnueabihf-gcc arm-linux-gnueabihf /usr/bin/arm-linux-gnueabihf-gcc-4.8 50 \\--slave /usr/bin/arm-linux-gnueabihf-g++ arm-linux-gnueabihf-g++ /usr/bin/arm-linux-gnueabihf-g++-4.8 arm-linux-gnueabihf-gcc-4.7 관련 도구를 gcc 그룹에 등록하기 12sudo update-alternatives --install /usr/bin/arm-linux-gnueabihf-gcc arm-linux-gnueabihf /usr/bin/arm-linux-gnueabihf-gcc-4.7 40 \\--slave /usr/bin/arm-linux-gnueabihf-g++ arm-linux-gnueabihf-g++ /usr/bin/arm-linux-gnueabihf-g++-4.7 Raspberry pi Toolchain 등록하기Raspberry pi 배포본에서 제공하는 arm gcc compile를 arm-linux-gnueabihf 그룹에 등록해 보자 [^2]. git으로 툴체인을 다운받아 ~/raspberrypi/tools 에 설치한다고 가정한다. [^3] 1git clone https://github.com/raspberrypi/tools ~/raspberrypi/tools 다운로드한 tools 밑에 32bit, 64bit 버전의 컴파일러가 있다. 32bit 버전은 tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian/bin64bit 버전: tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin 다운로드 한 후에 적절한 위치에 놓고, 해당 경로를 확인한다. 123456$ cd ~/rpi-arm/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin/$ arm-linux-gnueabihf-gcc --versionarm-linux-gnueabihf-gcc (crosstool-NG linaro-1.13.1+bzr2650 - Linaro GCC 2014.03) 4.8.3 20140303 (prerelease)Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 64bit Raspberry Pi arm-linux-gnueabihf-gcc- 관련 도구를 gcc 그룹에 등록하기 12sudo update-alternatives --install /usr/bin/arm-linux-gnueabihf-gcc arm-linux-gnueabihf ~/raspberrypi/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin/arm-linux-gnueabihf-gcc-4.8.3 30 \\--slave /usr/bin/arm-linux-gnueabihf-g++ arm-linux-gnueabihf-g++ ~/raspberrypi/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin/arm-linux-gnueabihf-g++","link":"/2017/04/05/linux-2017-04-05-crosscompile-arm/"},{"title":"MongoDB - Database와 User Authentication","text":"2018-06-21 설치 링크로 대체{:.right-history} MongoDB 설치후 데이터베이스 위치, 로그, 인증 등에 관련한 서버 구성과 설정을 정리한다. MongoDB 2.6 과 MongoDB Community Edition 3.x 버전을 사용했다. mongoDB 접근제어mongoDB 는 설치과정 중에 인증과 관련해 설정하는 부분이 없어서 설치 후 누구나 DB에 접속 할 수 있다. 인증을 추가해 데이터베이스 관리자와 데이터베이스 사용자로 구분해서 이용하고, 각 데이터베이스의 사용자는 허가된 역할(Role)을 가지고 데이터베이스에 접근 가능하도록 구성한다. 여기서는 다음 두 가지를 다루고 있다. (1) 데이터베이스 관리자 추가 (2) 데이터베이스 사용자 추가 Ubuntu/Debian 리눅스 배포본에 MongoDB 3.x 버전이 지원되지 않으면, MongoDB Community Edition 를 패키지 혹은 소스로 설치할 수 있다. MongoDB Community Edition 3.4 on Armv8 MongoDB Community Edition 3.6 데이터베이스 관리자mongod가 비인증 모드로 실행중인 상태에서, mongo 클라이언트로 데이터베이스에 접속한다.접속에 성공하면 &gt; 프롬프트가 표시된다. 그리고 접속한 후에 admin 데이터베이스로 전환한다. 123&gt; use adminswitched to db admin&gt; mongo 클라이언트로 접속해 mongoDB 데이터베이스 관리자 admin 추가해서, 사용자 롤로 userAdminAnyDatabase 롤을 추가해준다. mongoDB 2.6 이후 관리자 계정 추가mongoDB 2.6 이후는 db.createUser() 로 사용자를 추가한다. [^2]다음은 admin 데이터베이스에서 사용자를 관리하는 admin 계정을 생성하고 있다. 123456789101112131415161718192021&gt;&gt; db.createUser({ user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() // 데이터베이스 사용자 확인[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] [^2]: Enable Authentication after Creating the User Administrator(v2.6) mongoDB 2.4 이전 관리자 계정 추가mongoDB 2.4 까지는 새로운 사용자는 db.addUser() 로 추가한다.[^1] 123456$ mongo // mongo client 로 접속&gt;use admin // admin DB 사용&gt;db.addUser( { user: &quot;&lt;username&gt;&quot;, // admin name pwd: &quot;&lt;password&gt;&quot;, roles: [ &quot;userAdminAnyDatabase&quot; ] // Database role } ) mongoDB 2.6까지 32bit 버전을 지원하고 있다. [^1]: Add User Administrator(v2.4 ) 관리자 계정을 만든후 MongoDB에 mongo 클라이언트로 인증 로그인을 한 후에 데이터베이스를 생성하고 해당 데이터베이스 사용자에 접근 권한을 추가해 준다. security.authorizationmongodb.conf 파일에 security.authorization 을 활성화 한다 12security: authorization: enabled 데이터 베이스 생성과 롤 기반 인증관리자 로그인이제 데이터베이스 관리자 계정으로 로그인해서 사용하려는 데이터베이스를 use로 선택하고 해당 데이터베이스 사용자를 추가해준다. mongo 클라이언트 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 1234$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0 혹은 인증없이 mongo 클라이언트로 데이터베이스에 접속한 후에 db.auth() 명령을 사용할 수 있다. 123456789101112&gt; use adminswitched to db admin&gt; db.auth(&quot;admin&quot;, &quot;****&quot;)1&gt; show users{ &quot;_id&quot; : ObjectId(&quot;5733676238ac1ddf4cf745c2&quot;), &quot;user&quot; : &quot;admin&quot;, &quot;readOnly&quot; : false, &quot;pwd&quot; : &quot;24413999168dccff96dcc735720c85ce&quot;}&gt; 이제 각 데이터베이스에 사용자를 생성해서 사용해서 인증한 사용자만 데이터베이스를 사용하게 할 수 있다. Database 사용자 추가mongoDB v3.x 사용자 관리mongoDB v2.6 히우는 대부분 mongoDB v3.4와 호환되는 사용자 관리 명령을 사용한다. 여기서는 User Management Methods (v3.4)를 참고하고 있다. Name Description db.auth() 데이터베이스에 사용자 인증 db.createUser() Creates a new user. db.updateUser() Updates user data. db.changeUserPassword() 사용자 패스워드 변경 db.dropAllUsers() 데이터베이스에 관련된 모든 사용자를 삭제한다. db.dropUser() 한 사용자를 삭제한다 db.grantRolesToUser() 롤과 권한을 사용자에 허용한다 db.revokeRolesFromUser() 사용자에 부여한 롤을 삭제한다 db.getUser() 지정한 사용자의 정보를 반환한다 db.getUsers() 데이터베이스에 관련된 모든 사용자의 정보를 반환한다 createUser()db.createUser() 는 두 개의 도큐멘트를 인자로 사용한다: db.createUser(user, writeConcern) 여기서 user 도큐멘트는 아래 같은 형식을 갖는다: 12345678{ user: &quot;&lt;name&gt;&quot;, pwd: &quot;&lt;cleartext password&gt;&quot;, customData: { &lt;any information&gt; }, roles: [ { role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; } | &quot;&lt;role&gt;&quot;, ... ]} customData: 선택적으로 추가할 정보를 담은 도큐멘트. 다음은 product 데이터베이스로 전환해서 product 데이터베이스 사용자를 추가하고 있다. customeData 를 주목하자. 12345678&gt; use productsdb.createUser( { user: &quot;user1&quot;, pwd: &quot;changeMe&quot;, customData: { employeeId: 12345 }, // prducts roles: [ { role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; }, { role: &quot;readAnyDatabase&quot;, db: &quot;admin&quot; }, &quot;readWrite&quot;] }, { w: &quot;majority&quot; , wtimeout: 5000 } ) 다양한 사례는 createUser() Exmaple 를 참고하자. mongoDB v2.4는 사용자 추가 방법이 조금 다르다. mongoDB v2.4 사용자 추가사용하려는 데이터베이스의 계정으로 접근제어를 추가해 주어야 한다. mongoDB 2.4 까지는 새로운 사용자는 db.addUser() 로 추가한다.[^3] [^3]: Add User To Database(v2.4) 아래는 데이터베이스 관리자 계정 admin으로 로그인해서, 필요하면 students 데이터베이스를 생성합니다. 그리고 students 데이터베이스 사용자 student 계정을 추가하고 있다. 123456789101112131415&gt; use studentsswitched to db students&gt; db.addUser('student', '****'){ &quot;user&quot; : &quot;student&quot;, &quot;readOnly&quot; : false, &quot;pwd&quot; : &quot;7a70591507db46bdd3df47a213d8922f&quot;, &quot;_id&quot; : ObjectId(&quot;57336a71c1ef2bed6688d296&quot;)}&gt; db.auth('student', '012345')1&gt; db.student.save({name:'qkboo', class:'Database', grade:'A'})&gt; db.student.find(){ &quot;_id&quot; : ObjectId(&quot;57336b7d1be9091521cbeb36&quot;), &quot;name&quot; : &quot;qkboo&quot;, &quot;class&quot; : &quot;IoT&quot;, &quot;grade&quot; : &quot;A&quot; }&gt; 이제 mongo 클라이언트로 생성한 students 에 데이터베이스 사용자 student로 로그인한다. 123$ mongo student -u student -p ****MongoDB shell version: 2.4.10connecting to: student 만약 해당 데이터베이스 사용자가 아닌 계정에서 데이터베이스 접근시 다음 같이 인증되지 않은 접근으로 에러를 발생한다. 12345678$ mongoMongoDB shell version: 2.4.10connecting to: test&gt; use studentswitched to db student&gt; show dbsTue Sep 27 23:45:38.269 listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;unauthorized&quot; } at src/mongo/shell/mongo.js:46&gt; MongoDB에 관련 글MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4","link":"/2017/04/20/linux-2017-04-20-mongodb-user-auth/"},{"title":"Tmux cheatsheet","text":"2017-07-14: 윈도우에서 session 관리 2017-07-10: tmux copy &amp; paste{:.right-history} 터미널 명령은 $ tmux 로 표현하고, Tmux window 에서 Prefix key 키 조합은 는 C{:.keyword} 표기하고, Meta key인 Alt는 M{:.keyword}으로 표기한다 - Tmux Start 참조. 여기서는 .tmux.conf 에서 기능키/메타키 연결해서 기본 Prefix key인 Ctrl+b 를 Ctrl+a로 묶었다. 123set -g prefix C-abind C-a send-prefixunbind C-b Tmux 명령tmux는 세션을 만들고, 세션에서 window를 구성하고, window 안에 pane을 사용한다. 새로운 세션 시작하기12$ tmux #새로운 새션$ tmux new -s session_name #session_name으로 새로운 세션 세션을 dettach하면 세션은 저장된다. 사용하지 않으면 kill로 종료한다. 세션 이용하기123$ tmux ls$ tmux list-session$ tmux list-windows # Window 목록 열린 세션에 붙기. 세션 번호중 낮은 번호에 우선해서 접속한다. 123$ tmux attach$ tmux at$ tmux a 특정 세션에 접속하기 세션 번호 혹은 이름으로 접속한다. 1$ tmux a -t session_name 세션 마감하기1$ tmux kill-session session_name Tmux로 접속한 session은 처음 한개의 Window를 갖는다. window 안에서 session, window, pane을 관리한다. 각 윈도우는 한 개 이상의 Pane 구획으로 나누어 사용할 수 있다. Tmux Window현재 세션 이용 12C-s #Session 목록C-$ #Session 이름 변경 window 사용하기세션에서 여러 윈도우를 추가 해서 사용할 수 있다. 1C-c #새로운 윈도우 생성 여러 윈도우는 윈도우 순서에 따라 현재 윈도우 화면을 교환 할 수 있다. 1234567C-w #윈도우 목록C-1 ... #지정 윈도우 번호로 전환: 0,1,...C-p #이전 윈도우로 이동C-n #다음 윈도우로 이동C-l #가장 마지막 윈도우로 이동C-, #현재 윈도우 이름 변경C-&amp; #현재 윈도우 제거 현재 세션에서 나온다. 세션은 백그라운드에서 실행된다. 12C-d #현재 세션을 빠져 나온다 (detach)C-D #빠져나올 세션을 선택할 수 있다. Tmux paneTmux window를 여러 분할면 pane으로 나눠 사용한다. 1234567891011C-% #수직으로 나누기C-&quot; #수평으로 나누기C-z #현재 pane 확대 및 돌아오기C-{ #현재 pane을 이전 pane 위치로 이동C-} #현재 pane을 다음 pane 위치로 이동C-Arrow #앞,뒤 pane을 방향키로 이동C-M+Arrow #pane 크기를 방향키에 따라 변경C-spacebar #pane 방향 전환 (수직&lt;-&gt;수평)C-! #현재 pane을 새 window로 분리C-x #pane 종료C-[ #pane에서 스크롤 기능을 활성화 Session transitionTmux window 상태에서 여러 세션 사이의 전환 단축키; 12345C-$ # 현재 세션 이름 바꾸기C-( # 이전 세션으로 전환C-) # 다음 세션으로 전환C-L # 사용한 세션중 마지막 세션으로 전환C-s # 사용 가능한 세션 목록 Tmux copy &amp; pastetmux 는 자체 버퍼에 터미널에서 선택한 영역의 텍스트를 복사해서 사용할 수 있다. 1234C-[ # copy modeCtrl+space # 복사할 영역을 선택한다. 터미널에 영역이 선택되어 보인다.Ctrl+w # 선택한 영역을 복사한다.C-] # 붙여 넣는다. 단, 시스템 버퍼는 별도의 플러그인을 사용한다. Copy with mouse dragmouse mode를 활성화 하면 터미널에서 마우스 드래그로 텍스트를 선택하면 tmux buffer에 복사되게 한다. .tmux.conf 파일에 다음 구성을 추가한다: 1set -g mouse on","link":"/2017/05/05/linux-2017-05-05-tmux-cheatsheet/"},{"title":"Tmux Start","text":"2017-07-10: tmux-continum 추가{:.right-history} Tmux는 terminal multiplexer로 서버에 여러 프로그램을 세션에 저장하고, 다른 작업 혹은 연결을 끊었다 다시 접속해서 세션을 열어 작업을 이어갈 수 있다. {: width=”600”} [그림. Tmux 실행 모습 (tmux.github.io)] 설치여기서는 tmux 2.x 이상을 사용한다. Ubuntu 14.04, Raspbian Jessie, Armbian 등에서 tmux가 1.8, 1.9 버전이 제공 Ubuntu 15, 16 Xenivior 버전은 Tmux 2.1 macOS는 brew 를 사용한다. Tmux 2.3 설치이전 Ubuntu 14.04, Raspbian 등에서 tmux가 1.8, 1.9 버전이 제공되는데 package manager 같은 기능을 사용할 수 없다. 소스로 빌드해서 사용할 수 있다. Ubuntu 14.04 desktop, orangepi plus, raspberry pi jessie 초기 버전에서 빌드 소스 설치혹시 모르니 기존 낮은 버전의 tmux를 삭제하고 시작해 보자. 1$ sudo apt remove --purge tmux 소스를 https://github.com/tmux/tmux/releases/ 에서 최신 버전으로 다운로드 하고 빌드한다. 1234567sudo apt updatesudo apt install -y libevent-dev libncurses-devwget https://github.com/tmux/tmux/releases/download/2.3/tmux-2.3.tar.gztar xvzf tmux-2.3.tar.gzcd tmux-2.3/./configure &amp;&amp; makesudo make install deb 바이너리 설치 단, libtinfo5 6.x 설치시 의존성 라이브러리 문제로 패키지 삭제 문제 발생!!! https://launchpad.net/ubuntu/yakkety/amd64/tmux/2.2-3 에 빌드되어 있는 바이너리를 Ubuntu 14.04 설치하기 위해서 다음 패키지 버전이 필요하다. Depends on: libc6 (&gt;= 2.14) libevent-2.0-5 (&gt;= 2.0.10-stable) libtinfo5 (&gt;= 6) libutempter0 (&gt;= 1.1.5) 기본 설치후 업그레이드를 했다면 libc6 버전은 문제가 없는듯. 12$ sudo apt-cache show libc6$ sudo apt-cache show libtinfo5 Ubuntu14.04.4 LTS 버전의 libtinfo5는 5.9로 다음 같이 설치해 준다. 1$ wget http://launchpadlibrarian.net/271601076/libtinfo5_6.0+20160625-1ubuntu1_amd64.deb 그리고 tmux 2.2 버전의 deb 를 다운로드한다. 1$ wget http://launchpadlibrarian.net/263289132/tmux_2.2-3_amd64.deb 설치 12$ sudo dpkb -i libtinfo5_6.0+20160625-1ubuntu1_amd64.deb$ sudo dpkb -i tmux_2.2-3_amd64.deb 이제 tmux 명령으로 다중 터미널 명령을 사용할 수 있다. macOS에서 tmux 설치homebrew를 사용해서 tmux를 설치한다. 2017년 현재 2.4 버전이 설치된다. 1$ brew install tmux 이제 tmux 명령으로 시작할 수 있다. 시작tmux 를 시작하면 하나의 세션에 하나의 윈도우가 만들어 진다. 12$ tmux # 세션을 시작하고 참가한다.$ tmux new -s foo # 세션 foo를 시작하고 참가한다 세션에 참가하면 하나 혹은 그 이상의 윈도우에서 Pane을 배치해 사용할 수 있다. {: width=”600”}[그림. Tmux window layout] Control와 Meta keyTmux 세션 참가후 Window에서는 Prefix key로 Session, Window, Pane 관련 명령을 키로 조합해 사용한다. 기본 Prefix key는 Control+b key고 옵션으로 사용하는 Meta key는 Alt 키 이다. 여기서 Prefix key는 C와 조합으로 표기하고, Meta key인 Alt는 M으로 표기한다. 윈도우 명령 control, meta 키 조합과 병행해 윈도우에서 명령모드를 사용할 수 있다. 명령모드는 C-: 키로 시작하고, 명령모드에서 명령 자동 완성을 지원한다. {: width=”600”}[그림. Window command mode] Pane 다루기윈도우는 수직/수평으로 구획을 나눌수 있다. C-“ 키로 현재 Pane 아래에 수평으로 새 Pane을 나눈다. 그리고 **C-%**키로 수직으로 새 Pane을 나눌 수 있다. {: width=”600”}[그림. Tmux Window Pane] C-q : pane 번호를 표시하고 번호를 눌러서 이동 C-o : pane을 순서대로 이동 C-방향키 : 해당 방향으로 이동 C-M-방향키 : 해당 방향으로 크기 조절 C-M-1~5 : 몇 가지 미리 설정된 레이아웃을 고를 수 있고, prefix space로 이 레이아웃을 순서대로 - 돌아가며 선택 가능 C-z : 특정화면만 확대하기 다시 예전 Panes상태로 돌아오기 Pane을 지우려면 터미널 exit 명령 혹은 C-x 키로 빠져 나올 수 있다. Window 다루기윈도우는 명령모드에서 new-window 혹은 C-c 키로 새 윈도우를 추가할 수 있다. {: width=”600”}[그림. new Window ] 윈도우 사이의 이동은 윈도우 번호에 따라 단축키 C-0,1,2…9를 사용하거나 C-w로 윈도우 목록에서 선택해 이동할 수 있다. C-n, C-p : 다음 윈도우, 이전 윈도우로 이동 C-l : 직전 사용하던 윈도우로 이동 C-w : 윈도우 리스트를 띄우고 선택 C-, : 윈도우 이름 바꾸기 세션 사용중에 세션을 빠져 나오려면 C-d 로 detach 하거나, 명령모드 C-:에서 detach 명령을 준다. 복사와 스크롤Tmux 화면 버퍼는 한 화면분 밖에 안되서, 이전 화면 내용을 보려면 스크롤 기능을 켜야 한다. C+[ 키는 스크롤 키고, 우측상단에 페이지 표시가 나타난다. 키보드 방향키나 Page Up/Down키로 스크롤이 가능하다. 세션 연결세션은 하나 혹은 그 이상 만들고 attach 명령으로 세션에 참가할 수 있다. 1234$ tmux new -s foo -d # 세션 foo를 시작하고 빠져나온다.$ tmux ls # 세션 목록을 출력한다.0: 1 windows (created Fri May 12 10:26:00 2017) [80x24] (attached)foo: 1 windows (created Fri May 12 10:34:18 2017) [80x24] 터미널에서 세션에 참가하려면 attach 명령과 대상 세션을 지정해 준다. 대상 세션은 tmux ls 명령에 표시되는 세션번호 혹은 세션이름을 지정한다. 123$ tmux attach$ tmux attach -t 0 # 세션 0번에 참여한다$ tmux attach -t foo # 세션 foo에 참여한다. 세션을 완전히 종료 시키려면, tmux 세션에서 명령모드 C-: 에서 kill-session 명령을 실행한다.혹은 다른 터미널에서 세션번호 혹은 세션 이름으로 종료한다. 1$ tmux kill-session -t 3 # 세션번호 3을 종료한다. 설정파일 .tmux.conf사용자 홈디렉토리에 .tmux.conf 파일에 tmux에 대한 설정을 명시할 수 있다. Control + a 사용하기Capslock키를 Control 키로 대체해 사용하면, Control+a 키 조합이 편하다. .tmux.conf 에 키 조합을 변경한다. 12345#Control+a에 'prefix' 연결set -g prefix C-a#send-prefix를 Control+a에 전달bind C-a send-prefixunbind C-b 위에서 prefix는 C-a 로 재배치된다. Mouse On/Off123456789# Toggle mouse on with META mbind m \\ set-option -g mouse on \\;\\ display 'Mouse: ON'# Toggle mouse off with META Mbind M \\ set-option -g mouse off \\;\\ display 'Mouse: OFF' Plugin managerTmux Pluin Manager 를 설치하고, tmux 기능을 확장할 수 있다. tpm 설치먼저 사용자 홈 디렉토리에 저장한다. 1$ git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm 다음 설정을 tmux.conf 에 저장한다. 1234567# List of pluginsset -g @plugin 'tmux-plugins/tpm'set -g @plugin 'tmux-plugins/tmux-sensible'set -g @plugin 'tmux-plugins/tmux-resurrect'# Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)run '~/.tmux/plugins/tpm/tpm' plugin 관리플러그인 설치를 위해서 C-I (대문자) 를 실행플러그인 업그레이드를 위해서 C-U 를 실행 플러그인 목록에서 플러그인을 선택하고 C-M-u (소문자) Tmux-Resurrectiontmux-resurrect{:.keyword}는 tmux 세션을 백업/복구 할 수 있는 플러그인이다. tmux.conf에 다음을 추가 1set -g @plugin 'tmux-plugins/tmux-resurrect' 플러그인 설치를 위해서 C-I 를 실행하면 설치를 시작한다. Resurrection 플러그인으로 백업/복구하는 키는 다음 같이 지정되어 있다: C-s : save C-r : restore Tmux-continuumtmux-resurrect{:.keyword} 에서 저장한 환경을 자동으로 저장/복구할 수 있는 플러그인이다. tmux-continuum tmux-continuum{:.keyword} 의 주요 기능은: tmux{:.keyword} 환경을 15분 마다 자동 저장 컴퓨터/서버 시작시 tmux{:.keyword} 자동 시작 tmux{:.keyword} 시작시 자동 복구 tmux 1.9 이상, bash, tmux-resurrect plugin 설치.tmux.conf 파일에 아래 플러그인을 추가: 12set -g @plugin 'tmux-plugins/tmux-resurrect'set -g @plugin 'tmux-plugins/tmux-continuum' tmux 에서 플러그인 설치를 위해서 C-I (대문자) 를 실행 그리고 .tmux.conf 파일에 continuum-restore 을 on으로 해준다. 1set -g @continuum-restore 'on' tmux 세션을 모두 나와서 tmux 서버를 모두 kill-session 같은 명령으로 종료시킨후 tmux를 다시 시작하면 .tmux/resurrect 에 저장된 마지막 세션이 복구되는 것을 확인할 수 있다. 이제부터 15분 마다 자동 저장하고 서버를 재시작한 후에 tmux를 다시 시작하면 저장한 환경을 자동으로 복구해 준다. tmux status 표시tmux-continuum 의 상태를 tmux status line에 표시할 수 있다. 1set -g status-right 'Continuum status: #{continuum_status}' Linux에서 tmux 자동 시작tmux-continuum 은 Linux systemd, macOS 에서 자동 시작을 지원한다. Linux는 .tmux.conf 파일에 다음 부트 옵션을 추가한다. 1set -g @continuum-boot 'on' 그리고 현재 실행중인 세션에 변경한 설정을 적용하려면 1$ tmux source-file ~/.tmux.conf macOS에서 tmux 자동 시작.tmux.conf 파일에 다음 부트 옵션을 추가한다. 1set -g @continuum-boot 'on' 그리고 현재 실행중인 세션에 변경한 설정을 적용한다. 1$ tmux source-file ~/.tmux.conf 맥이 재시작 하면 자동으로 Terminal.app 이 실행된다. 터미널 크기는 다음 옵션으로 지정한다: 1234set -g @continuum-boot-options 'fullscreen' # terminal window will go fullscreenset -g @continuum-boot-options 'iterm' # start iTerm instead of Terminal.appset -g @continuum-boot-options 'iterm,fullscreen' # start iTerm in fullscreen 다중 tmux 서버는 지원하지 않는다.tmux 로 서버를 하나 시작하고, tmux -S /tmp/foo 같이 다른 소켓을 사용했다고 자동 저장/복구가 별도로 진행되지 않는다. [^10] 여기까지 설정한 내용은 qkboo/tmux.conf gist 에서 확인 가능. ### 설정 저장 tmux 설정을 위힌 default 파일이 존재하지 않는다는 점이다. 그래서 tmux 기본 설정을 어딘가 추출해서 보관해두면 다시 돌아오는데 편리하다. 현재 tmux에 설정된 값은 다음 명령어로 추출할 수 있다. 1$ tmux show -g | sed 's/^/set-option -g /' &gt; ~/.tmux.current.conf tmux.conf를 적용하는 명령은 source-file이다. 1$ tmux source-file ~/.tmux.current.conf 참고 Tmux-Part1 Tmux-Part2 Tmux 소개 tmux 사용에 도움되는 설정과 플러그인 정리 스크롤에 대한 의견 tmux-한글-파일명-출력-문제-해결하기 [^10]: Behaviro when running multiple tmux servers","link":"/2017/05/04/linux-2017-05-04-tmux-start/"},{"title":"synergy build","text":"2017-09-17: 최초 작성{:.right-history} SynergySynergy는 키보드와 마우스 자원을 공유할 수 있는 클라이언트 서버 프로그램이다. 홈페이지: https://symless.com/synergy Github: https://github.com/symless/synergy-core {:width=”600”} [그림. Synergy 통한 결합 (symless.com)] https://symless.com/synergy 에서 유료 가입도 가능하고, 소스 기반의 배포본을 직접 빌드해서 사용할 수 있다. 사용하는 Mac과 Arm 기반의 Orangepiplus, Raspberry Pi 사이의 키보드/마우스 공유를 위해서 Synergy를 사용하는데, Arm 기반의 바이너리가 없어서 빌드를 하는 과정을 기록했다. Build여기서는 다음 저장소의 버전을 사용. https://github.com/brahma-dev/synergy-stable-builds 위 페이지의 releases 페이지에 MacOS 버전은 dmg 로 제공받을 수 있다. 다만 Arm 기반 머신의 바이너리는 없어서 소스 빌드를 해야 한다. 다운로드한 소스에서 README 파일을 참고해서 빌드를 한다. 사전 준비소스 빌드를 위해서 개발용 패키지가 필요하다. 여기서 Ubuntu, Debian 계열에서 필요한 패키지만 나열했다. [^1] Ubuntu 10.04 to 15.10 1sudo apt-get install cmake make g++ xorg-dev libqt4-dev libcurl4-openssl-dev libavahi-compat-libdnssd-dev libssl-dev libx11-dev Debian 7/8 1sudo apt-get install build-essential cmake libavahi-compat-libdnssd-dev libcurl4-openssl-dev libssl-dev lintian python qt4-dev-tools xorg-dev fakeroot Orangepi Plus현재 Orangepiplus 머신에 Armbian 릴리즈를 설치해서 사용중이다. 그런데 빌드중 gtest, qmake 관련한 에러가 발생해서 libgtest와 qt4-qmake 를 설치했다. 12sudo apt install libgtest-devsudo apt install qt4-qmake libqt4-dev build소스를 git으로 다운로드한다. 123git clone https://github.com/brahma-dev/synergy-stable-builds.git synergycd synergycat README README에서 “hm conf” 와 “hm build” 로 빌드한다고 한다. 쉘 유틸리티 hm.sh 를 사용한다. 1./hm.sh 먼저 빌드환경을 설정 - hm.sh genlist 결과 중에서 선택한다. 123$ ./hm.sh genlist1: Unix Makefiles2: Eclipse CDT4 - Unix Makefiles 해당 빌드환경으로 선택해 설정을 시작한다. 12345$ ./hm.sh conf -g 1Mapping command: conf -&gt; configureRunning setup...Setup complete.cmake version 3.5.1 빌드를 진행한다 - 거의 1시간 이상 소요 허…ㄱ 허…ㄱ 1$ ./hm.sh build 빌드중 다음같은 qmake 에러가 발생하면 12Going back to: /home/qkboo/Hdd/synergy-stable-buildsError: Could not test for cmake: qmake: could not exec '/usr/lib/arm-linux-gnueabihf/qt4/bin/qmake': No such file or directory qt4-qmake를 설치해 준다. 1sudo apt install qt4-qmake libqt4-dev 빌드가 완료되면 build/bin 디렉토리 밑의 실행 파일을 적당한 곳에 옮겨 놓고 synergy 를 실행하면 된다. synergy 사용보통 서버는 마우스/키보드를 공유할 컴퓨터이고, 클라이언트는 공유 마우스/키보드를 사용할 컴퓨터이다.그러므로 같은 네트워크에 있는 컴퓨터여야 한다. ( 같은 허브, 라우터 등) 아래 같이 해주면 기본적으로 마우스/키보드를 서버-클라이언트에서 사용할 수 있다. (1) 먼저 클라이언트에서 synergy를 실행해서 클라이언트 screen name을 정한다. 보통 호스트 이름이 그대로 사용된다.이 screen name으로 서버에서 접속을 허용되므로 주의해야 한다. (2) 서버에서 synergy를 실행해 클라이언트를 추가하고 클라이언트의 screen name을 입력해준다. {:width=”600”} ## 참조 [^1]: 실제 공식 컴파일 위키","link":"/2017/09/17/linux-2017-09-17-synergy-build/"},{"title":"Ubuntu&#x2F;시스템 전원관리","text":"Ubuntu - 시스템 전원관리우분투 시스템을 명령으로 잠자기, 깨우기가 가능하다. 컴퓨터의 BIOS에서 Wake On Lan이 활성화 되어야한다. WakeOnLanwakeonlan을 활성화 하려면 이더넷 인터페이스를 화인한다. 123456789$ ifconfigenp5s0 Link encap:Ethernet HWaddr 0f:1a:92:51:70:a9 inet addr:192.168.0.10 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe20::6595:e3fd:ad6:10f1/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:85121 errors:0 dropped:0 overruns:0 frame:0 TX packets:11677 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:25916710 (25.9 MB) TX bytes:1481803 (1.4 MB) 계속 ethtool 로 WakeOnLan이 활성화 되었는지 확인한다. 123456789101112131415161718192021222324252627$ sudo ethtool enp5s0[sudo] password for USERNAME:Settings for enp5s0: Supported ports: [ TP MII ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full Advertised pause frame use: Symmetric Receive-only Advertised auto-negotiation: Yes Link partner advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full Link partner advertised pause frame use: Symmetric Receive-only Link partner advertised auto-negotiation: Yes Speed: 100Mb/s Duplex: Full Port: MII PHYAD: 0 Transceiver: internal Auto-negotiation: on Supports Wake-on: pumbg Wake-on: g Current message level: 0x00000033 (51) drv probe ifdown ifup Link detected: yes 내용중에 Supports Wake-on: 항목이 WakeOnLan 지원을 확인할 수 있다. 문자에 g 가 있으면 Magic Packet™을 지원한다. 그러나 d 가 포함되지 않았으면 아래 명령으로 WoL을 활성화 해야 한다. 1$ sudo ethtool -s enp5s0 wol g 이 명령은 대부분의 시스템에서 재시동이 필요하다. 시스템이 ifupdown 으로 구성되어 있으면 /etc/network/interfaces 에 아래 같이 12345678910auto loiface lo inet loopback# The primary network interfaceauto eth0iface eth0 inet static address 10.0.0.1 netmask 255.255.255.0 gateway 10.0.0.138 up ethtool -s eth0 wol g https://askubuntu.com/questions/764158/how-to-enable-wake-on-lan-wol-in-ubuntu-16-04 Power management우분투 14 버전과 이후 버전의 시스템 전력 관리가 다르다. Ubuntu 14.04 이전1$ sudo apt install powermanagement-interface pmi 명령 혹은 pm-*** 명령을 사용해서 컴퓨터를 재울 수 있다. 12pmi action suspendpmi action hibernate 노트북에서 다음 명령도 실행된다. 12sudo pm-suspendsudo pm-hibernate Ubuntu 15 / 16 이상대상 컴퓨터를 잠자기 모드 ( suspend) 1$ sudo systemctl suspend 최대절전모드인 Hibernation은 pm-hibernate 명령을 사용한다. 1$ sudo pm-hibernate Wake-up 명령네트워크에 연결된 장치를 깨우기 위해서 wakeonlan 명령을 사용할 수 있다. wakeonlan MAC_ADDRESS 12$ wakeonlan 00:1d:92:51:70:d8Sending magic packet to 255.255.255.255:9 with 00:1d:92:51:70:d8 mac에서는 homebrew 로 wakeonlan 명령을 설치해서 사용할 수 있다. 모니터 다루기노트북 화면을 끄거나, 외부 모니터 표시를 잠시 멈출 수 있다. console 에서To turn off monitor in console, the command is the following: 12sudo vbetool dpms off # turn offsudo vbetool dpms on # turn on To regain control of the console on pressing enter key, I suggest sudo sh -c ‘vbetool dpms off; read ans; vbetool dpms on’ X windows 상태에서https://askubuntu.com/questions/253818/manually-turn-off-monitor 데스크탑 윈두우 터미널에서 xrandr 을 실행한다. 12345678910~$ xrandrScreen 0: minimum 8 x 8, current 1280 x 800, maximum 32767 x 32767LVDS1 connected primary 1280x800+0+0 (normal left inverted right x axis y axis) 331mm x 207mm 1280x800 59.9*+ 1024x768 60.0 800x600 60.3 56.2 640x480 59.9 640x400 60.0VGA1 disconnected (normal left inverted right x axis y axis)VIRTUAL1 disconnected (normal left inverted right x axis y axis) in terminal(your laptop screen is something like LVDS1, and your external monitor is some thing like VGA). turn off laptop screen12xrandr --output LVDS1 --off # turn offxrandr --output LVDS1 --on # turn on If you need to turn on the laptop screen:: 노트북 화면 크기를 조정한다. 1xrandr --output LVDS --mode 1280x800 외부 모니터를 끄려면 1xrandr --output VGA --off 참조 WakeOnLan","link":"/2017/11/01/linux-2017-11-01-ubuntu-maintain-power/"},{"title":"mongodb - Collection","text":"CollectionmongoDB는mongoDB는 Collection 이 데이터베이스 테이블과 같은 개념이다. 아래 테이블은 관계형 데이터베이스 MySQL과 MongoDB의 개념을 비교해 주고 있다. [^1] MySQL MongoDB Table Collection Row Document Column Field Joins Embedded documents, linking 늦은 데이터베이스 생성 Lazy Creationuse 명령은 데이터베이스가 존재하지 않으면 새로운 데이터베이스를 생성하고, 그리고 해당 데이터베이스로 전환한다. 12&gt; use mydbswitched to db mydb 그러나 mongodb는 lazy creation 방식을 채용해서 실제 데이터가 CRUD로 조작 될 때 컬렉션이 데이터베이스에 생성된다. use DATABASE 명령 만으로는 실제 데이터 저장공간이 만들어 지지 않는다. 아래같이 show dbs 를 실행해도 데이터베이스가 검색되지 않는다. 123456&gt; use first;switched to db first&gt; show dbs;local (empty)test 0.203125GB 아래와 같이 collection.save() 함수로 새로운 컬렉션에 도큐멘트을 생성하면 데이터베이스 저장 공간에 컬렉션 안에 도큐멘트가 생성되면서 실제 데이터가 저장된다. 12345&gt; db.first.save({ hello: &quot;Hello, Mongodb&quot;});&gt; show dbs;first 0.203125GBlocal (empty)test 0.203125GB 현재 use 로 사용 중인 데이터베이스는 dropDatabase() 함수로 데이터베이스를 삭제할 수 있다. 12345&gt; use firstswitched to db first&gt; db.dropDatabase(){ &quot;dropped&quot; : &quot;first&quot;, &quot;ok&quot; : 1 }&gt; show dbs Collection과 DocumentsmongoDB에 저장되는 도큐멘트는 JSON ojbect 와 유사하게 속성:값 형태로 구성된다. 123var a = { age: 25 };var n = { name: &quot;Ed&quot;, languages: [&quot;c&quot;, &quot;ruby&quot;, &quot;js&quot;] };var student = { name: &quot;Jim&quot;, scores: [75, 99, 87.2] }; mongoDB는 document를 컬렉션에 저장한다. collection.save()아래는 collection.save() 함수로 {a: 99} 도큐멘트를 scores 렉션에 저장하라는 명령이다. 1db.scores.save({ a: 99 }); 실제 데이터베이스의 컬렉션에 도큐멘트가 저장될 때는 바이너리 직렬 구조인 Binary JSON이라는 BSON 으로 저장된다.[^5] 그리고 해당 콜렉션의 담긴 도큐멘트를 find() 함수로 출력한다. 1db.scores.find(); 반복문을 이용해서 여러개의 documents를 저장할 수 있다. 1for(i=0; i&lt;100; i++) { db.scores.save( {a: i, exam: 5 } ) }; 컬렉션 내용을 find()를 실행하면 10개의 결과가 출력됩니다. 123456&gt; for(i=0;i&lt;100;i++){db.scores.save({a:i,b:'bbb'})};&gt; db.scores.find();{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 } 이렇게 데이터베이스에 저장된 컬렉션을 관계형 데이터베이스 처럼 CRUD 명령 셋트를 이용해 질의를 해서 사용한다. Basic Queries관계형데이터 베이스와 NoSQL 데이터베이스는 Query Language가 다르다. SQL과 NoSQL의 CRUDSQL의 INSERT 1INSERT INTO users (user_id, age, status) VALUES ('bcd001', 45, 'A') mongoDB의 INSERT 12345db.users.insert({ user_id: &quot;bcd001&quot;, age: 45, status: &quot;A&quot;,}); SQL의 SELECT 1SELECT * FROM users mongoDB의 find() 1db.users.find(); SQL의 UPDATE 1UPDATE users SET status = 'C' WHERE age &gt; 25 mongoDB의 update() 12345db.users.update( { age: { $gt: 25 } }, { $set: { status: &quot;C&quot; } }, { multi: true }); SQL의 DELETE 1DELETE FROM users WHERE user_id='bcd001' mongoDB의 remove() 123db.users.remove({ user_id: &quot;bcd0001&quot;,}); collection의 주요 CRUD 함수컬렉션에 대한 query는 Collection Method 에 설명되어 있다. 아래 테이블은 주요 CRUD 함수. Name db.collection.find() 컬렉션에서 쿼리를 행하고 결과를 cursor 객체로 반환 db.collection.findOne() 쿼리를 실행하고 도큐멘트 하나를 반환한다. db.collection.findAndModify() 자동으로 수정하고 도큐멘트 하나를 반환한다. db.collection.save() 새 도큐멘트를 삽입하기 위해 insert() 와 update()를 묶어 놓은 함수 db.collection.insert() 컬렉션 안에 새 문서를 생성한다. db.collection.insertOne() 컬렉션 안에 새 문서 하나를 생성한다. db.collection.insertMany() 컬렉션 안에 새 문서 여러개를 생성한다. db.collection.update() 컬렉션 안의 문서를 수정한다 db.collection.updateOne() 컬렉션 안에 문서 하나를 수정한다 db.collection.updateMany() 컬렉션 안에 여러 문서를 수정한다 db.collection.remove() 컬렉션에서 문서(들)을 삭제한다 db.collection.renameCollection() 컬렉션 이름을 바꾼다 컬렉션 보기show collections 명령은 콜렉션의 목록을 볼 수 있다. 12345&gt; show collectionsfooscoressystem.indexesusers collection.renameCollection()로 콜렉션명을 수정 할 수 있다. 1db.[collectionName].renameCollection(&quot;newCollectionName&quot;); 콜렉션의 삭제는 아래와 같다. 1&gt; db.[collectionName].drop() document 조회 – find()find()는 컬렉션 안의 도큐멘트 전체 혹은 지정한 도큐멘트의 속성에 해당하는 도큐멘트를 반환한다. 1db.[collectionName].find([Document]); 데이터베이스 컬렉션 students 안의 도큐멘트를 find() 함수로 보여준다. 12&gt; db.students.find(){ &quot;_id&quot; : ObjectId(&quot;513b38ad81dc4b8f06062146&quot;), &quot;name&quot; : &quot;james&quot;, &quot;age&quot; : 24, &quot;grade&quot; : &quot;A&quot; } find()로 콜렉션에 지정한 속성 값만 검색할 수 있다. 1234&gt; db.students.save({name:'jessi', age:20, grade:'A'});&gt; db.students.find({name:'james'}){ &quot;_id&quot; : ObjectId(&quot;513b38ad81dc4b8f06062146&quot;), &quot;name&quot; : &quot;james&quot;, &quot;age&quot; : 24, &quot;grade&quot; : &quot;A&quot; }&gt; 컬렉션 scores 에서 a가 0인 데이터를 출력해 보자. 1234&gt; db.scores.find({a:0});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; } 컬렉션 scores 에서 a:1, b:bbb인 데이터를 출력해 보자. 12&gt; db.scores.find({a:1, b:'bbb'});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592b&quot;), &quot;a&quot; : 1, &quot;b&quot; : &quot;bbb&quot; } 컬렉션 scores 안의 모든 도큐멘트를 a:1을 기준으로 정렬해서 반환한다. 12345&gt; db.scores.find().sort({a:1});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592b&quot;), &quot;a&quot; : 1, &quot;b&quot; : &quot;bbb&quot; } 컬렉션 scores 안의 도큐멘트 숫자를 반환한다. 12&gt; db.scores.count();110 findOne()find()와 동일한 매개변수를 이용할 수 있습니다. 다른점은 find()는 커서를 리턴하지만, findOne()은 데이터베이스에서 첫번째 document나 null을 리턴합니다. 1234567&gt; db.scores.findOne({a:0});&gt; ```결국 이 쿼리는```js&gt; find({a:&quot;0&quot;}).limit(1). 와 동일한 결과를 얻습니다. limit();쿼리의 결과의 수를 제한된 수의 결과로 제한하게 해서 처리할 수 있습니다. MongoDB cursors are not snapshots - operations performed by you or other users on the collection being queried between the first and last call to next() of your cursor may or may not be returned by the cursor. Use explicit locking to perform a snapshotted query. mongo 쉘 에서 고급 기법에 대해서는 아래 링크를 참조하세요. http://www.mongodb.org/display/DOCS/mongo+-+The+Interactive+Shell Cursor 객체find()는 cursor 객체를 리턴합니다. cursor 객체는 쿼리의 결과 집합에 대한 포인터라고 한다.[^3]cursor는 여러 데이터의 집합이므로 아래 같이 이용 할 수 있다. 1234&gt; var cursor = db.scores.find();&gt; while(cursor.hasNext()) printjson(cursor.next());{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 } printjson() 은 내장 함수로 데이터를 json 형식으로 출력해 준다. mongo 쉘로 사용시 아래 처럼 foreach 콜백 함수를 이용할 수 있다. 123&gt; db.scores.find().forEach(printjson);{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }… 또한 cursor를 배열 처럼 이용 할 수 있다. 123&gt; var cursor = db.scores.find();&gt; printjson(cursor[10]);{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; } 이 시점에 결과가 메모리에 적재되기 때문에 아주 큰 데이터를 다루면 out of memory를 만나게 될 수 있다. 배열 스타일의 접근을 위해 cursor 를 배열로 변경할 수 있다. 123&gt; var arr = db.scores.find().toArray();&gt; arr[10];{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; } 도큐멘트 - updatemongoDB에서 도큐멘트 갱신은 update methods를 참고한다. update() 메서드는 다음 형식으로 되어 있다: 1db.collection.update(query, update, options) 아래와 같은 두 개의 document가 있다. 12&gt; db.books.save({name:'James',language:['Java','C++']});&gt; db.users.save({name:'Jenny',language:['HTML5','Actionscript']}); update() 업데이트를 하면 전체 문서에 대해서 갱신이 된다. 아래 쿼리는 Jenny 라는 name 속성을 가진 도큐멘트를 모두 주어진 도큐멘트 속서으로 변경한다. 1234&gt; db.users.update( {name:'Jenny'}, {name:'James',language:['Korea','English']});&gt; db.users.find();{ &quot;_id&quot; : ObjectId(&quot;4fc05ff01708cc4a3eadd3c8&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Java&quot;, &quot;C++&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc0601d1708cc4a3eadd3c9&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Korea&quot;, &quot;English&quot; ] } 데이터의 일정부분만 갱신하려면 $set 연산자 및 배열을 위한 $push, $pull 연산자를 함께 사용할 수 있다. 12345678910&gt; db.users.update( {name:'James'}, {'$set': {age:'30'}} );&gt; db.users.find();{ &quot;_id&quot; : ObjectId(&quot;4fc0601d1708cc4a3eadd3c9&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Korea&quot;, &quot;English&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc060fa1708cc4a3eadd3ca&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Java&quot;, &quot;C++&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc060fe1708cc4a3eadd3cb&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Korea&quot;, &quot;English&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc05ff01708cc4a3eadd3c8&quot;), &quot;age&quot; : &quot;30&quot;, &quot;language&quot; : [ &quot;Java&quot;, &quot;C++&quot; ], &quot;name&quot; : &quot;James&quot; }&gt; db.users.update({name: 'Sue'}, {'$pull': {'languages': 'scala'} });&gt; db.users.update({name: 'Sue'}, {'$push': {'languages': 'ruby'} }); collection.remove()도큐멘트의 항목을 삭제할 수 있다. 12&gt; db.users.remove({name:'James'});&gt; db.users.find(); 모든 데이터를 제거하려면 remove()만 호출합니다. 1&gt; db.users.remove(); index 생성 123db.scores.encureIndex( {a:1, b:’bbb’});group(), min(), max(), $where Query와 Projection 연산자쿼리에 제약 혹은 확장을 할 수 있는 쿼리 선택자 (Query selector)는 비교, 논리, 요소, 배열 등에 대한 연산자로 지원된다. Projection 연산자는 쿼리의 특정 부분만을 투영할 수 있는 연산자를 지원하고 있다. [^4] 자세하고 더 많은 내용은 Query and Projection operators를 참조하라. $gt 연산자입력된 데이터에서 20보다 큰 데이터를 찾아 보겠습니다. 12345&gt; db.scores.find({a:{'$gt':30}});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005949&quot;), &quot;a&quot; : 31, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400594a&quot;), &quot;a&quot; : 32, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400594b&quot;), &quot;a&quot; : 33, &quot;b&quot; : &quot;bbb&quot; }… $gte 연산자$gte는 Greater Than or Equal로 크거나 같은 값을 비교하는 연산자 123&gt; db.scores.find({a:{'$gte':22}});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005940&quot;), &quot;a&quot; : 22, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005941&quot;), &quot;a&quot; : 23, &quot;b&quot; : &quot;bbb&quot; } $lt, $lte 연산자$lte 연산자는 작거나 같은 값을 비교하는 연산자 1234&gt; db.scores.find( {a:{'$lte':5}} );{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 } $ne 연산자$ne 연산자는 같지 않은 값을 비교하는 연산자 1234&gt; db.scores.find({b:{'$ne':'bbb'}});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 } $gte 와 $lte를 동시에 쓰기도 한다 1234&gt; db.scores.find({a: {'$gte':5,'$lte':8}});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e32&quot;), &quot;a&quot; : 5, &quot;b&quot; : 6 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e33&quot;), &quot;a&quot; : 6, &quot;b&quot; : 7 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e34&quot;), &quot;a&quot; : 7, &quot;b&quot; : 8 } $in in Array$in 연산자는 주어진 컬렉션 값이 포함되었는지 비교한다. 12345&gt; db.scores.find({a:{'$in':[10,20,30,40]}});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005934&quot;), &quot;a&quot; : 10, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400593e&quot;), &quot;a&quot; : 20, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005948&quot;), &quot;a&quot; : 30, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005952&quot;), &quot;a&quot; : 40, &quot;b&quot; : &quot;bbb&quot; } 반대로 $nin 연산자는 주어진 컬렉션에 포함 안된 값을 비교한다. 1234567&gt; db.scores.find({a:{'$nin':[10,20,30]}});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 }…has more","link":"/2017/04/21/linux-2017-04-21-mongodb-collections/"},{"title":"Ubuntu&#x2F;Debian Basic Security settings","text":"리눅스 시스템을 설치후 기본적인 보안 설정과 도구를 사용하는 과정을 정리했다. firewall 과 sshd rootkit fail2ban Firewall과 ssh 보안 구성사용자 로그인에 제약을 두고, 원격 접속에 대해서 방화벽과 sshd 보안을 강화한다. sudoer 등록처음 로그인후 새로운 사용자 등록하고 suders에 직접 권한을 줄 수 있다. sudo 새 사용자 등록sudo 사용자를 추가해서 사용하려면, adduser 혹은 useradd 명령을 사용해서 사용자를 등록 할 수 있다. 새 사용자 등록먼저 adduser를 사용한 등록은, 1234567891011121314151617# adduser qkbooAdding user `qkboo' ...Adding new group `qkboo' (1000) ...Adding new user `qkboo' (1000) with group `qkboo' ...Creating home directory `/home/qkboo' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for qkbooEnter the new value, or press ENTER for the default Full Name []: Gangtai Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] y useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. http://www.tecmint.com/add-users-in-linux/ ‘useradd‘ 명령은 크게 두가지 일을 한다: 추가한 사용자에 대한 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 편집 사용자 홈 디렉토리 생성 1$sudo useradd -m qkboo 그리고 패스워드를 등록한다. 1234$ sudo passwd qkbooNew password:Retype new password:passwd: password updated successfully userdel 로 사용자 완전 삭제시 1$ userdel -r sambaguest visudovisudo 명령으로 sudoers 파일을 편집할 수 있다. sudoer에 있는 root는 제외하고 사용자로 등록한다. 123$ sudo visudo# User privilege specificationpi ALL=(ALL:ALL) ALL sudo 사용자를 sudo 그룹에 등록해 둔다. 1$ sudo usermod -aG sudo pi ufw를 사용한 방화벽 등록1$ sudo apt install ufw 방화벽 기본 규칙을 실행한다. 12$ sudo ufw default deny incoming$ sudo ufw default allow outgoing 리눅스 방화벽 구성에 대해서는 포스트 UFW Firewall on Ubuntu/Debian 에 자세히 설명하고 있다. 123$ sudo ufw allow ssh$ sudo ufw allow http$ sudo ufw allow https 그리고 ufw로 방화벽을 활성화 한다. 1234$ sudo ufw statusStatus: inactive$ sudo ufw enable 현재 서버의 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 1$ netstat -tlnp ping (icmp) 허용/거부UFW 기본설정은 ping 요청을 허용하도록 되어있다. 이것은 /etc/ufw/before.rules 파일에 정의되어 있는데 여기서 icmp 프로토콜 관련한 항목을 DROP으로 처리하거나 삭제하면 ping을 방지할 수 있다. 123456 # ok icmp codes-A ufw-before-input -p icmp --icmp-type destination-unreachable -j ACCEPT-A ufw-before-input -p icmp --icmp-type source-quench -j ACCEPT-A ufw-before-input -p icmp --icmp-type time-exceeded -j ACCEPT-A ufw-before-input -p icmp --icmp-type parameter-problem -j ACCEPT-A ufw-before-input -p icmp --icmp-type echo-request -j ACCEPT samba 허용 12$ sudo ufw allow Samba$ sudo ufw allow from 192.168.0.0/16 to any app Samba syslog 에 패킷 필터링 결과를 로깅 하려면, 12$ sudo ufw logging onLogging enabled 리눅스 방호벽에 ssh 허용한다. ufw를 사용한다면 다음 같이 해준다. ssh 보안 ssh Brute-force Attack 방어 1$ sudo ufw limit ssh ssh를 특정 IP 주소에만 접속을 허용한다 1sudo ufw allow from 192.168.0.100 to any port 22 1sudo ufw allow from 192.168.0.100 to any port 22 proto tcp sshd 보안 구성ssh 사용에 특정한 사용자, 호스트 등에서만 사용하도록 제한하게 구성한다. sshd_config 수정/etc/ssh/sshd_config에서 다음 내용으로 수정한다. 포트, IP, Time out 시간을 지정할 수 있다. 12345678910111213141516#sshd 포트넘버 변경 (Port)Port 2222#sshd Listen AddressListenAddress 192.168.0.200# alive 메시지 사용 결정TCPKeepAlive no # 기본 yes.# 클라이언트가 살아있는지 확인하는 간격.ClientAliveInterval 60 # 기본 0.# 클라이언트에서 응답이 없을 때 메시지를 보내는 횟수ClientAliveCountMax 3 # 확인 횟수# Login Prompt에서 사용자 입력을 기다리는 시간을 초 단위로 입력.LoginGraceTime 20 #( 1m: 기본 1분지정, 0은 시간제한없음) 사용자 계정에 대한 접근 1234567891011121314# no로 설정하면 root 계정으로 Login 불가능.PermitRootLogin no# SSH 접속을 통해 Login을 허용할 User를 지정. 지정된 User 외의 접속은 차단됨.# 여러 계정 입력시 Space로 구분.AllowUsers foo# sudo(관리자)그룹만 로그인가능( 다른 유저들도 ssh로그인을 가능하게 하려면 이부분 삭제 )AllowGroups sudo# 모두 접속이 허용, 여기에 등록된 group만 접속 거부됨#DenyGroups# 모두 접속이 허용, 여기에 등록된 계정만 접속 거부됨#DenyUsers issue 이용ssh 로그인시 Banner로 지정한 Text File의 내용을 Login Prompt에 출력한다. 시스템 접근에 대한 사전 경고이다. /etc/ssh/sshd_config 에 Banner를 추가한다. 12# 설정한 경로에 존재하는 Text File의 내용을 Login Prompt에 출력.Banner /etc/issue.net 그리고 /etc/issue.net 파일에 다음 경고를 넣어준다. 12345678910111213141516171819202122232425&gt; ***************************************************************************&gt; NOTICE TO USERS&gt;&gt; This computer system is the private property of its owner, whether&gt; individual, corporate or government. It is for authorized use only.&gt; Users (authorized or unauthorized) have no explicit or implicit&gt; expectation of privacy.&gt;&gt; Any or all uses of this system and all files on this system may be&gt; intercepted, monitored, recorded, copied, audited, inspected, and&gt; disclosed to your employer, to authorized site, government, and law&gt; enforcement personnel, as well as authorized officials of government&gt; agencies, both domestic and foreign.&gt;&gt; By using this system, the user consents to such interception, monitoring,&gt; recording, copying, auditing, inspection, and disclosure at the&gt; discretion of such personnel or officials. Unauthorized or improper use&gt; of this system may result in civil and criminal penalties and&gt; administrative or disciplinary action, as appropriate. By continuing to&gt; use this system you indicate your awareness of and consent to these terms&gt; and conditions of use. LOG OFF IMMEDIATELY if you do not agree to the&gt; conditions stated in this warning.&gt;&gt; **************************************************************************** systemd 를 사용하면, 12$ sudo systemctl restart sshd.service$ sudo systemctl status sshd.service upstart를 사용하면, 1$ sudo service ssh restart 공개키 방식을 이용일반 패스워드를 사용하는 로그인 방식보다 rsa 키를 이용한 접속이 보다 보안에 좋다. 그리고 일단 한번 설정해 놓으면 편하다. 서버에 /etc/ssh/sshd_config 설정에서 rsa키 사용에 대한 설정이 제대로인지 살펴본다. 12PubkeyAuthentication yesRSAAuthentication yes ssh 클라이언트클라이언트에서 공개키 생성을 한다. 키의 크기를 높이려면 -b 옵션으로 1024, 2048, 4096 값을 제시한다. 1234567891011121314151617181920212223(CLIENT)$ mkdir ~/.ssh(CLIENT)$ chmod 700 ~/.ssh(CLIENT)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@CLIENT_HOST&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/daddy/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /Users/daddy/.ssh/id_rsa.Your public key has been saved in /Users/daddy/.ssh/id_rsa.pub.The key fingerprint is:SHA256:nBbRg+tTnmEbyuqzb0cqeBfzuaj1XOJP3n767Xmj3s0 USER@CLIENT_HOSTThe key\\'s randomart image is:+---[RSA 4096]----+| .o || ..o || .. . || ..o= || oS= = || .B = || . ..B..o || . =.+=+= ..o*|| o+Oo.=o++=BE|+----[SHA256]-----+ 개인 비밀키와 공개키 파일이 ~/.ssh 폴더에 기본 파일이름 id_rsa.pub, id_rsa.prb 파일로 저장된다. 서버에서 할일서버에서 비밀키를 생성한다. 12(SERVER)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@SERVER&quot;(SERVER)$ chmod 700 ~/.ssh 클라이언트 공개키를 서버 배포서버로 id_rsa.pub를 scp 로 복사해서 authorized_keys 파일에 더해주면 된다. 아래 같이 할 수 있다. 1cat ~/.ssh/id_rsa.pub | ssh USER@SERVER 'cat &gt;&gt; .ssh/authorized_keys' scp로 복사하고 서버에서 authorized_keys 파일에 더해줄 수 있다. 123(CLIENT)$ scp ~/.ssh/id_rsa.pub USER@SERVER:~/client.pub(CLIENT)$ ssh userid@SERVER(SERVER)$ cat client.pub &gt;&gt; .ssh/authorized_keys; rm client.pub 이제 해당 서버로 로그인해 본다. 아래 같이 시스템 명칭을 주고 생성할 수 도 있다. 1ssh-keygen -t rsa -C &quot;Raspberry Pi #123&quot; 권한은 아래와 같이 클라이언트와 서버 모두 설정한다. 1234chmod 600 ~/.ssh/id_rsachmod 644 ~/.ssh/id_rsa.pubchmod 644 ~/.ssh/authorized_keyschmod 644 ~/.ssh/known_host 그리고 클라이언트에서 서버로 ssh 접속을 해본다. 로그인 과정 없이 로그인되면 공개키 방식의 인증이 마무리되ㅓㅇㅆ다. 1(CLIENT)$ ssh USER@SERVER 개인키 파일을 이용한 로그인-i 옵션을 이용하면 개인키를 여러개 만들어 두고 서버 마다 달리 로그인 할 수 있다. 1ssh -i .ssh/개인키 id@host-Name Root kitchkrootkit 루트킷 탐지 프로그램 일반적인 루트킷, 커널 기반 루트킷, Worm 까지도 탐지 가능 설치1$ sudo apt install chkrootkit 컴파일로 빌드 설치시 http://www.chkrootkit.org/ 에서 다운로드후 빌드한다. 123$ tar -zxvf chkrootkit.tar.gz$ cd chkrootkit-0.50$ make sense 루트킷 실행1$ sudo chkrootkit not infected, not found 가 아닌 경우 잘 살펴보자. rkhunterRootkit이 System에 설치되어 있는지 Check합니다. chkrootkit 에서 검사하지 않는 설정 파일들이나 서버 계정 등 을 검사 하기 때문에 chkrootkit 과 함께 사용하면 좋다. 1$ sudo apt install rkhunter 설치 시에 MTA(Matil Transfer Agent)인 Postfix가 의존성으로 같이 설치됩니다. RPi Jessie에서 설치시 rkhunter Invalid SCRIPTWHITELIST configuration option: Non-existent pathname: /usr/bin/lwp-request 경고 발생lwp-request는 명령행 HTTP 사용자 에이전트로 사용하지 않는다면 &gt; /etc/rkhunter.conf에 있는 SCRIPTWHITELIST /usr/bin/lwp-request 주석 처리참조: lwp-request 실행1$ sudo rkhunter -c skip 1$ sudo rkhunter -c --skip-keypress --pkgmgr dpkg 1$ sudo rkhunter -c -sk // --skip-keypress updateproperties update 1$ sudo rkhunter --propupd 업데이트 점검 1$sudo rkhunter --update cron 설정12345$ sudo vi /etc/default/rkhunterCRON_DAILY_RUN=&quot;true&quot;CRON_DB_UPDATE=&quot;true&quot;APT_AUTOGEN=&quot;true&quot; 자세한 결과가 저장된 /var/log/rkhunter.log의 내용을 토대로 Google에서 검색하거나 Rkhunter Users Mailing List를 이용한다. /var/log/rkhunter.log ## Fail2ban 로그를 검사해 의심스런 IP 를 찾아 Firewall rule에 등록해 관리하는 것은 어려운 과정이다. Fail2ban은 정규표현식을 사용해서 로그에서 의심스런 IP를 찾아 Firewall 등록 할 수 있도록 해준다. 설치fail2ban 은 iptables 패키지와 함께 설치한다. 1$ sudo apt install iptables fail2ban 그리고 systemctl 로 재대로 서비스가 시작되는지 확인해 본다. 12$ sudo systemctl restart fail2ban.service # 재시작$ sudo systemctl status fail2ban.service # running 상태 확인 설정을 위해서 fail2ban 설정 파일인 fail2ban.conf, 그리고 jail 파일 jail.conf 파일을 .local 파일로 복사한 사용자 정의 파일에서 사용한다. 123$ cd /etc/fail2ban$ sudo cp fail2ban.conf fail2ban.local # 설정파일$ sudo cp jail.conf jail.local # jail 설정 /etc/fail2ban 디렉토리주요 파일, fail2ban.local : fail2ban 주요 설정 파일 jail.local: jail 설정 파일 jail.d/defaults-debian.conf: jail enable/disable paths-common.conf: 로그 파일 경로 paths-debian.conf: 로그 파일 경로 fail2ban.localfail2ban 에서 전역 설정을 무선언해 줍니다. 예를 들어 검출된 IP중에 무시할 영역을 선언해 줍니다. 1234[DEFAULT]ignoreip = 127.0.0.1/8 192.168.0.1/24bantime = 2592000 # 금지 시간을 늘린다.maxretry = 3 # 금지된 행위 시도 횟수 jail.localjail.d/defaults-debian.conf 파일에 jail 을 활성화 혹은 비활성화 시킨다. 기본으로 sshd 만 활성화 되어 있다. 아래는 nginx 에 대해서도 활성화 했다. 12345678[sshd]enabled = true[nginx-http-auth]enabled = true[nginx-botsearch]enabled = true 시스템 서비스 포트 확인현재 시스템의 활성화되어 있는 포트는 netstat 명령으로 확인할 수 있다. 12345$ sudo netstat -tulpentcp 0 0 127.0.1.1:53 0.0.0.0:* LISTEN 0 12762 731/dnsmasqtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 0 16387 670/sshdtcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 0 10674 708/nginx -g daemon 열려 있는 포트를 fail2ban 의 jail을 활성화해서 방화벽으로 감시하면 된다. fail2ban 사용fail2ban-client, fail2ban-regex 명령을 이용해 jail의 ban 상태를 확인하거나 테스트 할 수 있다. Jail 실행 확인fail2ban-client 명령으로 해당 jail을 확인 할 수 있다. 1234$ sudo fail2ban-client statusStatus|- Number of jail: 6 - Jail list: nginx-noproxy, nginx-noscript, nginx-nohome, nginx-badbots, sshd 전체 jail 중에 특정한 것만 확인한다. 12345678Status for the jail: ssh|- filter| |- File list: /var/log/auth.log| |- Currently failed: 208| `- Total failed: 4357`- action |- Currently banned: 679 | `- IP list: 2.176.38.209 116.31.116.53 181.21.6.110 153.171.66.99 190.67.247.209 201.179.200.15 103.207... 테스트의심스런 동작을 Filter로 선언해서 사용하는데 해당 필터를 점검해야할 필요가 있다. 다음 1$ sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf lastb실패한 로그인 시도View Failed Login Attempts – lastb 참조. -w 로 사용자 이름을 출력하고 첫번째 열만 자른 후 정렬한 후, uniq 명령으로 중복되는 이름을 제거한 후 출력한다. 1$ sudo lastb -w | cut -d &quot; &quot; -f 1 | sort | uniq | less 이중에서 접속한 IP와 횟수를 출력한다. 12345678$ sudo lastb -f /var/log/btmp.1 -w -i | awk '{print $3}' | sort | uniq --count | sort -nr | less[sudo] root의 암호: 2166 112.85.42.156 1945 112.85.42.193 1591 112.85.42.201 1327 112.85.42.230 1146 112.85.42.196 참조[^1]: Ubuntu Server의 보안을 위해서 해야 할 것들 (Part 1)[^2]: Ubuntu Server의 보안을 위해서 해야 할 것들 (Part 2)[^3]: How To Protect SSH with Fail2Ban on Ubuntu 14.04[^4]: 우분투 방화벽(UFW) 설정","link":"/2017/04/03/linux-2017-04-03-linux-basic-securities/"},{"title":"Photoshop Clipping Mask","text":"클리핑 마스크는 원본 이미지에 다른 이미지를 합성할 때 유용하다. 클리핑 마스크 Clipping MaskClipping-Mask는 원본의 특정 영역에, 클리핑 마스크로 다독거린 이미지로 매스킹해서 깔끔하게 합성한 이미지를 표현한다. 그래서 클리핑 마스크는 원본 이미지에 다른 이미지를 합성할 때 유용하다. 원본 이미지에서 일분 영역만을 Clipping-Mask 이미지로 대입해서 표현할 수 있다. 노트북 사진의 배경 변경하기여기서 사용한 방법은 이곳 블로그([^1]) 를 참조해서 연습했다 - 링크에 있는 스마트폰 배경을 클리핑하는 과정은 자세히 설명되어 있다. 아래 그림 같이 왼쪽 맥북 화면에 F1 배경 이미지를 Clipping Mask를 넣어 보자. {:width=”800”} [그림. 노트북에 배경을 클리핑한 예제] 이미지 준비: 1. 배경 이미지를 하나. 2. 노트북 이미지 하나. 노트북 배경 만들기: 배경 이미지를 합성할 노트북 이미지를 가져와서 노트북 이란 레이어로 만든다. 이미지에서 배경을 대입할 영역을 Lasso 같은 툴로 선택한다. 선택된 상태에서 *레이어복제 (Ctrl+J, Cmd+J)*를 실행하면, 선택한 부분만 새 레이어로 만들어 지는데, 이 이름을 타겟 이라고 하겠다. 타겟에 넣을 이미지를 가져와서, 레이어 혹은 스마트 오브젝트 등으로 추가해 레이어를 배경 으로 하자 레이어 패널에서 배경 레이어와 타겟 레이어 사이를 Alt+클릭 혹은 Ctrl+Alt+g키를 누르면 Clipping Mask가 생성되서 배경이 클리핑 마스크한 타겟에만 보이게 된다. {:width=”800”} [그림. 레이어 패널 상태와 배경을 클리핑한 상태] 노트북 이미지 누운 경사와 배경을 맞추려면 배경 레이어에서 Transform 으로 조절하면 된다. Edit -&gt; Transform -&gt; Skew 로 조절할 수 있다. 클리핑 마스크 이미지가 타겟에 보여지지만 노트북 이미지를 가리는 부분이 생길 수 있다 - 여기서는 맥북의 Dock이 가려져 보인다.이때는 노트북 레이어에서 배경 마스크에 보이게 하려면, 노트북 레이어를 Lasso, Maque, Eraser 등으로 지워주면 원하는 모습에 가까와 진다. 사진에서 원하는 부분 지우기이미지나 사진에서 원하는 부분만 남기고 나머지를 지우는 작업을 많이 하게 되는데 이때도 Clipping-Mask를 사용하면 깔끔하게 된다. {:width=”600”} 작업할 사진/이미지를 가져온다. 여기서 앞의 F1 배경 사진에서 레드불 RB16 차를 뒤 배경 아스팔트와 잔디로 채우는 작업을 클리핑마스크와 스탬프 도구를 함께 사용하면 두드러지지 않게 차를 지울 수 있다. 가져온 이미지를 *레이어복제(Ctrl+J, Cmd+J)*한다. 복제한 레이어 이름을 work으로 하겠다. work 이미지에서 Pen, Maque, Lasso 같은 도구로 사라지게 할 영역을 둘러싸고 선택영역으로 만든다. 선택영역 상태에서 레이어 패널에서 레이어복제(Ctrl+J, Cmd+J) 해서 레이어 이름을 대상으로 하겠다. 이 대상 레이어 위헤 빈 레이어를 하나 만들고 레이어 이름을 클리핑 이라고 하자, 대상과 클리핑 레이어 사이를 Alt+클릭 하면 클리핑레이어가 클리핑 마스크로 전환된다. work 레이어에서 Stamp 툴을 선택하고, 교체할 영역을 Alt+클릭으로 지정해 준다. 그리고 클리핑 레이어를 선택하고 바꿀 이미지 영역을 클릭해주면 원본 손상없이 클리핑마스크 영역만 원하는 이미지 영역으로 스탬프로 복제하게 된다. {:width=”400”} 참조[^1]: 클리핑마스크 활용한 이미지 틀안에 쉽게 넣기","link":"/2017/05/20/photoshop-2017-05-20-photoshop-clipping-mask/"},{"title":"Photoshop - 찢어진 틈 사이의 이미지 콜라쥬 효과 만들기","text":"포토샵으로 Collages 를 만드는 과정을 해보았다. 찢어진 틈 사이의 이미지 콜라쥬 효과 만들기 1. 찢어진 틈 사이의 이미지 콜라쥬 효과 만들기스케치북을 찢은 사이로 사진이 보이게 하는 효과를 내보자. {:width=”800”} 배경사진 위에 찢은 스케치북 레이어를 두고, 복제한 사진을 연필 스케치 필터 효과를 준 후에, 클리핑 마스크를 적용하고 있다. 작업pixabay.com 에서 “찢어진 종이” ripped papers 로 검색해서 적당한 것을 찾아서 사용했다. {:width=”800”} 준비한 사진 위에 ripped paper를 배치한다. {:width=”800”} 먼저 1) 사진 이미지 레이어에서 Ctrl/Cmd+J키로 레이어를 복제해서, 레이어의 맨 위에 위치한다. 2) Filter &gt; Stylized &gt; Find Edges 효과를 준 후에 Desaturation으로 적절히 조절한다. 3) 마지막으로 레이어에서 오른쪽 클릭으로 클리핑마스크를 주고 Blend mode를 Multiply로 준다. Opacity를 줄여 보며 연필 스케치한 종이를 찢은 효과가 나도록 한다. {:width=”800”} 원 배경 사진 혹은 복제한 레이어는 Rasterized 한 상태여야 한다. (스마트 이미지는 Saturation 적용이 안된다) 참조 Ripped paper image 본인 배경사진","link":"/2018/08/16/photoshop-2018-08-16-collages-rippedimage/"},{"title":"Python - Install virtualenv on Linux","text":"Python 개발환경을 위해서 시스템에 설치된 python2.7, python3.x 에서 사용하는 패키지 모듈을 pip를 사용해서 패키지를 관리할 수 있다. 그리고 시스템 모듈과 별도의 버전 환경으로 버전 관리 도구인 virtualenv와 virtualenvwrapper 를 사용해 파이썬 가상 개발 환경을 구성하는 방법을 설명한다. Python virtualenv 개발환경 구축하기최근 리눅스 배포본은 python2.7, python3.x 버전이 내장되어 있다. raspbian-wheezy에는 Python 2.7과 Python 3.2가 설치되어 있다 raspbian jessie에는 Python 2.7과 Python 3.3이 설치되어 있다. armbian Debian Jessie, Ubuntu Xenial 에도 Python 2.7과 Python3.3 이 설치되어 있다. 파이썬 개발환경은 virtualenv 를 기반으로 사용하는 것을 권장한다. 그리고 가상 개발 환경은, 시스템 개발자 모듈 설치 시스템 Python pip 설치 pip에서 시스템 Python virtualenv, virtualenvwrapper 설치 가상환경 만들기 순서로 구성할 수 있다. Python 가상 개발 환경 설치다양한 파이썬 버전을 위해 환경 구성을 해주는 유틸리티. pyenv : “Simple Python Version Management”, 로컬에 다양한 파이썬 버전을 설치하고 사용할 수 있도록 한다. pyenv를 사용함으로써 파이썬 버전에 대한 의존성을 해결할 수 있다. virtualenv : “Virtual Python Environment builder”, 로컬에 다양한 파이썬 환경을 구축하고 사용할 수 있도록 한다. 일반적으로 Python Packages라고 부르는 ( pip install을 통해서 설치하는 ) 패키지들에 대한 의존성을 해결할 수 있다. autoenv : 만약 pyenv와 virtualenv를 통해서 의존성을 해결한다고 하더라도 작업할때마다 설정해주는 것은 귀찮은 작업이다. 특정 프로젝트 폴더로 들어가면 자동으로 개발 환경을 설정해주는 autoenv라는 스크립트를 활용할 수 있다. pyenvhttp://pythonstudy.xyz/python/article/506-파이썬-가상환경 여기서는 virtualenv와 virtualenvwrapper를 사용해서 모듈을 설치하고 관리한다. pip 모듈을 사용해서 virtualenv 와 virtualenvwrapper 를 설치한다. virtualenv 단독 사용다음 참조. http://dgkim5360.tistory.com/entry/python-virtualenv-on-linux-ubuntu-and-windows virtualenv는 가상환경이 설치된 위치로 이동해서, 설치한 폴더에서 source 명령을 통해 환경을 활성화해야 한다. 이런 점을 보완해 쉘 명령을 제공하는 virtualenvwrapper와 함께 쓰는 것을 권한다. 여기서는 pip로 virtualenv와 virtualenvwrapper를 설치해서 사용한다. virtualenv와 virtualenvwrappervirtualenv는 가상의 파이썬 작업환경을 만들어 준다. 작업환경을 따로따로 만들어, 시스템 파이썬 모듈이나 다른 가상의 작업환경에게 영향을 주지 않는다. 또한 pip는 시스템의 site-packages 폴더 /usr/lib/python2.7/site-packages에 모듈을 설치하는데 virtualenv를 이용하면 분리할 수 있다. 이제 pip로 virtualenv와 virtualenvwrapper를 설치한다. 12$ pip3 install virtualenv$ pip3 install virtualenvwrapper virtualenvwrapper는 virtualenv 통합 환경을 쉽게 다룰 수 있게 해준다. 쉘 프로파일 .bashrc, .profile 등에 다음 라인을 추가한다. 123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh 그리고 쉘 환경을 로딩하기 위해서 다시 로그인 하거나 다음 같이 source 명령을 이용해도 좋다. 12345678910111213141516$ source .profileebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extentpermitted by applicable law.Last login: Fri Oct 23 18:17:41 2015 from 192.168.219.103virtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/get_env_details 다음 에러가 발생하면 쉘에 VIRTUALENVWRAPPER_PYTHON 를 추가해 준다. /usr/bin/python: No module named virtualenvwrappervirtualenvwrapper.sh: There was a problem running the initialization hooks. If Python could not import the module virtualenvwrapper.hook_loader,check that virtualenvwrapper has been installed forVIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is Quick-Start새로운 가상환경은 mkvirtualenv 명령으로 만든다. 가상환경으로 전환시 프롬프트가 (NAME) $ 형태로 표시된다. 123$ mkvirtualenv django2 #기본 python 버전의 환경 생성...(django2):~$ # 실행 가상 환경 쉘 mkvirtualenv 명령은 -p 옵션으로 파이썬 버전을 명시할 수 있다. 1$ mkvirtualenv -p python3 django3 --system-site-packages 옵션은 site-package 시스템 버전을 사용하게 한다. 1$ mkvirtualenv --system-site-packages -p python3 django3 workon 명령으로 설치한 가상 환경 목록을 보거나 혹은 해당 가상환경으로 전환할 수 있다. 12345$ workondjango2 django3$ workon django3...(django3):~$ 프로젝트 환경을 빠져 나오려면 deactivate를 실행한다. 1(django3):~$ deactivate 가상환경 복사하기12$ cpvirtualenv django3 new_djang4$ rmvirtualenv django3 pyvenv3.3에서부터 pyvenv에 기본으로 설치되어 있다. 다만 3.3에서는 pip를 가상 환경을 만들 때마다 설치해주어야 한다. 3.4에서는 pip까지 기본으로 설치되어 있다. 12345$ mkdir django_tests$ cd django_tests$ pyvenv-3.4 env$ source env/bin/activate # env의 파이썬 활성화(env)$ deactivate # 시스템 파이썬으로 복귀 System serviceVirtualevn 환경을 시스템 시작 스크립, 크론, 파이썬 스크립에서 사용하려면 해당 가상 환경 위치의 python 혹은 가상환경의 jupyter-notebook 같은 명령 위치를 지정하면 된다. https://serverfault.com/questions/821575/systemd-run-a-python-script-at-startup-virtualenv 참조virtualenvwrapper","link":"/2017/04/03/python-2017-04-03-virtualenv-linux/"},{"title":"Python - Install virtualenv on macOS X","text":"Python 개발환경을 위해서 macOS에 설치된 python2.7 그리고 brew 같은 유틸리티로 python3.x 를 설치하고, pip를 사용해서 패키지를 관리할 수 있다. 그리고 다양한 모듈과 시스템 모듈의 분리를 위해서 버전 관리 도구인 virtualenv와 virtualenvwrapper 를 사용해 가상 개발 환경을 구성하는 방법을 설명한다. macOS에서 Python virtualenv 개발환경 구축하기macOS 에는 python2.6, python2.7이 설치되어 있다. python3를 설치하려면 HomeBrew, MacPort 같은 시스템 유틸리티 관리자를 이용한다. 여기서는 HomeBrew 를 사용했다. 1$ brew install python3 사전 준비파이썬 패키지 도구인 pip(Python Package Index, PyPI)는 파이썬 모듈을 검색, 설치, 관리 할 수 있다.설치된 python 버전에 따라 pip가 설치되어 있다. brew로 python3를 설치하면 pip3 버전이 설치된다. pip --version 버전 정보를 출력하면 버전과 site-packages 위치를 확인할 수 있다. 1234$ pip --versionpip 7.1.2 from /Library/Python/2.7/site-packages (python 2.7)$ pip3 --versionpip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6) site-packagespip 로 설치되는 패키지 모듈은 시스템의 site-packages 폴더에 설치된다. python2.7은 /usr/lib/python2.7/site-packages python3.4는 /usr/lib/python3.4/site-packages 그래서 시스템에 설치된 pip는 sudo로 설치한다. brew로 설치한 python3의 pip3는 사용자 환경에서 접근이 가능해서 sudo 없이 설치해도 된다. 12$ sudo pip install --upgrade pip$ pip3 install --upgrade pip3.6 이후는 특별히 버전을 명시하지 않으면 pip는 pip3.6을 사용한다고 가정한다. Python 가상 개발 환경 설치앞서 언급한데로 개발을 위해 site-package 모듈을 유지하고 개발을 위해 설치하는 패키지 모듈을 python 버전에 의존해 관리하는 버전 관리자로 pyenv, virtualenv 같은 버전 관리자를 사용한다. 버전 관리자는 사용자 환경에 시스템 모듈을 복사해 새로 설치되는 모듈을 기존 시스템 버전과 혼동되지 않게 해준다. virtualenv와 virtualenvwrapper여기서 pip로 virtualenv와 virtualenvwrapper를 설치한다. 12$ pip3.6 install virtualenv$ pip3.6 install virtualenvwrapper 쉘 프로파일 .bashrc, .profile 등에 다음 라인을 추가한다. 123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh 그리고 쉘 환경을 로딩하기 위해서 다시 로그인 하거나 다음 같이 source 명령을 이용하면 아래 같이 virtualenvwrapper 에서 제공하는 환경변수가 설정된다. 아래는 source 명령으로 .profile을 컴파일한 결과를 보여준다. 12345678910111213$ source .profilevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/get_env_details 다음 같이 에러가 발생하면 쉘에 VIRTUALENVWRAPPER_PYTHON 를 추가해 준다. /usr/bin/python: No module named virtualenvwrappervirtualenvwrapper.sh: There was a problem running the initialization hooks. If Python could not import the module virtualenvwrapper.hook_loader,check that virtualenvwrapper has been installed forVIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is 점검I then search for the location of virtualenv and virtualenv wrapper to confirm their locations: 12$ pip3 show virtualenvLocation: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages 12$ pip3 show virtualenvwrapperLocation: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages Quick-Start새로운 가상환경은 mkvirtualenv NAME 명령으로 만든다. 가상환경으로 전환시 프롬프트가 (NAME) $ 형태로 표시된다. 123$ mkvirtualenv django2 #기본 python 버전의 환경 생성...(django2):~$ # 실행 가상 환경 쉘 mkvirtualenv 명령은 -p 옵션으로 파이썬 버전을 명시할 수 있다. 1$ mkvirtualenv -p python3 django3 --system-site-packages 옵션은 site-package 시스템 버전을 사용하게 한다. 1$ mkvirtualenv --system-site-packages -p python3 django3 workon NAME 명령으로 설치한 가상 환경 목록을 보거나 혹은 해당 가상환경으로 전환할 수 있다. 12345$ workondjango2 django3$ workon django3...(django3):~$ 프로젝트 환경을 빠져 나오려면 deactivate를 실행한다. 1(django3):~$ deactivate","link":"/2017/04/03/python-2017-04-03-virtualenv-mac/"},{"title":"Python - 과학계산을 위한 Jupyter(pip)","text":"과학계산을 위한 Python3 및 pip를 사용한 scipy, jupyter 설치 및 구성을 요약하고 있다. https://packaging.python.org/guides/installing-scientific-packages/ 과학계산을 위한 Python Jupyter과학계산을 위한 Python 과 Jupyter Notebook 환경을 정리한다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy 등 Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux Setup시스템에 Python2, Python3 가 설치되었는지 확인: Ubuntu/Debian 계열: Python 2.7, Python 3.5 설치되어 있다. openSUSE : Python2.7 Python 3 설치시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. 12sudo apt-get install build-essentialsudo apt-get install python-dev python-distlib python3-dev python3-distlib python-dev, python-distlib, apython-setuptools 은 파이썬 개발과 패키징을 지원한다. apt-get install libfreetype6-devapt-get install pkg-configapt-get install libpng-devapt-get install pkg-config libzmq3-dev은 쥬피터 노트북에서 필요로 한다. 1sudo apt-get install libzmq3-dev python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 Pandas 로 데이터 셋트를 다룰 예정, libgdal-dev 은 geopandas에서 geospatial analysis 에 필요하다. 1sudo apt-get install libgdal-dev For Debian Jessie and Stretch installing the following packages resolves the issue: 1sudo apt-get install libblas3 liblapack3 liblapack-dev libblas-dev Your next issue is very likely going to be a missing Fortran compiler, resolve this by installing it like this: 1sudo apt-get install gfortran pip 설치1apt-get install python3-pip python3 설치후 마지막으로 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 12sudo pip install -U pipsudo pip install -U setuptools pip로 설치하기Python2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. Scientific stack아래 같이 사용자 영역에 python3 기반으로 설치해보자, pip 를 파이썬 버전의 site-package 에 모듈을 설치하기 위해서 파이썬 -m 을 사용한다. 1python3 -m pip install --user numpy sympy nose scipy는 설치 시스템에 따라 시간이 많이 걸린다. 또한 swap 영역을 사용하므로 스왑파일시스템을 활성화 하는 것을 권한다. 1python3 -m pip install --user scipy error스왑 파일시스템을 사용하지 않거나 모자라면 아래 같이 가상메모리 에러 혹은 컴파일 에러가 나는 것 같다. 123 #warning &quot;Using deprecated NumPy API, disable it by &quot; \\ ^~~~~~~virtual memory exhausted: Cannot allocate memory 글쓴이는 OdroidC2, Armbian Stretch 에서 시도했다. pandas 및1python3 -m pip install --user pandas 파이썬이 있고 pip를 사용하여 패키지를 설치하려면 다음 명령을 사용합니다. matplotlib pillow graphviz scikit-learn conda를 사용한 패키지 설치설치된 파이썬이 있다면 conda 패키지 매니저를 사용하여 다음 명령을 실행하면 필요한 패키지를 모두 얻을 수 있습니다. conda install numpy scipy scikit-learn matplotlib pandas pillow graphviz python-graphvizpip를 사용한 패키지 설치 설치 확인설치되고 사용이 가능한지 확인한다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 12python3 -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3 12python3 -c &quot;import scipy;print(scipy.__version__)&quot;0.16.0 1python3 -c &quot;import numpy;print(matplotlib.__version__)&quot; ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 1$ python3 -m pip install --user jupyter 물론 가상환경이 아닌 시스템 패키지로 설치해도 된다.$ sudo pip install jupyter geopandas osmnx jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. Upgrade jupyter여기서는 pip 가상머신을 이용하고 있어서 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1$ python3 -m pip install -U jupyter python3 -m pip freeze —local &gt; requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567$ jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2017/10/30/python-2017-10-30-jupyter-scitific-pip/"},{"title":"Python - 과학계산을 위한 Jupyter(Armbian)","text":"Odroid C2, Raspberry Pi 계열의 ARM CPU를 위한 Armbian 에서 과학계산을 위한 Jupyter 설치 및 구성까지 요약하고 있다. https://packaging.python.org/guides/installing-scientific-packages/ 과학계산을 위한 Python Jupyter과학계산을 위한 Python 모듈을 시스템 패키지로 설치하고 pip 를 사용해서 Jupyter Notebook 을 설치하고 사용하는 과정을 정리했다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy, pandas Setup시스템에 Python2, Python3 가 설치되었는지 확인: Ubuntu/Debian 계열: Python 2.7, Python 3.5 설치되어 있다. openSUSE : Python2.7 시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. 12sudo apt-get install build-essentialsudo apt-get install python-dev python-distlib python3-dev python3-distlib python-dev, python-distlib, apython-setuptools 은 파이썬 개발과 패키징을 지원한다. pip 설치배포본에 pip가 설치되어 있지 않으면 1apt-get install python3-pip python3 설치후 마지막으로 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 라이브러리 설치Scientific stack - apt시스템 패키지로 과학계산을 지원하는 Python2, Python3 모듈을 설치. 12$ sudo apt-get install python-numpy python-decorator python-scipy python-matplotlib$ sudo apt-get install python3-decorator python3-numpy python3-scipy python3-matplotlib symbolic mathematics 관련 패키지도 설치한다. 12sudo apt-get install python-sympy python-nosesudo apt-get install python3-sympy python3-nose 설치되고 사용이 가능한지 확인한다. 다음 두 모듈 numpy, scipy 의 버전이 출력되면 된다. 12python -c &quot;import numpy;print(numpy.__version__)&quot;1.12.1 12python -c &quot;import scipy;print(scipy.__version__)&quot;0.18.1 여기까지 설치하면 의존성에 관련한 아래 같은 여러 패키지가 함께 설치된다. requests : Python package provides a graceful interface for making HTTP requests, pil : provides Python imaging capabilities, scrapy : is a web scraping framework, geopy provides geocoding and geodesic distance functions, shapely provides 2D geometry manipulation, pyproj: provides cartographic transformations. In the second command, jupyter provides interactive coding notebooks, geopandas spatializes pandas, OSMnx lets you work with OpenStreetMap street networks. 이 패키지들은 별도로 설치를 하고자 하면 pip로 설치하거나 시스템 패키지로 다음 같이 설치 할 수 있다. Python2 1sudo apt-get install python-requests python-pil python-scrapy python-geopy python-shapely python-pyproj Python3 pil -&gt; Pillow 1sudo apt-get install python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj PandasPandas 로 데이터 셋트를 다룰 예정이라면 1sudo apt-get install libgdal-dev libgdal-dev 은 geopandas에서 geospatial analysis 에 필요하다. 1sudo apt-get install python-pandas python3-pandas ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. Jupyter 관련 모듈을 pip로 사용자 환경에 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 1sudo apt-get install libzmq3-dev libzmq3-dev은 쥬피터 노트북에서 필요로 한다. pip먼저 pip를 업그레이드 해준다. 1$ sudo pip install -U pip Python2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. Install Jupyter사용자 환경에서 pip로 Jupyter를 설치한다. Python3 환경에서 설치를 권장하고 있다. 1$ python3 -m pip install --user jupyter 그리고 필요하면 Python2에서 설치할 수 있다. 1$ python2 -m pip install --user jupyter jupyter notebook을 실행해 보자. 서버로 실행jupyter notebook 을 바로 실행하면 로컬 머신의 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 브라우저 없이 시작한다. 1234567$ jupyter notebook --no-browser --ip=* --port=8000[I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e jupyter notebook을 시작하면 콘솔에 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} 사용자 설치 모듈 목록여기까지 pip로 사용자 환경 local에 설치한 모듈 목록을 백업해 둘 수 있다. 1$ pip freeze —-local &gt; requirements.txt Upgrade jupyter여기서는 pip 가상머신을 이용하고 있어서 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1$ python3 -m pip install -U --user jupyter ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service 현재 서버의 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 12$ netstat -tlnptcp 0 0 127.0.0.1:8585 0.0.0.0:* LISTEN 11906/python3 virtualenv 이용Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux 참조 Installing the Jupyter Notebook Scipy Install Scientific Python on Raspberry Pi","link":"/2017/10/30/python-2017-10-30-jupyter-scitific-virtuaenv/"},{"title":"Python - 과학계산을 위한 Jupyter(Armbian)","text":"Debian 계열의 ARM CPU를 위한 Armbian 에서 과학계산을 위한 Jupyter 설치 및 구성까지 요약하고 있다. https://packaging.python.org/guides/installing-scientific-packages/ 과학계산을 위한 Python Jupyter과학계산을 위한 Python 과 Jupyter Notebook 환경을 정리한다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy 등 Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux 공개 사이트 Google Colaboratory nbview Setup시스템에 Python2, Python3 가 설치되었는지 확인: Ubuntu/Debian 계열: Python 2.7, Python 3.5 설치되어 있다. openSUSE : Python2.7 Python 3 설치시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. 12sudo apt-get install build-essentialsudo apt-get install python-dev python-distlib python3-dev python3-distlib python-dev, python-distlib, apython-setuptools 은 파이썬 개발과 패키징을 지원한다. pip 설치apt-get install python3-pip python3 설치후 마지막으로 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 라이브러리 설치1sudo apt-get install libzmq3-dev libzmq3-dev은 쥬피터 노트북에서 필요로 한다. python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 Scientific stack - pipPython2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. xlsx 파일을 위해 xlrd 패키지 설치 pip install -U –user xlrd Scientific stack - apt과학계산을 지원하는 Python2 모듈을 시스템 패키지에 apt 로 설치할 수 있다. 12$ sudo apt-get install python-numpy python-decorator python-scipy$ sudo apt-get install python-matplotlib Python3 패키지도 설치한다. 12$ sudo apt-get install python3-decorator python3-numpy python3-scipy$ sudo apt-get install python3-matplotlib symbolic mathematics 관련 패키지도 설치한다. 12sudo apt-get install python-sympy python-nosesudo apt-get install python3-sympy python3-nose 설치되고 사용이 가능한지 확인한다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 12python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3 12python -c &quot;import numpy;print(numpy.__version__)&quot;0.16.0 여기까지 설치하면 의존성에 관련한 아래 같은 여러 패키지가 함께 설치된다. requests : Python package provides a graceful interface for making HTTP requests, pil : provides Python imaging capabilities, scrapy : is a web scraping framework, geopy provides geocoding and geodesic distance functions, shapely provides 2D geometry manipulation, pyproj: provides cartographic transformations. In the second command, jupyter provides interactive coding notebooks, geopandas spatializes pandas, OSMnx lets you work with OpenStreetMap street networks. 이 패키지들은 별도로 설치를 하고자 하면 pip로 설치하거나 시스템 패키지로 다음 같이 설치 할 수 있다. Python2 1sudo apt-get install python-requests python-pil python-scrapy python-geopy python-shapely python-pyproj Python3 1sudo apt-get install python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj PandasPandas 로 데이터 셋트를 다룰 예정이라면 1sudo apt-get install libgdal-dev libgdal-dev 은 geopandas에서 geospatial analysis 에 필요하다. 1sudo apt-get install python-pandas python3-pandas ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 여기서는 가상환경을 구성해 Jupyter 관련 패키지를 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 virtualenv 와 virtualenvwrapperpip 를 업그레이드하고, 가상 개발환경에서 쥬피터 관련 모듈을 설치하고 관리하기 위해 pip로 virtualenv, virtualenvwrapper 설치한다. 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 1sudo pip install --upgrade pip 그리고 virtualenv, virtualenvwrapper 설치하는데, 사용자의 .local 폴더에 설치하도록 한다. 1pip install --user virtualenv virtualenvwrapper 자동으로 추가되지 않으면, 다음 스크립을 .bashrc 에 추가해 준다. 123456789# set PATH for pipif [ -d &quot;$HOME/.local/bin&quot; ] ; then PATH=&quot;$HOME/.local/bin:$PATH&quot;fiVIRTUALENVWRAPPER_PYTHON=/usr/bin/python3export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource $HOME/.local/bin/virtualenvwrapper.sh 로그아웃했다 로그인하면 mkvirtualenv, rmvirtualenv 등의 명령어 스크립이 설치된다. Jupyter 가상환경다음은 mkvirtualenv 명령으로 jupyter라는 가상환경을 python3, 시스템 패키지 사용을 위해 –system-site-packages 옵션으로 생성한다. 1234mkvirtualenv -p python3 --system-site-packages jupyter(jupyter) $(jupyter) $ python --versionPython 3.4.6 가상환경 jupyter 에서 필수 모듈이 사용 가능한지 확인한다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 1234(jupyter) $ python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3(jupyter) $ python -c &quot;import numpy;print(numpy.__version__)&quot;0.16.0 그리고 pip로 Jupyter 가상환경에 Jupyter를 설치한다. 1(jupyter)$ pip install jupyter 물론 가상환경이 아닌 시스템 패키지로 설치해도 된다.$ sudo pip install jupyter geopandas osmnx jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. Upgrade jupyter여기서는 pip 가상머신을 이용하고 있어서 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1(jupyter)$ pip install -U jupyter virtualenv, virtualenvwrapper는 여기서 사용자 .local 환경에 설치했으므로 1pip install -U --user virtualenv virtualenvwrapper pip3 freeze —local &gt; requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567$ jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일다음 같이 설정 파일을 생성해서 사용할 수 있다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345## The base URL for the notebook server.c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. 우선 jupyter-notebook 명령의 절대 경로를 찾아서 이 위치를 유닛 파일의 Exec 명령에 사용한다. 12$ which jupyter-notebook/home/foo/.local/bin/jupyter-notebook systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.local/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service 현재 서버의 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 세번째 컬럼 처럼 127.0.0.1 에 열리면 외부에서 접근이 안된다. 12$ netstat -tlnptcp 0 0 127.0.0.1:8585 0.0.0.0:* LISTEN 11906/python3 12$ netstat -tlnptcp 0 0 0.0.0.0:8585 0.0.0.0:* LISTEN 11906/python3 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2017/10/30/python-2017-10-30-jupyter-scitific/"},{"title":"Python 과학계산을 위한 Jupyter Notebook - macOS","text":"과학계산을 위한 Jupyter 설치 및 구성까지 요약하고 있다. 과학계산을 위한 Python JupyterRaspberry Pi 3 위에 설치한 openSUSE LEAP 42.3 과 15.0 에서 과학계산을 위한 Python 개발환경과 Jupyter Notebook 환경을 정리한다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy 등 Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux Setup시스템에 Python2, Python3 가 설치되었는지 확인: macOS : Python2.7 python.org 설치python.org 에서 package 를 다운받아 설치한다. Uninstall package installerhttps://stackoverflow.com/questions/3819449/how-to-uninstall-python-2-7-on-a-mac-os-x-10-6-4/3819829#3819829 brew에서 Python 3 설치brew로 최신 3.7을 설치 1brew install python3 You can install Python packages withpip3 install They will install into the site-package directory /Users/qkboo/Library/Python/3.7/site-packages pip User SchemePython2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. virtualenv 와 virtualenvwrapperpip 를 업그레이드하고, 가상 개발환경에서 쥬피터 관련 모듈을 설치하고 관리하기 위해 pip로 virtualenv, virtualenvwrapper 설치한다. 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 1pip install --upgrade pip 그리고 virtualenv, virtualenvwrapper 설치하는데, 사용자의 .local 폴더에 설치하도록 한다. 1pip install --user virtualenv virtualenvwrapper 자동으로 추가되지 않으면, 다음 스크립을 .bashrc 에 추가해 준다. 123456789# set PATH for pipif [ -d &quot;$HOME/.local/bin&quot; ] ; then PATH=&quot;$HOME/.local/bin:$PATH&quot;fiVIRTUALENVWRAPPER_PYTHON=/usr/bin/python3export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource ~/Library/Python/3.7/bin/virtualenvwrapper.sh 로그아웃했다 로그인하면 mkvirtualenv, rmvirtualenv 등의 명령어 스크립이 설치된다. Scientific stack과학계산을 지원하는 Python 패키지를 설치한다. 1pip install --user numpy scipy matplotlib jupyter pandas sympy nose ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 여기서는 가상환경을 구성해 Jupyter 관련 패키지를 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 Jupyter 가상환경 사용시다음은 mkvirtualenv 명령으로 jupyter라는 가상환경을 python3, 시스템 패키지 사용을 위해 –system-site-packages 옵션으로 생성한다. 1234567891011mkvirtualenv -p python3 --system-site-packages jupyterRunning virtualenv with interpreter /usr/local/bin/python3Using base prefix '/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7'New python executable in /Users/qkboo/.virtualenvs/jupyter/bin/python3.7Also creating executable in /Users/qkboo/.virtualenvs/jupyter/bin/pythonInstalling setuptools, pip, wheel...(jupyter) $(jupyter) $ python --versionPython 3.4.6 가상환경 jupyter 에서 필수 모듈 numpy, scipy가 사용 가능한지 확인한다. 1234(jupyter) $ python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3(jupyter) $ python -c &quot;import scipy;print(scipy.__version__)&quot;0.16.0 그리고 pip로 Jupyter 가상환경에 Jupyter를 설치한다. 1(jupyter)$ pip install jupyter --user Python User scheme 에 설치시 macOS는 아래 위치에 설치되므로 경로에 추가한다. 1/Users/qkboo/Library/Python/3.7/bin jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. 현재까지 설치된 pip 모듈 목록을 저장하자. 1pip freeze --local &gt; jupyter-requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567$ jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter-notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service Upgrade jupyter여기서는 pip 가상머신을 이용하고 있고, virtualenv, virtualenvwrapper는 여기서 사용자 .local 환경에 설치했으므로 1pip install -U --user virtualenv virtualenvwrapper 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1(jupyter)$ pip install -U jupyter 1pip freeze —local &gt; requirements.txt 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2018/10/20/python-2018-10-20-jupyter-scitific-macos/"},{"title":"openSUSE - 과학계산을 위한 Python, Jupyter Notebook","text":"이 글은 OpenSuse LEAP 15 에서 과학계산을 위한 파이썬 환경을 위한 Jupyter Notebook을 설치하는 과정을 요약하고 있다. 이 글에서는 시스템 패키지로 Python3, jupyter-notebook 을 설치하고, 파이썬 가상환경에서 과학계산 파이썬 모듈을 설치한 후에 Jupyter notebook 을 운영하도록 한다. 과학계산을 위한 Python Jupyter 환경 아래 같은 플랫폼에서 시스템 패키지 소프트웨어와 파이썬 모듈을 설치하는 과정이다. Raspberry Pi 3 openSUSE LEAP 42.3, 15.0, 15.1 Jupyter Notebook Python 그래프 matplotlib 및 pillow 이미지 라이브러리 과학계산 모듈: numpy, scipy 등 파이썬 가상환경 pandas Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux 설치시스템에 Python2, Python3 가 설치되었는지 확인: Python 환경openSUSE 15.0에서 파이썬은 python2, python3.6 시스템 패키지로 설치되어 있다. pip를 설치해 준다. 1sudo zypper in python3-pip pip 를 여러 버전 사용중이라면, 만약 python2-pip 도 사용중이고 pip를 pip3로 사용하려면 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. pattern devel 로 검색해 보면,,, 123456789101112131415161718192021222324sudo zypper install -t pattern develS | Name | Summary | Type--+----------------------+-------------------------------------+-------- | devel_C_C++ | C/C++ Development | patterni | devel_basis | Base Development | pattern | devel_gnome | GNOME Development | pattern | devel_ide | Integrated Development Environments | pattern | devel_java | Java Development | pattern | devel_kde | KDE Development | pattern | devel_kde_frameworks | KDE Frameworks Development | pattern | devel_kernel | Linux Kernel Development | pattern | devel_mono | .NET Development | pattern | devel_perl | Perl Development | pattern | devel_python | Python Development | pattern | devel_python3 | Python 3 Development | pattern | devel_qt4 | Qt 4 Development | pattern | devel_qt5 | Qt 5 Development | pattern | devel_rpm_build | RPM Build Environment | pattern | devel_ruby | Ruby Development | pattern | devel_tcl | Tcl/Tk Development | pattern | devel_web | Web Development | pattern | devel_yast | YaST Development | pattern 이 중에서 devel_basis, python 관련 개발용 모듈을 설치한다. 1sudo zypper install -t pattern devel_basis 파이썬 개발 모듈을 설치한다. 12sudo zypper install -t pattern devel_python devel_python3sudo zypper install python-distutils-extra curses 관련 파이썬 모듈을 설치해야 한다. python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 1sudo zypper in python-curses python3-curses matplotlibmatplot 을 설치하면 numpy, scipy, pillow python3-tk 등이 함께 설치된다. 123456789101112131415sudo zypper in python-matplotlib python3-matplotlib...다음 새 패키지가 설치됩니다. cups cups-client cups-filters ghostscript ghostscript-x11 libICE6 libSM6 libXt6 libavahi-glib1 libcupscgi1 libcupsimage2 libcupsmime1 libcupsppdc1 libopenjp2-7 libpoppler73 libqhull7-7_2_0 libqpdf21 libwebp6 libwebpdemux2 libwebpmux2 libxml2-tools parallel-printer-support poppler-data poppler-tools python-functools32 python-subprocess32 python-tk python2-Cycler python2-Pillow python2-matplotlib python2-matplotlib-tk python2-numpy python2-olefile python2-pyparsing python2-python-dateutil python2-pytz python2-six python3-Cycler python3-Pillow python3-matplotlib python3-matplotlib-tk python3-olefile python3-tk다음 권장 패키지가 자동으로 선택되었습니다. cups-filters ghostscript ghostscript-x11 libxml2-tools poppler-data poppler-tools python2-Pillow python2-matplotlib-tk python3-Pi numpy 개발자 패키지를 설치한다. 1sudo zypper in python2-numpy-devel python3-numpy-devel Jupyter NotebookJupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 여기서는 가상환경을 구성해 Jupyter 관련 패키지를 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 가상환경으로 venv 사용 설치Zeromq-devel 설치한다. libczmq5은 쥬피터 노트북에서 필요로 한다. LEAP 14는 libzmq3 다. 1sudo zypper install zeromq-devel libzmq5 jupyter notebook 을 시스템 패키지로 설치한다. 1234567891011121314151617181920212223242526272829303132sudo zypper in python3-jupyter_notebook...다음 새 패키지가 설치됩니다. ethtool libcmark0_28_3 libgfortran4 libibverbs libibverbs1 liblua5_1-5 libmlx4-1 libmlx5-1 libnuma1 libopenblas_openmp0 librdmacm1 libucm0 libucp0 libucs0 libuct0 libxslt1 mpi-selector openmpi openmpi-config openmpi-libs pandoc python-sip-common python3-Automat python3-Babel python3-Genshi python3-Jinja2 python3-MarkupSafe python3-PyNaCl python3-Pygments python3-Send2Trash python3-Twisted python3-asn1crypto python3-attrs python3-backcall python3-bcrypt python3-bleach python3-certifi python3-cffi python3-constantly python3-cryptography python3-cssselect python3-defusedxml python3-entrypoints python3-gevent python3-greenlet python3-html5lib python3-hyperlink python3-idna python3-incremental python3-ipython_genutils python3-jedi python3-jsonschema python3-jupyter_client python3-jupyter_core python3-jupyter_ipykernel python3-jupyter_ipyparallel python3-jupyter_ipython python3-jupyter_ipywidgets python3-jupyter_nbconvert python3-jupyter_nbformat python3-jupyter_notebook python3-jupyter_qtconsole python3-jupyter_widgetsnbextension python3-lxml python3-mistune python3-mpi4py python3-numpy python3-pandocfilters python3-paramiko python3-parso python3-pexpect python3-pickleshare python3-prometheus_client python3-prompt_toolkit python3-psutil python3-ptyprocess python3-py python3-pyOpenSSL python3-pyasn1 python3-pyasn1-modules python3-pycparser python3-pycrypto python3-pycurl python3-pymongo python3-pyserial python3-python-dateutil python3-pytz python3-pyzmq python3-service_identity python3-simplegeneric python3-simplejson python3-sip python3-terminado python3-testpath python3-tornado python3-traitlets python3-wcwidth python3-webencodings python3-zope.interface rdma-core다음 권장 패키지가 자동으로 선택되었습니다. ethtool openmpi-config pandoc python3-Genshi python3-Pygments python3-Twisted python3-cffi python3-gevent python3-jupyter_client python3-jupyter_ipykernel python3-jupyter_ipyparallel python3-jupyter_ipython python3-jupyter_ipywidgets python3-jupyter_nbconvert python3-jupyter_nbformat python3-jupyter_notebook python3-jupyter_qtconsole python3-lxml python3-mpi4py python3-numpy python3-paramiko python3-pexpect python3-psutil python3-py python3-pycurl python3-pymongo python3-service_identity python3-simplejson python3-tornado다음 패키지가 제안되지만 설치되지 않습니다. python3-jupyter_notebook-latex 가상환경 구성jupyter notebook 을 실행하고 사용할 파이썬 과학계산 모듈을 위한 가상환경을 구성한다. 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 1sudo pip install --upgrade pip 가상환경은 사용자 홈디렉토리의 .venv 폴더로 가정한다. python3, 파이썬 시스템 라이브러리를 함께 사용을 위해 –system-site-packages 옵션과 함께 jupyterscfy라는 가상환경을 생성한다. 12345~&gt; python3 -m venv --system-site-packages .venv/jupyterscfy~&gt; source .venv/jupyterscfy/bin/activate(jupyterscfy) ~&gt;(jupyterscfy) ~&gt; python --versionPython 3.6 가상환경의 pip 모듈을 최신버전으로 유지한다. 1(jupyterscfy) ~&gt; pip install --upgrade pip 실행jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. 123456789101112131415(jupyterscfy) ~&gt; jupyter notebook[I 01:15:02.799 NotebookApp] Writing notebook server cookie secret to /run/user/1000/jupyter/notebook_cookie_secret[I 01:15:21.630 NotebookApp] Loading IPython parallel extension[I 01:15:21.646 NotebookApp] Serving notebooks from local directory: /home/qkboo[I 01:15:21.646 NotebookApp] The Jupyter Notebook is running at:[I 01:15:21.647 NotebookApp] http://localhost:8888/?token=689ae860106f8a7274b50f68f69895420eab19064ebb8e69[I 01:15:21.648 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[W 01:15:21.708 NotebookApp] No web browser found: could not locate runnable browser.[C 01:15:21.710 NotebookApp] To access the notebook, open this file in a browser: file:///run/user/1000/jupyter/nbserver-8251-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=689ae860106f8a7274b50f68f69895420eab19064ebb8e69 jupyter notebook 을 종료하려면 Ctrl+C 로 인터럽트를 걸어준다. 1234567891011...^C[I 01:16:41.847 NotebookApp] interruptedServing notebooks from local directory: /home/qkboo0 active kernelsThe Jupyter Notebook is running at:http://localhost:8888/?token=689ae860106f8a7274b50f68f69895420eab19064ebb8e69Shutdown this notebook server (y/[n])? y[C 01:16:44.757 NotebookApp] Shutdown confirmed[I 01:16:44.760 NotebookApp] Shutting down 0 kernels(jupyterscfy) ~&gt; Scientific packagesnumpyscipymatplotlibpillow matplotlib는 외부 이미지를 png 형식만 지원한다. jpeg를 사용하려면 pillow 모듈을 설치한다. pillow 여기까지 설치하면 의존성에 관련한 아래 같은 여러 패키지가 함께 설치된다. requests : Python package provides a graceful interface for making HTTP requests, pil : provides Python imaging capabilities, scrapy : is a web scraping framework, geopy provides geocoding and geodesic distance functions, shapely provides 2D geometry manipulation, pyproj: provides cartographic transformations. In the second command, jupyter provides interactive coding notebooks, geopandas spatializes pandas, OSMnx lets you work with OpenStreetMap street networks. 이 패키지들은 별도로 설치를 하고자 하면 pip로 설치하거나 시스템 패키지로 다음 같이 설치 할 수 있다. Python2 1sudo apt-get install python-requests python-pil python-scrapy python-geopy python-shapely python-pyproj Python3 1sudo apt-get install python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj symbolic mathsymbolic mathematics 관련 패키지도 설치한다. 12sudo zypper install python-sympy python-nosesudo zypper install python3-sympy python3-nose Pandas 설치pandas 설치시 여러 번들이 필요해서 시스템 패키지가 아닌 conda 혹은 pip 로 설치한다. 123456$ time pip install pandas...real 118m4.118suser 114m47.176ssys 1m27.483s pandas를 pip로 설치시 Raspberry Pi 3의 OpenSuse 15.2 에서 실제 2시간 정도 걸린다. Pandas 로 지오 데이터 셋트를 다룰 예정이라면 백업현재까지 설치된 pip 모듈 목록을 저장하자. 1~&gt; pip freeze --local &gt; jupyter-requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567~&gt; jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} Jupyter 설정 이용jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123~&gt; jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py~&gt; cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1~&gt; jupyter-notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1~&gt; nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service Upgrade jupyter다음 같이 install 명령으로 업그레이드 할 수 있다. 1(jupyter)~&gt; pip install -U jupyter 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2019/09/05/python-2019-09-05-OpenSuse-JupyterNotebook-scientific/"},{"title":"NodeJS - mongoose","text":"이 글은 mongoose doc 에서 필요한 부분만 요약 정리했다. MongoDB와 MongooseNode.js에서 Mongodb에 연결하기 위해서 Driver가 필요 mongooseMongoDb를 위한 Node.js 커넥터로 Object Data Mapping (ODM)을 통해 MVC를 구현해 준다. using-mongodb-and-mongoose 설치프로젝트 폴더에서 npm으로 mongoose 모듈를 설치한다. 1$ npm i mongoose npm &lt; 5 이하 버전은 -S 혹은 --save 옵션으로 모듈 의존성을 package.json 에 추가한다. 12345678910&quot;dependencies&quot;: { &quot;body-parser&quot;: &quot;~1.13.2&quot;, &quot;cookie-parser&quot;: &quot;~1.3.5&quot;, &quot;debug&quot;: &quot;~2.2.0&quot;, &quot;express&quot;: &quot;~4.13.1&quot;, &quot;jade&quot;: &quot;~1.11.0&quot;, &quot;mongoose&quot;: &quot;^4.4.16&quot;, &quot;morgan&quot;: &quot;~1.6.1&quot;, &quot;serve-favicon&quot;: &quot;~2.3.0&quot;} Scheme 사용Scheme 는 Model 로 변환해야 한다. ^modelsmongoose.model() 메서드는 모델 이름과 스키마를 받아 변환한다. mongoose.model(modelName, schema); 12var schema = new mongoose.Schema({ name: &quot;string&quot;, size: &quot;string&quot; });var Tank = mongoose.model(&quot;Tank&quot;, schema); model()에 전달한 modelName은 mongoose가 자동으로 컬렉션에서 복수형으로 찾는다. 예를 들어 위의 Tank는 tanks 컬렉션을 참조한다. connect()mongoose 에서 mongodb 드라이버에 연결할 때 mongodb 버전에 따라 달리 접근한다. 또한 mongoose 4.x와 5.x 의 몇몇 옵션도 주의해서 사용해야 한다. mongodb 3.x 연결mongoose 4.x 버전 부터는 Promise를 선언하고 connect()를 연결한다. 123456789101112var mongoose = require(&quot;mongoose&quot;);mongoose.Promise = global.Promise;mongoose .connect(&quot;mongodb://localhost/somecollection&quot;) .then(() =&gt; console.log(&quot;connection succesful&quot;)) .catch((err) =&gt; console.error(err));//or mongo client optionmongoose.connect(&quot;mongodb://localhost/somecollection&quot;, { useMongoClient: true,}); mongoose 5.x 버전 부터는 Promise connect()를 연결한다. mongodb 2.x 연결mongodb 2.x 버전에서 createConnection(), connect() 메서드를 사용해 연결한다. 123456789101112var mongoose = require(&quot;mongoose&quot;);var connection = mongoose.createConnection(&quot;mongodb://localhost/sensors&quot;);//Schemasvar BookScheme = new mongoose.Schema({ title: String, author: String, year: String,});// Modelsvar BookModel = mongoose.model(&quot;Book&quot;, BookScheme); 여러 연결1234567891011var conn = mongoose.connect(&quot;mongodb://localhost/testA&quot;);var conn2 = mongoose.connect(&quot;mongodb://localhost/testB&quot;);var SensorModel = conn.model(&quot;qkboo_sensor&quot;, Sensorcheme);var ModelB = conn2.model( &quot;Model&quot;, new mongoose.Schema({ title: { type: String, default: &quot;model in testB database&quot; }, })); APIsave()Model#save()는 주어진 도큐멘트를 저장한다. return: Promise create()Model.create() 는 하나 혹은 그 이상의 도큐멘트를 저장할 수 있다. MyModel.create(docs) 는 주어지는 도큐멘트 마다 new MyModel(doc).save() 를 수행한다. methodsModel의 인스턴스는 documents 로 내장 메서드가 제공되지만, 사용자가 새로운 메서드를 추가할 수 있다. 12345var animalSchema = new Schema({ name: String, type: String });animalSchema.methods.findSimilarTypes = function (cb) { return this.model(&quot;Animal&quot;).find({ type: this.type }, cb);}; 이제 animalSchema 의 인스턴스는 새 메서드 findSimilarTypes 사용이 가능하다. 123456var Animal = mongoose.model(&quot;Animal&quot;, animalSchema);var dog = new Animal({ type: &quot;dog&quot; });dog.findSimilarTypes(function (err, dogs) { console.log(dogs); // woof}); Staticsstatic method도 추가할 수 있다. 123456789// assign a function to the &quot;statics&quot; object of our animalSchemaanimalSchema.statics.findByName = function (name, cb) { return this.find({ name: new RegExp(name, &quot;i&quot;) }, cb);};var Animal = mongoose.model(&quot;Animal&quot;, animalSchema);Animal.findByName(&quot;fido&quot;, function (err, animals) { console.log(animals);}); Db.prototype.authenticatemongodb 3.6 이후는 인증시 Socket을 통한 인증을 거부한다. 그래서 Db.prototype.authenticate 을 사용하지 않고 .MongoClient.connect 에서 인증 서명서와 함께 사용해야 한다. Promise1(node:24499) DeprecationWarning: Mongoose: mpromise (mongoose's default promise library) is deprecated, plug in your own promise library instead: http://mongoosejs.com/docs/promises.html 이것은 .save(), query 결과가 Promises/A+ conformant promises 를 반환한다는 것이다. 반환된 결과로 MyModel.findOne({}).then() and yield MyModel.findOne({}).exec() 같은 작업을 할 수 있다는 의미가 된다. Mongoose 4 는 기본으로 mpromise를 약속한다. 1234567891011var gnr = new Band({ name: &quot;Guns N' Roses&quot;, members: [&quot;Axl&quot;, &quot;Slash&quot;],});var promise = gnr.save();assert.ok(promise instanceof require(&quot;mpromise&quot;));promise.then(function (doc) { assert.equal(doc.name, &quot;Guns N' Roses&quot;);}); Queries are not promisesMongoose queries are not promises. 그러나 대신 양보와 비동기/대기를 위해 .then() 함수를 가지고 있다. fully-fledged promise 가 필요하다면 .exec() 함수를 사용하라. 123456789101112131415var query = Band.findOne({ name: &quot;Guns N' Roses&quot; });assert.ok(!(query instanceof require(&quot;mpromise&quot;)));// A query is not a fully-fledged promise, but it does have a `.then()`.query.then(function (doc) { // use doc});// `.exec()` gives you a fully-fledged promisevar promise = query.exec();assert.ok(promise instanceof require(&quot;mpromise&quot;));promise.then(function (doc) { // use doc}); Plugging in your own Promises Library New in Mongoose 4.1.0 기본 사용에서 mpromise가 만족스러웠지만, 고급 사용자는 ES6-style promises 같은 bluebird 라이브러리를 플러그인으로 넣거나 혹은 네이티브 ES6 를 사용하기를 바랬다. mongoose.Promise 로 좋아하는 ES6 스타일 프로마이즈를 사용할 수 있다. Mongoose ES6 native promises, bluebird, and q를 테스트했다. 어떤 라이브러리도 이론적으로Any promise library that exports an ES6-style promise constructor should work in theory, but theory often differs from practice. If you find a bug, open an issue on GitHub 12345678910111213var query = Band.findOne({ name: &quot;Guns N' Roses&quot; });// Use native promisesmongoose.Promise = global.Promise;assert.equal(query.exec().constructor, global.Promise);// Use bluebirdmongoose.Promise = require(&quot;bluebird&quot;);assert.equal(query.exec().constructor, require(&quot;bluebird&quot;));// Use q. Note that you **must** use `require('q').Promise`.mongoose.Promise = require(&quot;q&quot;).Promise;assert.ok(query.exec() instanceof require(&quot;q&quot;).makePromise); 참고 mongoose doc mongoose api doc mpromise bluebird](https://www.npmjs.com/package/bluebird) ES6-style promises [^1]: Promise 란","link":"/2017/07/13/nodejs-2017-07-13-mongodb-mongoose/"},{"title":"HTTPS를 위한 공인인증서 - Let&#39;s Encrypt 발급","text":"2020-06-02: 매뉴얼 방식 수정2020-02-02: 최초 작성{:.right-history} Nginx 서버에서 HTTPS 사용할 수 있는 공인인증서를 발급해 설치하려고 한다. 여기서는 Lets Encrypt 무료 공인인증서 발급을 다룬다. letsecrypt 공인인증서는 3개월 정도 기간만 사용 가능하고 갱신해야 한다. **단독 도메인을 호스팅하는 개인 서버에서 Nginx**에 적용해 본다. 인증서는 개별 도메인 혹은 와일드카드 인증서 로 도메인 안의 모든 호스트를 포함하는 두 종류로 발급이 가능하다. Let’s EncryptLet’s Encrypt 는 https://letsencrypt.org 에서 여러 인터넷 관련 업체의 후원을 받아 운영하고 있다. LetsEncrypt 발급발급을 위해 리눅스/맥 쉘 기반의 Certbot 유틸리티를 사용하거나 웹 기반으로 가능하다. 여기서는 Certbot 를 사용해서 Let’s Encrypt 와일드 카드 인증서를 발급해 보겠다. 인증서를 발급 받기위해서는 Let’s Encrypt 인증서를 자동으로 생성하고 관리하는 패키지인 certbot 를 먼저 설치해야 한다. 우분투/데비안에서 설치우분투/데이안 같은 리눅스 환경에서 설치하고 구성했다. 기타 다른 오에스 배포판은 아래 사이트에서 설치 명령어를 참고하자. https://certbot.eff.org/ Certbot 설치: 1234$ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update certbot 관련 Apache, Nginx 용 파이썬 모듈을 설치한다. Nginx 를 운영한다면 12$ sudo apt-get install python-certbot3-nginx #python3$ sudo apt-get install python-certbot-nginx Apache2 를 운영한다면, 12$ sudo apt-get install python-certbot3-apache #python3$ sudo apt-get install python-certbot-apache 와일드카드 인증서 발급와일드카드 인증서는 도메인의 호스트 단위에서 여러 서브 도메인까지 지원하는 인증서이다. 예를 들어 example1.kr 도메인의 하위 도메인 abc.example1.kr, 1234.example1.kr 등에 모두 적용하고자 할 때 와일드 카드 인증서를 발급하는 것이다. 이 인증서를 발급 하기 위해서는 도메인 서버를 다루거나 호스팅 기관의 도메인 관리 도구를 통해서 *DNS 레코드* 에 부가적인 정보를 추가해야 한다. 발급 요청시 letsencrypt 는 세 가지 방법으로 webroot와 Standalone, DNS의 3가지 방식으로 적절한 요청을 확인하는 검증 절차를 통해 발급을 인증서를 인가한다. webroot : 도메인 호스트 서버에 임의 Url에 접근해 검증. standalon: DNS: 도메인의 DNS 서버에 TXT 필드에 임의의 값 통해 검증. webroot 방식웹루트 방식으로 진행하기 전에 먼저 nginx 를 종료해 둔다. 1# systemctl stop nginx 다음 certbot 명령에서 수동모드로 도메인 example1.kr 도메인의 와일드카드 인증서와 호스트 example1.kr 에 대해 명령을 실행한다. 1# certbot certonly --manual -d &quot;*.example1.kr&quot; -d &quot;example1.kr&quot; 수동모드 진행을 시작하면 IP 로깅을 묻는다. 12345678 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you're running certbot in manual mode on a machine that is notyour server, please ensure you're okay with that.Are you OK with your IP being logged?- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: Y 이어서 다음 같이 웹 사이트 접근 URL을 통해서 인증하도록 요구한다. 123456789101112- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Create a file containing just this data:AyTml9aa0IXw0RjNHERtktSxIxjFAkJvUOVis8dDRLQ.dSiF50fKKa4aji-OuIlgg62idngOi4nR6yzEHRaTLsIAnd make it available on your web server at this URL:http://example1.kr/.well-known/acme-challenge/kyTAl9aa0IXw0RjNHERtktSxIxjFAkJvUOVis8dDRLO...Enter 웹 서비스에 파일을 추가하고 내용에 데이터를 넣은후 ngixn 를 시작한다. 1# systemctl start nginx 서버측에 검증을 위해 http://example1.kr/.well-known/acme-challenge/kyTAl9aa0IXw0RjNHERtktSxIxjFAkJvUOVis8dDRLO 경로에 텍스트 파일에 내용을 입력한다. URL 준비가 되면 터미널에서 enter 를 입력하고 정상적으로 인증이 되면 아래 같이 결과를 출력해 준다. 12345678910111213141516Waiting for verification...Cleaning up challengesIMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/example1.kr/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/example1.kr/privkey.pem Your cert will expire on 2020-09-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run &quot;certbot renew&quot; - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 정상적으로 진행되면 인증서와 개인키 파일이 저장된다: /etc/letsencrypt/live/example1.kr/fullchain.pem /etc/letsencrypt/live/example1.kr/privkey.pem 이 파일을 nginx 서버에 설정에 구성하면 된다. DNS 방식 와일드카드 인증서 요청다음 certbot 명령은 도메인 *.example1.com 의 와일드카드 인증서를 요청한다. 12345678910111213# certbot certonly --manual --preferred-challenges dns -d &quot;*.example1.com&quot; -d &quot;example1.com&quot;Saving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator manual, Installer NoneEnter email address (used for urgent renewal and security notices) (Enter 'c' tocancel): gangtai.goh@gmail.comSaving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator manual, Installer NoneObtaining a new certificatePerforming the following challenges:dns-01 challenge for example1.com IP 로깅을 묻는다. 1234567891011---NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you're running certbot in manual mode on a machine that is notyour server, please ensure you're okay with that.Are you OK with your IP being logged?---(Y)es/(N)o: y IP정보 수집 이후에 DNS의 TXT 레코드에 입력할 코드가 발급된다. 이 코드를 도메인 관리 도구에서 주어지 호스트명에 TXT 레코드에 입력한다. 예) 아래는 _acme-challenge.example1.kr 라는 호스트 1234567891011121314---Please deploy a DNS TXT record under the name\\_acme-challenge.example1.kr with the following value:aOVF_X388V8fYECoTJyArawJ95VpUffyUWqH8Q8bJAaBefore continuing, verify the record is deployed.---Press Enter to ContinueWaiting for verification...Cleaning up challenges DNS 관리하는 곳에서 서브 도메인 _acme-challenge.example1.kr 에 위에 출력된 해시코드를 TXT 레코드 추가해 준다. 적용한 후 아래 같이 dig 같은 네임서버 명령으로 txt 레코드에 추가한 해시코드가 나오는지 확인하고 엔터로 진행한다. 123456$ dig txt _acme-challenge.example1.kr...;; ANSWER SECTION:_acme-challenge.example1.kr. 180 IN TXT &quot;aOVF_X388V8fYECoTJyArawJ95VpUffyUWqH8Q8bJAa&quot; 그리고 발급된 도메인 인증서가 저장된 위치가 나타난다. 1234567891011121314IMPORTANT NOTES:- Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/example1.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/example1.com/privkey.pem Your cert will expire on 2020-05-23. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew _all_ of your certificates, run &quot;certbot renew&quot;- If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 정상적으로 진행되면 인증서와 개인키 파일이 저장된다: /etc/letsencrypt/live/example1.kr/fullchain.pem /etc/letsencrypt/live/example1.kr/privkey.pem 이 파일을 nginx 서버에 설정에 구성하면 된다. Let’s Encrypt 자동갱신Let’s Encrypt 인증서는 발급받으면 기간이 사용할 수 있는 기간이 3개월이다. 계속해서 HTTPS 서비스를 운영하려면 인증서가 만료되기 전에 갱신을 해야 한다. certbot 명령으로 자동으로 갱신할 수 있는데 보통 크론에 등록해 두고 사용할 수 있다. root 권한이 필요하므로 root 계정의 cronttab에 아래와 같은 내용을 추가한다. 아래는 3개월 후 달의 1일에 명령을 실행을 등록했다. 10 0 1 1-12/3 * /bin/bash -l -c 'certbot renew --quiet' 혹은 매달 실행하려면 아래 같이 매달 1일 인증서 갱신 명령어를 실행하도록 해도 될 것 같다. 10 0 1 * * /bin/bash -l -c 'certbot renew --quiet' Nginx 설정nginx에 와일드 카드 도메인을 사용할 여러 가상호스트가 구성되어 있다는 가정에서 시작한다. HTTPS 적용하기와일드 카드 nginx.conf 파일에 SSL이 활성화 되었는지 확인한다. 123456### SSL Settings##ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLEssl_prefer_server_ciphers on; 실제 적용할 가상호스트 파일의 server 섹션에 다음 같이 인증서 파일을 활성화 한다. 가상호스트 파일이 여러개고 같은 서브 도메인이면 똑같이 적용해 주면 된다. 123456789101112server { listen [::]:443 ssl http2 ipv6only=on; listen 443 ssl http2; server_name www.exmaple1.com example1.com; ssl_certificate /etc/letsencrypt/live/example1.kr/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example1.kr/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; http 요청을 https에 리다이렉트다음 구성은 http://example1.com 로 들어오는 모든 연결을 https://example1.com 으로 전환하는 구성이다. VirtualHost 별로 아래와 같이 Port 80 에 대한 Server설정과 443에 대한 Server설정을 분리 Port 80 에 대해서는 301 Redirect 설정 Nignx 재시작 123456789101112server { listen 80; server_name example1.com example2.com; return 301 https://$host$request_uri;}server { listen [::]:443 ssl http2 ipv6only=on; listen 443 ssl http2; server_name example1.com example2.com; ...} 참고 Certbot: Debian Instruction Getting Started 문서 Let’s Encrypt Wildcard-certificate-with-certbot Wildcard-domain step-by-step nginx ssl 설정 Let’s Encrypt 인증서 발급 - Anapche/Nginx","link":"/2020/02/02/linux-2020-02-02-letsencrypt%E1%84%87%E1%85%A1%E1%86%AF%E1%84%80%E1%85%B3%E1%86%B8/"},{"title":"IntelliJ Communication 사용한 Springboot 시작","text":"2022/8/10: 첫번째 버전. 첫번째 스프링 부트https://start.spring.io/ 사이트에 접속해 아래 같이 프로젝트 구성을 선택한다. 그리고 오른쪽 의존성 버튼을 눌러 Initializr 에서 의존성 플러그인을 추가한다. Dependencies 추가Web 관련해 보통은 Web, Dev tools 와 Lombok 플러그인을 지정한다. Generate 로 샘플 프로젝트 다운로드Initializr 에서 구성을 완료하고 의존성 모듈을 추가한 후에 Generate 버튼을 누르면 압축된 프로젝트가 다운로드 된다. 이 압축 파일을 풀어서 Intellij 에서 연다. runsrc/main 에서 java 파일을 열면 실행 버튼이 활성화 된다. index.html 파일 추가하기src/main/resources/static 폴더에 index.html 파일을 추가한다. 파일에 HTML 로 아래 같이 입력한다. 프로젝트에 컨트롤러 추가하기Spring Web 의존성을 추가해서 라이브러리를 설치하면 웹 관련 컨트롤러를 사용하기 좋다. 다음 같인 프로젝트에 컨트롤러 패키지를 추가하고 SampleController 클래스를 추가한다. 어노테이션으로 RestController 를 지정한다. hello 메서드를 작성한다. Uri 연계를 위해서 Mapper 어노테이션을 지정한다. 이제 http://localhost:4000/hello 주소를 요청한다. 실행 가능한 배포본 만들기스프링 프로젝트는 Tomcat 같은 WAS 가 필요하고 이를 배포하는 방법이 필요했다. 스프링 부트는 단독으로 실행 가능한 웹 애플리케이션을 jar 형태로 제작하고 사용하는 것이 가능하다. Gradle 을 사용해서 몇 번의 클릭만으로 실행 가능한 웹 애플리케이션을 제작할 수 있다 물론 실행을 위해서는 Java 환경이 필요한다. Gradle Task 사용Gradle view 의 task 에서 bootjar 항목을 실행한다. 프로젝트의 build 폴더의 lib 폴더에 프로젝트 이름+0.01-SNAPSHOT.jar 실행 파일이 생성되어 있는 것을 확인할 수 있다. 이 jar 를 다운로드해서 java 로 실행해 보자 1java -jar PROJECT-0.0.1-SNAPSHOT.jar","link":"/2022/08/10/Programming-Sprinboot-01-start-springboot-intellij/"},{"title":"Coordinate System","text":"https://varun.ca/polar-coords/ Coordinate system좌표시스템은 2D, 3D 공간 안에서 점들의 위치를 결정하는 수들을 사용하도록 한다. Cartesian Coordinate system가장 유명한 좌표 시스템은 데카르트 좌표 시스템이다. 숫자 x, y 점을 (x,y) 숫자 좌표 쌍으로 각 점을 위치하게 한다.SVG, Canvas, WebGL 그리고 Sketch &amp; Illustrator 에서 활용할 수 있다. {: width=”600”} Polar Coordinate System극좌표계는 2D 좌표 시스템으로 각 점이 r 과 \\(\\theta\\\\) 로 결정된다. r은 원점에서 원주까지 거리인 반지름이고 \\(\\theta\\) 는 {: width=”600”} Converting between Polar and Cartesian Coordinates삼각법을 사용한 아래 방정식으로 극좌표계 (r, \\\\(\\theta\\\\) )에서 데카르트 좌표계로 변환할 수 있다. 12float x = r * Math.cos(theta);float y = r * Math.sin(theta); Patterns아래 패턴은 모두 극좌표를 사용해 생성한 패턴이다. 데카르트 좌표는 사각 그리드 위에 배치하기 아주 좋은 선택이다. 만약 원 주변에 무언가를 배치하려면 극좌표이 우선 선택할 수 있다. 반지름 상수를 유지하기 때문에 각 점에 대한 각을 \\(angle = 360^{\\circ} * index / number of sides \\) 같이 계산한다. 아래 자바스크립트는 위 아이디어를 구현하고 있다. 위 그림에서 점의 바깥 가장자리 원은 points(12, 200) 을 사용해 생성했다. 그 다음 점들은 points(12, 175, 15) 를 사용했다. CodePen splash 가 이것을 사용해 구성했다. hl_lines1234567891011121314151617181920function points(count, radius, offset = 0) { const angle = 360 / count; const vertexIndices = range(count); return vertexIndices.map((index) =&gt; { return { theta: offset + degreesToRadians(offset + angle * index), r: radius, }; });}// number =&gt; [0, 1, 2, ... number]function range(count) { return Array.from(Array(count).keys());}function degreesToRadians(angleInDegrees) { return (Math.PI * angleInDegrees) / 180;} Polygon Generator보통 다각형(폴리곤)은 등각인 다각형으로 모든 측면이 같은 길이에 같은 각이다. 이것은 표준 다각형의 모든 정점은 원 위에 균등하게 배치된 점인 것이다. SVG 다각형을 생성하려면 points() 함수를 사용해 점의 목록을 생성한다. 그리고 점 사이를 연결한다. SVG에서 1234567891011121314151617/** * Usage with Vanilla JS/DOM: * polygonEl.setAttribute('points', polygon((5, 64, 18))); * * Usage with React: * &lt;polygon points={polygon((5, 64, 18)} /&gt; * * Usage with View: * &lt;polygon :points=&quot;polygon((5, 64, 18)&quot; /&gt; */function polygon(noOfSides, circumradius, rotation) { return points(noOfSides, circumradius, rotation).map(toCartesian).join(&quot; &quot;);}function toCartesian({ r, theta }) { return [r * Math.cos(theta), r * Math.sin(theta)];} 예) http://winkervsbecks.github.io/gemshttps://codepen.io/winkerVSbecks/pen/PmNJpJ 상대적 극좌표기본을 점을 (r,$$\\theta$$) 로 선언할 때 이것은 원점 (0,0)에 상대적이다. 결국 원점을 점 위치로 이동한 것 과 동일하므로 정점에 상대적으로 다루는 곡선의 위치로 선언해 사용한다. 12const x = cx + r * Math.cos(theta);const y = cy + r * Math.sin(theta); SVG 캔버스에서 어떤 위치에 가운데 위치한 다각형을 그리기 위해서 다각형 생성기를 수정한다. 123456789function polygon(noOfSides, circumradius, rotation, [cx = 0, cy = 0]) { return points(noOfSides, circumradius, rotation) .map((pt) =&gt; toCartesian(pt, [cx, cy])) .join(&quot; &quot;);}function toCartesian({ r, theta }, [cx, cy]) { return [cx + r * Math.cos(theta), cy + r * Math.sin(theta)];} 예) https://codepen.io/winkerVSbecks/pen/wrZQQm 회전극좌표를 이용한 사례중 어떤 점을 중심으로 회전하는 것을 생각할 수 있다. 여기 (cx, cy) 점이 회전하는 곳이다. 일정한 간격, 시간, 위치에 따라 \\(\\theta\\) 를 증가 혹은 감소 시키면 상대적 위치에서 점이 이동한다. 1234567x = cx + r * Math.cos(theta);y = cy + r * Math.sin(theta);// somewhere in an animation loopwindow.setInterval(() =&gt; { theta++;}, 1000 / 60); 예) https://codepen.io/Yakudoo/pen/aOEeXB 극좌표 곡선여기까지 개별 점 (위치)를 살펴보았다. 몇몇 점을 그룹지어 집합에 그룹지으 형상을 선언한다. 다각형 생성 함수를 사용해서 형상의 각 정점의 위치를 계산한다. 유사한 함수를 수학 방정식을 사용해 작성해서 복합 형상과 곡선을 생성할 수 있도록 한다. 2차원 곡선은 방정식 y = f(x) 형으로 묘사된다. 예를 들어 원의 방정식은 \\(x^2 + y^2 = r^2\\) 이다. 이것은 x와 상대적인 y 를 반복해서 자취(locus) 로 불리는 점의 집합을 생성할 수 있다. 각 점은 (x, f(x)) or (g(y), y) 형태를 가진다. 극좌표는 극좌표 곡선을 그릴 수 있다. 원의 극좌표 방정식은 r = 2 * cos(0) 이다. 극좌표 곡선 위에 점은 (r(0), 0) 형태를 갖는다. 1234567// examples of fn:// circle : 2 * Math.cos(theta)// blob thing : a * (1 - Math.cos(theta) * Math.sin(3 * theta))const r = fn(theta);const x = cx + r * Math.cos(theta);const y = cy + r * Math.sin(theta); https://codepen.io/winkerVSbecks/pen/pdVLPo EukleidesAll the diagrams in this post were created using a language called eukleides. It is a fantastic tool for making geometric drawings. Just look at this declarative API 😍 1234567c = circle(point(3, 0), 3)P = point(c, 170°)M = point(0, 0)N = point(6, 0)draw (M.N.P)label M, P, N right, 0.6","link":"/2018/07/10/Programming-coordinate-system/"},{"title":"Angularjs - Karma Unit Testing","text":"angularjs 단위 테스트에 대해 정리한다. angularjs 1.6.x 에서 진행했다. macOS, Linux 환경에 적합하다. node.js 를 nvm 가상환경에서 구축하고 사용하는 방법에 대해서는 Node.js Install with nvm 를 참조하면 된다. angularjs 단위 테스트에 대해 참고한 문서는 아래 참고 섹션에 제공했다. Angularjs Testingangularjs는 unit test와 E2E (end to end) 테스트를 제공하고 있다. Unit testing E2E testing 코드/모듈/함수 레벨 테스트팅 웹 UI 테스팅 서비스, 클래스, 오브젝트 테스트에 적합 웹 서버 필요 샌드박스, 독립 테스트에 적합 통합 테스트에 적합 랜더링 결과와 angularjs 데이터 부합 확인 fast 느리다 Karma자바스크립트 단위 테스트 도구로 테스트 러너 설정시 번거로운 부분을 쉽게 할 수 있다. 시작nodejs가 설치되었으면 새 프로젝트 폴더에서 npm init 로 프로젝트를 초기화 하고 123$ mkdir angularjs-karma-test$ cd angularjs-karma-test$ npm init 글로벌로 karma와 jasmine framework를 설치한다. 12$ npm i –g karma$ npm i -g jasmine jasmine-core 만약 karma를 프로젝트의 로컬 dev 모드로 설치한다면 jasmine도 같이 로컬로 설치하자. 12$ npm i -D jasmine jasmine-core$ npm i -D karma 프로젝트에 angularjs 모듈과 mock 모듈을 설치해 준다. 12$ npm i angular$ npm i -D angular-mocks 그리고 karma.conf.js 파일을 만들기 위해 karma init 명령을 실행하면 선택 입력 항목을 물어 온다. 기본 설정으로 진행한다. 1234567891011121314151617181920212223242526272829Which testing framework do you want to use ?Press tab to list possible options. Enter to move to the next question.&gt; jasmineDo you want to use Require.js ?This will add Require.js plugin.Press tab to list possible options. Enter to move to the next question.&gt; noDo you want to capture any browsers automatically ?Press tab to list possible options. Enter empty string to move to the next question.&gt; Chrome&gt;What is the location of your source and test files ?You can use glob patterns, eg. &quot;js/*.js&quot; or &quot;test/**/*Spec.js&quot;.Enter empty string to move to the next question.&gt;Should any of the files included by the previous patterns be excluded ?You can use glob patterns, eg. &quot;**/*.swp&quot;.Enter empty string to move to the next question.&gt;Do you want Karma to watch all the files and run the tests on change ?Press tab to list possible options.&gt; yesConfig file generated at &quot;/Users/qkboo/www-app/angularjs-karma/karma.conf.js&quot;. 현재 설정을 테스트하기 위해 start 명령으로 시작하면 karma 서버가 시작된다. 12$ karma start20 12 2017 12:41:02.798:INFO [karma]: Karma v1.7.1 server started at http://0.0.0.0:9876/ 데스크탑 환경이면 karma.conf.js 에 지정한 브라우저가 실행되어 보여준다. 테스트 스펙 작성실제 테스트 시나리오를 기술하는 jasmine 테스트 스펙 파일은 아래 같은 구조를 가지고 있다. 123456789101112131415161718192021describe(&quot;테스트 대상 설명&quot;, function () { // 테스트 전처리 before(function () {}); // 테스트 후처리 after(function () {}); // it 마다 매번 실행하는 전처리 beforeEach(function () {}); // it 마다 매번 실행하는 후처리 afterEach(function () {}); it(&quot;테스트 내용 설명&quot;, function () { // 테스트 }); it(&quot;테스트 내용 설명&quot;, function () { // 테스트 });}); 테스트 코드 작성app/src/app.js 1angular.module(&quot;myapp&quot;, [&quot;myapp.service&quot;]); 서비스 모듈을 생성하고 테스트 해보자, test/test.service.js 테스트 스펙을 작성해 보자. app/src/test/test.service.js 123456789describe(&quot;서비스 테스트&quot;, function () { beforeEach(module(&quot;myapp.service&quot;)); //모듈 로드 describe(&quot;서비스 모듈 버전 테스트&quot;, function () { it(&quot;현재 버전 반환&quot;, inject(function (version) { expect(version).toEqual(&quot;0.1&quot;); })); });}); myapp.service.js를 작성한다. app/src/service/myapp.service.js 1angular.module(&quot;myapp.service&quot;, []).value(&quot;version&quot;, &quot;0.1&quot;); //버전 karma를 종료했다 다시 실행한다 – (소스 및 스펙 변경이 바로 적용 안된다면…) 이제 테스트 스크립을 실행해 보기 위해 karma.conf.js에 소스 파일들을 명시하자. files는 karma가 실행될 때 로드되는 파일의 path를 가지고 있는 배열이다. 1234567files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/test/test*.js'], 앞서 실행한 karma 를 종료하지 않아도 된다. 소스를 추가하고 변경하면 테스트가 자동으로 시작된다. 브라우저는 angular-mock으로 테스트하는 프레임워크로 브라우저 내용에는 별다른 정보가 나타나지 않는다, 터미널에 테스트가 실패하면 12Chrome 63.0.3239 (Mac OS X 10.12.6) 서비스 테스트 서비스 모듈 버전 테스트 현재 버전 반환 FAILED Expected '0.1' to equal '1.0'. 버전 정보를 요구되는 값으로 변경하고 저장하면 로그에 다음 같이 테스트 스크립 성공 여부가 표시된다. 1Chrome 63.0.3239 (Mac OS X 10.12.6): Executed 1 of 1 SUCCESS (0.016 secs / 0.012 secs) 컨트롤러 테스트 작성컨트롤러는 Scope을 통해 데이터 바인딩이에 대해 … app/src/test/test.service.js 테스트 스펙을 작성해 보자. 컨트롤러 모듈을 들여오고 필요한 모듈, 여기서 $scope를 주입하고 모듈에 적재되었는지 테스트한다. 1234567891011121314151617181920212223242526describe(&quot;서비스 테스트&quot;, function () { var scope; // 1. 모듈을 들여오고 beforeEach(module(&quot;myapp.controller&quot;)); //모듈 로드 describe(&quot;컨트롤러 모듈 테스트&quot;, function () { //2. 필요한 모듈, 여기서 $scope를 주입하고 it(&quot;컨트롤러 들여오기&quot;, inject([ &quot;$rootScope&quot;, &quot;$controller&quot;, function ($rootScope, $controller) { // 새 스코프 scope = $rootScope.$new(); // 대상 컨트롤러에 의존성을 주입하고 들여온다. userListController = $controller(&quot;userListController&quot;, { $scope: scope, }); }, ])); //3. 모듈에 적재되었는지 테스트한다. it(&quot;userListController 컨트롤러가 정의되어 있다.&quot;, function () { expect(userListController).toBeDefined(); }); });}); 실제 컨트롤러 소스 가 없으므로 아래 같이 에러가 발생한다. 123456Chrome 63.0.3239 (Mac OS X 10.12.6) 서비스 테스트 컨트롤러 모듈 테스트 userListController 컨트롤러가 정의되어 있다. FAILED ReferenceError: userListController is not defined at UserContext.&lt;anonymous&gt; (app/src/test/test.controller.js:18:14)Chrome 63.0.3239 (Mac OS X 10.12.6): Executed 2 of 3 (2 FAILED) (0 secs / 0.013 secChrome 63.0.3239 (Mac OS X 10.12.6): Executed 3 of 3 (2 FAILED) (0 secs / 0.018 secChrome 63.0.3239 (Mac OS X 10.12.6): Executed 3 of 3 (2 FAILED) (0.026 secs / 0.018 secs) 이제 app/src/controller/myapp.controller.js 소스를 작성한다. 123456789angular .module(&quot;myapp.controller&quot;, []) .controller(&quot;userListController&quot;, [ &quot;$scope&quot;, function ($scope) { $scope.test = &quot;Hello Test!&quot;; }, ]); 이제 myapp.controller.js 를 karma.conf.js에 추가해 준다. 123456789files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/controller/myapp.controller.js', 'app/src/test/test*.js'], karma를 종료했다 다시 실행한다 – (소스 및 스펙 변경이 바로 적용 안된다면…) 실제 테스트가 제대로 수행되면 알개 같이 SUCCESS 메시지를 볼 수 있다. 1Chrome 63.0.3239 (Mac OS X 10.12.6): Executed 3 of 3 SUCCESS (0.018 secs / 0.013 secs) 컨트롤로 메서드 단위 테스트myapp.service 에 ‘UserService’ 를 선언한다. 12345678angular .module(&quot;myapp.service&quot;, []) .factory(&quot;UserService&quot;, [ function () { return {}; }, ]); 컨트롤러에 userList 배열을 선언해 주낟. 12345.controller('userListController', ['$scope', function($scope) { $scope.test = &quot;Hello Test!&quot;; $scope.userList = [];}]) test.controller.js 스펙에 12345678910111213141516171819202122232425262728293031323334353637describe(&quot;서비스 테스트&quot;, function () { var userListController, scope, mockService; beforeEach(module(&quot;myapp.controller&quot;)); //모듈 로드 describe(&quot;컨트롤러 모듈 테스트&quot;, function () { it(&quot;컨트롤러 들여오기&quot;, inject([ &quot;$rootScope&quot;, &quot;$controller&quot;, function ($rootScope, $controller) { scope = $rootScope.$new(); //임의 사용자 조회 서비스를 만든다. mockService = { getUserList: function (callback) { callback.call(null, [{ name: &quot;Hello&quot; }]); }, }; // 대상 컨트롤러에 의존성을 주입하고 'UserService' 서비스를 주입한다. userListController = $controller(&quot;userListController&quot;, { $scope: scope, UserService: mockService, }); }, ])); it(&quot;userListController 컨트롤러가 정의되어 있다.&quot;, function () { expect(userListController).toBeDefined(); }); // 사용자 조회 함수를 테스트 한다. it(&quot;사용자를 조회한다.&quot;, function () { scope.searchUsers(); // 1건의 결과가 있다. expect(scope.userList.length).toEqual(1); }); });}); 컨트롤러에 searchUsers() 함수가 없으므로 에러가 발생한다. 1TypeError: scope.searchUsers is not a function 컨트롤러에 UserService를 주입하고, searchusers() 함수를 선언해 준다. 1234567891011.controller('userListController', ['$scope','UserService', function($scope, UserService) { $scope.test = &quot;Hello Test!&quot;; $scope.userList = []; $scope.searchUsers = function() { UserService.getUserList(function(data) { $scope.userList = data; }) }}]) 서비스 단위 테스트앞서 서비스로 UserService 팩토리를 선언했다. 제대로 들여오는지 테스트 스펙에 다음 같이 선언할 수 있다. test.service.js 스펙에 다음을 추가하자. 123it(&quot;UserService가 정의되어 있다&quot;, inject(function (UserService) { expect(UserService).toBeDefined();})); 이제 getUserList() 함수를 테스트해보자 123456789101112131415161718var users;it(&quot;UserService.getUserList 가 사용자를 조회한다&quot;, inject(function ( UserService, $httpBackend) { // http 응답 $httpBackend.when(&quot;GET&quot;, &quot;sample.json&quot;).response([{ name: &quot;test&quot; }]); //서비스를 호출한다. UserService.getUserList(function (data) { users = respond.data; }); $httpBackend.flush(); // http 응답에 1건이 있으므로 expect(d.length).toBe(1);})); 실제 getUserList() 함수가 구현 안되어 있으므로 다음 같이 실패가 나타난다. 12320 12 2017 14:59:44.061:INFO [watcher]: Changed file &quot;/Users/qkboo/www-app/angularjs-karma/app/src/test/test.service.js&quot;.Chrome 63.0.3239 (Mac OS X 10.12.6) 서비스 테스트 UserService.getUserList 가 사용자를 조회한다 FAILED TypeError: UserService.getUserList is not a function 실제 서비스 객체에 함수를 선언해 주자. 12345678.factory('UserService', ['$http', function($http) { return { getUserList: function(callback) { $http.get('sample.json') .then(callback); } };}]) Directive 테스트1234567891011121314151617181920describe(&quot;디렉티브 테스트&quot;, function () { beforeEach(module(&quot;myapp.directives&quot;)); //모듈 로드 describe(&quot;app-version 디렉티브 테스트&quot;, function () { it(&quot;현재 버전 출력&quot;, function () { module(function ($provide) { $provide.value(&quot;version&quot;, &quot;TEST_VER&quot;); }); inject([ &quot;$compile&quot;, &quot;$rootScope&quot;, function ($compile, $rootScope) { var element = $compile(&quot;&lt;span app-version&gt;&lt;/span&gt;&quot;)($rootScope); expect(element.text()).toEqual(&quot;TEST_VER&quot;); }, ]); }); //it });}); 디렉티브 모듈을 선언한다 1234567891011angular .module(&quot;myapp.directives&quot;, []) .directive(&quot;appVersion&quot;, [ &quot;version&quot;, function (version) { return function (scope, elm, attrs) { elm.text(version); }; }, ]); 추가한 소스를 karma.config.js 에 추가해 준다. 12345678910files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/controller/myapp.controller.js', 'app/src/directive/myapp.directive.js', 'app/src/test/test*.js' ], 필터 테스트필터를 테스트 할 때는 필터를 inject 한 후에 호출하면서 진행한다. 먼저 테스트 스펙을 작성해 보자. 12345678910111213141516describe(&quot;필터 테스트&quot;, function () { beforeEach(module(&quot;myapp.filters&quot;)); //모듈 로드 var $filter; describe(&quot;length 필터 테스트&quot;, function () { beforeEach(inject(function (_$filter_) { $filter = _$filter_; })); it(&quot;null 이면 0을 반환&quot;, function () { var length = $filter(&quot;length&quot;); expect(length(null)).toEqual(0); }); });}); length 필터를 선언한 myapp.filters.js 소스 12345angular.module(&quot;myapp.filters&quot;, []).filter(&quot;length&quot;, function () { return function (text) { return (&quot;&quot; + (text || &quot;&quot;)).length; };}); karma.config.js 에 필터 소스를 추가해 준다. 추가한 소스를 karma.config.js 에 추가해 준다. 12345678910files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/controller/myapp.controller.js', 'app/src/filter/myapp.filters.js', 'app/src/test/test*.js' ], 새 컨트롤이 추가된 후 karma를 재시작해서 테스트를 진행한다.","link":"/2017/11/01/Programming-angularjs-test/"},{"title":"C&#x2F;C++ 표준","text":"C/C++ 표준https://m.blog.naver.com/PostView.nhn?blogId=tipsware&amp;logNo=221032917097&amp;proxyReferer=https%3A%2F%2Fwww.google.com%2Fhttps://junho85.pe.kr/1026 C11 - 2011https://en.wikipedia.org/wiki/C11_(C_standard_revision)) C99 - 1999https://en.wikipedia.org/wiki/C99 1gcc --std=c99 for loop 에 초기화 변수 선언 가능 12for (int i=0; i&lt;9; i++) {} C95 - 1995 wide character. wchar.h, wctype.h digraphs and for &amp;&amp; STDC_VERSION C90 - 1990ISO 표준. ANSI 에서도 받아들임. C89 와 동일한 언어. 약간의 에러 수정 C89 - 1989https://en.wikipedia.org/wiki/ANSI_C#C89 1989년 ANSI 에서 발표한 첫번째 공식 C 표준 gcc 6.3.1 ~ 7.3.1 - gnu11, gnu++145.4.0 - gnu11, gnu++98STDC_VERSION https://sourceforge.net/p/predef/wiki/Standards/ C11 - STDC_VERSION = 201112L","link":"/2017/11/01/Programming-c-cpp-standard/"},{"title":"Armbian 기반 MongoDB 4.2 설치","text":"Armbian 을 사용하는 보드에서 mongodb 4.2 를 설치한다. 여기에 대한 자세한 내용은 아래 링크를 참조하고 있다. https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/#install-mongodb-community-edition GPG error1W: GPG error: https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.2 Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 4B7C549A058F8B6B 12345$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 3B4FE6ACC0B21F327C549A058F8B6Bgpg: key 4B7C549A058F8B6B: public key &quot;MongoDB 4.2 Release Signing Key &lt;packaging@mongodb.com&gt;&quot; importedgpg: Total number processed: 1gpg: imported: 1 1$ sudo apt install -y mongodb-org 설정mongod.conf 를 간단하게 다음 1234567891011121314storage: #dbPath: /var/lib/mongodb dbPath: /home/qkboo/Db-data/mongodb4 journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.lognet: port: 27017 bindIp: 127.0.0.1 https://docs.mongodb.com/manual/core/security-mongodb-configuration/ 인증명령으로 mongod 로 실행이 가능한 MongoDB Server는 기본적으로 보안 모델이 없이 실행된다. 따라서 별도의 인증 절차를 가지고 있지 않습니다. 이 때문에 2017년 1월에는 이런 약점을 노린 랜섬웨어가 발생하기도 했습니다. MongoDB는 되도록이면 외부로부터의 신뢰되지 않은 접속을 허용하지 않는, 보안에 문제가 되지 않는 환경에서 보안 모델 없이 실행하는 것을 지향하고 있으나, 어쨌든 MongoDB도 ID와 비밀번호로 접근하는 기본적인 보안 모델을 가지고 있으니 이를 통해 MongoDB Server에 인증 과정을 추가해 보도록 합시다. 비인증 모드에서 관리자 계정 생성 인증 접속 1. 비인증 관리자 계정 생성하기mongod로 별도의 보안 모델이 없는 MongoDB Server를 실행하고, MongoDB Shell에 접속합니다. 1234&gt; mongoMongoDB shell version v3.6.3connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.3 MongoDB에는 admin이라는 데이터베이스가 존재하며, 해당 데이터베이스에 사용자를 추가합니다. 123456&gt; use admin&gt; db.createUser({ user: 'username', pwd: 'password', roles: ['userAdminAnyDatabase']}) db.createUser()는 현재 사용하고 있는 데이터베이스(여기서는 admin)에 사용자를 추가합니다. 여기에는 사용자 이름, 비밀번호와 함께 권한(roles)을 array로 정의합니다. MongoDB에서 빌트인으로 제공하고 있는 권한은 MongoDB Built-In Roles에서 확인할 수 있습니다. 위에서 정의한 userAdminAnyDatabase는 어느 데이터베이스든 사용자를 생성하고 제거할 수 있다는 것을 의미합니다. 모든 권한을 가지게 하려면 root를 사용하면 되고, MongoDB 2.4 이하의 경우 db.addUser()를 통해 사용자를 추가합니다. mongod 인증하기만약 mongod 명령으로 실행하면 MongoDB Server를 실행하도록 한다. 1&gt; mongod --auth MongoDB Server 재시작하기Ubuntu와 같은 리눅스 시스템에서 service mongod start처럼 service를 이용할 경우, config 파일을 통해 실행됩니다. 이 경우 /etc/mongod.conf를 다음처럼 수정하고 재시작(service mongod restart)하면 됩니다. mongodb 4.x인증을 활성화 하려면 12security: authorization: enabled mongodb 3.xmongod.conf 를 사용하면 다음 옵션을 true 로 구성한다. 1auth = true 그리고 서비스를 재시작한다. 12$ sudo systemctl restart mongod.service 2. 인증 접속mongo 쉘에 접속하여 db.auth()를 사용하는 것입니다. 12345$ mongoMongoDB shell version v4.2.1connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodbImplicit session: session { &quot;id&quot; : UUID(&quot;177716fe-5b3c-41f6-bdae-d2584819abff&quot;) }MongoDB server version: 4.2.1 쉘에서 db.auth() 를 사용해 인증에 성공하면 1이 나오면 성공이다. 12345&gt; use adminswitched to db admin&gt; db.auth('admin', '!23456789');1&gt; 인증 접속이 되면 로그에 아래 같은 로그를 확인할 수 있다. 12019-12-02T09:49:24.392+0000 I ACCESS [conn3] Successfully authenticated as principal admin on admin from client 127.0.0.1:52370 명령행에서 접근인증과 함께 admin 데이터베이스로 접근하려면 아래 같이 명령어에 아이디와 비밀번호를 명시만 해 주면 된다. 1&gt; mongo admin -u username -p password --authenticationDatabase admin 아래 같이 mongo 명령행에서 인증을 통해 접속하면 test 라는 데이터베이스로 접속합니다. 123456$ mongo -u admin -pMongoDB shell version v4.2.1Enter password:...&gt;&gt; use admin 사용자 계정 만들기관리자 계정을 만들고 인증까지 수행 했으면, 일반 사용자를 만들어 데이터베이스를 사용하도록 해보자. 관리자 계정을 만들었던 것처럼 계정을 만들고자 하는 데이터베이스를 use 한 다음 db.createUser()를 실행하면 된다. 123456789&gt; use bookdiaryswitched to db bookdiary&gt; db.createUser({... user:'student',... pwd:'0123456789',... roles:['dbOwner']... });Successfully added user: { &quot;user&quot; : &quot;student&quot;, &quot;roles&quot; : [ &quot;dbOwner&quot; ] }&gt; dbOwner라는 권한은 해당 데이터베이스에 대한 모든 수정/삭제 권한을 가진다는 것을 의미합니다. 사용자 인증db.auth()를 통해 인증을 진행해 봅시다. 123&gt; db.auth('username', 'password')1&gt; 참고 MongoDB Community Edition 3.6 on Ubuntu MongoDB: Enable authentication","link":"/2019/12/10/linux-mongodb-armbinan/"},{"title":"Yarn","text":"YarnYarn은 Facebook, Google, Exponent, Tilde가 만든 npm을 대체 할 수 있는 새로운 패키지 관리자 이다. npm의 두 가지 큰 문제를 해결하고자 한다,^Yarn vs npm: Everything You Need to Know npm 의 패키지 설치가 만족스럽게 빠르지 않다. 보안 문제가 우려되고 있다. 설치시에 코드가 실행되도록 하고 있다. 다른 듯 같은 점yarn의 버전 표기가 다르기 때문에 같은 패키지를 서로 다른 버전으로 설치하는 잘못이 발생할 수도 있다. npm 5 이후 많은 개선이 이루어 졌다. ^npm 5 vs yarn npm i 는 자동으로 package.json에 의존성을 저장한다. npm-shrinkwrap 가 사라지고 yarn 같이 package-lock.json 파일이 추가되었다. package.json이 파일은 npm과 yarn에서 의존성을 유지하기 위해 사용한다. 그러나 버전 번호가 다를 수 있다. 버전을 major와 minor 로 선택할 수 있고, 표기가 다음 같이 다르다 ^npm-vs-yarn node version: v8.0.0npm verison: 5.0.0yarn verison: 0.24.6 npm, yarn 양쪽 버전이 package.json에 명시되어 설치되는 문제가 생길 수 있다. 이것을 피하기 위해 정확히 yarn으로 설치되는 버전은 yarn.lock 에 관리된다. npm에서도 npm shrinkwrap 명령이 lock 파일을 생성해서 npm install 이 package.json을 읽기 전에 읽어 설치하는 것은 yarn.lock 을 먼저 읽는 것과 같다. 다만 yarn은 기본적으로 yarn.lock을 생성하고 업데이트 한다는 것이다. 병렬 설치npm 이 패키지를 설치하는 작업은 각 패키지를 설치하고 순차적으로 진행한다. yarn은 설치 작업을 별령로 진행한다. express 패키지 42개를 설치할 때 12npm: 9 secondsYarn: 1.37 seconds gulp package 는 의존하는 195개 패키지를 설치한다. 12npm: 11 secondsYarn: 7.81 seconds 출력npm 설치 과정은 장황스럽게 표시된다. yarn은 기본적으로 조금 단순하고 자세한 출력 옵션은 별도로 있다. CLI 의 다른 점yarn global글러벌 설치시 npm은 -g, --global 을 사용하는데, yarn은 global 첨자를 사용한다이다. 그리고 npm과 같이 글로벌 설치시에는 프로젝트 지정 의존성이 글로벌로 설치되지 않는다. global 앞첨자는 yarn add, yarn bin, yarn ls yarn remove 에서만 동작한다. yarn installnpm install 은 package.json 에 명시된 패키지들의 의존성을 설치한다. yarn은 순서데로 yarn.locak 혹은 package.json에 명시된 의존성을 설치한다. yarn add [-dev]npm은 package.json에 의존성을 추가하려면 npm install --save 별도의 플래그를 사용한다. yarn은 yarn add &lt;package&gt; 는 패키지를 설치하고 package.json에 의존성으로 추가한다. 그리고 --dev 플래그를 주면 developer dependency에 추가해 준다. yarn licenses [ls|generate-disclaimer]yarn license ls 는 패키지의 라이센스를 목록을 출력한다. yarn license generate-disclaimer 는 모든 패키지의 라이센스 내역에 대한 면책조항을 생성한다. yarn why의존성 그래프와 그림을 출력해 준다. yarn upgrade npm update와 비슷하게, yarn upgrade 는 package.json에 명시된 패키지를 업그레이드하고 yarn.lock을 재 생성한다. 주목할 점은 패키지를 명시해서 업그레이드 하면 최신 릴리즈로 갱신하고 package.json에 태그를 선언해 둔다. 메이저 릴리즈로 패키지를 업데이트 해준다는 의미이다. yarn generate-lock-entryyarn generate-lock-entry 명령은 package.json을 기초로 yarn.lock 을 생성한다. 이것은 npm shirinkwrap 과 비슷하다. 다만 주의해서 사용해야 하는데 yarn.lock 파일은 yarn add, yarn upgrade 시 생성되거나 업데이트 된다. ### 설치 https://yarnpkg.com/en/docs/install#linux-tab 에 설명되어 있다. macOS1brew install yarn nvm 같은 가상환경을 사용하면 node.js 설치를 제외한다. 1brew install yarn --without-node Ubuntu 16.04이하, 데비안 정식버전 에서12$ curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -$ echo &quot;deb https://dl.yarnpkg.com/debian/ stable main&quot; | sudo tee /etc/apt/sources.list.d/yarn.list 12sudo apt update &amp;&amp; sudo apt install yarnsudo apt-get update &amp;&amp; sudo apt-get install yarn openSUSEOn openSUSE, you can install Yarn via our RPM package repository. 12sudo zypper ar -f https://dl.yarnpkg.com/rpm/ Yarnsudo zypper in yarn 스크립 혹은 npm1curl -o- -L https://yarnpkg.com/install.sh | bash 설치후 경로에 추가한다.export PATH=”$PATH:/opt/yarn-[version]/bin” 사용The following command uses Yarn to install the express package: yarn add express 참조","link":"/2017/11/22/nodejs-nodejs-yarn-npm/"},{"title":"Naver ncloud 설정","text":"ncloud 서비스sudoer 설정새 사용자를 추가하고 suder 로 등록한 후에 사용한다. 우분투/데비안 계열 새 사용자 추가는 Odroid Install 문서를 참고한다. 새 사용자 등록adduser 추가할 사용자에 대한 정보를 하나씩 묻고, 사용자 홈 디렉토리가 생성된다. 추가한 사용자에 대한 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 편집이 된다 추가하고 패스워드를 입력한다. 12# adduser USERNAME# sudo passwd USERNAME 그리고 suder로 등록해 준다. sudoer 등록usermod 혹은 visudo 를 사용할 수 있다. 1# usermod -aG sudo USERNAME hostname 확인hostname 명령에 따라 현재 호스트 이름이 /etc/hosts 혹은 dns resolver에서 검색되야 한다. 12$ sudo systemcgl status nginxsudo: unable to resolve host ubuntu-84 위 같은 경고가 나타난다면 호스트 이름을 /etc/hosts 에 등록해 준다. ssh서버에 1$ ssh-keygen -t rsa -b 4096 -C &quot;USER@localhost&quot; 위 2 과정을 아래 명령 한 줄로 복사-&gt;붙여넣기를 동시에 할 수 있다. 클라이언트: 1cat ~/.ssh/id_rsa.pub | ssh &lt;USERNAME&gt;@&lt;IP-ADDRESS&gt; 'cat &gt;&gt; .ssh/authorized_keys' mongod-org 설치커뮤티티에디션 설치 네이버 NCloud에서 Micro server를 하나 생성한 후에, MongoDB Community Edition을 설치했고, ncloud의 Ubuntu 16.01 이미지로 서버를 생성한 후에 업그레이드해서 16.04.4 LTS 버전에서 설치했다. 설정mongodb 설정mongodb auth 현재 실행중인 mongod 를 종료한다. sudo systemctl stop mongod.service MongoDB 설정Mongo Database를 사용하기 위해서 데이터 파일 위치, 로그, 포트, Ip 주소 등에 대한 구성을 mongod.conf 에서 할 수 있다. 수정된 구성이 작동하는지 mongo 클라이언트로 접속해서 테스트한다. mongod.conf/etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. 123456789101112131415 dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 0.0.0.0 설정을 저장하고 명령 라인에서 MongoDB를 다시 시작한 후에 mongo client로 접속한다. 모든 인터페이스에 db 접속을 허용하면 bindIpAll: true 를 사용한다. 1$ sudo mongod --port 27017 --dbpath /var/lib/mongodb 이어서 클라이언트로 데이터베이스에 접속한다.접속에 성공하면 &gt; 프롬프트가 나온다. 12$mongo&gt; admin 계정mongod 에서 데이터베이스 및 사용자를 관리할 admin 이란 관리자를 추가하자 123&gt; use adminswitched to db admin&gt; 관자자의 권한과 역할을 선언한다. 12345678&gt;db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] } 사용자의 role 을 변경, 12345678910111213141516171819&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}])&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] 관리자 admin 계정을 admin 데이터베이스에 추가한 후에 mongo client로 admin 계정으로 로그인해서 … 터미널에서 시작한 mongod 를 종료한다. 수동으로 mongod 를 시작하면 root 계정으로 데이터 파일이 생성된다. systemctl로 서비스 시작 전에 data 폴더 퍼미션을 맞춰준다. Directory permissions로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 몽고디비 사용자가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongo.daemon /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata 데이터베이스 사용자 추가데이터베이스를 생성하고 해당 데이터베이스를 접속하는 사용자 계정을 추가하자. 수동으로 접근제어 –auth 옵션으로 데이터베이스를 시작하면, mongo 클리이언트 로그인시 -u , -p 와 –authenticationDatabase 를 지정해 주어야 한다. 1$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot; The following operation creates accountUser in the products database and gives the user the readWrite and dbAdmin roles. 123456789use productsdb.createUser( { user: &quot;accountUser&quot;, pwd: &quot;password&quot;, roles: [ &quot;readWrite&quot;, &quot;dbAdmin&quot; ] })```","link":"/2018/06/24/linux-naver-ncloud/"},{"title":"Build ffmpeg - macOS","text":"Mac OS X 에서 ffmpeg 빌드Android OS에 사용할 ffmpeg를 macOS에서 크로스컴파일러로 빌드해서 포팅하는 과정을 담고 있다.필요한 것은 homebrew xcode command line Android NDK stanalone toolchain 준비할 것Homebrew 를 이용한 빌드를 위해서 xcode와 homebrew 설치가 필요하다. Homebrew 설치 http://goo.gl/Uu7p8 Xcode command line tool이 필요하다. Xcode 최신버전들은 Command line tool을 수동으로 설치해야 한다. Xcode를 실행하여 ‘Preferences &gt; Downloads &gt; Command Line Tools’ 항목을 설치 homebrew 설치1ruby &lt;(curl -fsSkL raw.github.com/mxcl/homebrew/go) 그리고 homebrew doctor 명령을 실행해 설치 환경과 내용이 이상 없는지 확인한다. 1homebrew doctor update로 포뮬라들을 최신으로 갱신해 준다. 1brew update homebrew에서 설치하는 개체를 Ruby script로 패키지에 대해 선언한 명세서를 Formula라고 하고 install 명령에 의해 /usr/local/Library/Formula 에 설치한다. homebrew에서 패키지를 하나 설치한다. 1$ brew install wget 그리고 패키지의 업그레이드, 제거는 다음과 같다. 12brew upgrade [foo]brew uninstall [foo] 의존성 패키지 설치ffmpeg 에 필요한 의존선 패키지를 설치한다. 1234brew install automake celt faac fdk-aac git \\lame libass libtool libvorbis libvpx libvo-aacenc \\opencore-amr openjpeg opus sdl schroedinger shtool \\speex texi2html theora wget x264 xvid yasm Install libaacplus (atm. there is no recipe for it) 컴파일 환경에 대해 [^1]를 참조했다. http://tipok.org.ua/node/17 123wget http://217.20.164.161/~tipok/aacplus/libaacplus-2.0.2.tar.gztar xzf libaacplus-2.0.2.tar.gzcd libaacplus-2.0.2 libtool on osx is quite different from the gnu libtool, which is called glibtool on osx 1234567cat autogen.sh | sed 's/libtool/glibtool/' &gt; autogen2.shsed -i '.bck' -e 's/libtool/glibtool/' autogen.sh./autogen.shmake &amp;&amp; make installcd .. Standalone toolchainhttp://goo.gl/P20dD Standalone toolchain은 Android NDK 최근 버전부터 추가된 기능입니다. 이걸 사용하면 ndk-build 명령을 쓰지 않고 기존의 configure -&gt; make를 사용하던 컴파일 과정을 그대로 사용해서 라이브러리를 컴파일 할 수 있습니다. ndk를 통해서 toolchain을 빌드한다. 자세한 사항은 STANDALONE-TOOLCHAIN 참조한다. 1234$ {NDK}/build/tools/make-standalone-toolchain.sh \\--platform=android-8 \\–install-dir=/MYDEV/android=9-toolchain$ export PATH=/MYDEV/android=9-toolchain/bin:$PATH 샘플 코드 컴파일 방법test.cpp 가 있다고 가정하고 1$ arm-linux-androideabi-g++ -o test_arm test.cpp Makefile 을 다음과 같이 만든다. 12345678910ARM_COMPILE = arm-linux-androideabi-CC = g++ARM_CC = $(ARM_COMPILE)g++ARM_INCLUDES = -I /MYDEV/android=9-toolchain/sysroot/usr/includeCFLAGS = -O2 -Wall -D_LINUX -fno-strict-aliasing -D_COLOR_LOGBINS = testarm: $(ARM_CC) $(CFLAGS) -o test_arm test.cpp $(ARM_INCLUDES) ffmpeg buildstandalone toolchain을 사용한다. ffmpeg configuration 1export ANDROID_ROOT=/cygdrive/c/my-android-toolchain 1234567891011121314151617ANDROID_ROOT=/home/qkboo/my-android-toolchain \\./configure --target-os=linux \\--arch=arm \\--enable-cross-compile \\--cc=$ANDROID_ROOT/bin/arm-linux-androideabi-gcc \\--cross-prefix=$ANDROID_ROOT/bin/arm-linux-androideabi- \\--extra-cflags=&quot;-marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon&quot; \\--extra-ldflags=&quot;-Wl,--fix-cortex-a8&quot; \\--disable-doc \\--disable-ffmpeg \\--disable-ffplay \\--disable-ffprobe \\--disable-ffserver \\--disable-avdevice \\--disable-network \\--disable-devices \\--disable-filters 맨 첫 줄의 ANDROID_ROOT 값은 자신이 standalone toolchain을 설치한 폴더로 수정합니다. 참고로 “–arch=arm”과 “–enable-cross-compile”: arm CPU 용으로 cross compile 하겠다는 옵션입니다. “–cc”나 “–cross-prefix”: cross compile 할 때 사용할 compiler에 관한 정보를 줍니다. “–extra-cflags”나 “–extra-ldflags”는 neon 사용할 때 쓰는 옵션입니다. (c:/android-ndk-r5b/docs/STANDALONE-TOOLCHAIN.html 참조) 나머지는 ffmpeg에서 이러이러한 기능은 빼고 컴파일 하겠다는 뜻입니다. 예를들어 network 이런 기능은 필요없겠지요? 생성된 config.h 파일을 열어봅니다. 1234567891011#define ARCH_ARM 1#define HAVE_ARMV5TE 1#define HAVE_ARMV6 1#define HAVE_ARMV6T2 1#define HAVE_ARMVFP 1#define HAVE_NEON 1 위와 같은 설정들이 잘 되어 있음을 확인할 수 있으실 겁니다. config.h 파일에서 #define restrict restrict 부분을 찾아 다음과 같이 바꾼다. 1#define restrict X264 컴파일http://bongjaemoon.wordpress.com/2012/05/25/ffmpeg-x264-compile-for-using-with-android-ndk-on-mac-osx/ Application.mk 작성g:/Root/FFmpegBasic/jni 폴더에 Application.mk 파일을 만듭니다.내용은 간단히 아래와 같이 한 줄만 작성합니다. APP_ABI := armeabi-v7a 참고:arm architecture ARMv7-A 이상을 타겟으로 컴파일 하겠다는 옵션입니다.arm CoretexA8 이상의 core가 이에 해당됩니다.앞서 말씀드린대로 arm11 코어를 사용한 Optimus One, Galaxy Neo 같은 폰에서는 안 돌아가겠지요. Android.mk 작성 http://www.viper.pe.kr/docs/make-ko/make-ko_toc.html (한글)http://sunsite.ualberta.ca/Documentation/Gnu/make-3.79/html_chapter/make_toc.html (영문) Android.mk 는 폴더마다 여러개를 작성해야 합니다.공통으로 사용할 common.mk 파일을 먼저 작성한 후, 각각 폴더마다 설명하겠습니다. common.mk g:/Root/FFmpegBasic/jni/ffmpeg 폴더에 common.mk 파일을 만듭니다.모든 Android.mk에서 공통으로 include 해서 사용할 파일입니다. common.mk에서는 크게 두가지 일을 할 것입니다.1) 공통으로 사용할 컴파일 옵션을 정의합니다.2) configure를 통해 생성된 파일에서 컴파일 할 소스 파일 이름들을 읽어 저장합니다. 컴파일 옵션은 다음과 같이 한 줄이면 됩니다. 1.COMMON_CFLAGS := -DHAVE_AV_CONFIG_H -D_ISOC99_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_POSIX_C_SOURCE=200112 -D_XOPEN_SOURCE=600 -DPIC -std=c99 -fomit-frame-pointer -fPIC -fno-math-errno -fno-signed-zeros -fno-tree-vectorize참고:컴파일 옵션이 복잡해 보이지만 그냥 configure에서 생성된 컴파일 옵션을 그대로 정리해 준 것 뿐입니다. ffmpeg 폴더의 common.mak 파일을 열어보시면아래와 같은 부분이 있습니다.1.%.o: %.c 2.$(CCDEP)3.$(CC) $(CPPFLAGS) $(CFLAGS) $(CC_DEPFLAGS) -c $(CC_O) $&lt;FFmpeg 컴파일 할 때, $(CPPFLAGS) $(CFLAGS) $(CC_DEPFLAGS) 이 세 개의 매크로에 정의된 옵션들을 사용하는 것을 알 수 있습니다. ffmpeg 폴더의 config.mak 파일을 열어보시면 이 값들이 정의되어 있습니다. CPPFLAGS는 아래와 같습니다.1.CPPFLAGS= -D_ISOC99_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_POSIX_C_SOURCE=200112 -D_XOPEN_SOURCE=600 -DPIC이 값들은 다 사용해 줍니다. CFLAGS는 엄청 깁니다.1.CFLAGS= -marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon -std=c99 -fomit-frame-pointer -fPIC -marm -g -Wdeclaration-after-statement -Wall -Wno-parentheses -Wno-switch -Wdisabled-optimization -Wpointer-arith -Wredundant-decls -Wno-pointer-sign -Wcast-qual -Wwrite-strings -Wtype-limits -Wundef -Wmissing-prototypes -Wno-pointer-to-int-cast -O3 -fno-math-errno -fno-signed-zeros -fno-tree-vectorize -Werror=implicit-function-declaration -Werror=missing-prototypes복잡해 보이지만 하나씩 차근히 보면 정리가 됩니다.여기서 -marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon -g -O3 옵션들은 다 뺍니다.우리는 Android ndk-build를 사용할 것이기 때문에 -O3 같은 최적화 관련 옵션은 지정하지 않습니다.(이것은 android build system이 알아서 해줍니다)-marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon 이와 같은 cross compile관련, neon 관련 옵션도 빼줍니다.(이것은 나중에 Android.mk의 옵션으로 지정해 줄 것입니다)마지막으로 -W 로 시작하는 옵션은 warning 관련 옵션이니 그냥 다 뺍니다. CC_DEPFLAGS는 별 것 없고 상관없는 값들입니다. 무시합니다. 추가로 subdir.mak 파일을 보시면 아래와 같은 부분이 있습니다. 1.$(OBJS) $(SUBDIR)%.ho $(SUBDIR)%-test.o $(TESTOBJS): CPPFLAGS += -DHAVE_AV_CONFIG_H$(OBJS) 에 정의된 모든 파일에 위 조건이 해당되므로 -DHAVE_AV_CONFIG_H 도 포함합니다. 이렇게 정리하면 위에서 한 줄로 정리한 COMMON_CFLAGS 컴파일 옵션들이 나옵니다. 컴파일 할 소스 파일들을 정의 이 부분은 소스가 좀 길고 복잡하게 느껴질 수 있습니다. 하지만 역시 핵심은 간단합니다. 먼저 FFmpeg의 Makefile을 하나만 분석해 보겠습니다.ffmpeg 폴더의 common.mak 파일을 열어보면 아래와 같은 부분이 있습니다.1.OBJS += $(OBJS-yes)컴파일에 사용할 소스 파일은 OBJS 매크로와 OBJS-yes 매크로에 정의되어 있다는 것을 알 수 있습니다.우리도 이 소스들을 컴파일 하면 되므로 똑같이 적어줍니다. 이제 OBJS 매크로에는 xxxxx.o 와 같은 object 파일들이 쭉 저장되게 됩니다.이걸 그냥 간단히 전부 xxxxx.c로 변환해서 쓰면 가장 쉽겠지만 그렇게 간단하지는 않습니다.우선 c 파일 외에도 xxxxx.S 와 같은 어셈블리 코드들이 포함되어 있고,neon 컴파일 해야하는 소스들은 xxxxx.c.neon 또는 xxxxx.S.neon 과 같이 neon 접미사를 붙여줘야 하기 때문입니다. 다행인 것은, FFmpeg 소스들을 보면 neon 컴파일 해야 하는 소스들은 모두_neon.c 와 같이 _neon 접미사가 붙어 있어서 이것으로 구분이 가능합니다.(ffmpeg/libavcodec/arm 폴더의 파일들을 훑어 보시기 바랍니다)따라서 _neon 접미사를 검색해서 해당 접미사가 있는 소스에만 .neon을 마지막에 추가해 주면 됩니다. 위와 같은 과정을 수동으로 일일이 진행하셔도 좋지만 번거로우니 Makefile 문법을 사용해 작성해 주면 됩니다.최종적으로 컴파일 할 소스 파일들은 각각 다음 매크로에 저장할 것입니다. C_FILES: 컴파일 할 c 파일S_FILES: 컴파일 할 S 파일NEON_C_FILES: neon 컴파일 할 c 파일NEON_S_FILES: neon 컴파일 할 S 파일FFFILES: 컴파일 할 모든 소스 파일 전부 정의 이제까지 설명한 것을 종합해서 common.mk의 전체 소스를 보여드리면 아래와 같습니다.common.mk 파일을 다음과 같이 작성해줍니다. 01.COMMON_CFLAGS := -DHAVE_AV_CONFIG_H -D_ISOC99_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_POSIX_C_SOURCE=200112 -D_XOPEN_SOURCE=600 -DPIC -std=c99 -fomit-frame-pointer -fPIC -fno-math-errno -fno-signed-zeros -fno-tree-vectorize02. 03.OBJS += $(OBJS-yes)04. 05.ALL_S_FILES := $(wildcard $(LOCAL_PATH)/$(ARCH)/.S)06.ALL_S_FILES := $(addprefix $(ARCH)/,$(notdir $(ALL_S_FILES)))07. 08.NEON_S_FILES := $(wildcard $(LOCAL_PATH)/$(ARCH)/_neon.S)09.NEON_S_FILES := $(addprefix $(ARCH)/,$(notdir $(NEON_S_FILES)))10. 11.NEON_C_FILES := $(wildcard $(LOCAL_PATH)/$(ARCH)/*_neon.c)12.NEON_C_FILES := $(addprefix $(ARCH)/,$(notdir $(NEON_C_FILES)))13. 14.S_FILES := $(filter-out $(NEON_S_FILES),$(ALL_S_FILES))15. 16.C_OBJS := $(OBJS)17.ifneq ($(S_FILES),)18.S_OBJS := $(S_FILES:.S=.o)19.S_OBJS := $(filter $(S_OBJS),$(C_OBJS))20.C_OBJS := $(filter-out $(S_OBJS),$(C_OBJS))21.else22.S_OBJS :=23.endif24. 25.ifneq ($(NEON_S_FILES),)26.NEON_S_OBJS := $(NEON_S_FILES:.S=.o)27.NEON_S_OBJS := $(filter $(NEON_S_OBJS),$(C_OBJS))28.C_OBJS := $(filter-out $(NEON_S_OBJS),$(C_OBJS))29.else30.NEON_S_OBJS :=31.endif32. 33.ifneq ($(NEON_C_FILES),)34.NEON_C_OBJS := $(NEON_C_FILES:.c=.o)35.NEON_C_OBJS := $(filter $(NEON_C_OBJS),$(C_OBJS))36.C_OBJS := $(filter-out $(NEON_C_OBJS),$(C_OBJS))37.else38.NEON_C_OBJS :=39.endif40. 41.C_FILES := $(C_OBJS:.o=.c)42.S_FILES := $(S_OBJS:.o=.S)43.NEON_C_FILES := $(NEON_C_OBJS:.o=.c.neon)44.NEON_S_FILES := $(NEON_S_OBJS:.o=.S.neon)45. 46.FFFILES := $(sort $(NEON_S_FILES)) $(sort $(NEON_C_FILES)) $(sort $(S_FILES)) $(sort $(C_FILES)) 참고:OBJS 와 OBJS-yes 매크로가 어떻게 생성되는지 보겠습니다. ffmpeg/libavcodec 폴더의 Makefile을 열어 봅니다.1.OBJS = allcodecs.o 2.audioconvert.o 3.avpacket.o 4.bitstream.o 5.bitstream_filter.o 6.dsputil.o 위와 같은 소스를 볼 수 있습니다.이는 다시 말하면 allcodecs.c, audioconvert.c … 와 같은 소스들은 컴파일 옵션과 상관없이 무조건 컴파일 하겠다는 뜻입니다. 다음으로 아래와 같은 코드들이 이어집니다.1.OBJS-$(CONFIG_AANDCT) += aandcttab.o2.OBJS-$(CONFIG_AC3DSP) += ac3dsp.o3.OBJS-$(CONFIG_CRYSTALHD) += crystalhd.offmpeg 폴더의 config.mak 파일을 열어서 CONFIG_AANDCT, CONFIG_CRYSTALHD 등을 찾아 보시면 이게 어떻게 돌아가는지 알 수 있습니다.config.mak 파일을 열어 보면 아래와 같이 되어 있습니다.1.CONFIG_AANDCT=yes2.!CONFIG_CRYSTALHD=yes즉, “OBJS-$(CONFIG_AANDCT)”는 “OBJS-yes”로 변환되어 aandcttab.c 는 컴파일할 것이고,”OBJS-$(CONFIG_CRYSTALHD)”는 그렇지 않으니 crystalhd.c 는 컴파일 하지 않을 것 입니다. 이런 방법은 거의 모든 open source library에서 사용하고 있는 표준적인 방법이니 익숙해지는 것이 좋습니다. 참조[^1]: Compiling ffmeg on macOS ffmpeg on Mac","link":"/2015/01/01/Programming-ffmpeg-build-macos/"},{"title":"Raspberry Pi : Digital Signage","text":"Digital Signage라즈베리파이에서 슬라이드쇼 구현해 보자. py-slideshowhttps://github.com/cgoldberg/py-slideshow/ pyglet 으로 이미지를 패닝, 확대 효과를 가진 슬라이드 쇼. Screenly OSEScreenly Open Source Edition은 디지털 시그네이지 소프트웨어 이다. 소스: https://github.com/Screenly/screenly-ose Screenly OSE works on all Raspberry Pi versions, including Raspberry Pi Zero and Raspberry Pi 3 Model B. Disk imagesThe recommended installation method is to grab the latest disk image from here 라즈비안에서 설치Raspbian Lite 에서 설치를 할 수 있다. 먼저 sudo apt install -y network-manager 1234567891011$ bash &lt;(curl -sL https://www.screenly.io/install-ose.sh) _____ __ ____ _____ ______ / ___/_____________ ___ ____ / /_ __ / __ \\/ ___// ____/ \\__ \\/ ___/ ___/ _ \\/ _ \\/ __ \\/ / / / / / / / /\\__ \\/ __/ ___/ / /__/ / / __/ __/ / / / / /_/ / / /_/ /___/ / /___/____/\\___/_/ \\___/\\___/_/ /_/_/\\__, / \\____//____/_____/ /____/Screenly OSE requires a dedicated Raspberry Pi / SD card.You will not be able to use the regular desktop environment once installed.Do you still want to continue? (y/N) 1Would you like to use the experimental branch? It contains the last major changes, such as the new browser and migrating to Docker (y/N) It looks like NetworkManager is not installed. Please install it by running ‘sudo apt install -y network-manager’ and then re-run the installation. 1Would you like to perform a full system upgrade as well? (y/N) 설치를 시작하면 15분 이상이 소요된다.This installation will take 15 minutes to several hours, depending on variables such as: 12Installation completed.You need to reboot the system for the installation to complete. Would you like to reboot now? (y/N) pipresent python2 기반이고, 실행이 안됐다. https://pipresents.wordpress.com https://github.com/KenT2/pipresents-beep Requirements must use the latest version of Raspbian Stretch with Desktop (not the Lite version) must be run from the PIXEL desktop. must be installed and run from user Pi installrequired packages 12sudo apt install python-imaging python-pil.imagetk python-pexpectsudo apt install unclutter mplayer uzbl optional packages sudo pip install evdev (if you are using the input device I/O plugin)sudo apt-get install mpg123 (for .mp3 beeps) 1wget https://github.com/KenT2/pipresents-beep/tarball/master -O - | tar xz Dead-simple Digital menuhttps://github.com/angryrancor/ezdmb","link":"/2018/12/06/raspberrypi-digital-signage/"},{"title":"Hammerspoon 사용해 데스크탑 자동화","text":"HammerspoonHammerspoon 은 macOS의 데스크탑 자동화를 위해 Lua scipt 를 사용하는 엔진이다. Hammerspoon을 다운받아 설치하고 에 있는 Getting Started 를 보고 바로 시작할 수 있다. 설치최신 릴리즈를 Latest Hammerspoon 에서 다운받아 Application 폴더로 옮긴다. 그리고 Hammerspoon을 실행하면 Status bar에 나타난다. [그림. Hammerspoon] 맥 환경설정 / 보안 및 개인정보 에서 손쉬운 사용에 hammerspoon을 추가해 주고 활성화 한다. [그림. 보안 및 개인정보에서 제어 허용] Open configHammerspoon 메뉴에서 Open Config 를 실행하면 시스템의 .lua 확장자를 열 수 있는 텍스트 에디터가 실행된다. 이곳에 Getting Started 의 샘플 스크립을 복사해서 바로 사용해 볼 수 있다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;Y&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x - 10 f.y = f.y - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;K&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.y = f.y - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;U&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x + 10 f.y = f.y - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;H&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;L&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x + 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;B&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x - 10 f.y = f.y + 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;J&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.y = f.y + 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;N&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x + 10 f.y = f.y + 10 win:setFrame(f)end) init.lua 에 스크립을 작성하고 저장한 후에 Hammerspoon 메뉴에서 Reload config를 실행하고 Console… 메뉴로 스크립 활성화를 확인할 수 있다. Window Resizing*Cmd+Opt+Ctrl+F** 키로 윈도우를 고정된 크기로 변경할 수 있게 사용하고 있다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182--[[ Window Resizing--]]-- Full screenhs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = max.w f.h = max.h win:setFrame(f)end)-- 4:3 ratio: XGA, 1280x960, SXGA+, UGA-- Resizing: XGA 1024-768hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F1&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1024 f.h = 768 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1024x768&quot;}):send()end)-- Resize: 1280x960 (1024)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F2&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1280 f.h = 960 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1280x960&quot;}):send()end)-- Resize: SXGA+ 1400x1050hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F3&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1400 f.h = 1050 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1400x1050&quot;}):send()end)-- Resize: 1920x1080hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F4&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1920 f.h = 1080 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1920x1080&quot;}):send()end) Aerosnaphttps://blog.jverkamp.com/2016/02/08/duplicating-aerosnap-on-osx-with-hammerspoon/","link":"/2018/05/15/OS-mac-hammerspoon/"},{"title":"openSUSE: firewalld","text":"firewalld 를 이용해서 방화벽을 구성해 보자. RedHat, Ubuntu, OpenSUSE LEAP 15.0 등은 시스템 기본 파이어월 관리자로 firewalld 를 제공한다고 한다. firewalldfirewalld 는 …. firewalld는 ufw 처럼 iptables 을 구성할 수 있다. [그림. Firewall Stack (redhat.com)] 네트워크를 지역 관리가 가능해서 다른 네트워크, 지역에 따라 다른 규칙으로 구성해서 사용할 수 있다.For example “Home” and “Office” where all communications with local machines are allowed, and “Public Wi-Fi” where no communication with the same subnet would be allowed. https://www.ctrl.blog/entry/ufw-vs-firewalld firewalld 설치OpenSUSE LEAP 15.0, RedHat, Ubuntu 등은 시스템 기본 파이어월 관리자로 firewalld 를 제공한다고 한다. 1$ sudo apt install firewalld Start firewalldTo start firewalld, enter the following command as root: 1systemctl start firewalld root 사용자로 시작한다. 12sudo systemctl enable firewalldsudo reboot For more information about the service status, use the systemctl status sub-command: 123456sudo systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: disabled) Active: active (running) since Thu 1970-01-01 09:01:48 KST; 48 years 6 months agosudo firewall-cmd --state Stop firewalldTo stop firewalld, enter the following command as root: 1systemctl stop firewalld To prevent firewalld from starting automatically at system start, enter the following command as root: 1systemctl disable firewalld To make sure firewalld is not started by accessing the firewalld D-Bus interface and also if other services require firewalld, enter the following command as root: 1systemctl mask firewalld 사용해 보기firewalld 는 명령라인 firewall-cmd 와 GUI로 firewall-config 명령을 지원한다. Zone 설정Get a list of all supported zones 1firewall-cmd --get-zones List all zones with the enabled features. 12345678910111213141516$ firewall-cmd --list-all-zones...public target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 기본으로 제공하는 Zone drop: Any incoming network packets are dropped, there is no reply. Only outgoing network connections are possible. block: Any incoming network connections are rejected with an icmp-host-prohibited message for IPv4 and icmp6-adm-prohibited for IPv6. Only network connections initiated within this system are possible. public: For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. external: For use on external networks with masquerading enabled especially for routers. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. dmz: For computers in your demilitarized zone that are publicly-accessible with limited access to your internal network. Only selected incoming connections are accepted. workFor use in work areas. You mostly trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. homeFor use in home areas. You mostly trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. internalFor use on internal networks. You mostly trust the other computers on the networks to not harm your computer. Only selected incoming connections are accepted. trustedAll network connections are accepted. Zone 12sudo firewall-cmd --get-default-zonepublic 서비스This command prints a space separated list. Get a list of all supported services 1$ firewall-cmd --get-services This command prints a space separated list. Get a list of all supported icmptypes 1firewall-cmd --get-icmptypes 서비스를 제거하려면 1234# firewall-cmd --zone=public --remove-service=httpsuccessroot@odroidc2:/home/qkboo# firewall-cmd --zone=public --remove-service=httpssuccess Http, Ssh 방화벽 활성화http, https 를 공개 서비스를 지원하는 기본 존인 public에 추가한다. 123sudo firewall-cmd --add-service=sshsudo firewall-cmd --add-service=httpsudo firewall-cmd --add-service=https sudo firewall-cmd –zone=public –add-service=http –permanent 방화벽을 갱신한다 12firewall-cmd --reloadfirewall-cmd --state 혹은 zone을 지정해 추가한다. 1234sudo firewall-cmd --zone=web --add-service=sshsudo firewall-cmd --zone=web --add-service=httpsudo firewall-cmd --zone=web --add-service=httpssudo firewall-cmd --zone=web --list-all Likewise, we can add the DNS service to our “privateDNS” zone: 12sudo firewall-cmd --zone=privateDNS --add-service=dnssudo firewall-cmd --zone=privateDNS --list-all Zone 에 구성한 서비스 등은 런타임 혹은 완전히 방화벽에 구성할 수 있다. To change settings in both modes, you can use two methods:Change runtime settings and then make them permanent as follows: 12firewall-cmd &lt;other options&gt;firewall-cmd --runtime-to-permanent Set permanent settings and reload the settings into runtime mode: 12firewall-cmd --permanent &lt;other options&gt;firewall-cmd --reload 모든 구성 내용 확인: 1234567891011121314$ sudo firewall-cmd --list-allpublic target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 특정 zone 에 대한 내역을 출력한다: 123456789101112131415$ sudo firewall-cmd --zone=public --list-allpublic target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 참조https://www.linode.com/docs/security/firewalls/introduction-to-firewalld-on-centos/ FirewallD RedHat: Getting started with firewalld How to set up firewalld on CentOS 7 Firewalld configuration and usage","link":"/2019/12/10/linux-firewalld/"},{"title":"Awk 기본","text":"awk 이용awk란 이름은 이 유틸리티를 작성한 A.V.Aho, P.J. Weinberger, B. Kernigham의 머리글자를 따온 것으로 주로 패턴의 검색과 조작을 주목적으로 만들어진 것이다. 즉 파일의 각 줄에 필드(field)를 인식할 수 있는 패턴 매칭 기능을 가지고 이들 필드를 자유자재로 조작 가능한 유틸리티를 작성하고자 만든 것이다. awk 패턴 매칭 awk pattern {action} filenamesawk -f parttern-action-file filenames filenames: 입력화일 awk실행 action을 가진 프로그램 file 패턴내용| 패턴 | 설명 || —————— | ——————————————————————————————————————————————————————————————– | — | ————————————————————————————————————————— || BEGIN | 입력화일을 읽어들이기 전에 옆에 제시되는 문자을 실행시키도록 한다. || END | awk가 모든 입력을 처리한 후, 옆에 제시되는 문장을 실행시키도록 한다. || expression | 식을 평가한 후 이 식이 참, 즉 non-zero이거나 non-null인 경우 문장을 실행한다. || /re/ | 정규식과 일치하는 문자열을 포함하고 있는 라인에서 문장을 실행한다. || compound-pattern | 복합패턴이라는 것으로 &amp;&amp;(and), | | (or) , !(not) 그리고 괄호에 의해 연결시킨 것이다. expression의 경우와 마찬가지로 복합 패턴도 참인 경우의 문장을 실행시킨다. || pattern1, pattern2 | 이러한 패턴을 범위 패턴이라 한다. 현재 처리되고 있는 라인이 pattern1과 일치되고, 다음에 따라오 는 라인 중 임의의 라인이 pattern2와 일치할 때, 범위 패턴은 두 라인 사이의 각 라인과 일치한다. | awk에서 찾은 내용은 다음 변수에 저장되어 있다. 변수 내 용 FILENAME 현재 처리되고 있는 입력 파일의 이름 FS 입력 필드 분리문자 NR 현재 레코드(행)의 번호 NF 현재 레코드(행)의 필드의 갯수 OFS 출력되는 필드의 분리문자 auth.log 패턴 분석12Apr 16 06:43:04 homepi sshd[20198]: User root from 222.73.37.31 not allowed because not listed in AllowUsersApr 16 06:43:07 homepi sshd[20198]: Failed password for invalid user root from 222.73.37.31 port 41030 ssh2 sshd 접속하는 root 접속 요청을 찾으려면, 1awk '/sshd|root/' /var/log/auth.log # sshd,root 가 있는 줄을 출력 찾은 결과의 특정 컬럼만 출력 가능하다: 1$ awk '/sshd|Failed/ {print $13}' /var/log/auth.log 1$ awk '{print &quot;Number of fields: &quot; NF}' /var/log/auth.log 로그인 실패한 root 사용자가 사용하는 IP만을 추출하고자 한다면, Apr 16 06:43:07 homepi sshd[20198]: Failed password for invalid user root from 222.73.37.31 port 41030 ssh2 12$ awk '/Failed password/ {print $13,&quot;:&quot;,$15 }' /var/log/auth.log222.73.37.31 : 49415 위 결과를 정렬하면, 같은 IP들이 징렬되어 나열된다. 123456awk '/Failed password/ {print $13,&quot;:&quot;,$15 }' /var/log/auth.log | sort ```이 겹치는 결과에서 하나의 IP만 식별하고, 반복된 숫자를 출력하고, 정렬한다.```shawk '/Failed password/ {print $13,&quot;:&quot;,$15 }' /var/log/auth.log | sort | uniq -c | sort -n 123456789101112awk '/^north/' datafile # north로 시작하는 줄 출력awk '/^(no | so)/' datafile : no 또는 so 로 시작하는 줄 출력awk '$5 ~ /\\.[7-9]+/' datafile : 다섯 번째 필드가 마침표 다음엣 7과 9사이 숫자가 하나 이상 나오는 레코드 출력awk '$2 !~ /E/ { print $1, $2 }' datafile : 두 번째 필드에 E 패턴이 없는 레코드의 첫 번째와 두 번째 필드 출력awk '$3 ~ /^Joel/{ print $3 &quot; is a nice guy.&quot;} ' datafile : 세 번째 필드가 Joel로 시작하면 &quot; is a nice guy&quot;와 함께 출력awk '$8 ~ /[0-9][0-9]$/ { print $8 }' datafile : 여덟 번째 필드가 두 개의 숫자이면 그 필드가 출력awk '$4 ~ /Chin$/ { print &quot;The price is $&quot; $8 &quot;.&quot; }' datafile : 네 번째 필드가 Chine으로 끝나면 &quot;The price is $&quot; 8번 필드 및 마침표가 출력awk -F: '{ print $1 } ' datafile : -F 옵션은 입력 필드를 ':'로 구별.awk -F&quot;[ :]&quot; '{ print $1, $2 } ' datafile : 입력 필드로 스페이스와 ':'를 필드 구별자로 사용awk -f awk_script.file datafile : -f 옵션은 awk 스크립트 파일 사용할 때 씀. auth.log 에 있는 잘못된 로그인 정보만 출력 12awk '(/sshd|invalid/){print $(NF-5)}' /var/log/auth.logawk '(/sshd|invalid/){print $13}' /var/log/auth.log 연산자| 연산자 | 설명 || —————– | ———————————— | —- | ———— | — | ———————— || = += -= *= /= %= | 배정(assignment)연산자 || + - * / % ++ – | 산술 연산자 || | | &amp;&amp; ! | 논리 연산자( | | = OR, &amp;&amp; = AND, ! = NOT) || &gt;&gt;= &lt; &lt;= == != | 비교 연산자 || v p | 변수 V가 패턴 P에 부합되면 참 || v !p | 변수 V가 패턴 P에 부합되지 않으면 참 | 123456awk '$7 == 5' datafile : 7번 필드가 5와 같다면 출력awk '$2 == &quot;CT&quot; { print $1, $2 }' datafile : 2번 필드가 &quot;CT&quot; 문자와 같으면 1, 2 번 필드 출력awk '$7 &lt; 5 { print $4, $7}' datafile : 7번 필드가 5보다 작다면 4번, 7번 필드 출력awk '$6 &gt; .9 { print $1, $6}' datafile : 6번 필드가 .9 보다 크다면 1번, 6번 출력awk '$8 &gt; 10 &amp;&amp; $8 &lt; 17 ' datafileawk '$2 == &quot;NW&quot; || $1 ~ /south/ { print $1, $2 }' datafile 액션 awk pattern {action} filenames ① expressions② print expression-list③ printf(format, expression-list)④ if (expression) statement⑤ if (expression) statement else statement⑥ while (expression) statement⑦ for (expression; expression; expression) statement⑧ for (variable in array) statement⑨ do statement while (expression)⑩ break⑪ continue⑫ next⑬ exit⑭ exit expression⑮ {statement} 참조 https://ko.wikibooks.org/wiki/예제로_배우는_AWK/명령행_인자_사용하기 http://www.dreamy.pe.kr/zbxe/CodeClip/6332","link":"/2018/05/19/linux-linux-awk/"},{"title":"Monitoring fail2ban","text":"Monitoring fail2banInstall로그를 검사해 의심스런 IP 를 찾아 Firewall rule을 관리하기 어렵다 Fail2ban은 정규표현식을 사용해서 로그에서 의심스런 IP를 찾아 Firewall 등록할 수 있도록 해준다. Fail2ban로그를 검사해 의심스런 IP 를 찾아 Firewall rule에 등록해 관리하는 것은 어려운 과정이다. Fail2ban은 정규표현식을 사용해서 로그에서 의심스런 IP를 찾아 Firewall 등록 할 수 있도록 해준다. 설치fail2ban 은 iptables 패키지와 함께 설치한다. 1$ sudo apt install iptables fail2ban 그리고 systemctl 로 재대로 서비스가 시작되는지 확인해 본다. 12$ sudo systemctl restart fail2ban.service # 재시작$ sudo systemctl status fail2ban.service # running 상태 확인 설정을 위해서 fail2ban 설정 파일인 fail2ban.conf, 그리고 jail 파일 jail.conf 파일을 .local 파일로 복사한 사용자 정의 파일에서 사용한다. 123$ cd /etc/fail2ban$ sudo cp fail2ban.conf fail2ban.local # 설정파일$ sudo cp jail.conf jail.local # jail 설정 /etc/fail2ban 디렉토리설치된 후 관련된 설정 파일은 /etc/fail2ban 디렉토리에 저장됩니다. 관련한 로그 기록은 /etc/logratate.d/fail2ban에 정의되어 /var/log/fail2ban.log 로 저장됩니다. 다음은 설정 디렉토리 구조 12345678910111213141516171819$ tree -L 2 fail2ban/fail2ban/├── action.d│ ├── ...│ ├── ufw.conf│ └── xarf-login-attack.conf├── fail2ban.conf├── fail2ban.local├── fail2ban.d├── filter.d│ ├── ...│ ├── sshd.conf│ └── xinetd-fail.conf├── jail.conf├── jail.d│ └── defaults-debian.conf├── jail.local├── paths-common.conf└── paths-debian.conf jail.conf: jail 이라 불리는 모니터링할 대상에 대한 기본 옵션과 행위를 선언한다. action.d/iptables-multiport.conf: fila2ban 이 jail에 맞게 거부(Ban)한 IP를 다루는 기본 액션이다. fail2ban.local : fail2ban 주요 설정 파일 jail.local: jail 설정 파일 jaild.d/defaults-debian.conf: jail enable/disable paths-common.conf: 로그 파일 경로 paths-debian.conf: 로그 파일 경로 설정fail2ban은 jail 을 구성하고 jail의 filter 그리고 action으로 나뉘어 있다. fail2ban.conf 구성fail2ban.conf는 기본 구성 변수로 loggin, socket 그리고 PID 파일 등등이 설정된다. 별도의 파일로 Jail을 구성할 때 fail2ban.local 같은 이름을 사용하고 새로 설정되는 값은 기본 설정 값을 재정의 하게 된다. 단 같은 [default] 섹션이 존재하면 구성된 내용 적용이 잘 안된다. 다음 스크립을 사용하면 모둔 변수를 주석 처리하고 수정할 옵션만 복사해 준다. 1sed 's/\\(^[[:alpha:]]\\)/# \\1/' fail2ban.conf | sudo tee fail2ban.local 1&amp;&gt; /dev/null fail2ban.local 파일은 다음과 같은 내용을 담을 것이다. loglevel: The level of detail that Fail2ban’s logs provide can be set to 1 (error), 2 (warn), 3 (info), or 4 (debug). logtarget: Logs actions into a specific file. The default value of /var/log/fail2ban.log puts all logging into the defined file. Alternately, you can change the value to STDOUT, which will output any data; STDERR, which will output any errors; SYSLOG, which is message-based logging; and FILE, which outputs to a file. socket: The location of the socket file. pidfile: The location of the PID file. jail.conf/etc/fail2ban/jail.conf 는 데몬, 서비스에 대한 jail을 구성한다. jail은 log를 읽어 불필요한 것을 찾아 낸다.다음은 jail.conf에서 주석이 달린 jail.local을 생성해 준다. 1sed 's/\\(^[[:alpha:]]\\)/# \\1/' jail.conf | sudo tee jail.local 1&amp;&gt; /dev/null If using CentOS or Fedora open jail.local and set the backend to systemd. This is not necessary on Debian 8, even though it is a SystemD system. /etc/fail2ban/jail.local 1backend = systemd 화이트리스트 IP먼저 검출된 IP 중에 무시할 영역, 화이트리스트를 선언해 줍니다. 리스트는 ‘,’로 구분하고 서브넷 혹은 IP주소를 입력한다. 12[DEFAULT]ignoreip = 127.0.0.1/8 192.168.0.1/24 차단 시간과 재시도 횟수bantime, findtime, maxretry 은 차단 시간에 대한 구성이다. 123bantime = 2592000findtime = 600maxretry = 3 bantime: 검출된 IP가 접속 차단 시간을 초단위로 선언해 준다. -1 이면 영속적으로 밴 된다. findtime: ban이 설정 전에 로그인 간격 시간 maxretry: 최대 횟수 https://arno0x0x.wordpress.com/2015/12/30/fail2ban-permanent-persistent-bans/ 로컬 시스템의 이메일 주소를 sendmail -t user@email.com, replacing user@email.com with your email address. 이메일fail2ban에 검출되는 jail이 있으면 이메일 설정에 따라 메일로 경고를 받을 수 있다. destemail: The email address where you would like to receive the emails. sendername: The name under which the email shows up. sender: The email address from which Fail2ban will send emails. 그리고 action 설정을 조절할 필요가 있다, 이것은 ban 상황이 기준점에 닿으면 발생한다. 기본 액션 %(action_)s은 사용자만 ban 한다. action_mw 액션은 ban을 실행하고 WhoIS 리포트로 메일을 보내준다. action_mwl은 모든 로그까지 함께 보내준다. You will also need to adjudst the action setting, which defines what actions occur when the threshold for ban is met. The default, %(action_)s, only bans the user. action_mw will ban and send an email with a WhoIs report; while action_mwl will ban and send an email with the WhoIs report and all relevant lines in the log file. This can also be changed on a jail-specific basis. 1action = %(action_)s 1$ sudo service fail2ban restart 각 서버스에 대한 Jail 설정필터를 이용해 Jail을 만들어 의심스런 접근을 막아 보자. 앞서 복사한 jail.local 파일에는 주요 서비스가 모두 선언되어 있고 sshd 만 활성화 되어 있다. Jail은 다음 같이 구성된다. 12345678[ssh]enabled = trueport = sshfilter = sshdlogpath = /var/log/auth.logmaxretry = 6 enabled: Determines whether or not the filter is turned on. port: The port Fail2ban should be referencing in regards to the service. If using the default port, then the service name can be placed here. If using a non-traditional port, this should be the port number. For example, if you moved your SSH port to 3456, you would replace ssh with 3456. filter: The name of the file located in /etc/fail2ban/filter.d that contains the failregex information used to parse log files appropriately. The .conf suffix need not be included. logpath: Gives the location of the service’s logs. maxretry: Will override the global maxretry for the defined service. findtime and bantime can also be added.action: This can be added as an additional setting, if the default action is not suitable for the jail. Additional actions can be found in the action.d folder. 각 서비스에 대한 jail은 jail.d에 설정 파일을 구성해도 된다. (1) sshd Brute-force Attack과 같은 접근을 차단하는 필터로 로그에 아래와 유사한 패턴이 나오면 IP를 검출한다. Jul 22 06:56:50 foo sshd[14984]: Failed password for invalid user a from xxx.xxx.xxx.xxx port 55452 ssh2 jail.config 혹은 jail.local 에서 기본으로 활성화 되어 있다. (2) ssh-ddos sshd-ddos Filter를 사용해 SSH Service를 Scanning하거나 telnet으로 접속할 떄 발생하는 Message를 검사하여 해당 IP의 접근을 차단할 수 있습니다. 이 Filter로 검출되는 /var/log/auth.log의 Message는 다음과 같습니다. Jul 23 13:16:25 foo sshd[21989]: Did not receive identification string from xxx.xxx.xxx.xxx Jail 설정을 위해서 다음과 같이 입력합니다. 12[sshd-ddos]enabled = true 혹은 $ sudo vi /etc/fail2ban/jail.d/sshd-ddos.conf 1$ sudo service fail2ban restart Failregrexs다양한 필터를 사용할 수있다. 의심스런 동작을 Filter로 선언해서 사용하는데 해당 필터를 점검해야할 필요가 있다. 다음 1$ sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf 이 필터를 사용자가 작성할 수 있는데 파이썬의 정규식을 사용해서 사용자 지정 필터를 작성한다. access.log 필터 작성해 보기nginx 로그를 대상으로 200 에러를 검출해 보자 191.134.232.57 - - [28/Nov/2016:07:30:23 +0900] &quot;GET / HTTP/1.1&quot; 200 1125 &quot;http://hundej 123.143.201.75 - - [28/Nov/2016:17:29:18 +0900] “HEAD / HTTP/1.1” 200 0 “-“ “python-requests/2.10.0” fail2ban-regex /var/log/nginx/access.log /etc/fail2ban/filter.d/nginx-test.conf Ban 관리 fail2ban-client set YOURJAILNAMEHERE unbanip IPADDRESSHERE Use iptables -L -n to find the rule name……then use fail2ban-client status to get the actual jail names. 룰 이름이 표시된다 f2b- 으로 시작하는 룰을 찾는다 그리고 fail2ban-status 는 fail2ban-client set YOURJAILNAMEHERE unbanip IPADDRESSHERE HOW to fail2ban http://www.fail2ban.org/wiki/index.php/HOWTOs basic usages12sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf 1sudo iptables -L --line-numbers Nginx기본으로 /etc/fail2ban/jail.conf 에 [nginx-http-auth] jail이 하나 선언되어 있다. [nginx-http-auth] enabled = truefilter = nginx-http-authport = http,httpslogpath = /var/log/nginx/error.log nginx jailnginx-noscript웹 사이트에서 실행되고 침투할 수 있는 코드를 찾아 준다. php 등이 웹 사이트와 연동되지 않았다면 아래 제일을 추가해서 이런 임의의 실행코드 형식 실행을 방지할 수 있다 12345678[nginx-noscript]enabled = trueport = http,httpsfilter = nginx-noscriptlogpath = /var/log/nginx/access.logmaxretry = 6 nginx-badbots웹 요청에 악의적인 봇을 호출하는 것을 방지한다. 1234567[nginx-badbots]enabled = trueport = http,httpsfilter = nginx-badbotslogpath = /var/log/nginx/access.logmaxretry = 2 filter추가한 jail 이 동작할 필터를 작업해 주어야 한다. 필터는 /etc/fail2ban/filter.d 디렉토리에 있다. nginx-http-auth.conf기본으로 제공하는 nginx-http-auth.conf 필터에 하나를 더 추가해 준다. 아래는 사용자가 아이디와 비밀번호를 입력하지 않는 경우에 대해 필터한다. 아래의 no user/password 패턴을 추가한다. 1234567[Definition]failregex = ^ \\[error\\] \\d+#\\d+: \\*\\d+ user &quot;\\S+&quot;:? (password mismatch|was not found in &quot;.*&quot;), client: &lt;HOST&gt;, server: \\S+, request: &quot;\\S+ \\S+ HTTP/\\d+\\.\\d+&quot;, host: &quot;\\S+&quot;\\s*$ ^ \\[error\\] \\d+#\\d+: \\*\\d+ no user/password was provided for basic authentication, client: &lt;HOST&gt;, server: \\S+, request: &quot;\\S+ \\S+ HTTP/\\d+\\.\\d+&quot;, host: &quot;\\S+&quot;\\s*$ignoreregex = nginx-badbots.conf1sudo cp apache-badbots.conf nginx-badbots.conf nginx-noscript[nginx-noscript] jail 은 다음 내용을 입력한다: 12345[Definition]failregex = ^&lt;HOST&gt; -.*GET.*(\\.php|\\.asp|\\.exe|\\.pl|\\.cgi|\\.scgi)ignoreregex = nginx-nohome12345[Definition]failregex = ^&lt;HOST&gt; -.*GET .*/~.*ignoreregex = nginx-noproxy12345[Definition]failregex = ^&lt;HOST&gt; -.*GET http.*ignoreregex = Jail 실행 확인1234$ sudo fail2ban-client statusStatus|- Number of jail: 6`- Jail list: nginx-noproxy, nginx-noscript, nginx-nohome, nginx-badbots, ssh-ddos, ssh 그리고 iptable의 서비스로 방화벽 규칙에 fail2ban 규칙이 동작중인지 확인한다. 123456789101112 $ sudo iptables -S...-A fail2ban-nginx-badbots -j RETURN-A fail2ban-nginx-nohome -j RETURN-A fail2ban-nginx-noproxy -j RETURN-A fail2ban-nginx-noscript -j RETURN-A fail2ban-ssh -j RETURN-A fail2ban-ssh-ddos -j RETURN... 그리고 fail2ban 의 jail 실행 상태를 자세히 보고 싶므면 status 뒤에 jail 이름을 주면 된다. 12345678910$ sudo fail2ban-client status nginx-badbotsStatus for the jail: nginx-badbots|- filter| |- File list: /var/log/nginx/access.log| |- Currently failed: 0| `- Total failed: 0`- action |- Currently banned: 0 | `- IP list: `- Total banned: 0 Testing의심스런 동작을 Filter로 선언해서 사용하는데 해당 필터를 점검해야할 필요가 있다. 다음 1$ sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf Ban 관리nginx 인증 요구시 잘못된 인증을 시도하면 fail2ban 규칙에 따라 접근이 금지당한다. 그리고 jail 규칙이 잘 적용 됐는지 결과를 다음 같이 확인할 수 있다: 1234567891011$ sudo fail2ban-client status nginx-http-authOutputStatus for the jail: nginx-http-auth|- filter| |- File list: /var/log/nginx/error.log| |- Currently failed: 0| \\- Total failed: 12\\- action |- Currently banned: 1 | \\- IP list: 111.111.111.111 \\- Total banned: 1 인증 규칙에 어긋나는 접근을 시도한 IP인 111.111.111.111을 확인 할 수 잇다.금지된 IP는 해당 jail을 이용해 다음 같이 해제할 수 있다. 1$ sudo fail2ban-client set nginx-http-auth unbanip 111.111.111.111 nginx-req-limit http://blog.ricardomacas.com/index.php?controller=post&amp;action=view&amp;id_post=3 fail2squaredhttps://supine.com/posts/2012/08/fail2ban-monitoring-itself-recursively/ TO COMPLETELY FLUSH THE FAIL2BAN LOG FILE AND CLEAR OUR BLACKLIST FILEsudo service fail2ban stopsudo truncate -s 0 /var/log/fail2ban.logsudo truncate -s 0 /etc/fail2ban/ip.blacklistsudo rm /var/lib/fail2ban/fail2ban.sqlite3sudo service fail2ban restart https://ubuntu101.co.za/security/fail2ban/fail2ban-persistent-bans-ubuntu/ sqlite3fail2ban.conf file, I found the following: 1dbfile = /var/lib/fail2ban/fail2ban.sqlite3 So, I did a little research to try to find out how access the database. To open or connect to the database: 1$ sqlite3 /var/lib/fail2ban/fail2ban.sqlite3 To list all the tables in the database: 12sqlite&gt; .tablesbans fail2banDb jails logs To query a table: 1sqlite&gt; SELECT * FROM logs; Another table: sqlite&gt; SELECT * FROM bans; To disconnect from the database: sqlite&gt; .quit 참조 참조: https://www.digitalocean.com/community/tutorials/how-to-protect-ssh-with-fail2ban-on-debian-7 How to protect Nginx Server with fail2ban How to proect ssh with fail2ban on Debian fail2ban 과 iptables Nginx fail2ban jails Fail2ban Wiki","link":"/2017/11/22/linux-ubuntu-fail2ban/"},{"title":"Python - Build python source","text":"2015년 쯤 작성한 것으로 Raspberry Pi, Orange Pi, Odroid SBC 보드에서 3.4를 빌드했다. 2017년 현재 배포본, Debian Jessie, Ubuntu Xeniel 등은 3.4, 3.5가 내장되어 배포되고 있다.Python 3.6 이상 최신 소스를 빌드하는데 참고할 수 있다. Build Python 3.4Raspbian Wheezy에는 3.2가 설치되어 있다. Jessie 가 출시된 이후에 3.2에 대한 모듈 의존성 관리가 되지 않고 있어서 3.4 이상이 설치가 필요하다. SSL/TLS 지원을 하기 위해 libssl, openssl 라이브러리를 설치한다. 12$ sudo apt update$ sudo apt install libssl-dev openssl Python3.4를 다운로드하고 컴파일하고 설치한다.Raspbian Weezy 에는 Python3.2가 있어서, 최신 3.4를 설치하려면 다운로드해서 컴파일 하면 된다. 1234$ wget https://www.python.org/ftp/python/3.4.3/Python-3.4.3.tgz$ tar xvzf Python-3.4.3.tgz$ cd Python-3.4.3/$ ./configure Raspberry Pi 2에서 빌드시 꽤 많은 시간을 사용한다. 12345$ ./configure...real 2m16.512suser 1m16.360ssys 0m20.630s 컴파일하고 빌드시 한 시간 이상 필요하다. 123456$ make # 한 시간 소요$ sudo make install...real 16m40.747suser 15m51.550ssys 0m24.030s 크로스컴파일 환경을 사용할 수 있다.","link":"/2017/04/04/python-python-build/"},{"title":"MySQL 5.x 설치 (1)","text":"MySQLInstallUbuntu 16 x64, armhf 등에서 패키지로 설치 1 Startmysql-server 를 설치하며 만든 root 사용자 패스워드를 사용해서 데이터베이스에 접속한다. 123456789$ mysql -u root -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 1Server version: 5.6.26 MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. 데이터베이스 보기 123456789mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+ mysql shell 에서 root 패스워드 변경 12mysql&gt; update user set password=password('PASSWORD') where user = ‘root’;mysql&gt; flush privileges; MySQL 설정MySQL에서 설정파일을 읽는 순서는 다음과 같다. /etc/my.cnf/etc/mysql/my.cnf/usr/local/mysql/etc/my.cnf~/.my.cnf /etc/my.cnfutf-u 문자셋을 기본으로 설정하기 위해서 my.cnf 파일을 다음 같이 사용한다. 만약 외부에서 데이터베이스를 접속하면 설정의 bind-address 막아 주어야 한다. 그렇지 않으면 클라이언트에서 접속 시도시 다음 2003 에러가 난다.[^2] 1ERROR 2003 (HY000): Can't connect to MySQL server on MySQL 설정 파일에서 문자셋을 변경할 수 있다. 다믕 같이 자신의 my.cnf 파일을 작성한다. client, mysqld, mysql 에 대해서 utf8 사용을 선언해 준다. 1234567891011[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock[mysql.server]user=mysqlbasedir=/var/lib[safe_mysqld]err-log=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid 1234567891011121314151617[client]..default-character-set=utf8[mysqld]character-set-client-handshake=FALSEinit_connect=&quot;SET collation_connection = utf8_general_ci&quot;init_connect=&quot;SET NAMES utf8&quot;character-set-server=utf8collation-server=utf8_general_ci[mysqldump]default-character-set=utf8[mysql]default-character-set=utf8 Mysql Secure Installation1# mysql_secure_installation SSLSSL을 통한 암호화 접속을 허용하려면 서버측과 클라이언트 측 모두 인증 파일을 만들어야 한다. https://dev.mysql.com/doc/refman/5.7/en/using-encrypted-connections.html 서버측 인증인증 --ssl 옵션으로 파일은, –ssl-ca identifies the Certificate Authority (CA) certificate. –ssl-cert identifies the server public key certificate. This can be sent to the client and authenticated against the CA certificate that it has. –ssl-key identifies the server private key. mysql_ssl_rsa_setup 유틸리티를 실행하면 data 디렉토리 밑에 생성해 준다.[^5] ca.pemserver-cert.pemserver-key.pem 파일을 생성해 준다. 12345[mysqld]ssl-ca=/var/mysql/ca.pemssl-cert=/var/mysql/server-cert.pemssl-key=/var/mysql/server-key.pem openssl 이용openssl을 이용해 수동으로 키를 생성한다. [^6] 123#cd /etc/mysql#openssl genrsa 2048 &gt; ca-key.pem ca certificate 생성 1openssl req -new -x509 -nodes -days 1000 -key ca-key.pem &gt; ca-cert.pem 1openssl req -newkey rsa:2048 -days 1000 -nodes -keyout server-key.pem &gt; server-req.pem private key를 생성합니다. [root@EDYDR51P0 newcerts]# openssl x509 -req -in server-req.pem -days 1000 -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 &gt; server-cert.pem 증서를 가지고 SSL 로 접속할려면 요런 옵션으로 접속하면 된다. mysql -u root -p –ssl –ssl-ca=c:\\cert\\cert.pem 참조https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-16-04 https://pythonschool.net/category/databases.htmlERROR 2003 (HY000) [^5]: Creating SSL &amp; RSA Certificates and keys[^6]: [Creating SSL Certificates and keys Using openssl](6.4.3.2 Creating SSL Certificates and Keys Using openssl)","link":"/2017/03/11/Databases-mysql5-1-install/"},{"title":"MySQL 5.x 소스 빌드 (2)","text":"MySQL소스 빌드mysql 계정 생성 groupadd mysql // 시스템에 mysql 그룹 생성useradd -g mysql -M -s /bin/false mysql // 시스템 로그인이 불가하며 홈디렉터리를 제외하여 mysql 계정을 생성mysql 소스 파일 다운로드 및 압축 해제 mysql 설치에 필요한 필수 패키지 사전 설치 1yum install -y cmake bison gcc gcc-c++ ncurses-devel mysql 데이터베이스 서버를 구축하기 위하여 mysql 최신 버전의 소스를 다운로드 받아 압축을 해제. 1234$ wget http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.28.tar.gz$ tar xzvf mysql-5.6.28.tar.gz$ cd mysql-5.6.28 mysql db 설치에 필요한 사전 작업이 완료되면 설치를 진행할 수 있다. Mysql 은 5.5 버전 이후의 버전은 configure 명령어가 아닌 아래와 같이 cmake 명령어를 이용하여 configure 를 진행. mysql cmake command 정리 1$ cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql - DENABLED_LOCAL_INFILE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 - DWITH_EXTRA_CHARSETS=all -DDEFAULT_CHARSET=utf8 - DDEFAULT_COLLATION=utf8_general_ci -Dwith_ZLIB=system - DENABLE_DTRACE=0 mysql 환경 설정파일 및 mysql 초기화mysql 설치작업이 끝나면 데몬을 구동하기 위한 초기화 작업이 필요하다. 다음과 같이 작업이 완료되면 최초 설치 작업은 마무리 된다. mysql 환경설정 기본 파일 복사 1$ cp ./support-files/my-default.cnf /etc/my.cnf mysql 초기화 12$ cd /usr/local/mysql$ /usr/local/mysql/scripts/mysql_install_db –user=mysql mysql 서비스 스크립트 및 서비스 설정Mysql 설정이 완료되면 부가적으로 서비스의 스크립트와, 부팅 시 자동으로 서비스가 올라오도록 아래와 같은 기본 설정을 추가한다. mysql 서비스 스크립트 및 서비스 runlevel 등재 12$ cd /usr/local/mysql$ cp -a support-files/mysql.server /etc/init.d/mysqld # ln -s /etc/init.d/mysqld /etc/rc3.d/S90mysqld Startmysql-server 를 설치하며 만든 root 사용자 패스워드를 사용해서 데이터베이스에 접속한다. 12345678910111213141516171819$ mysql -u root -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 1Server version: 5.6.26 MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema |+--------------------+3 rows in set (0.00 sec) 사용자가 사용할 데이터베이스를 만든다. 12mysql&gt;create database mydb;Query OK, 1 row affected (0.00 sec) 계속해서 새로운 사용자를 만든다. 1234# 현재 머신에서만 접속할 수 있는 사용자 계정mysql&gt; GRANT ALL privileges ON *.* TO ID@localhost IDENTIFIED BY '*****';# 외부, 원격에서 접속할 수 있는 사용자 계정mysql&gt; GRANT ALL privileges ON *.* TO ID@'%' IDENTIFIED BY '*****'; localhost 머신의 MySQL 데이터베이스에 myid라는 이름의 아이디를 만들고, 패스워드는 password로 설정 사용자 데이터베이스 사용새로 생성한 사용자 ID로 로그인을 해서 데이터베이스를 만든다. 123root@a5d2a69fa410:/# mysql -u qkboo -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\\\g. MySQL 설정MySQL에서 설정파일을 읽는 순서는 다음과 같다. /etc/my.cnf/etc/mysql/my.cnf/usr/local/mysql/etc/my.cnf~/.my.cnf /etc/my.cnfutf-u 문자셋을 기본으로 설정하기 위해서 my.cnf 파일을 다음 같이 사용한다. MySQL 설정 파일에서 문자셋을 변경할 수 있다. 다믕 같이 자신의 my.cnf 파일을 작성한다. client, mysqld, mysql 에 대해서 utf8 사용을 선언해 준다. 1234567891011121314151617[client]..default-character-set=utf8[mysqld]character-set-client-handshake=FALSEinit_connect=&quot;SET collation_connection = utf8_general_ci&quot;init_connect=&quot;SET NAMES utf8&quot;character-set-server=utf8collation-server=utf8_general_ci[mysqldump]default-character-set=utf8[mysql]default-character-set=utf8 참조 https://pythonschool.net/category/databases.html","link":"/2017/03/11/Databases-mysql5-2-install-src/"},{"title":"MySQL 5.x 시작 (3)","text":"MySQL사용자 관리mysql-server 를 설치하며 만든 root 사용자 패스워드를 사용해서 데이터베이스에 접속한다. 1$ mysql -u root -p 사용자 데이터베이스사용자가 사용할 데이터베이스를 만든다. 12mysql&gt;create database mydb;Query OK, 1 row affected (0.00 sec) 그리고 CREATE USER, INSERT 로 새 사용자를 추가할 수 있다. create user userid@HOST identified by ‘PASSWORD’; 사용자 foo 를 localhost 와 모든 것을 의미하는 패턴 %로 추가하면: 12mysql &gt; create user foo@localhost identified by 'password';mysql &gt; create user 'foo'@'%' identified by 'password'; 혹은 1insert into user (host, user, password) values ('localhost', 'hiru', 'password('hirururu')); 사용자 제거mysql &gt; drop user ‘hiru’;mysql &gt; delete from user where user =’hiru’ 사용자 생성시 다음같이 1396 에러는 CREATE USER/GRANT 명령으로 사용자와 권한을 추가/관리해야 하는데 mysql.db, mysql.user 테이블을 직접 조작하다가 일관성이 깨졌기 때문 12mysql&gt; create user 'shopuser'@'localhost' identified by ')12345';ERROR 1396 (HY000): Operation CREATE USER failed for 'shopuser'@'localhost' 제대로 사용자를 삭제하고 drop user shopuser@localhost flush privileges; 로 갱신해 준다. 권한 주기권한을 추가하고 삭제하기 위해서, GRANT와 REVOKE의 명령을 사용한다. GRANT 명령 등으로 데이터베이스 사용자가 데이터베이스 자원에 접근하는 권한을 만들 수 있다. GRANT ALL privileges ON DB_NAME.TABLE TO USER_ID@[HOST] IDENTIFIED BY ‘PASSWORD’GRANT [SELECT,DELETE,INSERT,UPDATE,] ON DB_NAME.TABLE TO USER_ID@[HOST] IDENTIFIED BY ‘PASSWORD’ DB_NAME,TABLE 등에 * 패턴을 사용할 수 있다. HOST: 접근하는 소스 호스트 PASSWORD: 패스워드 http://www.w3big.com/ko/mysql/mysql-administration.html 현재 머신에서만 접속할 수 있는 사용자 계정, 외부, 원격에서 접속할 수 있는 사용자 계정을 추가해 준다. 123mysql&gt; use mysql; # mysql system dbmysql&gt; GRANT ALL privileges ON mydb.* TO foo@localhost IDENTIFIED BY '*****';mysql&gt; GRANT ALL privileges ON mydb.* TO foo@'%' IDENTIFIED BY '*****'; 혹은 12grant select, insert, update, delete on mydb.* to foo@host identified by 'password';mysql &gt; grant select, insert, update, delete on dbname.table to userid@'192.168.%' identified by 'password'; 권한을 확인하는 방법 12mysql &gt; show grants for foo@localhostmysql &gt; show grants for 'foo'@'%'; 변경된 권한을 적용하기 1mysql &gt; flush privileges; 권한을 삭제하는 방법 1mysql &gt; revoke all on dbname.table from username@host 추가한 사용자는 SELECT로 확인할 수 있다. 1mysql&gt; select host,authentication_string from user where user='foo'; 사용자 데이터베이스 사용새로 생성한 사용자 ID로 로그인을 해서 데이터베이스 정보를 확인해 보자. 12345678910$ mysql -u foo -pEnter password:mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mydb |+--------------------+ 그리고 데이터베이스를 사용하려면 use [DATABASE] 로 변경한다. 1mysql&gt; use mydb; Character Setmysql에서 한글이 ?로 표시되는 경우. 12345678mysql&gt; SELECT * FROM department;+----+------+| id | name |+----+------+| 1 | ??? || 2 | ??? |+----+------+2 rows in set (0.00 sec) my.cnf의 문자셋과 터미널 문자셋이 일치하지 않아서 그렇다. MySQL은 설치시 지정하지 않았다면 기본적으로 문자셋이 ‘latin1’으로 설정되어 있다. 123456789101112131415161718192021mysql&gt; show variables like 'c%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ || collation_connection | latin1_swedish_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci || completion_type | NO_CHAIN || concurrent_insert | AUTO || connect_timeout | 10 || core_file | OFF |+--------------------------+----------------------------+15 rows in set (0.00 sec) MySQL 설정 파일에서 문자셋을 변경할 수 있다. 다믕 같이 자신의 my.cnf 파일을 작성한다. client, mysqld, mysql 에 대해서 utf8 사용을 선언해 준다. 1234567891011121314151617[client]..default-character-set=utf8[mysqld]character-set-client-handshake=FALSEinit_connect=&quot;SET collation_connection = utf8_general_ci&quot;init_connect=&quot;SET NAMES utf8&quot;character-set-server=utf8collation-server=utf8_general_ci[mysqldump]default-character-set=utf8[mysql]default-character-set=utf8 mysql&gt; show variables like ‘char%’;+————————–+—————————-+| Variable_name | Value |+————————–+—————————-+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+————————–+—————————-+8 rows in set (0.00 sec) 사용자 관리GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP-&gt; ON TUTORIALS.*-&gt; TO ‘zara‘@’localhost’-&gt; IDENTIFIED BY ‘zara123’; SQLStructural Query Language로 튜플 간의 관계를 계산해서 결과를 도촐한다. SEQUEL: Structured English QUEry Language; part of SYSTEM R, 1974 SQL/86: ANSI &amp; ISO standard SQL/89: ANSI &amp; ISO standard SQL/92 or SQL2: ANSI &amp; ISO standard SQL3: in the works… SQL2 supported by ORACLE, SYBASE, INFORMIX, IBM DB2, SQL SERVER, OPENINGRES,… SQL의 구성 SQL consists of the following parts: Data Definition Language (DDL) Interactive Data Manipulation Language (Interactive DML) Embedded Data Manipulation Language (Embedded DML) Views Integrity Transaction Control Authorization Catalog and Dictionary Facilities 교수 학습 연습데이터 유형 http://www.w3big.com/ko/mysql/mysql-data-types.html table professor 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 scode varchar(4) 학번, 기본키 sname varchar(20) 이름 sdept varchar(20) 학과 sphone varchar(15) 전화번호 123456CREATE TABLE professor ( pcode varchar(4) NOT NULL PRIMARY KEY, pname varchar(10), pdept varchar(12), pphone varchar(8)); table student 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 scode varchar(4) 학번, 기본키 sname varchar(20) 이름 sdept varchar(20) 학과 sphone varchar(15) 전화번호 create student table 123456CREATE TABLE student ( scode char(4) NOT NULL PRIMARY KEY, sname char(10), sdept char(12), sphone char(8)); table course 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 ccode varchar(4) 과목코드, 기본키 cname varchar(20) 과목명 ctime int 강의 시수 croom varchar(15) 강의실 create course table 123456CREATE TABLE course ( ccode varchar(4) NOT NULL PRIMARY KEY, cname varchar(10), ctime integer, croom varchar(8)); table lecture 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 lpcode varchar(4) 교수코드, 기본키 lccode varchar(4) 과목코드, 기본키 create lecture table 12345CREATE TABLE lecture ( lpcode char(4) NOT NULL, lccode char(4) NOT NULL, PRIMARY KEY (lpcode, lccode)); table advice 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 apcode varchar(4) 교수코드, 기본키 asccode varchar(4) 학번, 기본키 create advice table 12345CREATE TABLE advise ( apcode char(4) NOT NULL, ascode char(4) NOT NULL, PRIMARY KEY (apcode, ascode)); table register 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 rscode varchar(4) 학번, 기본키 rcccode varchar(4) 과목코드, 기본키 create register table 12345CREATE TABLE register ( rscode char(4) NOT NULL, rccode char(4) NOT NULL, PRIMARY KEY (rscode, rccode)); 데이터 입력123456789101112INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P001','김 구','컴퓨터공학과','0001');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P002','안창호','컴퓨터공학과','0002');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P003','이육사','국문학과','0003');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P004','박종화','국문학과','0004');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P005','심 훈','사학과','0005');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P006','한용운','사학과','0006'); 외부 데이터 파일 이용파일에 필드 간의 ‘,’로 구분한 데이터 파일이 있다. 물론 필드 구별 문자는 데이터의 내용에 따라 사용자가 임의로 정 할 수 있다.파일: studens.txt 123456S001, 박소명, 컴퓨터공학과, 123-4567S002, 최민국, 컴퓨터공학과, 234-5678S003, 이승호, 국문학과, 345-6789S004, 정수봉, 국문학과, 456-7890S005, 김상진, 사학과, 567-8901S006, 황정숙, 사학과, 678-9012 studnets.txt 파일을 읽어들이는 것은 스크립트 파일을 작성하거나 mysql에서 직접 실행할 수 있다.먼저 스크립트 파일 students.sql은 다음과 같다. 123use mydb;load data local infile &quot;student.txt&quot; into table studentfields terminated by ',' ; 이제 mysql 클라이언트에서 데이터를 읽어 들인다. 12mysql&gt;source students.sql; 데이터 조회 SELECT [DISTINCT] select _expr essi onFROM table_listWHERE where_definitionORDER BY col_name [ASC|DESC]GROUP BY col _name_listLIMIT [offset ], rows 예제-1) 전체 교수 리스트를 출력하는 SQL 검색 문을 작성하라.mysql &gt; sel ect * fromprof; 예제-2) 전체 교수 리스트를 이름순서로 출력하는 검색 문을 작성하라.mysql &gt; sel ect * fromprof order by pname; 예제-5) 전체 교수 리스트를 이름 역순으로 출력하는 검색 문을 작성하라.mysql &gt; sel ect * fromprof order by pname desc; 전체 교수 리스트를 학과별로 출력하는 검색 문을 작성하라.mysql &gt; sel ect * fromprof order by pdept, pname; 예제-4) 국문학과 교수 리스트를 이름순서로 출력하는 검색 문을 작성하라.mysql&gt; select * from professor where pdept =’국문학과’; JOIN“FROM 테이블명 AS 별명” 구문은 SQL 문장에서 별명으로 테이블을 참조하 는 역할은 한다. 예제-6) MySQL 과목을 강의하는 교수님의 이름, 전화번호와 강의실을 검색 하는 문장을 작성하라.mysql&gt; select p.pname, p.pphone, c.croom from professor p, course c, lecture lwhere c.cname=’MySQL’ and c.ccode=l.lccodeand l.lpcode=p.pcode; 예제-7) ‘김구’ 교수님이 강의하는 과목명, 강의 시수와 강의실을 검색하는 문장을 작성하라. 1234select c.cname, c.ctime, c.croomfrom professor as p, course as c, lecture as lwhere p.pname = '김 구' and p.pcode = l.lpcode and l.lccode = c.ccode; 예제-8) 각 학생이 수강 신청한 과목에 대해서 학생이름, 전화번호, 과목명, 강의실, 강의 시수를 검색하는 문장을 작성하라. 1234select s.sname, s.sphone, c.cname, c.ctime, c.croomfrom student as s , course as c, register as rwhere s.scode = r.rscode and r.rccode = c.ccodeorder by s.sname, c.cname; sub-query예제-9) 각 학생이 신청한 총 학점을 구하는 검색식을 작성하라. 1234select s.sname, s.sdept, s.sphone, sum(c.ctime)from student as s , course as c, register as rwhere s.scode = r.rscode and r.rccode = c.ccodegroup by s.sname; WHERE 조건절에 해당하는 결과를 GROUP BY 구절에 명시된 s.sname 필드에 따라 그룹으로 결과를 분류하고 난 후, SELECT 필드에 SUM(c.cti me) 함수를 사용해서 c.cti me 필드에 대한 합을 구함으로써 각 학 생이 신청한 총 학점를 구할 수 있다. 예제-10) 각 학과별 교수님은 몇 분인지 구하는 검색식을 작성하라. 123select pdept, count(*)from professorgroup by pdept; LIMIT 구절예제-11) 페이지 크기가 2 일 때, (예제-8)의 결과에서 두 번째 페이지를 검색하는 SQL문장은 작성하라.select s.sname, s.sphone, c.cname, c.ctime, c.croom fromstudent as s , course as c, regi ster as rwhere s.scode = r.rscode and r.rccode = c.ccode order by s.sname, c.cname￼￼limit 2, 2; 마지막 행의 limit 2, 2구절에서, 첫 번째 인자는 오프셋(offset)으로 검 색 결과 레코드들의 순번을 의미한다. 오프셋 값은 0 부터 지정하기 때문에 오프셋값2는전체레코드중에서세번째레코드를가리킨다. 두번째는 인자는 출력하는 레코드 수(rows)를 의미한다. 따라서, 레코드 수 2 는 2 개 의 레코드를 출력하라는 의미가 된다. Update UPDATE tbl_nameSET col_name1 = expr1, col_name2 = expr2, …[WHERE where_definition] [LIMIT rows]; 예제-12) 교수테이블에서 ‘김 구’ 선생님의 이름을 ‘하은용’ 교수님으로 변 경하는 문장을 작성하라.update prof set pname =’하은용’ where pname =’김구’; 예제-13) 지도 테이블의 교수코드가 ‘P007’ 인 레코드들을 모두 ‘P005’ 로 변경하라.update advise set apcode =’P005’ where apcode =’P007’; 예제-14) 강의 시수가 2인 과목들의 강의 시수를 하나 증가 시키고, 강의실 을 Lab1로 변경하라.update course set ctime=ctime + 1, croom=’Lab1’ where ctime=2; Delete DELETE FROM tbl_name[WHERE where_definition] [LIMIT rows] 예제-15 ) 국문학과 학생 레코드를 삭제하는 문장을 작성하라.delete fromstudent where sdept =’국문학과’; PyMySQL 튜토리얼PyMySQL 설치 1$ pip install PyMySQL 만약 pip 로 설치가 안되면 다음 같이 setup.py를 이용해 직접 설치 할 수 있다.$ # X.X is the desired PyMySQL version (e.g. 0.5 or 0.6).$ curl -L https://github.com/PyMySQL/PyMySQL/tarball/pymysql-X.X | tar xz$ cd PyMySQL*$ python setup.py install$ # The folder PyMySQL* can be safely removed now. 123456CREATE TABLE users ( 'id' int(11) NOT NULL AUTO_INCREMENT, 'email' varchar(255) COLLATE utf8_bin NOT NULL, 'password' varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY ('id')) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ; 데이터베이스 삭제 1mysql&gt; drop database mydb; 사용자 비밀번호 변경1mysql&gt; set password for ''myid''@''localhost'' = password(''password''); 테이블 생성show 명령으로 데이터베이스 자원 현환을 볼 수 있다. mysql&gt; help show 다음은 데이터베이스 목록을 보고, ‘mydb’를 사용합니다. 12345678910111213mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mydb || mysql || performance_schema |+--------------------+4 rows in set (0.00 sec)mysql&gt;use mydb... 테이블 현황 1234567mysql&gt; show tables;+----------------+| Tables_in_mydb |+----------------+| test |+----------------+1 row in set (0.00 sec) 테이블 만들기 12345678mysql&gt;CREATE TABLE users (\\ id int(11) NOT NULL AUTO_INCREMENT,\\ email varchar(255) COLLATE utf8_bin NOT NULL,\\ password varchar(255) COLLATE utf8_bin NOT NULL,\\ PRIMARY KEY (id)\\) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin\\AUTO_INCREMENT=1 ; mysql&gt; 터미널에서 여러 줄의 명령을 입력하기 위해서 줄의 끝에 ‘'를 사용해서 여러줄을 입력했다. 이럴게 만들어진 테이블은 show 명령으로 작성 스크립트를 확인할 수 있다. 123456789mysql&gt; show create table users;| Table | Create Table | users | CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `email` varchar(255) COLLATE utf8_bin NOT NULL, `password` varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin |1 row in set (0.00 sec) 테이블의 구성 요소는 desc 명령을 확인할 수 있다. 123456789mysql&gt; desc users;+----------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || email | varchar(255) | NO | | NULL | || password | varchar(255) | NO | | NULL | |+----------+--------------+------+-----+---------+----------------+3 rows in set (0.00 sec) 데이터 입력1234mysql&gt; insert into users values (0, 'aaa@example.com', 'sldfjslfj');mysql&gt; insert into users values (0, 'bbb@example.com', 'sldfjslfj');mysql&gt; insert into users values (0, 'ccc@example.com', 'sldfjslfj');mysql&gt; insert into users values (0, 'ddd@example.com', 'sldfjslfj'); Alter12345678mysql&gt; #컬럼 추가mysql&gt; alter table users add first_name varchar(10);mysql&gt; alter table users add last_name char(10);mysql&gt; alter table users add point int(5);mysql&gt; alter table users add gener int(5);mysql&gt; #컬럼 삭제mysql&gt; alter table users drop gener; 참조 https://pythonschool.net/category/databases.html","link":"/2017/03/11/Databases-mysql5-3-start/"},{"title":"Docker 기반 mongodb","text":"Docker 기반 mongodbOfficial : https://hub.docker.com/_/mongo/참조: https://github.com/dockerfile/mongodb 로컬에 “mongo_data” 라는 데이터 저장소가 있고 29817 포트로 실행하기를 한다면 다음 같다: 1$ docker run -d -p 29817:27017 -v /home/its/mongo_data:/data/db --name mongodb mongo 그리고 docker로 시작한 mongodb 컨테이너에 있는 mongo 를 사용해서 데이터베이스에 접속할 수 있다. 1$ docker exec -it mongodb mongo 인증 이용 1$ docker run -d -p 29817:27017 -v /home/its/mongo_data:/data/db --name mongodb mongo --auth admin 데이터에이스에서 사용자 관리 계정 등록 12$ docker exec -it mongodb mongo admin&gt; db.createUser({ user: 'jsmith', pwd: 'some-initial-password', roles: [ { role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; } ] });","link":"/2019/12/21/Databases-docker-mongodb/"},{"title":"mongodb 3.4 on Armbian","text":"2018-06-22 내용 정리, User auth 링크{:.right-history} 이 문서는 MongoDB Community Edition 3.4 버전을 64bit OS인 Amd64, Arm64 지원 OS에 설치해 사용하기 위해서 Install MongoDB Community Edition, on-ubuntu를 따라서 진행했다. 여기서는 Arm을 사용하는 SBC[^2] 컴퓨터에 mongodb 3.4 버전을, Hardkernel Odroid C2를 사용해서 설치를 진행했다. Odroid C2 for 64bit Armbian Ubuntu Xeniel MongoDB Community edition테스트한 Arm64 기반의 Odroic C2 에서는 MongoDB Community Edition을 설치한 후에 systemd 관련 스크립트와 설정 파일등이 적절히 설치되지 않아서, 이 부분에 대한 언급을 추가했다. 사전준비여기서는 Odroid C2 를 사용하고 Armbian 배포본에서 Ubuntu Xeniel 버전을 사용했다. Armbian 배포본 Debian Jessie 에는 아직 mongodb 64bit 를 제공하지 않고 있다. 레포지토리 등록아래 같이 키 서버를 등록하고 apt source list에 mongodb 를 등록한다. 여러분 시스템이 적용되는 지는 [^1]에 잘 설명되어 있다. 키서버 등록 1$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6 Mongodb 3.4 는 /etc/apt/sources.list.d/mongodb-org-3.4.list 파일 생성하고 아래 같이 해당 리눅스 버전에 맞는 소스 목록을 추가한다. Ubuntu 16.04 1echo &quot;deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list Ubuntu 14.04 1echo &quot;deb [ arch=amd64 ] http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list remove key &amp; ppa설치 후 필요 없어서 키 서버, 저장소 목록을 지우려면, 삭제할 키 해시 코드 확인: 다음 같이 8자리 코드로 나오거나 1234sudo apt-key listpub 4096R/A15703C6 2016-01-11 [expires: 2018-01-10]uid MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt; 다음 같이 긴 해시 코드로 나온다. 123456--------------------pub rsa4096 2016-01-11 [SC] [expires: 2018-01-10] 0C49 F373 0359 A145 1858 5931 BC71 1F9B A157 03C6uid [ unknown] MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt;/etc/apt/trusted.gpg.d/debian-archive-jessie-automatic.gpg``` 이 키를 1sudo apt-key del A15703C6 설치그리고 apt 명령으로 소스 캐시를 갱신하고 mongodb-org 커뮤니티 버전의 mongodb를 설치한다. 12sudo apt updatesudo apt install mongodb-org 설치전 mongodb 3.x 버전은 데이터 저장 파일 시스템으로 xfs 를 권장하고 있다. create systemd / service entrymongodb-org 설치후 systemctl 스크립트가 /etc/init.d에 복사되지 않았다. 여기서는 odroid-c2 armbian 설치 상태, 일반 리눅스 배포본은 잘 된다. 아래 명령을 실행해 mongodb.service 가 없으면 새로 생성해야 한다. 1$ sudo systemctl list-unit-files --type=service |grep mongodb 만약 mongodb.service 가 없다면, /lib/systemd/system/mongod.service 파일을 다음 같이 활성화 시켜준다. 12$ cd /lib/systemd/system$ sudo systemctl enable mongodb.service mongodb.service 가 있고, 12$ sudo systemctl list-unit-files --type=service |grep mongodbmongodb.service disabled disable 상태면 systemctl 명령으로 enable 시킨다. 1$ sudo systemctl enable mongodb.service 그리고 서비스를 시작한다. 1234567891011$ sudo systemctl start mongod.service$ sudo systemctl status mongod.service● mongod.service - High-performance, schema-free document-oriented database Loaded: loaded (/lib/systemd/system/mongod.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2017-07-18 09:17:53 UTC; 1s ago Docs: https://docs.mongodb.org/manual Main PID: 7234 (mongod) CGroup: /system.slice/mongod.service └─7234 /usr/bin/mongod --config /etc/mongod.confJul 18 09:17:53 odroidc2 systemd[1]: Started High-performance, schema-free document-oriented database. mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있다. Mongo Database 설정 mongodb 사용자와 디렉토리 퍼미션 확인 mongod.conf 설정 mongo client 접속 테스트 mongodb 인증 mongodb 사용자 확인mongodb-org 설치하면 사용자 mongodb가 만들어 지지만, 혹시 생성되지 않았으면 시스템에 사용자 mongodb 가 없으면 새로 만든다. 1$ sudo adduser --disabled-password --gecos &quot;&quot; --no-create-home --disabled-password --disabled-login mongodb 로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 몽고디비 사용자가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongo.daemon /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata mongod.conf 설정MongoDB의 systemd 서비스는 데이터베이스 구성 파일 /etc/mongod.conf 을 참조한다. /etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. 12345678910111213141516storage: dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 127.0.0.1,192.168.0.2 dbPath : 데이터베이스 스토리지 위치 bindIp: 서버 외에서 mongo 클라이언트가 접근하려면 IP 를 입력한다. 현재는 mongo.conf 설정 파일에 접근 제어가 없는 상태에서 mongo 클라이언트로 접속한다 Admin 사용자mongo 클라이언트로 접속에 성공하면 &gt; 프롬프트가 나온다. admin 데이터베이스로 전환한다. 12345$mongo&gt;&gt; use adminswitched to db admin&gt; admin 데이터베이스에서 관리자 role을 가진 사용자를 추가하고, 사용할 데이터베이스의 사용자와 접근 제어를 추가해서 사용하기 위해서 작업한다. user administratoruserAdmin role 혹은 userAdminAnyDatabase role을 가진 사용자 만든다. 다음은 admin 데이터베이스에서 사용자를 관리하는 admin 계정을 생성하고 있다. 12345678910&gt;db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() admin 사용자 패스워드 변경은 1&gt; db.changeUserPassword(&quot;accountUser&quot;, &quot;SOh3TbYhx8ypJPxmt1oOfL&quot;) 사용자의 role 을 변경, 12345678910111213141516171819&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}])&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] 혹은 updateUser 를 사용할 수 있다: 1db.updateUser( &quot;appClient01&quot;, ... security.authorizationmongodb.conf 파일에 security.authorization 을 활성화 한다 12security: authorization: enabled systemd 로 서비스를 재시작 한다. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 이제 인증 모드에서 데이터베이스에 접속해야 한다. 인증모드로 접속데이터베이스 시스템에 접근제어가 활성화 되면 mongo 클라이언트 접속시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; ### `mongod` 명령 사용 명령 mongod 로 MongoDB를 시작해 설정 파일 등이 제대로 동작하는지 확인할 수 있다. 비인증 모드 시작다음 같이 mongod 를 시작해 동작을 확인한다. 123$ sudo mongod --port 27017 --dbpath /data/mongodata...&gt; 인증 모드 시작앞서 시작한 명령행 mongodb를 종료하고 명령라인에서 재시작 --auth 옵션을 붙여 시작한다. 1$ mongod --auth --port 27017 --dbpath /data/mongodata 접근제어 --auth 옵션으로 데이터베이스를 시작하면 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 명령행으로 시작한 mongod 는 종료하고 설정 파일에 인증을 넣자. 데이터베이스 생성과 인증새 데이터베이스에 컬렉션을 생성하고 데이터베이스 사용자를 접근제어할 수 있는 내용은 MongoDB User Authentication 에서 다루고 있다. ### 기타 WiredTiger library panicext4 파일시스템에서 wiredTiger engine으로 실행중 아래 같은 에러가 발생, 여기[^10] 에서 --repair 로 재구성한 후 사용하도록 권장한다. 123452017-07-21T23:26:57.991+0900 E STORAGE [conn31] WiredTiger error (-31804) [1500647217:991504][803:0x7f5794fc20], file:collection-0--8962566541221692692.wt, WT_CURSOR.next: the process must exit and restart: WT_PANIC: WiredTiger library panic2017-07-21T23:26:57.992+0900 I - [conn31] Fatal Assertion 28558 at src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp 361 --repair 로 재구성 1$ sudo mongod --storageEngine wiredTiger --repair --dbpath /data/dbdata/ repaire를 sudo로 진행해서 /data/dbdata 안의 index 파일들이 root 소유권으로 바뀐다. 그래서 /data/dbdata 저장소를 chown으로 mongodb 사용자로 다시 설정 1$ sudo chown -R mongodb.mongodb /data/dbdata 이제 재시작 하면 된다. XFS warning1I STORAGE [initandlisten] ** WARNING: Using the XFS filesystem is strong$y recommended with the WiredTiger storage engine USB Memory 디스크 사용시Odroid C2에 64GB USB Memory를 외부 저장장치로 구성할 때 아래 같이 에러를 발생하며 diagnostic.data 폴더 에러, mongodb 가 다운된다. 아마 ext3 파일 시스템을 사용해서 그런 것 같다. 123456FTDC [ftdc] Uncaught exception in 'FileNotOpen: Failed to open interim file /data/mongodata/diagnostic.data/metrics.interim.temp' in full-time diagnostic data capture subsystem. Shutting down the full-time diagnostic data capture subsystem.2017-04-03T15:00:01.659+0900 E STORAGE [WTJournalFlusher] WiredTiger error (30) [1491199201:659123][877:0x7f7ccfec90], WT_SESSION.log_flush: /data/mongodata/journal/WiredTigerLog.0000000048: handle-write: pwrite: failed to write 128 bytes at offset 19456: Read-only file system2017-04-03T15:00:01.662+0900 E STORAGE [WTJournalFlusher] WiredTiger error (30) [1491199201:662709][877:0x7f7ccfec90], WT_SESSION.log_flush: journal/WiredTigerLog.0000000048: fatal log failure: Read-only file system stackoverflow 에 diagnostic-data 폴더를 지우고 다시 시작하도록 제시되고 있다: 1$ sudo rm -f /var/lib/mongo/diagnostic.data/* 그리고 /etc/mongod.conf에 full time diagnostic을 비활성화 했다. 12setParameter: diagnosticDataCollectionEnabled: false ## MongoDB 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 참고 MongoDB Tutorial 왜 Guardian은 MongoDB를 선택했나? 포스퀘어가 MongoDB를 선택한 이유 [^1]: Install mongodb on Ubuntu[^2]: SBC Sigle Board Computer. Raspberry Pi, Odroid 등등…[^3]: mongodb installation on Debian[^10]: UnsupportedFormat fatal assertion in wiredTiger following","link":"/2017/04/11/Databases-2017-04-11-mongodb-3-4-install-armv8/"},{"title":"MongoDB Community Edition 3.6 on Ubuntu","text":"2018-06-22 내용 정리, User auth 링크{:.right-history} 이 문서는 Ubuntu/Debian 계열 정규 배포본에 3.x 버전을 지원하지 않는 플랫폼에 MongoDB Community Edition 3.6 버전을 설치하는 과정을 정리하고 있다. 내용의 기초는 MongoDB Community Edition 3.6 버전을 Amd64, Arm64 지원하는 64bit OS에 설치해 사용하기 위해서 Install MongoDB Community Edition, on-ubuntu를 따라서 진행하고 경험상 필요한 부분을 추가로 정리했다. MongoDB Community Edition 3.6 설치 Mongo Database 구성 Install MongoDB 3.6 Community edition문서에 따르면 리눅스 계열은 Ubuntu, Red Hat, SUSE, Amazon, Debian 과 tarball 설치를 지원한다. 또한 macOS, Windows 플랫폼 설치도 지원한다고 한다. 테스트한 플랫폼은 64bit Ubuntu 16.04: Hardkernel Odroid C2: 64bit, Armbian MongoDB는 다음 패키지를 지원하고 있다: mongodb-org : 다음 패키지를 설치하기 위한 메타 패키지 mongodb-org-server : mongod daemon 과 구성 및 초기 스크립트. mongodb-org-mongos : mongos daemon. mongodb-org-shell : mongo shell. mongodb-org-tools : MongoDB 유틸리티: mongoimport bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop. 사전준비여기서는 Odroid C2 같은 64bit Arm을 지원하는 Armbian 배포본, 그리고 PC Linux/n-Cloud 등의 플랫폼에서 Ubuntu Xeniel 버전에 설치를 했다. Armbian 배포본 Debian Jessie/Stretch 에는 아직 mongodb 64bit 를 제공하지 않고 있다. 레포지토리 등록인증된 .dpkg, .apt 패키지를 설치하기 위해, 아래 처럼 서버의 키를 등록한다. 여러분 시스템이 적용되는 지는 [^1]에 잘 설명되어 있다. 키서버 등록 1$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2930ADAE8CAF5059EE73BB4B58712A2291FA4AD5 MongoDB용 소스 리스트 추가apt의 source list에 mongodb repository를 등록한다. 우분투 계열은 파일 생셩 /etc/apt/sources.list.d/mongodb-org-3.6.list 파일 생성하고 아래 같이 해당 리눅스 버전에 맞는 소스 목록을 추가한다. Ubuntu 16.04 1echo &quot;deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.6.list Ubuntu 14.04 1$ echo &quot;deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.6 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.6.list remove key &amp; ppa설치 후 필요 없어서 키 서버 저장소 목록을 지우려면, 삭제할 키 해시 8자리 코드를 확인한다. 1234$ sudo apt-key listpub 4096R/A15703C6 2016-01-11 [expires: 2018-01-10]uid MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt; 이 키를 삭제한다. 1$ sudo apt-key del A15703C6 설치그리고 apt 명령으로 소스 캐시를 갱신하고 mongodb-org 커뮤니티 버전의 mongodb를 설치한다. 12$ sudo apt update$ sudo apt install -y mongodb-org mongodb 3.x 버전은 데이터 저장 파일 시스템으로 xfs 를 권장하고 있다. 만약 특정 버전을 설치하려면 다음 같이 버전을 명시한다. 1$ sudo apt-get install -y mongodb-org=3.6.5 mongodb-org-server=3.6.5 mongodb-org-shell=3.6.5 mongodb-org-mongos=3.6.5 mongodb-org-tools=3.6.5 이전 mongod-org 3.4를 Armbian 에서 설치중 systemd unit 설정 파일과 MongoDB 시스템 계정 등이 생성되지 않는 경우가 있었다. 아래를 따라 손으로 생성해 주면 된다. mongodb 사용자mongod-org 설치후 시스템 사용자 mongodb 가 추가되야 한다. 만약 생성되지 않았으면, 새로 만든다. 1$ sudo adduser --disabled-password --gecos &quot;&quot; --no-create-home --disabled-password --disabled-login mongodb systemd service entry만약 mongodb-org 설치후 systemctl 스크립트가 /etc/init.d에 복사되지 않는 경우 여기서는 odroid-c2 armbian 설치 상태, 일반 리눅스 배포본은 잘 된다. systemd 서비스 파일이 /lib/systemd/system/mongod.service에 위치한다. 아래 명령을 실행해 mongodb.service 가 없으면 새로 생성해야 한다. 1$ sudo systemctl list-unit-files --type=service |grep mongodb 만약 mongodb.service 가 없다면, /lib/systemd/system/mongod.service 파일을 다음 같이 활성화 시켜준다. 12$ cd /lib/systemd/system$ sudo systemctl enable mongodb.service mongodb.service 가 등록됐는지 확인한다. 12$ sudo systemctl list-unit-files --type=service |grep mongodbmongodb.service disabled disable 상태면 systemctl 명령으로 enable 시킨다. 1$ sudo systemctl enable mongodb.service ### Run MongoDB Community Edition이 설치되면 요구되는 파일 및 폴더가 다음 위치에 생성됟다. /var/lib/mongodb : 기본 데이터 파일 위치 /var/log/mongodb : 기본 로그 저장 폴더 /etc/mongod.conf : mongod 구성 파일. 로그, 데이터 위치 등을 변경 가능 mongod 데몬은 mongodb user account 계정으로 실행된다. systemctl 명령으로 mongod 를 시작한다. 12$ sudo systemctl start mongod$ sudo systemctl status mongod 실행한 mongod를 확인해 보면 12$ ps -ef |grep mongodmongodb 15385 1 1 12:06 ? 00:00:00 /usr/bin/mongod --config /etc/mongod.conf mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있다. Mongo Database 설정 mongodb 사용자와 디렉토리 퍼미션 확인 mongod.conf 설정 mongo client 접속 테스트 mongodb 인증 퍼미션 확인로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 몽고디비 사용자가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongo.daemon /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata mongod.conf 설정MongoDB의 systemd 서비스는 데이터베이스 구성 파일 /etc/mongod.conf 을 참조한다. 먼저 /etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. 12345678910111213141516storage: dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 127.0.0.1,192.168.0.2 dbPath : 데이터베이스 스토리지 위치 bindIp: 서버 외에서 mongo 클라이언트가 접근하려면 IP 를 입력한다. 현재는 mongo.conf 설정 파일에 접근 제어가 없는 상태에서 mongo 클라이언트로 접속한다 Admin 사용자mongod에 인증이 비활성화 상태에서 mongo` 클라이언트로 접속에 성공하면 &gt; 프롬프트가 나온다. admin 데이터베이스로 전환한다. 12345$mongo&gt;&gt; use adminswitched to db admin&gt; admin 데이터베이스에서 관리자 role을 가진 사용자를 추가하고, 사용할 데이터베이스의 사용자와 접근 제어를 추가해서 사용하기 위해서 작업한다. user administratoruserAdmin role 혹은 userAdminAnyDatabase role을 가진 사용자 만든다. 다음은 admin 데이터베이스에서 사용자를 관리하는 admin 계정을 생성하고 있다. 12345678910&gt;db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() admin 사용자 패스워드 변경은 1&gt; db.changeUserPassword(&quot;accountUser&quot;, &quot;SOh3TbYhx8ypJPxmt1oOfL&quot;) 사용자의 role 을 변경, 12345678910111213141516171819&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}])&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] 혹은 updateUser 를 사용할 수 있다: 1db.updateUser( &quot;appClient01&quot;, ... security.authorizationmongodb.conf 파일에 security.authorization 을 활성화 한다 12security: authorization: enabled 인증모드는 v2.4이전에는 --auth 옵션을 사용하고, v2.6 이후에서 mongod.conf 파일 사용할 때 security.authorization 를 활성화 한다. systemd 로 서비스를 재시작 한다. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 이제 인증 모드에서 데이터베이스에 접속해야 한다. 만약 인증모드로 시작한 후에 다음 같이 인증 정보없이 로그인 하면 데이터베이스 사용시 에러를 만난다. 123456$ mongo&gt; show dbs;Tue Sep 27 23:22:40.683 listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;unauthorized&quot; } at src/mongo/shell/mongo.js:46&gt;&gt; show usersTue Sep 27 23:22:44.667 error: { &quot;$err&quot; : &quot;not authorized for query on test.system.users&quot;, &quot;code&quot; : 16550 } at src/mongo/shell/query.js:128 인증모드로 접속데이터베이스 시스템에 접근제어가 활성화 되면 mongo 클라이언트 접속시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 만약 데이터베이스 인증모드로 실행되는데 비인증 클라이언트 접근은 아래 같이 에러를 낸다: 1234567MongoDB shell version v3.6.5connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.5&gt; use studentsswitched to db students&gt; show users2018-06-25T18:30:38.174+0900 E QUERY [thread1] Error: not authorized on students to execute command { usersInfo: 1.0, $db: &quot;students&quot; } : 원격지에서 접근외부에서 mongodb로 접근시 authentication을 적용한 상태라면 다음과 같은 URL로 접근할 수 있다: “username:password@HOST_NAME/mydb” 그러나 외부접근시 클라이언트 버전과 서버의 Credential 버전이 맞지 않은 경우 다음 같이 실패 메시지를 확인할 수 있다. 2016-05-16T00:53:10.338+0900 I ACCESS [conn2] Failed to authenticate student@student with mechanism MONGODB-CR: AuthenticationFailed: MONGODB-CR credentials missing in the user document2016-05-16T00:53:10.352+0900 I NETWORK [conn2] end connection 220.121.140.59:51634 (0 connections now open) ### 데이터베이스 생성과 인증 새 데이터베이스에 컬렉션을 생성하고 데이터베이스 사용자를 접근제어할 수 있는 내용은 MongoDB User Authentication 에서 다루고 있다. ## MongoDB에 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 ### `mongod` 명령 사용 systemd가 아닌, mongod 명령으로 로 MongoDB를 시작해 설정 파일 등이 제대로 동작하는지 확인할 수 있다. 다만 데이터베이스가 생성하는 데이터와 로그 파일의 접근권한이 실행한 사용자 계정으로 처리되어 퍼미션 문제가 발생할 수 있다. mongoDB v2.4 인증모드로 시작mongod 명령라인으로 시작할 수 있다. 1$ sudo mongod --port 27017 --dbpath /data/mongodata mongoDB v2.4는 다음 같이 인증 모드로 시작한다. mongod 명령라인에서 --auth 옵션을 붙여 DB 인스턴스(mongod)를 시작 혹은 재시작한다. 1$ mongod --auth --port 27017 --dbpath /data/db1 혹은 mongod.conf 설정 파일에서 auth 를 활성화 한다. 1auth = true mongoDB v2.6 이후앞서 시작한 명령행 mongodb를 종료하고 명령라인에서 재시작 --auth 옵션을 붙여 시작한다. 1$ mongod --auth --port 27017 --dbpath /data/mongodata 접근제어 --auth 옵션으로 데이터베이스를 시작하면 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 참조[^1]: Install mongodb on Ubuntu","link":"/2018/06/08/Databases-2018-06-08-mongodb-3-6-install/"},{"title":"MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu&#x2F;Debian Armbian","text":"MongoDB에 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 Install MongoDB 4.2 Community edition 설치이 문서는 Arm64 기반 CPU를 사용하는 Raspberry Pi, Odroid, PINE64, OrangePi 등 SBC 지원 보드 계열 위에서 Ubuntu/Debian 에서 설치 및 사용 가능한 MongoDB Community Edition 4.2 버전을 설치하고 구성하는 과정을 정리하고 있다. MongoDB Community Edition 버전 Amd64, Arm64 의 설치는 Install MongoDB Community Edition on Debian 에서 제공하고 있다. 하지만 Arm64를 지원하는 Odroid C2, PINE64, OragePi 등 SBC 브드의 Armbian, Ubuntu 오에스에서 MongoDB Community Edition 을 저장소에서 apt 명령으로 직접 설치가 안되서 작은 트릭 이 필요하다. MongoDB Community Edition 4.2 설치 systemd 사용이 가능한 mongod Unit 파일 구성 MongoDB Community Edition 은MongoDB Community Edition 은 다음 패키지를 지원하고 있다: mongodb-org : 다음 패키지를 설치하기 위한 메타 패키지 mongodb-org-server : mongod daemon 과 구성 및 초기 스크립트. mongodb-org-mongos : mongos daemon. mongodb-org-shell : mongo shell. mongodb-org-tools : MongoDB 유틸리티. mongoimport, bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop. 테스트한 플랫폼64bit Arm을 지원하는 Armbian/Ubuntu 배포본을 사용했다. Armbian 기반: PINE64: 64bit, Armbian Hardkernel Odroid C2: 64bit, Armbian 사전준비설치를 위해 MongoDB Community Edition 을 지원하는 저장소를 위한 키 저장소를 구성해 레포지토리 등록인증된 .dpkg, .apt 패키지를 설치하기 위해, 아래 처럼 서버의 키를 등록한다. 키 서버 등록Install MongoDB Community Edition on Debian 에 있는데로 apt 저장소를 위한 키 서버를 등록한다. 1$ wget -qO - https://www.mongodb.org/static/pgp/server-4.2.asc | sudo apt-key add - 사용한 키가 필요 없어서 키 서버 저장소 목록을 지우려면 apt-key 명령으로 삭제할 키 해시 8자리 코드를 확인한다. 1234$ sudo apt-key listpub 4096R/A15703C6 2016-01-11 [expires: 2018-01-10]uid MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt; 이 키를 삭제한다. 1$ sudo apt-key del A15703C6 MongoDB용 소스 리스트 추가키 서버를 등록했으면 apt의 source list에 mongodb repository를 등록해야 한다. Ubuntu 16.04, 18.04 그리고 Debian Stretch/Buster with Armbian 에서 MongoDB Community Edition에 대한 저장소 source list 를 아래 같이 등록해서 사용하겠다. 아래 명령은 /etc/apt/sources.list.d/mongodb-org-4.2.list 파일을 생성하고 apt 소스 목록을 추가한다. 단, 저장소의 구분 이름인 multiverse 를 꼭 지정해 주자. 1echo &quot;deb [ arch=arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.2 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.2.list 보통 APT 계열의 저장소를 위한 소스 리스트는 아래 같이 구성된다. deb URL 배포판명 구분명마지막 구분명은 쓰이는 용도에 따라 main, universe, multiverse 등으로 구분이 되어 있다. 설치apt 명령으로 저장소 소스의 캐시를 갱신하고 mongodb-org 커뮤니티 버전 mongodb를 설치한다. 12$ sudo apt update$ sudo apt install -y mongodb-org 설치 중에 mongodb 3.x, 4.x 버전은 데이터를 저장하는 파일 시스템으로 xfs 를 권장하고 있어서 경고 메시지를 출력하는데 일단 무시한다. apt로 특정 버전을 설치하려면 다음 같이 버전을 명시한다. 1$ sudo apt-get install -y mongodb-org=4.1 무사히 설치를 완료하면 systemd 의 유니트가 추가되어 mongod 서비스를 통해 관리할 수 있다. 설치 확인systemctl 로 mongod 데몬이 동작을 확인해 보자, systemctl 로 서비스를 종료했다 재시작 해보자 12$ sudo systemctl stop mongod.service$ sudo systemctl start mongod.service mongod 가 정상적으로 동작하는지 status 상태를 확인해 보자. 123456789$ systemctl status mongod.service* mongod.service - MongoDB Database Server Loaded: loaded (/lib/systemd/system/mongod.service; disabled; vendor preset: enabled) Active: active (running) since Wed 2019-12-19 15:38:14 UTC; 3 weeks 6 days ago Docs: https://docs.mongodb.org/manual Main PID: 2051 (mongod) Memory: 191.3M CGroup: /system.slice/mongod.service `-2051 /usr/bin/mongod --config /etc/mongod.conf 여기까지 Arm64 기반 Debian Buster인 Armbian 시스템에 Mongodb Community Edition 4.2 버전을 설치하는 과정을 진행했다. mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있는데, 연결을 위해 mondod.conf 라는 구성 파일을 다루어 보자. 설치 위치MongoDB Community Edition이 설치되면 요구되는 파일 및 폴더가 다음 위치에 생성된다. /var/lib/mongodb : 기본 데이터 파일 위치 /var/log/mongodb : 기본 로그 저장 폴더 /etc/mongod.conf : mongod 구성 파일. 로그, 데이터 위치 등을 변경 가능 이제 데이터베이스 시스템을 사용하기 위한 데이터 파일, 네트워크 구성 및 인증 방법을 구성해야 한다. 실제 데이터 베이스 운영을 위해서 구성 파일인 mongod.conf 파일을 사용이 필요하면 이어지는 글을 참조하자. Mongo Database 설정과 사용자 인증 사용 만약 MongoDB community edition을 위 방법같이 설치를 했는데 systemctl 명령으로 찾지 못하면 아래 systemd unit 파일에 대한 글을 참조해서 추가해 주면 된다. systemd unit 파일Armbian 에서 설치중 systemd unit 설정 파일과 MongoDB 시스템 계정 등이 생성되지 않는 경우가 있었다. mongodb-org 설치후 systemd Unit 파일이 /etc/init.d에 복사되지 않는 경우 여기서는 odroid-c2 armbian 설치 상태, 일반 리눅스 배포본은 잘 된다. systemd 를 사용하기 위해서 MongoDB 서버 Daemon을 위한 Unit 파일을 아래를 따라 손으로 생성해 주면 systemctl 명령으로 서비스를 관리할 수 있다. MongoDB Daemon 사용자 추가 Service Unit File 작성 활성화 퍼미션 확인 Run 1. MongoDB Daemon 사용자 추가mongod 데몬은 mongodb user account 계정으로 실행된다. systemctl 명령으로 mongod 를 시작하고 사용하기 위해서는 mongod-org 서비스를 위해서 사용자 mongodb 가 추가되야 한다. 만약 생성되지 않았으면, 새로 만든다. 1$ sudo adduser --disabled-password --gecos &quot;&quot; --no-create-home --disabled-password --disabled-login mongodb 2. systemd service entry데비안/우분투 에서 systemd 서비스 파일은 /lib/systemd/system/ 밑에 위치한다. Mongodb Community Edition 의 Unit 파일은 mongod.service 이다. Mongodb Community Edition 설치시 Unit 파일이 복사되는데 파일이 있는지 확인한다. 1$ ls -l /lib/systemd/system/mongod.service 만약 mongod.service 가 없으면 새로 생성해야 한다. Unit 파일다음은 Mongodb Community Edition 설치시 기본으로 제공되는 유니트 파일이다. 만약 mongod.service 파일이 없으면 /lib/systemd/system/mongod.service 에 생성해서 사용할 수 있다. 123456789101112131415161718192021222324252627282930313233[Unit]Description=MongoDB Database ServerDocumentation=https://docs.mongodb.org/manualAfter=network.target[Service]User=mongodbGroup=mongodbEnvironmentFile=-/etc/default/mongodExecStart=/usr/bin/mongod --config /etc/mongod.conf#PIDFile=/var/run/mongodb/mongod.pidPIDFile=/run/mongodb/mongod.pid# file sizeLimitFSIZE=infinity# cpu timeLimitCPU=infinity# virtual memory sizeLimitAS=infinity# open filesLimitNOFILE=64000# processes/threadsLimitNPROC=64000# locked memoryLimitMEMLOCK=infinity# total threads (user+kernel)TasksMax=infinityTasksAccounting=false# Recommended limits for for mongod as specified in# http://docs.mongodb.org/manual/reference/ulimit/#recommended-settings[Install]WantedBy=multi-user.target 3. 활성화mongod.service 가 있으면 활성화 여부, 즉 systemd 에 mongod.service 가 등록 됐는지 확인한다. /lib/systemd/system/mongod.service 파일을 다음 같이 활성화 시켜준다. 12$ sudo systemctl list-unit-files --type=service |grep mongodmongodb.service disabled disable 상태면 systemctl 명령으로 enable 시킨다. 12$ cd /lib/systemd/system$ sudo systemctl enable mongodb.service 4. 퍼미션 확인MongoDB Community Editon을 소스 빌드로 설치하면 데이터 및 로그 디렉토리를 생성하고 사용자 퍼미션이 설정되야 한다. 예를 들어 로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 시스템 몽고디비 사용자 mongodb 가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongodb.mongodb /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata 5. Runsystemctl 명령으로 mongod 를 시작한다. 12$ sudo systemctl start mongod$ sudo systemctl status mongod 실행한 mongod를 확인해 보면 12$ ps -ef |grep mongodmongodb 15385 1 1 12:06 ? 00:00:00 /usr/bin/mongod --config /etc/mongod.conf mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있다. 참조[^1]: Install mongodb on Ubuntu","link":"/2019/12/20/Databases-2019-12-20-mongodb-4-2-install-arm64/"},{"title":"MongoDB 구성 설정과 사용자 인증 사용","text":"MongoDB에 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 Mongo Database 설정과 사용자 인증 사용이 문서는 MongoDB Community Edition 를 리눅스 플랫폼에서 시작과 운영에 필요한 구성 파일 mongod.conf 의 설정을 다루고 있다. 이를 통해 데이터베이스 서비스를 동작시키고, 인증한 사용자로서 클라이언트 프로그램으로 접속하기 위한 기본 인증방식을 구성하는 것을 정리하고 있다. Mongo Database 설정 기본인증 구성 이 글의 내용은 MongoDB Community Edition 3.6 이후 4.2 까지 사용이 가능하다. Mongo Database 설정우분투/데비안 계열은 설치시 mongod 데몬이 데이터베이스 운영에 필요한 여러 구성에 대한 설정을 위해서 /etc/mongod.conf 구성 파일을 사용한다. 구성 파일에 데이터베이스 구성에 필요한 여러 설정을 지정할 수 있다. mongodb 사용자와 디렉토리 퍼미션 확인 외부 접속 허용 여부 mongo client 접속 테스트 mongodb 인증 이제 실제 파일에 구성 내용을 설정하는데, 여기서는 mongod 의 기본인증 방법과 데이터 저장소에 대해서만 다룬다. mongod 설정MongoDB의 systemd 서비스는 보통 데이터베이스 구성 파일 /etc/mongod.conf 을 참조한다. mongod 서비스 상태를 확인해 보면 --config /etc/mongod.conf 옵션으로 구성 파일을 지시하고 있다. 123456789$ systemctl status mongod.service* mongod.service - MongoDB Database Server Loaded: loaded (/lib/systemd/system/mongod.service; disabled; vendor preset: enabled) Active: active (running) since Wed 2019-12-19 15:38:14 UTC; 3 weeks 6 days ago Docs: https://docs.mongodb.org/manual Main PID: 2051 (mongod) Memory: 191.3M CGroup: /system.slice/mongod.service `-2051 /usr/bin/mongod --config /etc/mongod.conf mongod.conf 파일을 살펴보자, mongod.conf 파일먼저 /etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. storage: 데이터 베이스 파일 저장 위치 및 방법 dbPath : 데이터베이스 스토리지 위치 systemlog: 로그 파일 및 로그 조작 방법 net: 네트워크 관련 bindIp: 서버 외에서 mongo 클라이언트가 접근하려면 IP 를 입력한다. 먼저 인증을 비활성화 한 구성을 하는데, 다음은 기본적인 mongod.conf 를 구성한 내용이다. 12345678910111213141516storage: dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 127.0.0.1,192.168.0.2 이제 mongo.conf 구성 파일이 준비되었으면 systemctl 로 mongod 데몬을 재시작한다.. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 간단한 구성 설정, 아직은 인증이 비활성화된 상태를 마련 했으면 사용자 인증을 통한 원격 접속을 살펴보자, mongo 기본인증보통 mongo 클라이언트 등에서 MongoDatabase 를 사용하기 위해서 클라이언트를 위한 인증을 제공해야 한다. 클라이언트를 위한 인증은 관리용 데이터베이스에서 데이터베이스 사용자를 등록하고 클라이언트가 등록한 사용자로 데이터베이스에 접속하는 방법을 사용한다. 인증을 추가하기 위해서 mongod의 mongo.conf 설정 파일에 접근 제어를 하지 않는 상태에서 mongo 클라이언트로 접속해서 기본인증을 위한 데이터베이스 사용자를 추가해 준다. Admin 사용자 생성mongod에 인증이 비활성화 상태에서 mongo 클라이언트로 접속에 성공하면 &gt; 프롬프트가 나온 후 use 명령으로 admin 데이터베이스로 전환한다. 12345$ mongo&gt;&gt; use adminswitched to db admin&gt; 1). admin 데이터베이스에서 관리자 role을 가진 사용자를 추가하고, 2). 사용할 데이터베이스의 사용자와 접근 제어를 추가해서 사용하기 위해서 작업한다. user administratoradmin 데이터베이스에 userAdmin role 혹은 userAdminAnyDatabase role을 가진 사용자 만든다. 다음은 admin 데이터베이스에서 사용자 admin 계정를 생성하고 있다. 12345678910111213&gt; use adminswitched to db admin&gt;&gt; db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() 사용자 패스워드 변경은 .changeUserPassword() 메서드를 사용한다. 1&gt; db.changeUserPassword(&quot;accountUser&quot;, &quot;SOh3TbYhx8ypJPxmt1oOfL&quot;) 사용자의 role 변경은 .grantRolesToUser() 메서드를 사용한다. 1&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}]) 혹은 updateUser() 를 사용할 수 있다: 1db.updateUser( &quot;appClient01&quot;, ... 현재 데이터베이스의 사용자를 출력한다. 123456789101112131415161718&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] admin 데이터베이스에 새로 생성한 admin 사용자로 로그인을 해보자. 그러기 위해서는 admin 데이터베이스에 인증 로그인을 한 후에 데이터 베이스를 생성하거나 사용할 수 있다. 인증 활성화mongod.conf 파일 안의 security 섹션에서 security.authorization 을 활성화 한다 12security: authorization: enabled 인증 활성화는 MongoDB v2.4이전에는 인증모드를 명령행의 --auth 옵션을 사용하고, v2.6 이후에서 mongod.conf 파일 사용할 때 security.authorization 를 활성화 하고 있다. systemd 로 서비스를 재시작 한다. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 이렇게 인증모드로 데이터베이스를 시작하면 인증 정보로 로그인해야 한다. 아래 같이 인증 정보없이 로그인 하면 데이터베이스 사용시 에러를 만난다. 123456$ mongo&gt; show dbs;Tue Sep 27 23:22:40.683 listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;unauthorized&quot; } at src/mongo/shell/mongo.js:46&gt;&gt; show usersTue Sep 27 23:22:44.667 error: { &quot;$err&quot; : &quot;not authorized for query on test.system.users&quot;, &quot;code&quot; : 16550 } at src/mongo/shell/query.js:128 이제 인증 모드에서 데이터베이스에 접속해야 한다. 인증모드로 접속데이터베이스 시스템에 접근제어가 활성화 되서 인증모드로 mongo 클라이언트 접속할 때는 옵션으로 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 앞서 생성해둔 admin 계정으로 접속해 보자, 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v4.2connecting to: mongodb://127.0.0.1:27017MongoDB server version: 4.2&gt; MongoDatabae는 데이터베이스 마다 인증한 사용자를 통해 조작을 하게 된다. 그래서 인증모드로 접속 되었지만, 어떤 데이터베이스에 비인증된 사용자로 접근하는 경우는 에러가 발생한다. 예를 들어서 admin 사용자로 인증 로그한 mongodb shell에서 아래 같이 비인증인 student 데이터베이스에 접근하면 에러가 난다: 12345&gt;&gt; use studentsswitched to db students&gt; show users2018-06-25T18:30:38.174+0900 E QUERY [thread1] Error: not authorized on students to execute command { usersInfo: 1.0, $db: &quot;students&quot; } : mongo 비인증 접근시위와 같이 로컬에서 mongo 클라이언트 접속하는 것 외에 외부에서 mongodb로 접근시 authentication을 적용한 상태라면 다음과 같은 URL로 접근할 수 있다: “username:password@HOST_NAME/mydb” 그러나 외부접근시 클라이언트 버전과 서버의 Credential 버전이 맞지 않은 경우 다음 같이 실패 메시지를 확인할 수 있다. 12&gt; 2016-05-16T00:53:10.338+0900 I ACCESS [conn2] Failed to authenticate student@student with mechanism MONGODB-CR: AuthenticationFailed: MONGODB-CR credentials missing in the user document&gt; 2016-05-16T00:53:10.352+0900 I NETWORK [conn2] end connection 220.121.140.59:51634 (0 connections now open) mongod 명령 사용보통 디버깅 목적으로 사용하기 위해서 systemd가 아닌 명령행에서 mongod 명령으로 로 MongoDB를 시작해 설정 파일 등이 제대로 동작하는지 확인할 수 있다. 다만 데이터베이스가 생성하는 데이터와 로그 파일의 접근권한이 실행한 사용자 계정으로 처리되어 퍼미션 문제가 발생할 수 있다. mongoDB v2.6 이후앞서 시작한 명령행 mongodb를 종료하고 명령라인에서 재시작 --auth 옵션을 붙여 시작한다. 1$ mongod --auth --port 27017 --dbpath /data/mongodata 접근제어 --auth 옵션으로 데이터베이스를 시작하면 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 이전 버전의 mongod 명령 mongoDB v2.4 인증모드로 시작``mongod` 명령라인으로 시작할 수 있다. 1$ sudo mongod --port 27017 --dbpath /data/mongodata mongoDB v2.4는 다음 같이 인증 모드로 시작한다. mongod 명령라인에서 --auth 옵션을 붙여 DB 인스턴스(mongod)를 시작 혹은 재시작한다. 1$ mongod --auth --port 27017 --dbpath /data/db1 혹은 mongod.conf 설정 파일에서 auth 를 활성화 한다. 1auth = true 참조[^1]: Install mongodb on Ubuntu","link":"/2019/12/20/Databases-2019-12-20-mongodb-config/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Service 관리","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 3개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.3 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x openSUSE: Basic OS Security for ServeropenSUSE는 systemd 를 사용한 서비스/데몬 시작/종료/활성화/비활성화 작업을 할 수 있다. 서비스에 대한 작업은 systemctl CLI 혹은 YaST에서 가능하다. yastopenSUSE는 yast 로 서비스 데몬도 설치/실행/멈춤 을 할 수 있다. {:width=”640”} 서비스는{:width=”640”} systemdhttps://doc.opensuse.org/documentation/leap/reference/html/book.opensuse.reference/cha.systemd.html https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal 1systemctl list-unit-files --type=service #현재 사용 가능한 모든 서비스 이 작업은 1234567systemctl stop SuSEfirewall2systemctl disable SuSEfirewall2zypper in ufwufw default denyufw enablesystemctl enable ufwsystemctl start ufw ssmtpsSMTP is a simple MTA to deliver mail from a computer to a mail hub (SMTP server). sSMTP is simple and lightweight, there are no daemons or anything hogging up CPU; Just sSMTP. Unlike Exim4, sSMTP does not receive mail, expand aliases, or manage a queue. https://wiki.debian.org/sSMTP 42.3, 15.0 에 ssmtp가 포함되지 않았다. https://build.opensuse.org/package/binaries/home:jloehel/ssmtp/openSUSE_Factory_ARM mail utitlity1$ sudo zypper install mail Then try to send email from command line with: 1$ echo &quot;Message Body&quot; | mail -s &quot;Message Subject&quot; receiver@example.com 참조[^1]: systemd: Enable/Disable Services","link":"/2017/10/21/raspberrypi-opensuse-services/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Basic Security","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 3개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.3 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x openSUSE: Basic OS Security for Server이전 글에서 라즈베리파이 3에 설치한 64bit OS openSUSE LEAP / JeOS를 서버 구성을 위해서 보안 설정을 한다. 이 글은 다음 세가지 내용을 포함하고 있다. ssh와 sshd 설정 방화벽 설정: YaST Firewall 대비 ufw 설치 Fail2ban 설치 및 설정 sshd_configssh 사용시 sshd securities 방화벽 설정openSUSE는 SuSEfirewall2 가 기본으로 제공되어 서비스를 활성화 하면 사용할 수 있다. 아직 익숙치 않아서 SuSEFirewall2 을 우분투/데비안에서 익숙한 ufw 를 설치해 사용하겠다. 1234567891011121314151617181920Basic Syntax: yast2 firewall interactive yast2 firewall &lt;command&gt; [verbose] [options] yast2 firewall help yast2 firewall longhelp yast2 firewall xmlhelp yast2 firewall &lt;command&gt; helpCommands: broadcast Broadcast packet settings disable Disables firewall enable Enables firewall interfaces Network interfaces configuration logging Logging settings masqredirect Redirect requests to masqueraded IP masquerade Masquerading settings services Allowed services, ports, and protocols startup Start-up settings summary Firewall configuration summary zones Known firewall zones 먼저 SuSEfirewall2 를 멈추고 비활성화 한다. 1sudo yast firewall disable 12systemctl stop SuSEfirewall2systemctl disable SuSEfirewall2 그리고 ufw를 설치하고 1zypper in ufw 1234ufw default denyufw enablesystemctl enable ufwsystemctl start ufw Fail2banrsyslog 를 설치한다. https://en.opensuse.org/SDB:SSH_systematic_attack_protection https://www.howtoforge.com/fail2ban_opensuse10.3 sshufwfail2banzypper in fail2ban 참조OpenSSH Public Key Authentication https://doc.opensuse.org/documentation/leap/security/html/book.security/cha.security.firewall.html","link":"/2017/10/21/raspberrypi-opensuse-ufw/"},{"title":"openSUSE: Network 관리","text":"Networkyast 명령으로 네트워크 구성을 수정할 수 있다. 실제 네트워크 관련 프레임워크는 wicked 를 사용한다. https://www.suse.com/documentation/sles11/book_sle_admin/data/sec_yast_ncurses_commands.html net-tools기존 ifconfig 가 deprecate 되서 ip 명령을 사용한다. [^2] ip command를 참고한다. 그리고 ip 명령 예제를 참고해 123ip aip addressip link IPGUI에서 YaSt 도구를 사용하면 쉽게 설정할 수 있다. 터미널에서는 wicked 시스템에 따라서 네트워크를 구성한다. https://doc.opensuse.org/documentation/leap/reference/html/book.opensuse.reference/cha.basicnet.html#sec.basicnet.manconf 타 리눅스 배포본에서 사용하는 방법의 구성 설정 파일은 /etc/sysconfig/network/ifcfg-[DEVICE] 이다. *[DEVICE]*는 사용할 인터페이스 이름이다. 1234BOOTPROTO=staticONBOOT=yesIPADDR=192.168.1.10LABEL=&quot;System eth0&quot; Gateway는 /etc/sysconfig/network/routes 파일에 다음 같이 구성해 준다.[^4] 1default gatewayaddr 192.168.1.1 DNS는 /etc/resolv.conf 를 참조하는데 yast 로 변경할 수 있다. 1yast dns edit nameserver1=192.168.1.1 https://doc.opensuse.org Link1sudo ip link set eth0 up","link":"/2017/11/22/raspberrypi-opensuse-network/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Service 관리","text":"Upgrade OpenSUSE LEAP 42.2 to LEAP 15https://en.opensuse.org/SDB:System_upgrade OpenSUSE LEAP 42.2를 LEAP 15.0으로 업그레이드 하려고 한다. [그림. 지원 중단 배포본 (OpenSUSE)] UpgradeUpdate repository다음 명령으로 현재 배포본의 Repository Url이 활성화 되어 있는지 확인한다. 12345678# zypper repos --uriRepository priorities are without effect. All enabled repositories share the same priority.# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-----------------------------------+-----------------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | openSUSE-Ports-Leap-42.2-Update | openSUSE-Ports-Leap-42.2-Update | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/update/42.2/2 | openSUSE-Ports-Leap-42.2-repo-oss | openSUSE-Ports-Leap-42.2-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/42.2/repo/oss/ 42.2 저장소 백업하고, 1# cp -Rv /etc/zypp/repos.d /etc/zypp/repos.d.Old 42.2 를 15.0 으로 변경하자, 1# sed -i 's/42.2/15.0/g' /etc/zypp/repos.d/* 업데이트 저장소 위치가 다르기 때문에 zypper repos --uri 에서 openSUSE-Ports-Leap-15.2-Update 를 삭제한다. 1zypper rr 1 그리고 openSUSE-Ports-Leap-15.0-Update 를 추가한다. 1zypper addrepo --check --refresh --name 'openSUSE-Leap-15.0-Update' http://download.opensuse.org/update/leap/15.0/oss/ repo-update 15.2 저장소가 제대로 들어갔는지 확인한다. 1234567# zypper repos --uriRepository priorities are without effect. All enabled repositories share the same priority.# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-----------------------------------+-----------------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | openSUSE-Ports-Leap-15.0-repo-oss | openSUSE-Ports-Leap-15.0-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/15.0/repo/oss/2 | repo-update | openSUSE-Leap-15.0-Update | Yes | ( p) Yes | Yes | http://download.opensuse.org/update/leap/15.0/oss/ 결과에서 repo-update 가 Enabled 컴럼이 Yes 인지 확인한다. 만약 No 라면 다음 명령으로 활성화 한다. 1zypper modifyrepo --enable repo-update Update repositoryzypper ref Distribution Upgrade12345678# zypper dup...613 packages to upgrade, 170 to downgrade, 340 new, 103 to remove, 6 to changearch.Overall download size: 658.0 MiB. Already cached: 0 B. After the operation,additional 774.1 MiB will be used.Continue? [y/n/...? shows all options] (y): y homepi64:~ # reboot[11840.081284] reboot: Restarting systemMMC: mmc@7e202000: 0, mmc@7e300000: 1Loading Environment from FAT… *** Warning - bad CRC, using default environment 진행중 42.2와 충돌하는 패키지가 표시되는데 모둔 1로 설치했다. 1234567891011124 Problems:Problem: nothing provides tar = 1.30 needed by tar-lang-1.30-lp150.2.3.2.noarchProblem: nothing provides python3-dbus-python needed by snapper-zypp-plugin-0.5.4-lp150.3.3.1.noarchProblem: nothing provides libgphoto2-6 = 2.5.18 needed by libgphoto2-6-lang-2.5.18-lp150.2.3.1.noarchProblem: nothing provides gpg2 = 2.2.5 needed by gpg2-lang-2.2.5-lp150.3.3.1.noarchProblem: nothing provides tar = 1.30 needed by tar-lang-1.30-lp150.2.3.2.noarch Solution 1: deinstallation of tar-lang-1.27.1-11.1.noarch Solution 2: keep obsolete tar-lang-1.27.1-11.1.noarch Solution 3: break tar-lang-1.30-lp150.2.3.2.noarch by ignoring some of its dependenciesChoose from above solutions by number or skip, retry or cancel [1/2/3/s/r/c] (c):1 재시동업그레이드를 설치한 후에 재시동 하면 약 5분 정도 펌웨어 등을 설치하는 과정을 거친다. 로그인해서 버전을 확인해 보자 qkboo@homepi64:~&gt; uname -aLinux homepi64 4.4.104-18.44-default #1 SMP Thu Jan 4 08:07:55 UTC 2018 (05a9de6) aarch64 aarch64 aarch64 GNU/Linux ~&gt; uname -aLinux homepi64 4.4.104-18.44-default #1 SMP Thu Jan 4 08:07:55 UTC 2018 (05a9de6) aarch64 aarch64 aarch64 GNU/Linux https://en.opensuse.org/SDB:Find_openSUSE_version","link":"/2018/07/17/raspberrypi-opensuse-upgrade-42-2-to-15/"},{"title":"","text":"Opensuse errorEmergency Mode 로 들어간 경우 “systemctl –failed -l 1journalctl -b http://susepaste.org/? 사이트에 올린다. btrfs check –repair /dev/sda6","link":"/2018/07/13/raspberrypi-opensuse-show-error/"},{"title":"Raspberry Pi : Upgrade OpenSUSE LEAP 42.2 to 42.3","text":"Raspberry Pi 3 에 설치해 사용중이던 openSUSE LEAP 42.2의 지원이 종료되어, 2019년가지 지원하는 LEAP 42.3으로 업그레이드하는 과정을 정리했다. openSUSE는 LEAP 15.0으로 최신 버전으로 배포하고 있다. 42.2에서 15.0으로 바로 업그레이드시 내가 해결 못하는 문제가 생겨서 42.3으로 업그레이드 했다. Upgrade OpenSUSE LEAP 42.2 to 42.3OpenSUSE LEAP 42.2 는 지원이 종료되어 42.3으로 업그레이드를 한다. {: width=”600”} [그림. 지원 중단 배포본 (OpenSUSE.com)] 업그레이드에 대한 과정은 [OpenSUSE System Upgrade](https://en.opensuse.org/SDB:System_upgrade) 에 나와있는데 42.3을 15.0으로 배포본 업그레이드 하는 과정과 일반 배포본에서 배포본 업그레이드가 설명되어 있어서 직접 시도하면서 정리했다. Upgrade 시작먼저 42.2 저장소 URI를 42.3 으로 변경한다. 42.3 Repository Uri현재 시스템의 Repository Uri를 확인해 보고 12345678$sudo zypper repos --uriRepository priorities are without effect. All enabled repositories share the same priority.# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-----------------------------------+-----------------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | openSUSE-Ports-Leap-42.2-Update | openSUSE-Ports-Leap-42.2-Update | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/update/42.2/2 | openSUSE-Ports-Leap-42.2-repo-oss | openSUSE-Ports-Leap-42.2-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/42.2/repo/oss/ 다른 저장소를 추가하지 않고 사용했다면 LEAP 42.2 배포본 저장소는 위와 같을 것이다. 현재 Uri인 저장소 백업하고, 1$sudo cp -Rv /etc/zypp/repos.d /etc/zypp/repos.d.Old 위 목록에서 openSUSE-Ports-Leap-42.2-repo-oss를 제거한다. 목록 번호로 제거할 수 있어서 rr 2 명령으로 제거한다. 1$sudo zypper rr 2 저장소 문자열 42.2 를 42.3 문자열로 치환한다 1$sudo sed -i s/42.2/42.3/ /etc/zypp/repos.d/* 여기에 앞에서 제거한 repo-oss 저장소를 LEAP 42.3을 위한 openSUSE-Leap-42.3-repo-oss 를 추가해 준다. 1$sudo zypper addrepo --check --refresh --name 'openSUSE-Leap-42.3-repo-oss' http://download.opensuse.org/ports/aarch64/distribution/leap/42.3/repo/oss/ repo-oss 새 저장소 Uri를 추가하고 배포본의 Repository Url를 출력해서 Enabled 컬럼이 활성화 되어 있는지 확인한다. 12345$sudo zypper repos --uri# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-------------+-----------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | repo-oss | openSUSE-Leap-42.3-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/42.3/repo/oss/2 | repo-update | openSUSE-Leap-42.3-Update | Yes | (r ) Yes | Yes | http://download.opensuse.org/update/leap/42.3/oss/ 만약 출력한 저장소 목록에서 Enabled 컬럼이 No 라면 다음 명령으로 활성화 한다. 1$sudo zypper modifyrepo --enable openSUSE-Leap-42.3-repo-oss 이제 42.3을 위한 저장소 Uri가 정리되었다. 실제 배포본 버전을 업그레이드 하기 위해서는 dup 명령을 내려 실행해야 하지만 역시 42.2를 15.0으로 직접 배포본 업그레이드 했을 때 문제가 발생해서 설치된 패키지를 업르레이드하고 배포본 업그레이드를 진행했다. Distribution Upgrade먼저 저장소에서 패키지 목록을 최신으로 갱신하고, package upgrade를 진행해 준다. 12zypper refzypper up 오에스에서 사용하는 패키지가 많기 때문에 패키지 업그레이드 과정은 꽤 긴 시간이 필요하다. 과정중에 펌웨어 버전 충돌이 나오면 Yes 해준다. 1234567891011Checking for file conflicts: ............................................[error]Detected 1 file conflict:File /lib/firmware/brcm/brcmfmac43430-sdio.bin from install of kernel-firmware-20170530-20.1.noarch (openSUSE-Leap-42.3-Update) conflicts with file from package bcm43xx-firmware-20160301-2.1.noarch (@System)File conflicts happen when two packages attempt to install files with the same name but different contents. If you continue, conflicting files will be replaced losing the previous content.Continue? [yes/no] (no): yes 그리고 재시동을 해준다. package upgrade를 완료한 후에 Distribution upgrade를 수행하자 1zypper dup 재시동업그레이드를 설치한 후에 재시동 하면 약 5분 정도 펌웨어 등을 설치하는 과정을 거친다. 로그인 프롬프트에서 openSUSE Leap 42.3 이 보이면 성공한 것이다. 1234Welcome to openSUSE Leap 42.3 - Kernel 4.4.104-18.44-default (ttyS0).homepi64 login: 보안 패치openSUSE는 upgrade와 patch 를 분리해서 제공한다. 패치는 보안 사항에 관련한 것을 제공하고 있다. lp 로 다운로드 가능한 패치를 확인할 수 있다. 123456789101112131415161718# zypper lpRetrieving repository 'openSUSE-Leap-42.3-Update' metadata ..................[done]Building repository 'openSUSE-Leap-42.3-Update' cache .......................[done]Loading repository data...Reading installed packages...Repository | Name | Category | Severity | Interactive | Status | Summary--------------------------+--------------------+-------------+-----------+-------------+--------+-----------------------------------------------------------------------openSUSE-Leap-42.3-Update | openSUSE-2017-1268 | security | important | --- | needed | Security update for webkit2gtk3openSUSE-Leap-42.3-Update | openSUSE-2017-1425 | recommended | low | --- | needed | Recommended update for grub2openSUSE-Leap-42.3-Update | openSUSE-2017-940 | security | important | --- | needed | Security update for subversionopenSUSE-Leap-42.3-Update | openSUSE-2018-118 | security | important | --- | needed | Security update for webkit2gtk3openSUSE-Leap-42.3-Update | openSUSE-2018-234 | recommended | low | --- | needed | Recommended update for grub2openSUSE-Leap-42.3-Update | openSUSE-2018-241 | recommended | moderate | --- | needed | Recommended update for yast2, yast2-nfs-client, yast2-services-manageropenSUSE-Leap-42.3-Update | openSUSE-2018-586 | recommended | low | --- | needed | Recommended update for grub2Found 7 applicable patches:7 patches needed (3 security patches) 패치는 보안 이슈에 대한 것으로 해당 보안 이슈 정보 혹은 분류 등을 확인할 수 있다. 목록에서 Name 컬럼이 발생한 보안 사항 번호로 이 번호로 조회할 수 있다. 1zypper info openSUSE-2017-462 패키지 내용은 CVE(Common Vulnerabilities and Exposures)로 보고된 보안 사항을 적용한 내용을 자세히 보여주고 있다. 패치 중에서 Category로 검색할 수 있다. 다음 같이 security 분류만 검색할 수 있다. 123456789101112zypper lp --category securityLoading repository data...Reading installed packages...Repository | Name | Category | Severity | Interactive | Status | Summary--------------------------+--------------------+----------+-----------+-------------+--------+--------------------------------openSUSE-Leap-42.3-Update | openSUSE-2017-1268 | security | important | --- | needed | Security update for webkit2gtk3openSUSE-Leap-42.3-Update | openSUSE-2017-940 | security | important | --- | needed | Security update for subversionopenSUSE-Leap-42.3-Update | openSUSE-2018-118 | security | important | --- | needed | Security update for webkit2gtk3Considering 3 out of 7 applicable patches:3 patches needed (3 security patches) 패치를 전체를 설치하려면 1sudo zypper patch 혹은 패치 중에서 특정 패치만 설치할 수 있다. 1sudo zypper install patch:openSUSE-2017-1268 참조 OpenSUSE System Upgrade openSUSE Update &amp; Patch","link":"/2018/07/10/raspberrypi-opensuse-upgrade-42-2-to-42-3/"},{"title":"Raspberry Pi: mmcblk","text":"mmcblkSD/MMC card 는 MMC 서브시스템을 /dev/mmcblk{id} 형식으로 블럭 장치로 사용한다. dmesg 로 부트 메시지를 보면 SDHCI 인터페이스에 장착한 장치를 확인할 수 있다. 12345678910111213141516171819202122232425262728[ 0.789621] sdhci: Secure Digital Host Controller Interface driver[ 0.789628] sdhci: Copyright(c) Pierre Ossman[ 0.789999] sdhost-bcm2835 3f202000.sdhost: could not get clk, deferring probe[ 0.790252] sdhci-pltfm: SDHCI platform and OF driver helper[ 0.791051] ledtrig-cpu: registered to indicate activity on CPUs[ 0.791232] hidraw: raw HID events driver (C) Jiri Kosina[ 0.791461] usbcore: registered new interface driver usbhid[ 0.791467] usbhid: USB HID core driver[ 0.792448] vchiq: vchiq_init_state: slot_zero = 0xb6980000, is_master = 0[ 0.794533] Initializing XFRM netlink socket[ 0.794566] NET: Registered protocol family 17[ 0.794724] Key type dns_resolver registered[ 0.795223] Registering SWP/SWPB emulation handler[ 0.796192] registered taskstats version 1[ 0.796681] vc-sm: Videocore shared memory driver[ 0.796694] [vc_sm_connected_init]: start[ 0.802967] [vc_sm_connected_init]: end - returning 0[ 0.809343] 3f201000.serial: ttyAMA0 at MMIO 0x3f201000 (irq = 87, base_baud = 0) is a PL011 rev2[ 0.809410] console [ttyAMA0] enabled[ 0.811406] sdhost: log_buf @ b6913000 (f6913000)[ 0.889149] mmc0: sdhost-bcm2835 loaded - DMA enabled (&gt;1)[ 0.889333] of_cfs_init[ 0.889478] of_cfs_init: OK[ 0.890211] Waiting for root device /dev/mmcblk0p2...[ 0.956566] mmc0: host does not support reading read-only switch, assuming write-enable[ 0.958563] mmc0: new high speed SDHC card at address 59b4[ 0.959555] mmcblk0: mmc0:59b4 00000 14.9 GiB[ 0.961428] mmcblk0: p1 p2 메시지에서 보듯 mmc0 장치에 카드가 삽입되기 전에 인터럽트가 없다. 12$ cat /proc/interrupts |grep mmc86: 393 0 0 0 ARMCTRL-level 88 Edge mmc0 https://developer.toradex.com/knowledge-base/sd-mmc-card-(linux)","link":"/2019/07/12/raspberrypi-sdcard-mmcblk/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Install","text":"2017-10-30: swap 추가, timezone 수정{:.right-history} Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 이글은 5개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Install 64bit openSUSE Leap 42.2 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter openSUSE: Build MongoDB 3.4.x Install 64bit openSUSE Leap 42.2 / JeOSopenSUSE는 Raspberry Pi 3를 위한 Opensuse community edition은 정식 버전 Leap 42.2 image, 개발버전 Tumbleweed image, 커뮤니티버전 non-upstream openSUSE Tumbleweed image* 으로 구성되어 있다. 이들 버전은 용도에 따라 JeOS, E20, LXQT X11 이미지로 다운받을 수 있다. Just Enought Operating System (JeOS) jeOS 이미지는 기본 오에스만을 포함하고 있다. https://www.suse.com/products/server/jeos/ E20 데스크탑 환경으로 Enlightenment 을 사용하 GUI 이미지 LXQt LXDE-Qt 와 RazorQt 병합한 데스크탑 환경 https://en.opensuse.org/LXQt ### Download and Install Download Page 의 두번째 Installing the 64-bit openSUSE Leap image 단락에 있는 JeOS image 를 다운로드 한다. Writing image to SD CardEtcher 등을 이용해서 다운받은 이미지 파일을 SD Card에 쓴다. {:width=”640”} dd 를 사용한다면,다운받은 .xz 파일을 dd 를 이용해서 SD Card에 쓴다. 1xzcat openSUSE-Leap42.2-ARM-JeOS-raspberrypi3.aarch64.raw.xz | sudo dd of=/dev/rdisk1 bs=4m; sync #### Serial console 여기서는 Serial console에서 네트워크 확인 및 초기 설정을 하고 ssh 로 서버에 로그인해서 시스템 구성을 진행한다. SD Card를 라즈베리파이에 꽃고 HDMI, Keyboard 및 Mouse 가 별도로 준비되어 있으면 직접 모니터를 보고 작업을 진행하면 좋다. USB to Serial 케이블을 사용해서 Raspberry Pi의 Serial Console에 연결한다. {:width=”640”} 그리고 시리얼 포트를 통해 tty 연결을 위해 터미널 프로그램에서 baud rate 115200 으로 연결한다. 아래는 macOS의 screen CLI 명령으로 usb serial 포트에 연결하고 있다. 1$ screen /dev/cu.usbserial 115200 이제 SD Card를 넣고 부팅을 하면, 터미널에 부트 단계가 진행되고 처음 5분 정도 소요된다. {:width=”640”} Raspberry Pi를 위한 이미지는 처음 계정은 root/linux 이다. 터미널에서 uname 은 aarch64 임을 확인 할 수 있다. 12root# uname -aLinux homepi 4.4.90-18.32-default #1 SMP Fri Oct 6 13:30:08 UTC 2017 (465b410) aarch64 aarch64 aarch64 GNU/Linux 처음으로 라즈베리파이에서 64bit 환경으로 운영해 볼 수 있게 됐다. ### 설치 후 서버 구성을 위해 할 일 JeOS를 서버로 구성하기 위해서 다음 같은 작업을 수행해 준다. root 패스워드 변경 sudoer 사용자 생성 DHCP를 고정 IP로 변경 root 패스워드root 사용자의 패스워드를 변경한다. {:width=”640”} UpdateUbuntu/Debian 계열의 패키지 명령 apt,apt-get 과 비슷한 openSUSE 명령라인 패키지 관리자는 zypper 가 있다. 123456789zypper help search # to print help for the search commandzypper refresh, ref # Refresh all repositories.zypper update, up # to update all installed packageszypper lp # to see what patch updates are neededzypper patch # to apply the needed patcheszypper se sqlite # to search for sqlitezypper rm sqlite2 # to remove sqlite2zypper in sqlite3 # to install sqlite3zypper in yast* # to install all packages matching 'yast*' zypper usages 에서 사용방법을 자세히 알 수 있다. 머저 최신 소프트웨어 목록으로 업데이트 한다. 12zypper refreshzypper ref 그리고 최근 업그레이드된 필요한 패키지를 다운로드하고 설치한다.[^1] 12zypper updatezypper up 지원중단된 패키지, 나뉘어진 패키지 등의 의존성을 고려한 업그레이드를 하려면 dup 명령을 사용한다.&gt; 12zypper dup # distribution upgradezypper dist-upgrade upgrade 후에실행중인 데몬을 재시작해줄 필요가 있는데 zypper ps -s 를 실행하면 목록을 표시해 준다. 1234567891011121314151617181920212223242526272829303132333435pi64:/home/ # zypper ps -sThe following running processes use deleted files:PID | PPID | UID | User | Command | Service------+-------+------+------------+----------------------------+-------------------307 | 1 | 0 | root | systemd-journald (deleted) | systemd-journald484 | 1 | 0 | root | auditd | auditd502 | 1 | 1000 | qkboo | python3 | jupyter513 | 1 | 499 | messagebus | dbus-daemon (deleted) | dbus525 | 1 | 0 | root | systemd-logind (deleted) | systemd-logind529 | 1 | 0 | root | agetty (deleted) | getty@tty1996 | 1 | 0 | root | cupsd | cups1018 | 1 | 0 | root | cron | cron1043 | 1 | 74 | ntp | ntpd | ntpd1047 | 1043 | 74 | ntp | ntpd | ntpd1145 | 1 | 0 | root | python2.7 | fail2ban1146 | 1 | 1000 | qkboo | node | pm2-qkboo2131 | 1 | 0 | root | agetty (deleted) | serial-getty@ttyS05716 | 1146 | 1000 | qkboo | node | pm2-qkboo5749 | 1146 | 1000 | qkboo | node | pm2-qkboo12400 | 1 | 0 | root | sshd (deleted) |12402 | 1 | 1000 | qkboo | systemd (deleted) |12405 | 0 | 1000 | qkboo | systemd (deleted) |12411 | 12400 | 1000 | qkboo | sshd (deleted) |12412 | 12411 | 1000 | qkboo | bash |12783 | 12412 | 0 | root | sudo |12784 | 12783 | 0 | root | bash |12876 | 1 | 0 | root | nginx | nginx12879 | 12876 | 494 | nginx | nginx | nginx12880 | 12876 | 494 | nginx | nginx | nginx12881 | 12876 | 494 | nginx | nginx | nginx12882 | 12876 | 494 | nginx | nginx | nginx15908 | 502 | 1000 | qkboo | node | jupyter15916 | 15908 | 1000 | qkboo | node | jupyter26929 | 502 | 1000 | qkboo | node | jupyter ip 주소 확인ifconfig 명령으로 현재 IP Address를 확인하고 이 IP Address에 ssh 를 사용해 접속한다. 1234567891011linux:~ # ifconfigeth0 Link encap:Ethernet HWaddr B9:40:EB:BA:10:02 inet addr:192.168.1.104 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe90::ba37:ebff:feba:1012/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:83136 errors:0 dropped:0 overruns:0 frame:0 TX packets:27300 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:120797947 (115.2 Mb) TX bytes:2369690 (2.2 Mb)linux:~ #linux:~ # shutdown now 좀더 편리한 사용을 위해 ifconfig 명령으로 찾은 IP address에 ssh 로그인을 해서 작업을 진행한다. 1$ ssh root@192.168.1.104 ### 시스템 설정 이제 sudoer 사용자로 시스템을 서버에 적합하게 구성해 보자. sudoer 추가 yast 소개 timezone Network 구성: 호스트 이름, IP 주소 swap 개선 yast로 사용자 추가 sudoerroot 사용자가 아닌 일반사용자를 sudoer로 등록해 관리자 기능을 대행 할 수 있다. 그러기 위해서 먼저 사용자를 추가한다. openSUSE yast라는 시스템 도구로 할 수 있지만 여기선 useradd 명령을 사용해서 사용자 추가한다. useradd에 대해서는 useradd 명령을 참조한다. useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. 추가한 사용자를 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 추가 그리고 -m 옵션으로 으로 사용자 홈 디렉토리 까지 생성한다. 1root# useradd -m foo 그리고 패스워드를 등록한다. 1234root# passwd fooNew password:Retype new password:passwd: password updated successfully sudoer 등록visudo 명령으로 /etc/sudoers 파일을 편집한다. 1$ sudo visudo sudoer 파일에 있는 User privilege 항목 아래에 새로운 사용자 foo를 아래 같이 등록한다. 123# User privilege specificationroot ALL=(ALL) ALLfoo ALL=(ALL) ALL 이제 root에서 로그아웃하고 새로 추가한 사용자로 로그인한다. 1234$ ssh foo@192.168.1.104Password:Have a lot of fun...foo@linux:~&gt; openSUSE는 관리자용 명령을 직접 내리면 찾지 못한다고 한다. 12foo@linux:~&gt; yast2 timezone-bash: yast2: command not found 그리고 처음으로 sudoer 사용자가 관리자 권한이 필요한 명령을 사용하기 위해 sudu 로 명령을 내리면 아래 같은 경고가 나온다. 12345678foo@linux:~&gt; sudo /sbin/yast2 timezoneWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. openSUSE는 시스템 관리 도구로 yast 를 사용해서 소프트웨어 설치, 네트워크 구성, 시간 관리, 보안 및 사용자 등을 다루는 소프트웨어로 GUI와 CLI 모두 사용할 수 있다. 시스템 네트워크를 구성하기 위해서 yast 명령을 사용해보자, yastyast는 GUI 혹은 ClI에서 사용이 가능하다 . 다음은 sudo yast 를 실행하면 Ncurse 로 표시되는 yast 화면이다. {:width=”640”} TAB 키로 각 항목을 이동할 수 있고, Enter로 실행한다. 전체 화면에서 F9는 Cancel, F10은 OK 기능을 수행한다. Timezone처음 설치후 CET 시간대로 되어 있어서 Asia/Seoul로 변경하고자 한다. 12linux:~ # dateSun Oct 29 09:19:31 CET 2017 시스템 시간대를 설정하려면 yast 를 시작해 System -&gt; Date and Time 을 실행해 시간대를 지정한다. 혹은 yast timezone 모듈 명령을 주면 해당 Date and Time 화면으로 이동할 수 있다. {:width=”640”} 시간대를 변경후 확인해 보면, 12linux:~ # dateSun Oct 29 17:22:11 KST 2017 ntp로 동기화하려면 Other Settings… 항목을 선택해 ntp server 를 설치하고 활성화 한다. {:width=”640”}{:width=”640”}","link":"/2017/10/20/raspberrypi-opensuse-jeos-install/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Nginx, Node JS, Jupyter","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 5개 글타래로 구성되며, openSUSE 설치, 개발도구 구성 및 서버 구축 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter Build MongoDB 3.4.x Nginx, Node JS, Jupyter Notebook Raspberry Pi 3 openSUSE LEAP 42.2 / JeOS Target services Nginx Nginx Proxy www app : nodejs (PORT 50000) jupyter notebook: PORT 8585 Node.js with nvm Python and virtualenv, jupyter notebook nginxnginx는 1.8 버전으로 당연히 사용하던 데비안 계열과 설정 파일 구성이 조금 다르다. nginx 사용자: nginx /etc/nginx/nginx.conf 가 sites-_ 폴더가 아닌 vhost_ 폴더를 가르킨다. 여기서는 sites-* 폴더를 그대로 사용한다. 기존 데비안 계열 형식 sites-* 폴더를 사용하고 사용자먄 nginx 사용. 설치zypper 로 nginx 배포본을 설치한다. 현재는 1.8.1-10.5.1 버전이다. 1sudo zypper in nginx 설치하면 사용자 nginx:nginx 가 추가된다. nginx.confnginx 설정은 Nginx - Install, WebDAV, Proxy on Ubuntu/Debian 에 설명되어 있다. 이 구성을 기초로 우분투/데비안 계열 같이 site-* 폴더를 구성해서 사용한다. 12cd /etc/nginxmv nginx.conf nginx.orig nginx.conf 에 include 지시자를 사용해 sites-enabled 를 추가한다. 12include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*; 그리고 sites-available, sites-enabled 폴더를 생성하고 사이트 파일을 만든다. 123cd /etc/nginxsudo mkdir sites-available sites-enabledsudo touch sites-available/my-site my-site 가상호스트 파일은 [my-site](/2017/04/03/ubuntu-nginx#my-site) 내용의 파일을 site-available 에 작성하고, 그 링크를 site-enabled에 링크를 걸어 준다. 12cd /etc/nginxsudo -s /etc/nginx/sites-available/my-site /etc/nginx/sites-enabled/my-site ### node.js nvm을 설치한다. 1curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh | bash Node.js 설치와 개발환경 설치에 대해서는 NodeJS / nvm 기반 개발환경 설치 글을 참조할 수 있다. node.js 설치최신 v8 버전을 설치한다. 123&gt; nvm install v8Downloading and installing node v8.8.1...Creating default alias: default -&gt; v8 (-&gt; v8.8.1) 12&gt; which node/home/qkboo/.nvm/versions/node/v8.8.1/bin/node pm2 설치node.js 앱을 시스템 서비스로 등록하기 위해서 pm2 를 설치한다. 1npm i -g pm2 예를 들어 express 앱이 있으면 다음 같이 pm2로 시작한다. 12cd www-apppm2 start -n &quot;www-app&quot; bin/www pm2 startupstartup 시 pm2 start 로 생성되는 .pm2 디렉토리의 pid 와 app.js 파일을 실행해 준다. pm2 startup systemd 로 스타트를 하면 2개의 프로세스가 만들어 진다. 방법은,,, 먼저 앱을 시작해 둔다. 1pm2 start -n &quot;www-app&quot; bin/www dump를 생성한다. pm2로 현재 실행중인 프로세스 정보를 save로 덤프하게 저장한다. systemd 서비스 스크립을 작성하는데 유용하다. 1pm2 save pm2 startup 명령 pm2 startup 명령은 pm2로 실행중인 프로세스를 systemd 서비스 유니트 파일로 제어 할 수 있다. 명령을 실행하면 sudo 명령으로 실행할 수 있는 스크립을 출력해 준다. 123$ pm2 startup systemd...sudo env PATH=$PATH:/home/foo/.nvm/versions/node/v8.8.1/bin /home/foo/.nvm/versions/node/v8.8.1/lib/node_modules/pm2/bin/pm2 startup systemd -u foo --hp /home/foo 이 스크립을 실행해 주면 pm2-foo.service 서비스 유니 파일이 생성된다. 12Target path/etc/systemd/system/pm2-foo.service 이 서비스 파일을 활성화하고 시작해준다. 1systemctl enable pm2-foo 이제 시스템을 재시작해도 pm2 로 실행중인 프로세스는 자동으로 시작된다. ### Python Python 개발 환경을 virtualenv 를 이용해서 구성하고, jupyter 를 설치한다. 그리고 시스템 시작 스크립으로 자동으로 시작하는 jupyter notebook 환경 구성까지 진행한다. python3 설치openSUSE에 python2.7 만 설치되어 있어서, python3 를 설치한다. 다른 버전을 설치하면 openSUSE에서는 자동으로 update-alternatives로 pip를 등록해준다. 123sudo zypper in python3update-alternatives: using /usr/bin/pip3.4 to provide /usr/bin/pip (pip) in auto mode 개발자 패키지 설치jupyter 등 개발, 서버 개발에 필요한 시스템 개발도구를 설치한다. 1sudo zypper in devel_basis 파이썬 개발과 패키지등에서 필요한 파이썬 헤더를 설치한다. 1sudo zypper in python3-devel python-devel jupyter에서 필요한 zmq 라이브러리를 설치한다. 1sudo zypper in python-distutils-extra libczmq3 libgdal20 libzmq3 : jupyter 에서 필요 libgdal : geospatial analysis with geopandas. openSUSE 에서는 curses 관련 파이썬 모듈을 설치해야 한다. 1sudo zypper in python-curses python3-curses python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 virtualenvpip 로 user scheme 에서 설치했다. 1pip install --user virtualenv virtualenvwrapper Scientific 과 Pandas 개발환경사용하려는 Python 버전에 따라 혹은 모두 아래 과학계산용 모듈을 시스템 패키지로 설치한다. 123sudo zypper in python-decorator python-numpy python-scipy python-matplotlibsudo zypper in python3-decorator python3-numpy python3-scipy python3-matplotlibsudo zypper in python3-sympy python3-nose 라즈베피라이, 오드로이드 등 환경에서 pip로 위 모듈을 설치시 시간이 많이 걸린다. pip install –user pandas decorator numpy scipy matplotlib sympy nose그래서 시스템 패키지로 설치했다. 겨로가적으로 앞선 scipy, matplotlib 설치하며 아래 모듈이 의존성에 따라 함게 설치된다. 1python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj Jupyter NotebookJupyter notebook 으로 파이선, typescript, javascript, c/c++ 등의 IDE 역할을 할 수 있다. 도한 Markdown 을 지원해서 문서화에도 휼륭한 플랫폼이다. jupyter 가상환경 만들기mkvirtualenv 명령으로 jupyter 라는 가상환경을 만드는데, 과학계산용 라이브러리를 시스템 패키지로 설치했으므로 여기서는 가상환경 생성시 시스템 패키지를 함께 참조하도록 생성한다. 12mkvirtualenv -p python3 --system-site-packages jupyter(jupyter) $ 가상환경에서 파이썬 버전을 확인하고 과학계산 개발 등에 필요한 라이브러리가 설치됐는지 확인하자. 12(jupyter) $ python --versionPython 3.4.6 필수 모듈이 설치되고 사용이 가능한지 확인한다. 버전 정보가 출력되면 관련 라이브러리가 제대로 설치되었고 가상환경에서 잘 접근되는 것이다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 설치가 안되었으면 앞의 파이썬 개발자 패키지 설치 단락을 확인한다. 12python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3 12python -c &quot;import numpy;print(numpy.__version__)&quot;0.16.0 그리고 Jupyter 가상환경에서 pip 로 Jupyter를 설치한다. 1(jupyter)$ pip install jupyter 주피커 노트북 파일이 저장되는 위치가 iPython 디렉토리라고 하면 아래 같이 시작할 수 있다. 1(jupyter)$ jupyter-notebook --no-browser --ip=* --port=8000 ./iPython 옵션은 --no-browser : 로컬 브라우저는 시작하지 않는다. --ip : 접속 가능 *는 모든 곳에서 접근 가능 --port: 이런 시작 구성을 설정 파일을 이용해서 저장할 수 있고 이 파일을 이용해서 시작하는 것을 권장한다. Jupyter 설정 파일 이용사용자 JUPYTER_DATA_DIR 인 홈 디렉토리 밑 ~/.jupyter 에 설정 파일을 구성해야 한다. 12(jupyter)$ jupyter notebook --generate-config(jupyter)$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py systemdjupyter notebook을 시스템 서비스로 등록해 보자. jupyter.service라는 시스템 서비스 파일을 /etc/systemd/system/jupyter.service 에 생성하고 아래 내용을 입력한다. 123456789101112131415[Unit]Description=HomePi Jupyter-Notebook[Service]Type=simplePIDFile=/run/homepi-jupyter.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mybook_config.pyUser=qkbooGroup=usersWorkingDirectory=/home/foo/iPythonRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 이 시스템 서비스 파이을 활성화하고 시작한다. 123sudo systemctl enable jupyter.servicesudo systemctl daemon-reloadsudo systemctl restart jupyter.service Typescript kerneljupyter notebook에서 Typescript 을 작성하고 컴파일한 결과를 확인할 수 있다. 먼저 Nodejs용 itypescript 모듈을 global로 설치한다. 1npm install -g itypescript its 명령으로 Jupyter kenel로 설치해 준다. 1its --ts-install=local Jupyter-notebook Nginx 설정Jupyter-notebook 을 nginx 뒤에서 실행시 아래 같은 동작이 반복적으로 보이이면 123456[I 19:26:48.843 NotebookApp] Adapting to protocol v5.1 for kernel 97e659cd-0509-4f56-878e-10e2c31803e2[I 19:26:48.853 NotebookApp] Restoring connection for 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1[I 19:26:48.881 NotebookApp] Starting buffering for 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1[I 19:26:51.904 NotebookApp] Adapting to protocol v5.1 for kernel 97e659cd-0509-4f56-878e-10e2c31803e2[W 19:26:51.930 NotebookApp] Replacing stale connection: 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1[W 19:26:51.957 NotebookApp] Replacing stale connection: 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1 jupyter-notebook-keeps-reconnecting 설명 처럼 nginx proxy 에서 http 버전을 명시해 준다. If you are using jupyter behind a nginx proxy, this post may be effective. Add this line to nginx conf. 1proxy_http_version 1.1; http_proxy_module 에 따르면 keepalive 를 사용하기 위해서 1.1 버전을 꼭 사용해야 할 것 같다. Sets the HTTP protocol version for proxying. By default, version 1.0 is used. Version 1.1 is recommended for use with keepalive connections and NTLM authentication. 참조용 jupyter-notebook conf 123456789101112131415161718192021222324252627282930313233343536373839upstream my-notebook-workhorse { server 127.0.0.1:8888 fail_timeout=0;}map $http_upgrade $connection_upgrade { default upgrade; '' close;}# let my-notebook deal with the redirectionserver { listen 80; server_name my-notebook.wh; server_tokens off; root /dev/null; # Increase this if you want to upload larger attachments client_max_body_size 20m; # individual nginx logs for this vhost access_log /var/log/nginx/my-notebook_access.log; error_log /var/log/nginx/my-notebook_error.log; location / { proxy_pass http://my-notebook-workhorse; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; auth_basic &quot;Restricted Content&quot;; # WebSocket support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_set_header Origin &quot;&quot;; proxy_read_timeout 86400; }} 참조 How to deploy nodejs app with pm2","link":"/2017/10/21/raspberrypi-opensuse-jeos-nginxjupyter/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Basic Security","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 3개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.3 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x openSUSE: Basic OS Security for Server이전 글에서 라즈베리파이 3에 설치한 64bit OS openSUSE LEAP / JeOS를 서버 구성을 위해서 보안 설정을 한다. 이 글은 다음 세가지 내용을 포함하고 있다. ssh와 sshd 설정 방화벽 설정: YaST Firewall 대비 ufw 설치 Fail2ban 설치 및 설정 sshd_configssh 사용시 sshd securities 방화벽 설정openSUSE 42.3까지 SuSEfirewall2 가 기본으로 제공되어 서비스를 활성화 하면 사용할 수 있다. UFWSuSEFirewall2 을 우분투/데비안에서 익숙한 ufw 를 사용할 수 있다. 1234567891011121314151617181920Basic Syntax: yast2 firewall interactive yast2 firewall &lt;command&gt; [verbose] [options] yast2 firewall help yast2 firewall longhelp yast2 firewall xmlhelp yast2 firewall &lt;command&gt; helpCommands: broadcast Broadcast packet settings disable Disables firewall enable Enables firewall interfaces Network interfaces configuration logging Logging settings masqredirect Redirect requests to masqueraded IP masquerade Masquerading settings services Allowed services, ports, and protocols startup Start-up settings summary Firewall configuration summary zones Known firewall zones 먼저 SuSEfirewall2 를 멈추고 비활성화 한다. 1sudo yast firewall disable 12systemctl stop SuSEfirewall2systemctl disable SuSEfirewall2 그리고 ufw를 설치하고 1zypper in ufw 1234ufw default denyufw enablesystemctl enable ufwsystemctl start ufw Fail2banrsyslog 를 설치한다. https://en.opensuse.org/SDB:SSH_systematic_attack_protection https://www.howtoforge.com/fail2ban_opensuse10.3 zypper in fail2ban 참조OpenSSH Public Key Authentication https://doc.opensuse.org/documentation/leap/security/html/book.security/cha.security.firewall.html","link":"/2017/10/21/raspberrypi-opensuse-jeos-securities/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 4개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.2 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x MongoDB Community Edition 설치Opensuse 용 MongoDB가 제공되지만 AMD64, X64 관련한 플랫폼에 지원될 뿐이다. Raspberry Pi 3에 JeOS를 설치하고 네이티브로 빌드해보기로 했다. 준비MongoDB 빌드를 위해서 git, gcc 등, Scons 가 필요하다. 컴파일 환경 준비최신 master branch는, 최신 C++11 compiler: VS2015 Update 2 or newer GCC 5.3.0 Clang 3.4 (or Apple XCode 5.1.1 Clang) or newer Python 2.7 SCons 2.3.5 or newer (for MSVC 2015 support) branch 3.2, 3.0 는 C++11 compiler: VS2013 Update 4 or newer. Note that VS2015 is currently not compatible with the 3.0 and 3.2 branches. You must use VS2013. GCC 4.8.2 or newer. Note that versions of GCC newer than 4.8.2 may produce warnings when building these branches, which are promoted to errors. Please use the –disable-warnings-as-errors build option if necessary to allow the build to succeed despite the warnings. Python 2.7 SCons 2.3.0 or newer 필요한 패키지여기서는 터미널에서 openSUSE yast 사용해 관련 패키지를 설치한다. yast를 시작한다.YaST -&gt; Software -&gt; Software Management 를 선택한다. ![][/images/opensuse/yast-sw2.png] gccgcc 을 선택한다. gcc를 선택하면 gcc-4.8 을 기본으로 설치한다. ![][/images/opensuse/yast-sw-gcc.png] 여러 버전을 설치하면 gcc 를 선택하기 위해 update-alternatives을 사용한다. 링크 update-alternatives 에서 설명을 볼 수 있다. 1234$ sudo update-alternatives --install /usr/bin/gcc gcc \\/usr/bin/gcc-4.8 10 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8$ sudo update-alternatives --install /usr/bin/gcc gcc \\/usr/bin/gcc-6 30 --slave /usr/bin/g++ g++ /usr/bin/g++-6 python검색어에 다음 패키지를 넣고 찾아 하나씩 + 키로 패키지를 선택한다. 1git python python-pip python-devel python3 python3-pip python3-devel Search Phrase에 다음 패키지를 찾아 개발관련 라이브러리를 설치한다. 12build-essential libboost-filesystem-dev libboost-program-options-dev libboost-system-dev libboost-thread-dev -y yast-sw-devel_basis 패키지를 찾아 설치한다. {:width=”640”} Search Phrase 에 gcc 를 넣고 적절한 버전을 선택한다. {:width=”640”} 그리고 Action 탭에서 설치를 실행한다. {:width=”640”} ssl 지원을 위해서 Debian과 Ubuntu systems에서 SSL 지원을 위해서 libssl-dev 가 필요하다. 1sudo zypper install libopenssl-devel 기념사진우분투/데비안 계열에 익숙해 있다가 Raspberry Pi 3 에 openSUSE 를 개발자용 패키지들을 설치하고, 맘 먹고 빌드를 시작해서 9일이 걸렸다. 9일 동안 꿋꿋이 버텨준 Raspberry Pi 3/openSUSE machine!!! {:width=”550”} 참조[^1]: Mongodb on Raspberry pi","link":"/2017/10/30/raspberrypi-opensuse-jeos-mongodb/"},{"title":"Raspberry Pi 3 64bit OS openSUSE LEAP 15: Install","text":"2017-10-30: swap 추가, timezone 수정{:.right-history} Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 이글은 5개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Install 64bit openSUSE Leap 42.2 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter openSUSE: Build MongoDB 3.4.x Install 64bit openSUSE Leap 42.2 / JeOSopenSUSE는 Raspberry Pi 3를 위한 Opensuse community edition은 정식 버전 Leap 42.2 image, 개발버전 Tumbleweed image, 커뮤니티버전 non-upstream openSUSE Tumbleweed image* 으로 구성되어 있다. 이들 버전은 용도에 따라 JeOS, E20, LXQT X11 이미지로 다운받을 수 있다. Just Enought Operating System (JeOS) jeOS 이미지는 기본 오에스만을 포함하고 있다. https://www.suse.com/products/server/jeos/ E20 데스크탑 환경으로 Enlightenment 을 사용하 GUI 이미지 LXQt LXDE-Qt 와 RazorQt 병합한 데스크탑 환경 https://en.opensuse.org/LXQt ### Download and Install Download Page 의 두번째 Installing the 64-bit openSUSE Leap image 단락에 있는 JeOS image 를 다운로드 한다. Writing image to SD CardEtcher 등을 이용해서 다운받은 이미지 파일을 SD Card에 쓴다. {:width=”640”} dd 를 사용한다면,다운받은 .xz 파일을 dd 를 이용해서 SD Card에 쓴다. 1xzcat openSUSE-Leap42.2-ARM-JeOS-raspberrypi3.aarch64.raw.xz | sudo dd of=/dev/rdisk1 bs=4m; sync #### Serial console 여기서는 Serial console에서 네트워크 확인 및 초기 설정을 하고 ssh 로 서버에 로그인해서 시스템 구성을 진행한다. SD Card를 라즈베리파이에 꽃고 HDMI, Keyboard 및 Mouse 가 별도로 준비되어 있으면 직접 모니터를 보고 작업을 진행하면 좋다. USB to Serial 케이블을 사용해서 Raspberry Pi의 Serial Console에 연결한다. {:width=”640”} 그리고 시리얼 포트를 통해 tty 연결을 위해 터미널 프로그램에서 baud rate 115200 으로 연결한다. 아래는 macOS의 screen CLI 명령으로 usb serial 포트에 연결하고 있다. 1$ screen /dev/cu.usbserial 115200 이제 SD Card를 넣고 부팅을 하면, 터미널에 부트 단계가 진행되고 처음 5분 정도 소요된다. {:width=”640”} Raspberry Pi를 위한 이미지는 처음 계정은 root/linux 이다. 터미널에서 uname 은 aarch64 임을 확인 할 수 있다. 12root# uname -aLinux homepi 4.4.90-18.32-default #1 SMP Fri Oct 6 13:30:08 UTC 2017 (465b410) aarch64 aarch64 aarch64 GNU/Linux 처음으로 라즈베리파이에서 64bit 환경으로 운영해 볼 수 있게 됐다. ### 설치 후 서버 구성을 위해 할 일 JeOS를 서버로 구성하기 위해서 다음 같은 작업을 수행해 준다. root 패스워드 변경 sudoer 사용자 생성 DHCP를 고정 IP로 변경 root 패스워드root 사용자의 패스워드를 변경한다. {:width=”640”} UpdateUbuntu/Debian 계열의 패키지 명령 apt,apt-get 과 비슷한 openSUSE 명령라인 패키지 관리자는 zypper 가 있다. 123456789zypper help search # to print help for the search commandzypper refresh, ref # Refresh all repositories.zypper update, up # to update all installed packageszypper lp # to see what patch updates are neededzypper patch # to apply the needed patcheszypper se sqlite # to search for sqlitezypper rm sqlite2 # to remove sqlite2zypper in sqlite3 # to install sqlite3zypper in yast* # to install all packages matching 'yast*' zypper usages 에서 사용방법을 자세히 알 수 있다. 머저 최신 소프트웨어 목록으로 업데이트 한다. 12zypper refreshzypper ref 그리고 최근 업그레이드된 필요한 패키지를 다운로드하고 설치한다.[^1] 12zypper updatezypper up 지원중단된 패키지, 나뉘어진 패키지 등의 의존성을 고려한 업그레이드를 하려면 dup 명령을 사용한다.&gt; 12zypper dup # distribution upgradezypper dist-upgrade upgrade 후에실행중인 데몬을 재시작해줄 필요가 있는데 zypper ps -s 를 실행하면 목록을 표시해 준다. 1234567891011121314151617181920212223242526272829303132333435pi64:/home/ # zypper ps -sThe following running processes use deleted files:PID | PPID | UID | User | Command | Service------+-------+------+------------+----------------------------+-------------------307 | 1 | 0 | root | systemd-journald (deleted) | systemd-journald484 | 1 | 0 | root | auditd | auditd502 | 1 | 1000 | qkboo | python3 | jupyter513 | 1 | 499 | messagebus | dbus-daemon (deleted) | dbus525 | 1 | 0 | root | systemd-logind (deleted) | systemd-logind529 | 1 | 0 | root | agetty (deleted) | getty@tty1996 | 1 | 0 | root | cupsd | cups1018 | 1 | 0 | root | cron | cron1043 | 1 | 74 | ntp | ntpd | ntpd1047 | 1043 | 74 | ntp | ntpd | ntpd1145 | 1 | 0 | root | python2.7 | fail2ban1146 | 1 | 1000 | qkboo | node | pm2-qkboo2131 | 1 | 0 | root | agetty (deleted) | serial-getty@ttyS05716 | 1146 | 1000 | qkboo | node | pm2-qkboo5749 | 1146 | 1000 | qkboo | node | pm2-qkboo12400 | 1 | 0 | root | sshd (deleted) |12402 | 1 | 1000 | qkboo | systemd (deleted) |12405 | 0 | 1000 | qkboo | systemd (deleted) |12411 | 12400 | 1000 | qkboo | sshd (deleted) |12412 | 12411 | 1000 | qkboo | bash |12783 | 12412 | 0 | root | sudo |12784 | 12783 | 0 | root | bash |12876 | 1 | 0 | root | nginx | nginx12879 | 12876 | 494 | nginx | nginx | nginx12880 | 12876 | 494 | nginx | nginx | nginx12881 | 12876 | 494 | nginx | nginx | nginx12882 | 12876 | 494 | nginx | nginx | nginx15908 | 502 | 1000 | qkboo | node | jupyter15916 | 15908 | 1000 | qkboo | node | jupyter26929 | 502 | 1000 | qkboo | node | jupyter ip 주소 확인ifconfig 명령으로 현재 IP Address를 확인하고 이 IP Address에 ssh 를 사용해 접속한다. 1234567891011linux:~ # ifconfigeth0 Link encap:Ethernet HWaddr B9:40:EB:BA:10:02 inet addr:192.168.1.104 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe90::ba37:ebff:feba:1012/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:83136 errors:0 dropped:0 overruns:0 frame:0 TX packets:27300 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:120797947 (115.2 Mb) TX bytes:2369690 (2.2 Mb)linux:~ #linux:~ # shutdown now 좀더 편리한 사용을 위해 ifconfig 명령으로 찾은 IP address에 ssh 로그인을 해서 작업을 진행한다. 1$ ssh root@192.168.1.104 ### 시스템 설정 이제 sudoer 사용자로 시스템을 서버에 적합하게 구성해 보자. sudoer 추가 yast 소개 timezone Network 구성: 호스트 이름, IP 주소 swap 개선 yast로 사용자 추가 sudoerroot 사용자가 아닌 일반사용자를 sudoer로 등록해 관리자 기능을 대행 할 수 있다. 그러기 위해서 먼저 사용자를 추가한다. openSUSE yast라는 시스템 도구로 할 수 있지만 여기선 useradd 명령을 사용해서 사용자 추가한다. useradd에 대해서는 useradd 명령을 참조한다. useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. 추가한 사용자를 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 추가 그리고 -m 옵션으로 으로 사용자 홈 디렉토리 까지 생성한다. 1root# useradd -m foo 그리고 패스워드를 등록한다. 1234root# passwd fooNew password:Retype new password:passwd: password updated successfully sudoer 등록visudo 명령으로 /etc/sudoers 파일을 편집한다. 1$ sudo visudo sudoer 파일에 있는 User privilege 항목 아래에 새로운 사용자 foo를 아래 같이 등록한다. 123# User privilege specificationroot ALL=(ALL) ALLfoo ALL=(ALL) ALL 이제 root에서 로그아웃하고 새로 추가한 사용자로 로그인한다. 1234$ ssh foo@192.168.1.104Password:Have a lot of fun...foo@linux:~&gt; openSUSE는 관리자용 명령을 직접 내리면 찾지 못한다고 한다. 12foo@linux:~&gt; yast2 timezone-bash: yast2: command not found 그리고 처음으로 sudoer 사용자가 관리자 권한이 필요한 명령을 사용하기 위해 sudu 로 명령을 내리면 아래 같은 경고가 나온다. 12345678foo@linux:~&gt; sudo /sbin/yast2 timezoneWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. openSUSE는 시스템 관리 도구로 yast 를 사용해서 소프트웨어 설치, 네트워크 구성, 시간 관리, 보안 및 사용자 등을 다루는 소프트웨어로 GUI와 CLI 모두 사용할 수 있다. 시스템 네트워크를 구성하기 위해서 yast 명령을 사용해보자, yastyast는 GUI 혹은 ClI에서 사용이 가능하다 . 다음은 sudo yast 를 실행하면 Ncurse 로 표시되는 yast 화면이다. {:width=”640”} TAB 키로 각 항목을 이동할 수 있고, Enter로 실행한다. 전체 화면에서 F9는 Cancel, F10은 OK 기능을 수행한다. Timezone처음 설치후 CET 시간대로 되어 있어서 Asia/Seoul로 변경하고자 한다. 12linux:~ # dateSun Oct 29 09:19:31 CET 2017 시스템 시간대를 설정하려면 yast 를 시작해 System -&gt; Date and Time 을 실행해 시간대를 지정한다. 혹은 yast timezone 모듈 명령을 주면 해당 Date and Time 화면으로 이동할 수 있다. {:width=”640”} 시간대를 변경후 확인해 보면, 12linux:~ # dateSun Oct 29 17:22:11 KST 2017 ntp로 동기화하려면 Other Settings… 항목을 선택해 ntp server 를 설치하고 활성화 한다. {:width=”640”}{:width=”640”}","link":"/2017/07/14/raspberrypi-opensuse-leap15-install/"},{"title":"Getting Started &#96;firewalld&#96;","text":"RedHat, CentOS, Fedora 배포본 등에서 표준 방화벽 인터페이스로 제공되는 최신 FirewallD 사용을 시작해 보자. firewalld 패키지 설치는 각 배포본의 방법으로 설치하면 된다. 여기서는 OpenSUSE, Armbian 배포본을 설치한 시스템에서 firewalld 방화벽을 구성하고 설정하는 과정을 요약 정리했다. Getting Started - FirewallDsudo systemctl enable firewalldsudo reboot We can verify that the service is running and reachable by typing: sudo firewall-cmd –state firewalld는 Zone 을 기반으로 서비스, 포트, IP 주소 등을 다양한 규칙으로 혼합해 사용할 수 있다. 기본으로 지원하는 zone은 다음 같다. 12$ sudo firewall-cmd --get-zonesblock dmz drop external home internal public trusted work 그리고 permanent로 활성화된 Zone은 12345$ sudo firewall-cmd --get-active-zonesdrop sources: ipset:blacklisttrusted sources: 192.168.0.0/24 220.121.170.0/24 Public Zone에 Http, Ssh 서비스http, https 를 공개 서비스를 지원하는 기본 public zone에 추가한다. 123$ sudo firewall-cmd --add-service=ssh$ sudo firewall-cmd --add-service=http$ sudo firewall-cmd --add-service=https 혹은 zone을 지정해서 서비스를 추가할 수 있다. 123$ sudo firewall-cmd --zone=public --add-service=ssh$ sudo firewall-cmd --zone=public --add-service=http$ sudo firewall-cmd --zone=public --add-service=https 1$ sudo firewall-cmd --zone=public --remove-service=ssh public zone에 대한 정보를 출력한다. 1234567891011121314$ sudo firewall-cmd --list-allpublic target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Trusted Zone 관리1$ sudo firewall-cmd --zone=trusted --add-service=ssh trusted zone의 IP 범위를 소스로 지정할 수 있다. 12$ sudo firewall-cmd --zone=trusted --add-service=dns$ sudo firewall-cmd --zone=trusted --add-source=192.168.1.0/24 1firewall-cmd --zone=zone-name --remove-source=&lt;source&gt; Trusted Zone의 정보를 출력한다. 1$ sudo firewall-cmd --zone=trusted --list-all Port포트에 따라 는 프로토콜을 지정해 줄 수 있다. 지정되지 않으면 기본 TCP 포트가 구성된다. 1firewall-cmd --remove-port=port-number/port-type 대체 http 포트인 8080을 추가해 보자. 1sudo firewall-cmd --zone=public --add-port=8080/tcp mongodb 같은 내부 데이터베이스 포트를 trusted zone에 추가해 준다. 1sudo firewall-cmd --zone=trusted --add-port=27017/tcp 포트 범위를 지정해 구성할 수 있다. 1sudo firewall-cmd --zone=public --add-port=4990-4999/udp 포트를 제거할 수 있다. 1sudo firewall-cmd --zone=zone-name --remove-source-port=&lt;port-name&gt;/&lt;tcp|udp|sctp|dccp&gt; Zone에 구성된 포트 정보를 출력할 수 있다. 12sudo firewall-cmd --zone=public --list-portssudo firewall-cmd --zone=trusted --list-ports 여기까지 firewall-cmd 로 설정한 내용은 실행중(런타임) 방화벽으로 구성되어 사용된다. 재시동 등의 이벤트가 발생하면 내용이 사라지게 된다. 영구적으로 보존하기 위해서는 --permanent 옵션을 사용해야 한다. PermenentZone 에 구성한 서비스, 포트, 소스, 프로토콜 등에 대한 설정을 영구적으로 보존해려면 --permanent 옵션을 사용해야 한다. 영구적인 구성을 설정을 보존하려면 아래 두가지 방법을 사용한다. 먼저 firewall-cmd 로 실행중 제한 내용을 구성하고, --runtime-to-permanent 를 실행해 준다. 1firewall-cmd --runtime-to-permanent 다른 방법을 firewall-cmd 에 --permanent 옵션을 주고 실행하면 영구 보존되어 저장된다. 1firewall-cmd --permanent &lt;other options&gt; reload방화벽을 갱신한다 1234firewall-cmd --reloadfirewall-cmd --statefirewall-cmd --list-all #publicfirewall-cmd --permanent --list-all #permanent 참조Firewalld configuration and usage RedHat: Getting started with firewalld How to set up firewalld on CentOS 7","link":"/2018/07/14/raspberrypi-opensuse-firewalld-start/"},{"title":"Raspberry Pi : Install Raspbian","text":"Install Rasbperry Pi OS 글타래는 아래 같이 구성되며 OS 설치, Service 구성 및 사용에 대해 작성한다. Raspberry Pi 설치준비 Install Raspbian OS Managing Service daemon Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter 2017-10-30: swap 추가, timezone 수정{:.right-history} Install Raspbian OSRaspberry Pi(라즈베리파이)에 Raspbian, Ubuntu 등을 설치하고 Serial Console 을 이용해서, 라즈베리파이를 처음 설정하고 SSH 구성을 활성화 하겠다. 라즈베리파이에 OS를 설치하기 위해서는 NOOBS를 사용하거나 오에스 이미지를 다운받아 SD Card에 구워서 사용한다. 라즈베리파이는 다음과 같은 OS 배포본을 사용할 수 있다. 운영체제 특징 Raspbian (Debian) Raspberry Pi + Debian의 합성어, 가장 범용 OS. Arch Linux (A non-Linux Distribution) ARM 프로세서를 지원하는 Arch Linux RISC OS ARM 프로세서를 위한 실시가(RTOS) 운영체제 OpenElec XBMC 미디어 센터 지원을 위한 운영체제 RaspBMC XBMC 미디어 센터 지원을 위한 운영체제 Pidora Pi + Fedora 운영체제 **Raspbian(라즈비안)**은 라즈베리파이를 위한 데비안 리눅스로 가장 대중적인 데비안 리눅스, 우분투와 같은 사용자 경험을 제공해 주고 있다. Raspberry Pi 준비설치에 앞서 준비해야 할 것 이 있습니다. Raspberry Pi 1, 2, 3 OS 설치 SD Memory Card: 8GB 이상, Class6 이상 USB to Serial Cable SDCard에 대해라즈베리파이는 SD 호환 카드에서 작동하도록 되어 있다. NOOBS를 이용한다면 최소 8GB 다른 버전은 최소 4GB Class 4는 4MB/s 쓰기 속도, Class 10은 10MB/s 쓰기가 가능하지만 Class 10이 Class 4를 앞선다는 것을 보장하진 않는다. 라즈베리파이는 Class 6의 8GB 사용을 권장하고 있다. Mac: SDCardFormatter SDCard 사용시 주의 정품 SD Card 사용을 권장 전원은 품질이 좋아야. 라즈베리파이 보드의 TP1, TP2 전력을 측정해서 4.75v 이하면 품질이 좋은 전원으로 바꾸길. 더불어 좋은 품질의 USB 케이블을 사용해야 한다. 종료시 sudo halt 를 이용하도록 오버클록은 지양하도록 ### Download and Install OS 설치와 서비스 설치는 크게 아래 과정을 거친다. (1). Download OS Image, Etcher, sdFormatter (2). OS image 파일을 SD Card에 쓴다. SD Card로 부팅후에 (1). 모니터 혹은 시리얼 콘솔에서 raspi-conifg 로 시스템 구성을 마무리 (2). 서비스 설치 (1). Download OS Image, Etcher, sdFormatter라즈베리안 OS를 다운로드, Raspberry Pi Raspbian Download 링크에서 다운 받을 수 있다. 토렌트와 zip 형식으로 다운 받을 수 있습니다. 다운로드된 파일은 yyyy-mm-dd-raspbian-wheezy.zip 형식으로 다운로드가 된다. 디스크 이미지 파일 yyyy-mm-dd-raspbian-wheezy.img 이 zip으로 압축되어 있는데,이 이미지 파일을 SD Card에 복사해야 한다. 디스크 이미지를 쓰기위한 프로그램으로 오에스 이미지를 SD Card, Disk 등에 쓴다. 보통 아래 프로그램을 이용한다. Windows : Win32DiskImager Linux: ImageWriter macOS: dd 명령 모든 플랫폼: Etcher SD Memory Card Formatter 5.0 for SD/SDHC/SDXC 이 글에서는 디스크 이미지 쓰기Etcher 프로그램을 이용해서 오에스 이미지 파일을 SD Card에 쓰겠다. macOS, Windows, Linux 지원 여기까지 필요한 준비 사항은: Raspbian OS Image SD Card Formatter OS image 파일을 SD Card 쓰기Etcher를 실행하고 {:width=”640”} dd 를 사용한다면,다운받은 .zip 파일을 unzip으로 풀어 dd`로 SD Card에 이미지를 쓴다. 1unzip -p 2017-06-21-raspbian-stretch-lite.zip | sudo dd of=/dev/rdisk1 bs=4M; sync MacOS는 dd의 bs 옵션이 소문자로 받는다: bs=4m 다쓴 SD Card를 마운트 한다. ssh 활성화Raspbian 2016-11-25일 릴리즈 이후 기본으로 ssh가 비활성화 되어 있다. 그래서 처음 부팅후 ssh 접속이 필요하다면 부트 파티션에 ssh 파일을 생성해 주면된다. 12$ cd /boot$ touch ssh #### Serial console 여기서는 Serial console에서 네트워크 확인 및 초기 설정을 하고 ssh 로 서버에 로그인해서 시스템 구성을 진행한다. SD Card를 라즈베리파이에 꽃고 HDMI, Keyboard 및 Mouse 가 별도로 준비되어 있으면 직접 모니터를 보고 작업을 진행하면 좋다. USB to Serial 케이블을 사용해서 Raspberry Pi의 Serial Console에 연결한다. {:width=”640”} 그리고 시리얼 포트를 통해 tty 연결을 위해 터미널 프로그램에서 baud rate 115200 으로 연결한다. 아래는 macOS의 screen CLI 명령으로 usb serial 포트에 연결하고 있다. 1$ screen /dev/cu.usbserial 115200 이제 SD Card를 넣고 부팅을 하면, 터미널에 부트 단계가 진행되고 처음 5분 정도 소요된다. {:width=”640”} Raspberry Pi를 위한 이미지는 처음 계정은 root/linux 이다. 터미널에서 uname 은 aarch64 임을 확인 할 수 있다. 12root# uname -aLinux homepi 4.4.90-18.32-default #1 SMP Fri Oct 6 13:30:08 UTC 2017 (465b410) aarch64 aarch64 aarch64 GNU/Linux 처음으로 라즈베리파이에서 64bit 환경으로 운영해 볼 수 있게 됐다. Raspbian OS Image 복사맥/리눅스에서 dd 명령을 이용해서 이미지를 복사할 수 있습니다. sudo dd bs=1m if=path_of_your_image.img of=/dev/diskn bs: 한번에 읽어들일 사이즈를 의미 마지막 옵션인 ‘diskn’의 n은 SD Card의 번호로 SDCard Formater에서 기억하란 번호입니다. 여기서 번호가 2로 가정합니다.그리고 Mac OSX는 디스크가 /dev 경로에 두 가지 종류가 있습니다. /dev/disk# 버퍼 디바이스로 데이터가 부가적인 처리를 통해 사용합니다. /dev/rdisk# 저수준 경로로 빠르고 dd 명령을 사용할 때 완벽합니다. Class 4 SD card는 rdisk 경로를 사용할 때 20배 빠릅니다. 먼저 포맷터로 포맷한 디스크 마운트를 해제합니다. 맥의 디스크유틸리티를 이용해서 마운트를 해제합니다. 이미지가 있는 곳에서 dd 명령으로 라즈비안을 복사합니다.3.2GB 크기를 복사해서 9분~15분 정도의 시간이 소요됩니다. zip 압축 파일을 입력으로 다음 같이 dd 명령으로 sd card에 쓴다. 1$ unzip -p 2016-05-27-raspbian-jessie.zip | sudo dd of=/dev/rdisk1 bs=1m 압축을 푼후 1234567$sudo dd bs=1m if=2015-02-16-raspbian-wheezy.img of=/dev/rdisk23125+0 records in3125+0 records out3276800000 bytes transferred in 551.608702 secs (5940443 bytes/sec) rdisk 이용시 에러가 발생하면 disk를 사용합니다. 다음 링크에 설명한 방법을 바탕으로 설명해보겠습니다.참조: http://elinux.org/RPi_Easy_SD_Card_Setup Mac diskutil 과 dd 이용diskutil로 디스크 목록 확인해 SD카드 번호 확인 1diskutil list 1diskutil unmountDisk /dev/disk1 이미지 쓰기 1$ sudo dd bs=1m if=image.img of=/dev/rdisk[n] conv=noerror,sync 위 명령으로도 ‘Permission Denied’ 가 나오면, 이것은 SD 카드의 파티션 테이블이 덮어쓰기를 막고 있다는 의미로 이 경우 파티션 테이블을 제거해야 한다. 다음 같이 zero로 SDCard를 덮어쓰면 all partitions, master boot records, and data를 지운다. 진행 상황을 보려면 status=progress 로 알 수 있다. 1$ sudo dd bs=1m if=image.img of=/dev/rdisk[n] conv=noerror,sync status=progress SD card를 포맷하려면 1$sudo dd if=/dev/zero of=/dev/rdisk1 bs=4k count=1 bs: 한번에 읽어들일 byte를 의미 count: block 수 입니다. 혹은 랜덤 데이터로 지우려면 1$dd if=/dev/urandom of=/dev/sda bs=4k Mac의 diskutil을 사용하면 1sudo diskutil partitionDisk /dev/disk3 1 MBR &quot;Free Space&quot; &quot;%noformat%&quot; 100% 다운로드한 이미지는 zip 압축 파일로 저장된다. 다음 같이 명령 파이프를 이용하면 압축 파일을 풀지않고 디스크에 이미지를 쓸 수 있다. 123$ unzip -p 2016-09-23-raspbian-jessie.zip* | sudo dd of=/dev/rdisk1 bs=4mpassword: **** 이미지를 dd 명령으로 작성한 후에 카드를 추출한다: 1sudo diskutil eject /dev/rdisk3 https://www.raspberrypi.org/documentation/installation/installing-images/mac.md clone disk1$ sudo dd if=/dev/diskX conv=sync,noerror bs=4m | gzip -c &gt; /path/to/backup.img.gz 반대로 디스크를 디스크이미지로 만들려면 다음 같이 dd 를 사용할 수 있습니다.쓰기 전에 sd card의 마운트한 파티션을 마운트를 해제해야 합니다. $sudo dd bs=1m if=2015-02-16-raspbian-wheezy.img of=/dev/rdisk2 SDFormatter 이용SDCard Formatter 를 이용해서 SD Card를 포맷할 수 있습니다. 윈도우즈, 리눅스 및 맥을 지원합니다. https://www.sdcard.org/downloads/formatter_4/ 오에스에 맞는 버전을 다운로드하고 실행하면 설치를 합니다. SD Card를 컴퓨터에 삽입합니다. SDFormatter를 실행하고 다음 화면 처럼 SD card를 포맷할 수 있습니다. SDFormatter 라는 프로그램을 설치하여, 옵션의 FORMAT SIZE ADJUSTMENT 설정을 ON 으로 하여 SD카드를 포맷 SDCard Formatter에서 디스크 선택시 디스크 번호를 잘 기억해 두세요. 윈도우즈에서 라즈비안 복사하기윈도우XP/7/8 에서 다운로드한 라즈비안 OS를 SD카드로 복사하겠습니다. 아래 링크에서 ‘Win32 Disk Imager’를 다운받아 사용해야 합니다. Win32 Disk Imager win32diskimager를 실행하고 다운받은 ‘2015-03-15-raspbian-wheezy.zip’ 파일을 선택하고 SD카드 위치를 선택해 주면 됩니다. 그리고 Write버튼을 눌러주고 기다리면 복사를 시작합니다. 부팅IP 강제 지정CD Card를 마운트 하면 boot 파티션이 마운트 된다. boot 파티션에 있는 cmdline.txt 에 ip= 옵션을 추가해 강제로 IP 주소를 지정할 수 있다. 1dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline rootwait **ip=192.168.0.203** Serial Console Raspbian 은 boot 파티션에 있는 cmdline.txt 옵션으로 기본적으로 serial console을 사용하도록 하고 있다. 1dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline rootwait Mac Serial보통 FTDI USB 케이브을 다음 두 제품이 대부분이다. Prolific PL2303: PL2303 MacOSX FTDI USB Serial: FTDIUSBSerialDriver_v2_3.zip macOS Maverick 이후 FTDI 드라이버가 포함되어 있다.혹시 새 버전을 설치하거나 이전 버전이 설치되어 삭제하려면 [^6] 123$ cd /Library/Extensions/$ sudo rm -r PL2303.kext$ sudo rm -r ProlificUsbSerial.kext FTDI 케이블을 사용한다고 가정하고 맥에 USB to Serial 케이블을 연결하면 /dev 장치에 cu., tty. 장치 드라이버가 생성된다. 두 장치는 다른 점이 있다.[^5] /dev/tty.* 장치는 DCD (data-carrier-detect) 신호를 대기한다, 이것은 누군가 호출해 온다는 의미이다. /dev/cu.* 장치는 DCD를 추정하지 않고 항상 즉시 연결한다(응답 혹은 성공) FTDI 로 시리얼을 사용시는 cu. 장치를 사용하면 된다. 일반적으로 screenMac에서 screen 사용시 1screen /dev/cu.usbserial-XXXXXXXX 115200 시리얼 터미널에서 빠져나오려면 ‘ctrl-a, ctrl-' 를 순서데로 입력 Linux Serial terminalLinux machine에서 Usb to serial 케이블을 사용할 수 있는지 콘솔 메시지에서 Serial console이 있는 지 확인한다. 12345$ dmesg | egrep --color 'serial'[ 1969.914088] usbcore: registered new interface driver usbserial[ 1969.914139] usbcore: registered new interface driver usbserial_generic[ 1969.914175] usbserial: USB Serial support registered for generic[ 1969.918325] usbserial: USB Serial support registered for pl2303 장치 드라이버는 보통 /dev/ttyUSB0 장치로 연결된다. 12$ ls /dev/ttyUSB*/dev/ttyUSB0 dtermdtermAUR is a tiny serial communication program. If you invoke it without parameters, it will connect to /dev/ttyS0 at 9600 baud by default. The following example connect to /dev/ttyS0 at 115200 baud, with 8 data bits, no parity bit and 1 stop bit-times: 1$ dterm 115200 8 n 1 See its homepage[1] for more examples. Minicomminicom can be obtained from the official repositories. Start Minicom in setup mode: 1$ minicom -s Using the textual navigation menu, change the serial port settings to the following: 12Serial Device: /dev/ttyS0Bps/Par/Bits: 9600 8N1 Press Enter to exit the menus (pressing Esc will not save changes). Remove the modem Init and Reset strings, as we are not connecting to a modem. To do this, under the Modem and Dialing menu, delete the Init and Reset strings. Optionally save the configuration by choosing save setup as dfl from the main menu. Restart minicom with the serial cable connected to the target machine. To end the session, press Ctrl+A followed by Ctrl+X. picocompicocom is a tiny dumb-terminal emulation program that is very like minicom, but instead of mini, it is pico. The following example connect to ttyS0 at 9600 bps: 1$ picocom -b 9600 /dev/ttyS0 Note: if the backspace key won’t work properly try out this option: ‘–omap delbs’See its manual for detailed usage. Screenscreen is able to connect to a serial port. It will connect at 9600 baud by default: 1$ screen /dev/ttyS0 115200 To end the session, press Ctrl+a followed by k. 여러 사용자로 열려면 -R 옵션을 주고 다시 연다 1screen -R /dev/tty.usbserial-XXXXXXXX 115200 screen 명령 사용중 어떤 상황에서 세션이 멈춘 경우 종료 명령이 안된다. 이 경우 screen 세션을 찾고 가제 종료를 시도해 본다. Type screen -list to identify the detached screen session. 1234~$ screen -list There are screens on: 20751.Melvin_Peter_V42 (Detached)Note: 20751.Melvin_Peter_V42 is your session id. Get attached to the detached screen sessionscreen -r 20751.Melvin_Peter_V42Once connected to the session press Ctrl + A then type :quit Attached session 종료 1234$ screen -lsThere is a screen on: 2667.ttys003.gogangtaeui-MacBook-Pro (Attached)1 Socket in /var/folders/02/4qk5tfw527b9zqx92gtv4m980000gn/T/.screen. screen -S sessionname -p 0 -X quit 참고http://www.mostlynetworks.com/2014/11/os-x-yosemite-prolific-usb-drivers/http://www.mostlynetworks.com/2015/01/fixing-prolific-driver-os-x/https://wiki.archlinux.org/index.php/disk_cloning Archlinux-Working with serial console [^5]: Mac tty[^6]: Uninstall PL-2303 on macOS X","link":"/2018/06/22/raspberrypi-raspbian-2-os-install/"},{"title":"Raspberry Pi : Raspbian 설치준비","text":"이 글은 Raspberry Pi Programming 과정을 진행하며 강의한 자료를 바탕으로 공개강의를 위한 텍스트로 슬라이드쉐어, blog.thinkbee.kr 그리고 실제 과정을 영상 youtube 채널에 공개할 목적으로 작성한다. Install Rasbperry Pi 글타래는 아래 같이 구성되며 간단한 소개, Serial console, OS 설치, Service 구성 및 사용에 대해 작성했다. Raspberry Pi 설치준비 Install Raspbian OS Managing Service daemon Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter 2017-10-30: swap 추가, timezone 수정{:.right-history} Raspbery Pi OS 설치준비*Raspberry Pi(라즈베리파이)*에 Serial Console 을 연결하고, Raspbian, Ubuntu 등을 설치한 후에 라즈베리파이를 처음 설정하고 SSH 구성을 활성화 하겠다. 라즈베리파이에 OS를 설치하기 위해서는 NOOBS를 사용하거나 오에스 이미지를 다운받아 SD Card에 구워서 사용한다. 라즈베리파이는 다음과 같은 OS 배포본을 사용할 수 있다. 운영체제 특징 Raspbian (Debian) Raspberry Pi + Debian의 합성어, 가장 범용 OS. Arch Linux (A non-Linux Distribution) ARM 프로세서를 지원하는 Arch Linux RISC OS ARM 프로세서를 위한 실시가(RTOS) 운영체제 OpenElec XBMC 미디어 센터 지원을 위한 운영체제 RaspBMC XBMC 미디어 센터 지원을 위한 운영체제 Pidora Pi + Fedora 운영체제 **Raspbian(라즈비안)**은 라즈베리파이를 위한 데비안 리눅스로 가장 대중적인 데비안 리눅스, 우분투와 같은 사용자 경험을 제공해 주고 있다. Raspberry Pi 설치 준비Raspberry Pi의 GPIO에 배치된 UART Rx, Tx 포트와 시리얼 케이블의 Tx, Rx로 크로스 연결하면 시리얼 콘솔로 작동한다. 설치에 앞서 준비해야 할 것이 있다. Raspberry Pi 1, 2, 3 SD Memory Card: 8GB 이상, Class6 이상 USB to Serial Cable Raspberry PiRaspberry Pi의 GPIO에 배치된 UART Rx, Tx 포트와 시리얼 케이블의 Tx, Rx로 크로스 연결하면 시리얼 콘솔로 작동한다. {:with=”500”} SD Memory Card라즈베리파이는 SD Meory Card 카드에서 부팅 및 운영 하도록 되어 있다. NOOBS를 이용한다면 최소 8GB 다른 버전은 최소 4GB Class 4는 4MB/s 쓰기 속도, Class 10은 10MB/s 쓰기가 가능하지만 Class 10이 Class 4를 앞선다는 것을 보장하진 않는다. 라즈베리파이는 Class 6의 8GB 사용을 권장하고 있다. 그림. SDCardFormatter PCIe 지원 SD Card 규격 7.0 USB to Serial CableUSB 주변기기가 대중화 되면 컴퓨터에 Serial port가 사라진 후에 USB to TTL 혹은 USB to Serial 로 Serial 케이블을 사용해야 한다. 구글 검색을 해보면 DB-9 포트 형태, 보드 형태 및 Raspberry Pi 같은 SBC 보드의 GPIO 포트에 사용하기 좋은 Adarfruit 판매하는 핀 형태의 제품도 있다. {: width=”600” } 그림.USB to Serial Cable(구글 이미지 검색 캡쳐)","link":"/2018/06/22/raspberrypi-raspbian-1-prepare/"},{"title":"SD Card 포맷 및 디스크 이미지 사용하기","text":"SBC, PC 등의 머신에서 SD Card 사용에 필요한 사항을 정리했다. 2018-08-30: 전체 내용 편집2017-10-30: swap 추가, timezone 수정{:.right-history} ## SD Card 와 디스크 이미지 사용하기 SD Card는 Secure Digital의 약자로 Flash memory(비휘발성) 카드 포맷이다. 자세한 내용은 Wikipedia: SD Card 를 확인하자. SD Card format Windows Disk Utility를 이용한다. SD Association의 SD Formatter 를 이용한다. macOS Diskutility 앱을 이용한다. SD Association의 SD Formatter 를 이용한다. Linux fdisk, parted 명령으로 포맷할 수 있다. dd 명령으로 macOSmacOS는 Disk Utility 프로그램을 명령줄에서 diskutil 명령으로 디스크에 대한 파티션, 포맷 및 점검을 할 수 있다. GUI 윈도우를 제공하지만 명령줄에서 diskutil 명령으로 파티션, 마운트 및 포맷을 할 수 있다. 명령줄에서 diskutil 명령으로 목록과 파티션 마운트를 해제하고 123$ diskutil list$ diskutil unmountDisk /dev/diskX 역시 dd 명령을 이용해 /dev/zero, /dev/urandom 을 디스크 전체에 써서 지울 수 있다. 1$ sudo dd if=/dev/urandom of=/dev/diskX bs=1000000 디스크 파티션은 partitionDisk 를 사용해서 파티션할 수 있다. 1$ sudo diskutil partitionDisk &lt;Disk&gt; GPT| FAT|exFAT|JHFS+ NAME SIZE SIZE: 0b 전체. zeros$ diskutil reformat /dev/rdisk3 LinuxUbuntu 등은 SD Card 슬롯에 삽입된 장치는 /dev/mmcblkX 같이 장치 이름을 붙인다. USB Stick 으로 SD Card 혹은 Micro SD Card를 사용하면 /dev/sdX 디스크 이름을 사용한다. lsblk 명령은 디바이스 장치가 마운트 된 곳을 출력해 준다. 123456789$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 119.2G 0 disk├─sda1 8:1 0 84.5G 0 part└─sda6 8:6 0 28.9G 0 part /mmcblk0 179:0 0 7.5G 0 disk├─mmcblk0p2 179:2 0 6.8G 0 part /media/qkboo/ROOT├─mmcblk0p3 179:3 0 486.1M 0 part└─mmcblk0p1 179:1 0 200M 0 part /media/qkboo/EFI 파티션 및 포맷을 위해 마운트된 파티션을 언마운트 한다. 12$ sudo umount /dev/mmcblk0p2$ sudo umount /dev/mmcblk0p1 parted 유틸리티로 파티션을 삭제, 생성할 수 있다. 다음은 명령라인에서 옵션을 주어 사용하는 방법이다 123$ sudo parted /dev/mmcblk0 rm 1$ sudo parted /dev/mmcblk0 rm 2$ sudo parted /dev/sdc mkpart primary ext3 4MiB 100% 결과로 mmcblk0 디스크 드라이브에 mmcblk0p1 파티션이 생성된다. 다음은 위와 같은 내용으로 fat32 파티션을 parted 를 Shell로 사용하는 예이다. 12345sudo parted /dev/mmcblk0(parted) mklabel msdos(parted) mkpart primary fat32 1MiB 100%(parted) set 1 boot on(parted) quit 마지막으로 파티션을 파일시스템으로 포맷해 준다. 1$ sudo mkfs -V -t vfat /dev/mmcblk0p1 역시 dd 명령을 이용해 /dev/zero, /dev/urandom 을 디스크 전체에 써서 지울 수 있다. 1$ sudo dd if=/dev/zero of=/dev/diskX bs=4M Disk cloneLinux, macOS 에서 파티션 도구, dd 를 사용해서 디스크 전체, 혹은 파티션을 이미지로 추출해 생성하는 과정을 정리했다. dd 이용하기dd 로 디스크의 전체를 이미지 파일로 생성할 수 있다. 다만 디스크 전체 섹터를 추출하므로 디스크 용량과 같은 크기를 가진 이미지 파일이 생성된다. 1dd bs=4M if=/dev/sdX of=image.gz conv=fsync Ubuntu gparted우분투 Live CD에서 gparted는 가능한 사용하지 않는 공간은 빼고 최소 크기로 줄여 줄 수 있다. 압축 이용하기전체 디스크 크기의 이미지 파일이 너무 크면, 압축유틸리티를 이용해 저장할 수 있다. 12dd bs=4M count=&lt;size_in_MBs&gt; if=/dev/sdX | gzip -c --fast| dd of=image.gzdd bs=4M count=&lt;size_in_MBs&gt; if=/dev/sdX | xz -c --fast| dd of=image.xz 반대로 압축한 이미지 파일을 디스크로 복원하기 위해서 unzip, gunzip, xz -d 압축을 해제한 결과를 파이프로 dd로 전달한다. 12dd if=/path/to/image.gz | gunzip -c | dd bs=1M of=/dev/sdYdd if=/path/to/image.xz | xzcat | dd bs=1M of=/dev/sdY macOS의 Disk Utility 이용GUI인 Disk Utility에서 SD Card 디스크를 선택하고 macOS의 .dmg 이미지 파일로 저장할 수 있고, 저장시 압축 선택이 가능하다. ### Disk Image를 SD Card에 쓰기 각 OS에서 dd 같은 Disk clone 도구를 사용해서 디스크 이미지를 SD Card에 쓸 수 있다. Etcher모든 OS 플랫폼을 지원하는 Etcher 사용을 권장한다. Etcher 을 다운받아 이미지 파일 선택해 대상 SD Card 에 GUI로 쓸 수 있다. {:width=”640”} dd를 사용한다면 이러지는 macOS, Linux 섹션을 참조한다. dd로 이미지 쓰기디스크 내용을 dd 명령으로 디스크 이미지 형태로 저장할 수 있다. 1$ sudo dd if=opensuse_jeos-20171030.img of=/dev/mmcblk0 bs=4m 압축 이미지로 제공하는 이미지 파일은 zcat, xzcat, gzcat 같은 표출 출력 유틸리티를 사용해, dd 명령에 파이프로 처리할 수 있다. 1$ xzcat openSUSE-Leap42.2-ARM-JeOS-raspberrypi3.aarch64.raw.xz | sudo dd of=/dev/rdisk1 bs=4m; sync 이제 이미지 SD Card를 보드에 넣고 부팅한 후 시스템 설정을 시작하면 된다. 시스템 구성을 하고, 여러 설정을 한 후 백업, 복사 등을 위해, 설정한 OS 를 디스크 이미지로 복제하는 경우가 많아 이때는 dd 명령을 사용할 수 있다. ### 이미지 파일 다루기 백업한 디스크 이미지 파티션을 확인하고 폴더에 마운트해서 내용을 확인할 할 수 있다. 이미지 파일의 파티션 정보를 fdisk, parted 명령으로 확인할 수 있다. fdisk 이용123456789101112$ fdisk -lu opensuse-e20.imgDisk opensuse-e20.img: 14.9 GiB, 16022241280 bytes, 31293440 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0xe0e3966bDevice Boot Start End Sectors Size Id Typeopensuse-e20.img1 2048 411651 409604 200M c W95 FAT32 (LBA)opensuse-e20.img2 413696 30282525 29868830 14.2G 83 Linuxopensuse-e20.img3 30283776 31278554 994779 485.7M 82 Linux swap / Solaris parted 이용123456789101112131415$ parted opensuse-42.3-homepi_16GB-firewalld.imgGNU Parted 3.2Using opensuse-42.3-homepi_16GB-firewalld.imgWelcome to GNU Parted! Type 'help' to view a list of commands.(parted) pModel: (file)Disk opensuse-42.3-homepi_16GB-firewalld.img: 16.0GBSector size (logical/physical): 512B/512BPartition Table: msdosDisk Flags:Number Start End Size Type File system Flags 1 1049kB 211MB 210MB primary fat16 lba 2 212MB 15.5GB 15.3GB primary ext4 3 15.5GB 16.0GB 509MB primary linux-swap(v1) Byte 단위로 보려면 1234567(parted) unitUnit? [compact]? B(parted) pNumber Start End Size Type File system Flags 1 1048576B 210765823B 209717248B primary fat16 lba 2 211812352B 15504653311B 15292840960B primary ext4 3 15505293312B 16014620159B 509326848B primary linux-swap(v1) 이미지 마운트디스크 이미지는 리눅스에서 mount 명령으로 마운트 할 수 있다. mount 명령으로 실제 파티션이 시작하는 위치를 offset으로 지정해서 마운트 한다. 앞서 사용한 opensuse-42.3-homepi_16GB.img 이미지의 파티션 정보가 다음 같다고 하자. 1234Number Start End Size Type File system Flags 1 1048576B 210765823B 209717248B primary fat16 lba 2 211812352B 15504653311B 15292840960B primary ext4 3 15505293312B 16014620159B 509326848B primary linux-swap(v1) 첫번째 파티션 시작 위치 1048576B 를 오프셋으로 삼아서 root 권한으로 mount 명령을 사용한다. 섹터 정보를 Byte 단위로 변경하려면, 파티션 정보에서 1 sector 크기가 512 를 확인하고, 이미피 파일의 파티션 시작 섹터를 곱해서 offset 범위를 계산한다. 1Sector size * Start = (in the case) 512 * 8192 = 4194304 (Byte) 이제 마운트 명령 mount -o loop,ro,offset 옵션을 주고, boot와 ROOT 파티션을 마운트 해보자, Now we have the offsets and we can use those to mount the filesystems using the loopback device: 12$ sudo mount -o loop,ro,offset=1048576 opensuse-42.3-homepi_16GB.img ~/mnt/boot/$ sudo mount -o loop,ro,offset=211812352 opensuse-42.3-homepi_16GB.img ~/mnt/ROOT/ 마운트가 성공하면 df 명령 혹은 mount 명령으로 마운트한 위치를 확인할 수 있다; 12345678910$ df -hFilesystem Size Used Avail Use% Mounted onudev 1.5G 0 1.5G 0% /devtmpfs 300M 5.1M 295M 2% /run/dev/sda6 29G 7.3G 20G 28% /tmpfs 1.5G 188K 1.5G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 1.5G 0 1.5G 0% /sys/fs/cgroup/dev/loop0 200M 4.4M 196M 3% /home/qkboo/mnt/boot/dev/loop1 200M 4.4M 196M 3% /home/qkboo/mnt/ROOT /dev/loop0 파일 시스템이 지정한 마운트 위치에 마운트했다는 것을 알 수 있다. 또한 -t [fs_type] 옵션으로 파티션의 파일 시스템을 명시할 수 있다. 이미지에서 한 파티션만 마운트 하기이미지에 있는 하나의 파티션만 마운트 할 수 있다. [^3] 앞의 이미지 파일 정보를 /dev/loop0 에 offset을 주고 1sudo losetup -o 4194304 /dev/loop0 sda.img Now the partition resides on /dev/loop0. You can fsck it, mount it etc 12sudo fsck -fv /dev/loop0sudo mount /dev/loop0 /mnt Unmount 12sudo umount /mntsudo losetup -d /dev/loop0 Truncate질문, 원래 2GB 데비안 이미지를 16GB SD Card에 썼다. 나머지 14GB 공간을 별도로 파티션 나눌 수 있나? 먼저 이미지 파티션 정보를 얻는다. 123456789$ fdisk -lu image.imgDisk image.img: 4096 MB, 4096000000 bytes, 8000000 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000a1bc7 Device Boot Start End Blocks Id Systemimage.img1 2048 5872026 5869978 b W95 FAT32 이미지 파티션의 끝 부분이 5872026 으로 5872026 * 512 = 2,8Gb 이고, 나머지는 안쓰는 공간이다. truncate 도구로 현재 파티션에서 빈공간을 잘라낸다. 다만 블럭 수가 0에서 시작하므로 섹터 수에 1을 더해준다.[^2] 1$ truncate --size=$[(5872026+1)*512] image.img Repair &amp; Corruption프롬프트에서 다음 명령으로 해당 파티션을 점검한다. 12# fsck -fy /dev/mmcblk0p2# reboo 혹은 다음 부팅시 처리할 수 있도록 한다. 12# touch /forcefsck# reboot Check Bad sector터미널에서 SD Card 삽입/추출 및 점검시 섹터 에러를 확인하기 위해 dmesg 로 감시할 수 있다. 다음 명령은 dmesg 가 발생하면, 내용 중 마지막 15줄을 터미널로 출력해 준다. 1$ watch &quot;dmesg | tail -15&quot; hdparamhdparam 1234$ sudo hdparm -t /dev/mmcblk0/dev/mmcblk0: Timing buffered disk reads: 58 MB in 3.09 seconds = 18.80 MB/sec badblocks1$ sudo badblocks -n -v /dev/mmcblk0 RecoveringGNU ddrescue is a data recovery tool. It copies data from one file or block device (hard disc, cdrom, etc) to another, trying to rescue the good parts first in case of read errors. https://www.gnu.org/software/ddrescue/ 참조[^2]: Truncate free space at disk image[^3]: Mount single partition from image of entire disk(device)","link":"/2016/12/20/raspberrypi-sdcard-usage/"},{"title":"Raspbian Wheezy : Python 설치","text":"Raspbian과 Pythonraspbian-wheezy에는 Python 2.7과 Python 3.2가 설치되어 있습니다. Python tools파이썬으로 개발하며 필요한 도구를 설치해서 사용하면 좋습니다. 파이썬 패키지 관리 도고, 가상 개발 환경 등의 설치를 통해서 APT로 설치라즈비안에서 사용하는 파이썬 패키지들은 apt를 이용해서 라즈비안 저장소의 다양한 패키지를 사용할 수 있습니다. apt로 파이썬 패키지를 설치해 사용할 수 있는데 Python 2.x와 Python 3.x의 호환을 위해서 Python 2.x는 ‘python-‘ 접두어를 사용하고 Python 3.x 패키지들은 ‘python3-‘ 를 사용합니다.예를 들어 picamera 패키지는 python-picamera와 Python 3.x 버전을 위해서 python3-picamera가 있습니다. 사전 준비기본 개발자 모듈이 설치 안되어 있다면 설치한다. 1$ sudo apt install build-essential Python 개발을 위해서는 리눅스에 파이썬 헤더가 필요하다. 그래서 python-dev 패키지를 설치해 준다.Jessie에서 Python3.4 헤더는 설치가 되어 있다. 12$ sudo apt-get install python3-devpython3-dev is already the newest version. python2 개발환경을 위해서 헤더를 설치하려면 1234$ sudo apt install python-devThe following extra packages will be installed: libexpat1-dev libssl-dev libssl-doc python2.7-dev pip전통적인 파이썬 패키지 도구인 PIP(Python Package Index, PyPI)를 이용하면 폭넓게 범위를 넓힐 수 있습니다. Raspbian Jessie : 기본으로 제공apt를 이용해 저장소에 있는 외부 패키지를 설치해 사용할 수 있습니다. 그렇지만 개발에 필요한 모든 패키지가 라즈비안 저장소에 있지 않거나 오래된 버전일 수 있습니다. Python2.x용 pip는 python-pip를 설치하고 Python3.x pip는 python-pip3 를 설치합니다. 12$ sudo apt-get install -y python-pip$ sudo apt-get install -y python3-pip Pip 소스로 설치혹은 pip를 최신 소스로 부터 직접 설치하려면 다음같이 실행합니다. 1$ wget https://bootstrap.pypa.io/get-pip.py 시스템에 설치된 python 버전 마다 sudo로 pip를 설치애야 합니다. Python3 을 위한 pip를 설치한다. 12$ sudo python3 get-pip.pySuccessfully installed pip-8.1.2 setuptools-24.0.3 wheel-0.29.0 다음은 Python2를 위한 pip를 설치합니다. 1$ sudo python2.7 get-pip.py Raspbian에서 사용자 계정에서 pip 설치하면 퍼미션 에러가 발생한다.OSError: [Errno 13] Permission denied: ‘/usr/local/lib/python2.7/dist-packages/pip-7.1.2.dist-info’sudo 명령으로 설치해야 한다. pip 설치 참조https://pip.pypa.io/en/latest/installing.htmlhttp://stackoverflow.com/questions/6587507/how-to-install-pip-with-python-3 슈퍼사용자로 pip 설치시 사용자 계정에서 사용하기 불편한 점이 많다. 그래서 가상 개발환경을 구성해 사용자 계정에서 제약없이 사용하도록 한다. pip 사용pyhthon2, python3 버전이 설치되어서 pip도 역시 해당 버전이 별도로 설치되어 있습니다. 다음 버전 저보를 출력하면 어떤 버전인지 확인이 가능합니다. 1234$ pip3 --versionpip 8.1.2 from /usr/local/lib/python3.5/dist-packages (python 3.5)$ pip2 --versionpip 8.1.2 from /usr/local/lib/python2.7/dist-packages (python 2.7) 특정 파이썬 버전의 패키지 모듈을 설치한다면 해당 pip 버전을 호촐하는게 정확합니다. upgrade pippip 는 다음 같이 업그레이드 해야 합니다. 1$pip install -U pip On Windows [5]: 1$python -m pip install -U pip Python 버전 관리자다양한 파이썬 버전을 위해 환경 구성을 해주는 유틸리티. pyenv : “Simple Python Version Management”, 로컬에 다양한 파이썬 버전을 설치하고 사용할 수 있도록 한다. pyenv를 사용함으로써 파이썬 버전에 대한 의존성을 해결할 수 있다. virtualenv : “Virtual Python Environment builder”, 로컬에 다양한 파이썬 환경을 구축하고 사용할 수 있도록 한다. 일반적으로 Python Packages라고 부르는 ( pip install을 통해서 설치하는 ) 패키지들에 대한 의존성을 해결할 수 있다. virtualenv와 virtualenvwrapper를 사용할 것이다. autoenv : 만약 pyenv와 virtualenv를 통해서 의존성을 해결한다고 하더라도 작업할때마다 설정해주는 것은 귀찮은 작업이다. 특정 프로젝트 폴더로 들어가면 자동으로 개발 환경을 설정해주는 autoenv라는 스크립트를 활용하자. 여기서는 virtualenv를 설치하고 virtualenvwrapper를 사용해서 모듈을 설치하고 관리한다. 그러기 위해서 먼저 시스템의 기본 /usr/bin/python 버전을 확인하고 해당 버전의 pip 모듈을 사용해서 virtualenv 와 virtualenvwrapper 를 설치한다. virtualenvvirtualenv는 가상의 파이썬 작업환경을 만들어 준다. 작업환경을 따로따로 만들어주면 해당 환경 내의 파이썬으로 무슨 짓을 해도 시스템 파이썬이나 다른 가상의 작업환경에게 영향을 주지 않는다.pip로 설치할 수 있습니다. pip는 시스템의 site-packages 폴더에, /usr/lib/python2.7/site-packages에 모듈을 설치한다. virtualenv를 이용하면 분리할 수 있다. 단, 현재 python2.7과 python3.4가 공존하는 상태에서 virtualenv는 python2.x를 기반으로 만들어 져서 /usr/bin/python을 찾는데 그래서 다음 같이 pip2 버전으로 virtualenv를 설치해 준다. 1$ pip install virtualenv virtualenv는 python 버전에 관계 없이 하나만을 설치해 두면 된다. virtualenvwrappervirtualenvwrapper는 virtualenv 통합 환경을 좀 더 쉽게 접근할 수 있도록 도와줍니다. ‘virtualenv’ 가 설치된 글로벌 사이트 패키지 위치에 설치되야 합니다. 아마 관리자 권한이 필요할 것입니다. 라즈비안에서는 sudo로 설치해 주어야 한다. 다름 같이 pip로 설치합니다. 1$ sudo pip install virtualenvwrapper 이제 일반 사용자 환경에서 python 개발환경을 구축해 보자. 셀 환경 구성하기쉘 (.bashrc, .profile, 등)에 다음 라인을 추가합니다. 123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh 그리고 쉘 환경을 로딩하기 위해서 다시 로그인 하거나 다음 같이 source 명령을 이용해도 좋습니다. 12345678910111213141516$ source .profileebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extentpermitted by applicable law.Last login: Fri Oct 23 18:17:41 2015 from 192.168.219.103virtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/get_env_details 다음 에러가 발생하면 쉘에 VIRTUALENVWRAPPER_PYTHON 를 추가해 준다. /usr/bin/python: No module named virtualenvwrappervirtualenvwrapper.sh: There was a problem running the initialization hooks. If Python could not import the module virtualenvwrapper.hook_loader,check that virtualenvwrapper has been installed forVIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is Quick-Start다음 같이 virtualenvwrapper 를 사용할 수 있습니다. workon 명령으로 실행 가상 환경 목록 혹은 변경한다. 1$workon 실행 가상 환경 ‘raspberrypi2’ 생성 1234567891011$ mkvirtualenv -p python2 raspberrypi2New python executable in raspberrypi2/bin/python2.7Also creating executable in raspberrypi2/bin/pythonInstalling setuptools, pip, wheel...done.virtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/get_env_details(raspberrypi2)pi@raspberrypi ~ $ # 실행 가상 환경 쉘 프로젝트 환경을 빠져 나오려면 ‘deactivate’를 실행한다. 1(raspberrypi2):~$ deactivate rpi.gpio1(raspberrypi2)$pip install rpi.gpio 이제 이 디렉토리 밑에서 코드 작업을 하고 사용하면 됩니다. 다른 Python 버전 환경 만들기123456$ mkvirtualenv -p python3 rpi_py3Running virtualenv with interpreter /usr/bin/python3New python executable in rpi_py3/bin/python3Also creating executable in rpi_py3/bin/pythonInstalling setuptools, pip...done.... virtualenv 사용위의 설명과 같이 고립된 작업환경을 만들려면 디렉토리 구조를 잘 구성해야 합니다. 다음 같이 라즈베리파이 프로그램을 작업할 ‘Blinke’ 디렉토리를 만듭니다. Blinken은 LED를 깜박이는 작업을 수행할 것입니다. 1234567$mkdir blinken$cd blinken$virtualenv envNew python executable in env/bin/pythonInstalling setuptools, pip...done.$. env/bin/activate(env)$ 마지막 명령으로 가상환경을 활성화시키면 프롬프트 앞에 (env)가 표시됩니다. 가상환경을 바탕으로 환경 설정이 동작한다는 것을 의미합니다. 이제 필요한 파이썬 패키지 및 프로그램을 설치하고 개발을 할 수 있습니다. 독립된 DJango 환경 이용하기12345$ mkdir django_tests$ cd django_tests$ virtualenv --no-site-packages env$ source env/bin/activate(env)$ 다시 시스템 파이썬으로 복귀하고 싶으면 deactivate를 실행합니다. 1(env)$ deactivate 다른 버전의 Python 환경 만들기1$ sudo python3 get-pip.py python3의 virtualenvwrapper를 설치한다. 123$ sudo pip3 install virtualenvwrapperCollecting virtualenvwrapper Using cached virtualenvwrapper-4.7.1-py2.py3-none-any.whl mkvirtualenv에서 python3의 환경을 하나 설치한.다. 123456$ mkvirtualenv -p python3 rpi_py3Running virtualenv with interpreter /usr/bin/python3New python executable in rpi_py3/bin/python3Also creating executable in rpi_py3/bin/pythonInstalling setuptools, pip...done.... 가상환경 복사하기cpvirtualenv oldenv newenvrmvirtualenv oldenv pyvenv3.3에서부터 pyvenv에 기본으로 설치되어 있다. 다만 3.3에서는 pip를 가상 환경을 만들 때마다 설치해주어야 한다. 3.4에서는 pip까지 기본으로 설치되어 있다. 12345$ mkdir django_tests$ cd django_tests$ pyvenv-3.4 env$ source env/bin/activate # env의 파이썬 활성화(env)$ deactivate # 시스템 파이썬으로 복귀 라즈비안 시스템과 파이썬파이썬을 이용하면 시스템 관련 정보를 활용할 수 있습니다. 라즈페리파이 모델 확인하기cpuinfo를 살펴보면 현재 라즈베리파이 모델을 확인할 수 있습니다. 1234$cat /proc/cpuinfo... Hardware : BCM2708 Revision : 0003 출력 결과에서 Revision을 살펴보면 라즈페리파이 모델을 확인할 수 있습니다. 이 리비전 번호를 다음 링크의 테이블에서 찾아 보면 확인이 가능합니다. http://elinux.org/RPi_HardwareHistory#Board_Revision_History Python으로 오에스 확인하기123456789101112131415$ pythonPython 2.7.3 (default, Mar 18 2014, 05:13:23)&gt;&gt;&gt; import os&gt;&gt;&gt; print os.nameposix&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.platformlinux2&gt;&gt;&gt; import platform&gt;&gt;&gt; platform.system()'Linux'&gt;&gt;&gt; platform.release()'3.18.7+'&gt;&gt;&gt; platform.machine()'armv6l' 참조 RPi HW History Python Library pyenv + virtualenv + autoenv 를 통한 Python 개발 환경 구축하기 Raspberry Pi에서 Python 3.4와 Django 1.7로 프로젝트 셋업하기 Python과 한글 Short Tutorial : Raspbian + Python3.4 + RPi.GPIO","link":"/2017/05/22/raspberrypi-rasbian-wheezy-python-setup/"},{"title":"Rasbian Wheezy 설치후 작업","text":"upgrade1# apt update &amp;&amp; apt dist-upgrade &amp;&amp; apt upgrade 업그레이드 중 1The following packages have been kept back: linux-image-c2 기존 리눅스 이미지를 지우고 업그리이드 중 에러가 나서 이미지 업그레이드가 안되었으므로, 이전 버전 이미지를 찾아 삭제해 주면 다시 업그레이드가 된다. 1234567# apt --installed list |grep linuxlinux-image-3.14.65-73/unknown,now 20160802 arm64 [installed,automatic]linux-image-3.14.79-94/unknown,now 20161121 arm64 [installed,automatic]linux-image-c2/now 73-1 arm64 [installed,upgradable to: 94-1]linux-libc-dev/xenial-updates,xenial-security,now 4.4.0-51.72 arm64 [installed]util-linux/xenial-updates,now 2.27.1-6ubuntu3.1 arm64 [installed] 이전 버전 이미지를 지운다. 업그레이드 후 uname 확인 12345678root@odroid64:~# apt autoremove linux-image-3.14.65-73...Preparing to unpack .../linux-image-c2_94-1_arm64.deb ...Unpacking linux-image-c2 (94-1) over (73-1) ...Setting up linux-image-c2 (94-1) ...# uname -aLinux odroid64 3.14.79-94 #1 SMP PREEMPT Mon Nov 21 17:13:27 BRST 2016 aarch64 aarch64 aarch64 GNU/Linux 설정hostnamedebian 계열에서 hostname을 변경하려면 hostnamectl 을 사용한다. 1234567891011121314$ sudo -s# hostnamectl set-hostname dlp# show settingsroot@debian:~# hostnamectl Static hostname: dlp Icon name: computer-vm Chassis: vm Machine ID: 5f47b11299ed4689a48a7f78197e452a Boot ID: bdeed3b6c079405bb45d79eff3e870a5 Virtualization: vmware Operating System: Debian GNU/Linux 8 (jessie) Kernel: Linux 3.16.0-4-amd64 Architecture: x86-64 TimezoneCLI에서 설정을 할 수 있다. 1# dpkg-reconfigure tzdata timedatectl timedatectl 명령으로 123456$ timedatectl list-timezones...Asia/Seoul...$ sudo timedatectl set-timezone Asia/Seoul 혹은 손으로 직접 수정한다면, Timezone은 /etc/localtime 이라는 바이너리로 저장되므로명령행에서 지원하는 timezone을 복사할 수 도 있다. 1$ sudo cp /usr/share/zoneinfo/Europe/London /etc/localtime 기본 에디터 변경odroid의 ubuntu 16.04는 기본에디터로 joe가 설치되어 있다. vim 으로 변경한다. 1234567891011121314# update-alternatives --config editorThere are 6 choices for the alternative editor (providing /usr/bin/editor). Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/joe 70 auto mode 1 /usr/bin/jmacs 50 manual mode 2 /usr/bin/joe 70 manual mode 3 /usr/bin/jpico 50 manual mode 4 /usr/bin/jstar 50 manual mode 5 /usr/bin/rjoe 25 manual mode 6 /usr/bin/vim.tiny 10 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 6 apt autocompetionbash-completion 이 빠져 있으면 1$ sudo apt install bash-completion apt-get 명령은 자동완성이 되지만 apt 명령은 안된다면 1$ sudo apt install --reinstall bash-completion Dnsutilsdig, nslookup 같은 명령이 있는 패키지. 1$ sudo apt install dnsutils 디스크tune2fsfsck로 마지막 체크한 시간 확인은 tune2fs 명령을 이용 12$sudo tune2fs -l /dev/sdbX | grep Last\\ cLast checked: Sun Dec 13 09:14:22 2015 마운트 횟수 12tune2fs -l /dev/sdbX | grep MountMount count: 157 12tune2fs -l /dev/sdbX | grep MaxMaximum mount count: -1 참조: https://linuxconfig.org/how-to-force-fsck-to-check-filesystem-after-system-reboot-on-linux fsck루트 파티션을 강제로 fsck 하게 하려면 루트 파티션에 forcefsck 파일을 생성해 둔다. 1$sudo touch /forcefsck forcefsck 파일은 단 한번만 부팅시 루트 파일시스템을 체크한다. 만약 지속적으로 파일 시스템을 체크하도록 하려면 tune2fs 를 사용해서 ‘Maximum mount count’ 파라미터를 사용하도록 한다. 아래 명령은 부팅시마다 루트 파티션을 체크하게 된다. 1tune2fs -c 10 /dev/sdb1 이렇게 하면 fsck Maxium mount 값을 양의 값으로 지정하게 된다. 그리고 10번째 부팅시 체크하도록 하려면 -c 10 을 준다. 1tune2fs -c 10 /dev/sdb1 SWAPswap 파일로 만들려면 12345$ sudo dd if=/dev/zero of=/data/swap4G bs=1G count=4sudo chmod 600 /swapfilesudo mkswap /swapfilesudo swapon /swapfilesudo swapon -s 123sudo mkswap /dev/sda1sudo swapon /dev/sda1sudo swapon -s grc터미널 컬러 처리 https://github.com/garabik/grc 1234grc netstatgrc ping hostnamegrc tail /var/log/sysloggrc ps aux lastblastb 명령은 /var/log/wtmp, /var/log/btmp 에 있는 로그인 기록에서 최근 로그인한 모든 목록을 출력한다. 다음은 최근 20개 목록을 출력한다. 12345$ sudo lastb -n 20root ssh:notty 112.85.42.230 Fri Jul 20 17:25 - 17:25 (00:00)root ssh:notty 112.85.42.230 Fri Jul 20 17:25 - 17:25 (00:00)oracle ssh:notty 210.182.116.102 Mon Jul 16 23:36 - 23:36 (00:00)cumulus ssh:notty 36.248.211.16 Mon Jul 16 20:59 - 20:59 (00:00) 실패한 로그인 시도https://www.guyrutenberg.com/2014/09/26/view-failed-login-attempts-lastb/ -w 로 사용자 이름을 출력하고 첫번째 열만 자른 후 정렬한 후, uniq 명령으로 중복되는 이름을 제거한 후 출력한다. 1$ sudo lastb -w | cut -d &quot; &quot; -f 1 | sort | uniq | less 이중에서 접속한 IP와 횟수를 출력한다. 12345678$ sudo lastb -f /var/log/btmp.1 -w -i | awk '{print $3}' | sort | uniq --count | sort -nr | less[sudo] root의 암호: 2166 112.85.42.156 1945 112.85.42.193 1591 112.85.42.201 1327 112.85.42.230 1146 112.85.42.196 기본 Python 만들기사용자 파이썬 앨리어스 만들기사용자 홈 디렉토리에 ~/.bashrc 파일에 앨리어스를 만든다. 1alias python='/usr/bin/python3.4' 다시 로그인 하거나 .bashrc를 컴파일해서 사용한다. 1$ . ~/.bashrc 시스템 전체로 파이썬 구성하기12$ update-alternatives --list pythonupdate-alternatives: error: no alternatives for python 여기서 python2.7과 python3.5 를 update-alternative 로 1$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1 12$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2update-alternatives: using /usr/bin/python3.4 to provide /usr/bin/python (python) in auto mode 파이썬 관련 대체 프로그램 목록을 보면, 123$ update-alternatives --list python/usr/bin/python2.7/usr/bin/python3.5 삭제를 하려면 1$sudo update-alternatives --remove python /usr/bin/python2.7","link":"/2017/04/02/raspberrypi-raspbian-wheezy-after-install/"}],"tags":[{"name":"nodejs tutorials","slug":"nodejs-tutorials","link":"/tags/nodejs-tutorials/"},{"name":"nvm","slug":"nvm","link":"/tags/nvm/"},{"name":"nodejs","slug":"nodejs","link":"/tags/nodejs/"},{"name":"mongodb","slug":"mongodb","link":"/tags/mongodb/"},{"name":"mongoose","slug":"mongoose","link":"/tags/mongoose/"},{"name":"TypeScript Tutorials","slug":"TypeScript-Tutorials","link":"/tags/TypeScript-Tutorials/"},{"name":"TypeScript","slug":"TypeScript","link":"/tags/TypeScript/"},{"name":"angular4","slug":"angular4","link":"/tags/angular4/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"middleware","slug":"middleware","link":"/tags/middleware/"},{"name":"웹토큰","slug":"웹토큰","link":"/tags/%EC%9B%B9%ED%86%A0%ED%81%B0/"},{"name":"JWT Toekn","slug":"JWT-Toekn","link":"/tags/JWT-Toekn/"},{"name":"JSON Web Token","slug":"JSON-Web-Token","link":"/tags/JSON-Web-Token/"},{"name":"debian","slug":"debian","link":"/tags/debian/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"odroid","slug":"odroid","link":"/tags/odroid/"},{"name":"armbian","slug":"armbian","link":"/tags/armbian/"},{"name":"raspberry pi","slug":"raspberry-pi","link":"/tags/raspberry-pi/"},{"name":"라즈베리파이","slug":"라즈베리파이","link":"/tags/%EB%9D%BC%EC%A6%88%EB%B2%A0%EB%A6%AC%ED%8C%8C%EC%9D%B4/"},{"name":"orange pi","slug":"orange-pi","link":"/tags/orange-pi/"},{"name":"오렌지파이","slug":"오렌지파이","link":"/tags/%EC%98%A4%EB%A0%8C%EC%A7%80%ED%8C%8C%EC%9D%B4/"},{"name":"banana pi","slug":"banana-pi","link":"/tags/banana-pi/"},{"name":"바나나파이","slug":"바나나파이","link":"/tags/%EB%B0%94%EB%82%98%EB%82%98%ED%8C%8C%EC%9D%B4/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"X11","slug":"X11","link":"/tags/X11/"},{"name":"install","slug":"install","link":"/tags/install/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Debian","slug":"Debian","link":"/tags/Debian/"},{"name":"Debian Strech","slug":"Debian-Strech","link":"/tags/Debian-Strech/"},{"name":"lvm","slug":"lvm","link":"/tags/lvm/"},{"name":"lvm2","slug":"lvm2","link":"/tags/lvm2/"},{"name":"Odroid","slug":"Odroid","link":"/tags/Odroid/"},{"name":"Odroid C2","slug":"Odroid-C2","link":"/tags/Odroid-C2/"},{"name":"firewall","slug":"firewall","link":"/tags/firewall/"},{"name":"security","slug":"security","link":"/tags/security/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"webdav","slug":"webdav","link":"/tags/webdav/"},{"name":"certificate ssl","slug":"certificate-ssl","link":"/tags/certificate-ssl/"},{"name":"odroid-c2","slug":"odroid-c2","link":"/tags/odroid-c2/"},{"name":"arm64","slug":"arm64","link":"/tags/arm64/"},{"name":"amd64","slug":"amd64","link":"/tags/amd64/"},{"name":"우분투","slug":"우분투","link":"/tags/%EC%9A%B0%EB%B6%84%ED%88%AC/"},{"name":"리눅스","slug":"리눅스","link":"/tags/%EB%A6%AC%EB%88%85%EC%8A%A4/"},{"name":"cross compiler","slug":"cross-compiler","link":"/tags/cross-compiler/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/tags/Raspberry-Pi/"},{"name":"Orange Pi","slug":"Orange-Pi","link":"/tags/Orange-Pi/"},{"name":"ARM","slug":"ARM","link":"/tags/ARM/"},{"name":"데비안","slug":"데비안","link":"/tags/%EB%8D%B0%EB%B9%84%EC%95%88/"},{"name":"tmux","slug":"tmux","link":"/tags/tmux/"},{"name":"terminal","slug":"terminal","link":"/tags/terminal/"},{"name":"synergy","slug":"synergy","link":"/tags/synergy/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"apache","slug":"apache","link":"/tags/apache/"},{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","link":"/tags/Artificial-Intelligence/"},{"name":"인공지능","slug":"인공지능","link":"/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"},{"name":"TensorFlow","slug":"TensorFlow","link":"/tags/TensorFlow/"},{"name":"angularjs","slug":"angularjs","link":"/tags/angularjs/"},{"name":"unit testing","slug":"unit-testing","link":"/tags/unit-testing/"},{"name":"karma","slug":"karma","link":"/tags/karma/"},{"name":"jasmine","slug":"jasmine","link":"/tags/jasmine/"},{"name":"jekyll","slug":"jekyll","link":"/tags/jekyll/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"bootstrap 4","slug":"bootstrap-4","link":"/tags/bootstrap-4/"},{"name":"brew","slug":"brew","link":"/tags/brew/"},{"name":"macos","slug":"macos","link":"/tags/macos/"},{"name":"맥오에스","slug":"맥오에스","link":"/tags/%EB%A7%A5%EC%98%A4%EC%97%90%EC%8A%A4/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"마크다운","slug":"마크다운","link":"/tags/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4/"},{"name":"photoshop","slug":"photoshop","link":"/tags/photoshop/"},{"name":"clipping-mask","slug":"clipping-mask","link":"/tags/clipping-mask/"},{"name":"collages","slug":"collages","link":"/tags/collages/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"virtualenv","slug":"virtualenv","link":"/tags/virtualenv/"},{"name":"virtualenvwrapper","slug":"virtualenvwrapper","link":"/tags/virtualenvwrapper/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"jupyter","slug":"jupyter","link":"/tags/jupyter/"},{"name":"jupyter-notebook","slug":"jupyter-notebook","link":"/tags/jupyter-notebook/"},{"name":"파이썬","slug":"파이썬","link":"/tags/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"opensuse","slug":"opensuse","link":"/tags/opensuse/"},{"name":"leap 42.3","slug":"leap-42-3","link":"/tags/leap-42-3/"},{"name":"leap 15","slug":"leap-15","link":"/tags/leap-15/"},{"name":"odroid c2","slug":"odroid-c2","link":"/tags/odroid-c2/"},{"name":"Scientific","slug":"Scientific","link":"/tags/Scientific/"},{"name":"Numpy","slug":"Numpy","link":"/tags/Numpy/"},{"name":"opensuse leap 15","slug":"opensuse-leap-15","link":"/tags/opensuse-leap-15/"},{"name":"Raspberry Pi 3","slug":"Raspberry-Pi-3","link":"/tags/Raspberry-Pi-3/"},{"name":"Raspbian","slug":"Raspbian","link":"/tags/Raspbian/"},{"name":"라즈비안","slug":"라즈비안","link":"/tags/%EB%9D%BC%EC%A6%88%EB%B9%84%EC%95%88/"},{"name":"openSUSE","slug":"openSUSE","link":"/tags/openSUSE/"},{"name":"LEAP 15.0","slug":"LEAP-15-0","link":"/tags/LEAP-15-0/"},{"name":"LEAP 42.3","slug":"LEAP-42-3","link":"/tags/LEAP-42-3/"},{"name":"SD Card","slug":"SD-Card","link":"/tags/SD-Card/"},{"name":"micro SD Card","slug":"micro-SD-Card","link":"/tags/micro-SD-Card/"},{"name":"jupyter notebook","slug":"jupyter-notebook","link":"/tags/jupyter-notebook/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"Armbian","slug":"Armbian","link":"/tags/Armbian/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"firewalld","slug":"firewalld","link":"/tags/firewalld/"},{"name":"방화벽","slug":"방화벽","link":"/tags/%EB%B0%A9%ED%99%94%EB%B2%BD/"},{"name":"파이어월","slug":"파이어월","link":"/tags/%ED%8C%8C%EC%9D%B4%EC%96%B4%EC%9B%94/"},{"name":"Coordinate System","slug":"Coordinate-System","link":"/tags/Coordinate-System/"},{"name":"Cartesian Coordinate","slug":"Cartesian-Coordinate","link":"/tags/Cartesian-Coordinate/"},{"name":"Polar Coordinate","slug":"Polar-Coordinate","link":"/tags/Polar-Coordinate/"},{"name":"전원관리","slug":"전원관리","link":"/tags/%EC%A0%84%EC%9B%90%EA%B4%80%EB%A6%AC/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Springboot","slug":"Springboot","link":"/tags/Springboot/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"yarn","slug":"yarn","link":"/tags/yarn/"},{"name":"Naver","slug":"Naver","link":"/tags/Naver/"},{"name":"Ncloud","slug":"Ncloud","link":"/tags/Ncloud/"},{"name":"ffmpeg","slug":"ffmpeg","link":"/tags/ffmpeg/"},{"name":"content","slug":"content","link":"/tags/content/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"formatting","slug":"formatting","link":"/tags/formatting/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"markup","slug":"markup","link":"/tags/markup/"},{"name":"Firewall","slug":"Firewall","link":"/tags/Firewall/"},{"name":"fail2ban","slug":"fail2ban","link":"/tags/fail2ban/"},{"name":"Security","slug":"Security","link":"/tags/Security/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Raspbian Wheezy","slug":"Raspbian-Wheezy","link":"/tags/Raspbian-Wheezy/"}],"categories":[{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"Angularjs","slug":"Programming/Angularjs","link":"/categories/Programming/Angularjs/"},{"name":"jekyll","slug":"jekyll","link":"/categories/jekyll/"},{"name":"Photoshop","slug":"Photoshop","link":"/categories/Photoshop/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/categories/Raspberry-Pi/"},{"name":"Database","slug":"Database","link":"/categories/Database/"},{"name":"OS","slug":"OS","link":"/categories/OS/"},{"name":"Python","slug":"Python","link":"/categories/Python/"}]}