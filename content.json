{"posts":[{"title":"hexo 의 icarus theme 수정하기","text":"git 으로 clone 한 icarus theme 를 사용하고 있다. bulma.io https://bulma.io/ inferno https://github.com/ppoffice/hexo-component-inferno layout 관련기본 레이아웃은 layout.jsx 이다.과련해서 bulma 의 CSS 정의를 살펴보면 도움이 된다. Bulma sizes: https://bulma.io/documentation/columns/sizes/ https://www.geeksforgeeks.org/bulma-different-column-sizes-per-breakpoint/?ref=ml_lbp 컬럼 수에 따른 조절…icarus/layout/layout.jsx 에서 컬럼수로 폭을 조절하는 것을 상대적으로 정해주니 좀 더 시원해 졌다. 123456789101112&lt;div class=&quot;columns&quot;&gt; &lt;div class={classname({ column: true, 'order-2': true, 'column-main': true, 'is-four-fifths': columnCount === 1, //'is-12': columnCount === 1, 'is-four-fifths-tablet is-four-fifths-desktop is-four-fifths-widescreen': columnCount === 2, 'is-three-quarters-tablet is-three-quarters-desktop is-three-quarters-widescreen': columnCount === 3 //'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2, //'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3 })} dangerouslySetInnerHTML={{ __html: body }}&gt;&lt;/div&gt; style 관련responsive.styl화면 폭 수정 themes/icarus/include/style/responsive.styl Javascript code determines the page width. 1234+fullhd() .is-2-column .container max-width: $widescreen - 1 * $gap width: $widescreen - 1 * $gap style.styl전체 스타일 시트는 themes/icarus/source/css/style.styl 에서 외부 .styl 을 import 해서 적용했다. 변경을 위해서 themes/my_icarus_custom 이란 폴더를 만들어 사용한다. 12345hexo ROOT/ |----- themes | |----- icarus/ |----- my_icarus_custom/ 배경이미지 적용 themes/icarus/source/css/style.styl 파일에 다음을 적용 12// my custums@import '../../../my_icarus_custom/bg' 배경 이미지는 hexo/source/images/ 아래에 저장했다. my_icarus_custom/bg.styl 파일에 CSS 스타일 작성 1234567body { background-image: url(&quot;/images/vlcsnap-2023-05-16-14h44m58s614.png&quot;); background-size: cover; background-repeat: no-repeat; background-attachment: fixed; background-position: 50% 50%;}","link":"/hexo_modification1-c48faa364a6a/"},{"title":"MySQL&#x2F;MariaDB Server SSH Over Tunneling","text":"클라이언트에서 원격 서버 MySQL DB server 접속시 SSH turnneling 을 이용할 수 있다. ssh tunneling 이해 SSHTunnelForwarder 클래스 HeidiSQL ssh tunnel 사용 ssh tnnneling 이해비 암호화된 통신을 지원하는 원격 프로그램이 암호화된 통신을 지원하는 ssh 를 사용해서 원격지에 접속이 가능하게 한다. 직접 TLS/SSL 구현을 하지 않더라도 SSL 로 암호화된 통신 채널을 통해 안전하게 프로그램을 사용할 수 있다. 터널링은 아래 같이 SSH 서버를 통해서 원격지에서 SSH 통신을 지원한다. 링크 참고2 의 그림 MySQL client 에서 Database server 포트 3306으로 직접 접속하지 않고 ssh 를 이용해 원격 서버에 연결하고 원격 서버 내부에서 mysql server 에 접속해 사용하게 해준다. SSHTunnelForwarder 이용 tunneling 사용sshtunnel 모듈이 필요하다. 123&gt; pip install pymysql&gt; pip install sshtunnel&gt; pip install paramiko 시나리오다음 2개의 시나리오는 참조 링크 3 의 공식문서에 있는 내용이다. 사례1) 사용자가 8080 웹 서비스에 연결할 필요가 있을 때 22번 포트로만 연결가능할 때 1234567891011---------------------------------------------------------------------- |-------------+ | +----------+ LOCAL | | | REMOTE | :22 SSH CLIENT | &lt;== SSH ========&gt; | SERVER | :8080 web service-------------+ | +----------+ | FIREWALL (only port 22 is open)---------------------------------------------------------------------- 사례2) SSH server 가 허용하는 경우. 1234567891011---------------------------------------------------------------------- |-------------+ | +----------+ +--------- LOCAL | | | REMOTE | | PRIVATE CLIENT | &lt;== SSH ========&gt; | SERVER | &lt;== local ==&gt; | SERVER-------------+ | +----------+ +--------- | FIREWALL (only port 443 is open)---------------------------------------------------------------------- DB접속 정보sshtunnel 패키지를 사용한다. DB 접속 정보를 외부 json 파일에서 얻어온다고 가정한다. 1234567891011121314151617import jsonfrom pathlib import Pathimport sqlalchemy as sqlafrom sqlalchemy import textimport pymysqlimport pandas as pdimport numpy as npROOT_PATH = Path.home()with open( ROOT_PATH / Path('.api_keys/secret_keys.json')) as f: secrets = json.loads(f.read())DB_USER, DB_PW = secrets['lecture']['userid'], secrets['lecture']['password']SERVER24_USER, SERVER24_PW = secrets['DBSERVER']['userid'], secrets['DBSERVER']['password'] SSHTunnelForwarder 사용1234SSHTunnelForwarder((HOST_IP, SSH_PORT), ssh_username='USER_ID', ssh_pkey='SSH_KEY', remote_bind_address=('127.0.0.1', 3306)) ssh_address_or_host: tuple 형태나 string 형태로 설정할 수 있으며, 위와같이 키워드를 생략할 수 있습니다. 튜플형식: (호스트주소, 포트) 함께 정의 문자열 형식: 호스트 주소 설정 (ssh_port 키워드도 별도로 설정해줘야 합니다.) ~/.ssh/config 에 설정한 Host ssh_port: ssh 서비스 포트 ssh_username: ssh 연결에 사용될 인증된 사용자 ssh_password: ssh 연결에 사용될 사용자의 접속 비밀번호 보안을 위해 비밀번호를 설정하는 것보다는 private key을 사용하는 것을 권장합니다. ssh_pkey: ssh 연결에 사용될 private key 파일 혹은 paramiko.pkey.PKey remote_bind_address: (호스트주소, 포트) 튜플 형식. ssh 연결을 통해 접속한 원격 서버에서 접속할 private server 접속 정보. with 구문과 사용SSHTunnelForwarder 클래스에 __enter__, __exit__ magic method가 정의되어 with 구문과 함께 사용한다. 12345678910111213with sshtunnel.SSHTunnelForwarder( (_host, _ssh_port), ssh_username=_username, ssh_password=_password, remote_bind_address=(_remote_bind_address, _remote_mysql_port), local_bind_address=(_local_bind_address, _local_mysql_port)) as tunnel: connection = mysql.connector.connect( user=_db_user, password=_db_password, host=_local_bind_address, database=_db_name, port=_local_mysql_port) Windows 경우 보안 경고를 확인!윈도우즈에서 파이썬 코드에서 SSHTunnelForwarder 를 처음 사용시 아래 같이 경고를 만난다. 사례1사례1 로 접속하는 방법이 전형적인 터널링 구현이다. SSHTunnelForwarder을 with 구문과 함께 쓸 수 있다. 12345678910111213141516171819202122232425import pymysqlfrom sshtunnel import SSHTunnelForwarderwith SSHTunnelForwarder(('DBSERVER', 2020), ssh_username=SERVER24_USER, ssh_password=SERVER24_PW, remote_bind_address=('127.0.0.1', 3306), ) as tunnel: # connect MySQL like local with pymysql.connect( host='127.0.0.1', #(local_host) user=DB_USER, passwd=DB_PW, db='lecture', charset='utf8', port=tunnel.local_bind_port, # ssh로 접속한 클라이언트 포트 cursorclass=pymysql.cursors.DictCursor) as conn: with conn.cursor() as cur: sql = &quot;show tables;&quot; cur.execute(sql) print(sql) results = cur.fetchall() print(results) for result in results: print(result) 터널링을 통해서 SQL Query가 잘 진행된다. 사례2) ssh_pkey 사용 (실패) 기록을 위해 남긴다. 잘 안되는 코드이다. 사례2 같이 직접 서버에 접근이 안되는 경우 ssh key pair 를 사용할 수 있다. 사용자 아이디, 패스워드 형식에서 패스워드를 직접 코드 등에 입력하기 보다 private key 쌍을 사용하면 좀 더 보안에 안전하다. ssh-keygen 으로 생성한 공개키를 DB 서버의 ssh/authorized_keys`` 파일에 id_rsa.pub 내용을 ssh-copy-id또는scp` 명령으로 서버에 복사한다. 1&gt; ssh-copy-id -i ~/.ssh/id_rsa.pub username@jump_server_host -p ssh_port scp 를 사용해도 좋다 123&gt; scp -P 2020 .\\.ssh\\id_rsa qkboo@DBSERVER:~/auth_key#복사한 공개키를 `.ssh/authorized_keys` 에 추가한다.&gt; cat auth_key &gt;&gt; .ssh/authorized_keys SSHTunnelForwarder 에서 ssh_pkey 에 비밀키를 지정해 준다. 123456789101112131415161718192021222324252627with SSHTunnelForwarder(('DBSERVER', 2020), ssh_username='qkboo', ssh_pkey='~/.ssh/id_rsa', remote_bind_address=('127.0.0.1', 3306)) as tunnel: print( tunnel.ssh_host_key ) print( tunnel.local_bind_address ) print( tunnel._remote_binds ) # connect MySQL like local with pymysql.connect( host='127.0.0.1', #(local_host) user='user1', passwd='012345', db='lecture', charset='utf8', port=3306, # port=tunnel.local_bind_port, cursorclass=pymysql.cursors.DictCursor) as conn: with conn.cursor() as cur: sql = &quot;show tables;&quot; cur.execute(sql) print(sql) results = cur.fetchall() print(results) for result in results: print(result) SQLAlchemy engine 생성하기SQLAlchemy 의 engine 을 생성할 수 있다. with 구문과 함께 사용할 수 있지만 engine 을 여러 프로시저에서 지속해서 사용한다면 아래 같이 start(), stop() 사이에 pymysql, sqlalchemy 코드를 배치해도 좋다. 12345678910111213141516# SSH Tunnel 사용1from sshtunnel import SSHTunnelForwarderserver = SSHTunnelForwarder(('DBSERVER', 2020), ssh_username=SERVER24_USER, ssh_password=SERVER24_PW, remote_bind_address=('127.0.0.1', 3306), )server.start() # Tunnel 시작local_port = str(server.local_bind_port)engine = sqla.create_engine(f'mysql+pymysql://{DB_USER}:{DB_PW}@127.0.0.1:{local_port}/bookstore')query = &quot;&quot;&quot;SELECT * FROM book;&quot;&quot;&quot;df = pd.read_sql(sqla.text(query), con=engine)engine.dispose()server.stop() # Tunnel 종료 with 구문과 사용 123456789101112# SSH Tunnel 사용2 - with 구문과 사용with SSHTunnelForwarder(('192.168.0.24', 2020), ssh_username=SERVER24_USER, ssh_password=SERVER24_PW, remote_bind_address=('127.0.0.1', 3306), ) as tunnel: local_port = str(tunnel.local_bind_port) engine = sqla.create_engine(f'mysql+pymysql://{DB_USER}:{DB_PW}@127.0.0.1:{local_port}/bookstore') query = &quot;&quot;&quot;SELECT * FROM book;&quot;&quot;&quot; df_sector = pd.read_sql(sqla.text(query), con=engine) engine.dispose() 클라이언트에서 ssh tunnel 사용클라이언트에서 MySQL / MariaDB 접속시 보안을 위해서 SSH over 방식을 통해 3306 포트가 아닌 ssh over 방법을 사용할 수 있다. HeidiSQL ssh tunnel 사용하기 MysQL Workbench 에서 ssh tunnel 사용하기 Server 에서 bind 제외하기 1. HeidiSQL ssh tunnel 사용하기유형을 SSH Tunnel 로 선택하고 MySQL / MariaDB 데이터베이스의 DB 사용자 계정과 비밀번호을 입력한다. SSH tunnel 을 만들어줄 ssh client 를 선택하고 개인 키 파일을 선택한다. SSH 로 로그인하는 DB server의 사용자 계정 ID를 입력한다. 선택한 개인 키가 로그인 패스워드를 대체한다. SSH 아이디-패스워드 방법은 잘 안된다. 2. MysQL Workbench 에서 ssh tunnel 사용하기MySQL workbench 에서 ssh tunnel 로 접속하려면 DB 서버측에 authorized_keys 에 클라이언트 공개키가 등록되어야 한다. DB 서버의 `ssh/authorized_keys`` 파일에 id_rsa.pub 내용을 추가한다. 1&gt; scp -P 2020 .\\.ssh\\id_rsa qkboo@192.168.0.24:~/auth_key 복사한 공개키를 .ssh/authorized_keys 에 추가한다. 1cat auth_key &gt;&gt; .ssh/authorized_keys root 계정은 잘 안된다. 3. Server 에서 bind 제외하기서버에서 my.cnf 에서 0.0.0.0 으로 bind 를 제외하고 로컬 127.0.0.1 만 두면, SSH tunnel 방법으로 통해 접근하므로 좀 더 안전할 수 있다. 1bind-address = 127.0.0.1 참고 참고1 : MySQL SSH Tunnel 소개, blog 참고2 - SSH Tunneling : SSH Tunnel 이란 참고3 : sshtunnel docs","link":"/mysqlclient_SSH_Tunneling-59f215a18e7e/"},{"title":"MariaDB 클라언트-서버 TLS&#x2F;SSL 암호화 연결(2)","text":"MariaDB 클라언트-서버 TLS/SSL 클라이언트 사용 글 타래: MariaDB 클라언트-서버 TLS/SSL 암호화 연결(1) MariaDB 클라언트-서버 TLS/SSL 암호화 연결(2) MariaDB 클라언트-서버 TLS/SSL 암호화 연결(3) 서버측에서 MariaDB/MySQL 의 TLS를 활성화한 다음 실제 다양한 클라이언트에서 접속을 시도해 보자. 서버에서 생성한 CA 파일 ca.pem, 클라이언트 인증서 client-ssl.pem, 클라이언트 키 client-key.pem 을 다운로드해서 사용한다. 글 진행 순서 클라이언트 인증서 다운로드 DB API: python 에서 SSL 접속 HeidiSQL 에서 SSL 접속 MySQL Workbench 에서 SSL 접속 1. 클라이언트 인증서 다운로드앞서 MariaDB 클라언트-서버 TLS/SSL 암호화 연결(1) 만든 ca.pem, client-cert.pem, client-key.pem 을 외부접속할 클라이언트 PC로 다운받는다. 123456&gt; mkdir .ssl/mysql/&gt; cd .ssl/mysql# 다운로드&gt; scp -P 2020 USERID@HOST_IP:/etc/ssl/mysql/ca.pem .&gt; scp -P 2020 USERID@HOST_IP:/etc/ssl/mysql/client-ssl.pem .&gt; scp -P 2020 USERID@HOST_IP:/etc/ssl/mysql/client-key.pem . 다운로드한 파일은 3종류로 123456&gt; ls .ssl/mysqlMode LastWriteTime Length Name---- ------------- ------ -----a--- 2023-07-16 오후 4:38 1984 ca.pem-a--- 2023-07-16 오후 4:38 1497 client-cert.pem-a--- 2023-07-16 오후 4:38 1679 client-key.pem 서버와 비슷하게 mysql client 설정에 인증키들을 설정해주면 그냥 접속해도 ssl로 접속된다. 아래 참고2 에서 mysql client 의 클라이언트 측 my.cnf/my.ini 파일에 ssl-ca, ssl-cert, ssl-key 를 설정하면 된다. 2. DB API: python 에서 SSL 접속pymysql, sqlalchemy 등 mysql client API 에 ssl_ca, ssl_key, ssl_cert 인자에 클라이언트용 인증 파일을 연결한다. pymysqlpymysql.connect 에 ssl_ca, ssl_key, ssl_cert 인자 클라이언트용 인증 파일의 경로가 SSL_CA, SSL_CERT, SSL_KEY 에 있다고 가정한다. 12345678910111213141516conn = pymysql.connect(host='192.168.0.10', user=DB_USER, password=DB_PW, db='bookstore', ssl_ca=SSL_CA, ssl_key=SSL_KEY, ssl_cert=SSL_CERT, charset='utf8') # Connection 으로부터 Cursor 생성curs = conn.cursor()sql = &quot;select * from book&quot;curs.execute(sql)rows = curs.fetchall()print(rows) # 전체 rowsconn.close() SQLAlchemy : enginesqlalchemy의 create_engin에 connect_args 인자에 클라이언트 인증 파일의 경로가 SSL_CA, SSL_CERT, SSL_KEY 에 있다고 가정한다. 123456789ssl_args = {'ssl_ca': SSL_CA, 'ssl_cert': SSL_CERT, 'ssl_key': SSL_KEY}engine = sqla.create_engine( f'mysql+pymysql://{DB_USER}:{DB_PW}@192.168.0.24/bookstore', connect_args=ssl_args)query = &quot;&quot;&quot;SELECT * FROM book;&quot;&quot;&quot;df = pd.read_sql(sqla.text(query), con=engine) C 라이브러리 사용 SSL 접속참고2 를 보면 C API를 사용한 `libmariadb.dll`` 라이브러리에서 SSL 사용하는 C++ 콘솔 예제 가 있다. 3. HeidiSQL 에서 SSL 접속HeidiSQL 에서 SSL 을 이용해 접속할 수 있다. 아래 그림 같이 DB 정보를 입력한 후에 SSL 탭에서 SSL을 체크만 하면 된다. 접속이 되면 프로그램 아래 상태바의 정보를 클릭해 보면 SSL 연결을 확인할 수 있다. 앞서 다운로드한 서버측이 제고한 클라이언트 인증 키를 지정하고 연결하면 아래 같은 cipher mis match 에러가 뜬다. 이것은 아마도 서버측의 openssl.cnf 에 정의되어 있는 CipherString 버전이 달라서 그런것 같다. 여기 Connect error “SEC_E_ALGORITHM_MISMATCH”.. 의 글타래에 설명되어 있다. 테스트한 서버는 ** Armbian 23.02.2 Bullseye** 로 CipherString 이 DEFAULT@SECLEVEL=2 로 나온다. TLS versions1234567&gt; show global variables like 'tls_version';+---------------+-------------------------+| Variable_name | Value |+---------------+-------------------------+| tls_version | TLSv1.1,TLSv1.2,TLSv1.3 |+---------------+-------------------------+1 row in set (0.007 sec) CipherString 테스트MySQL 설정파일 참조3에 따르면 server-side encrypted-connection control 을 위해서 아래 변수를 사용할 수 있다고 한다. 1ssl_cipher: The list of permissible ciphers for connection encryption. my.cnf 의 SSL/TLS 영역 다음을 추가해 보자. 1ssl_cipher=DEFAULT:@SECLEVEL=1 재시작한후 아래 그림 같이 서버에서 만든 클라이언트 인증서를 사용해보니 잘 된다. root 계정 접속도 잘 된다. 4. MySQL Workbench 에서 SSL 접속MySQL Workbench 에서도 SSL 연결로 데이터베이스에 접속할 수 있다. DB 접속 계정 정보를 입력한다. SSL 탭에서 SSL 관련 옵션을 선택하는데 여기서는 if available 로 지정했다. 서버측이 SSL활성화가 되어 있으면 자동으로 SSL 통신을 진행한다. Test 로 확인해 보면 SSL 접속이 잘 되고 있는 것을 알 수 있다. 5. 사용자 SSL 권한 부여새 사용자를 생성할 때 아래 같이 접속시 REQUIRE 인자로 SSL 로만 접속하도록 할 수 있다. 사용자의 추가/권한 부여에 대해서 MySQL CLI/Admin: 권한부여 글을 참고. 12345678910# SSL/TLS(가장 기본적인 암호화 접속)mysql&gt; CREATE USER 'admin'@'localhost' IDENTIFIED BY '********' REQUIRE SSL;# X509mysql&gt; CREATE USER 'admin'@'localhost' IDENTIFIED BY '********' REQUIRE X509;# CIPHER 'cipher'mysql&gt; CREATE USER 'admin'@'localhost' IDENTIFIED BY '********' REQUIRE CIPHER 'EDH-RSA-DES-CBC3-SHA';mysql&gt; flush privileges; 기존 사용자는 사용자 권한에서 SSL을 권한을 추가한다. 12mysql&gt; GRANT ALL PRIVILEGES ON DB이름.* TO 'USERID'@'%' REQUIRE SSL;mysql&gt; flush privileges; 주어진 grant에 SSL/X509 등이 주어졌는지 확인한다. 1mysql&gt; SHOW GRANTS FOR 'USERID'@'HOST'; 내부 네트워크 외부 네트워크로 분리해 사용한다면 외부에서는 무조건 SSL 을 사용하도록 할 수 있을 것 같다. — 참고1 : OpenSSL을 이용한 사설 인증서 생성 참고2 : MariaDB 외부접속시 ssl 사용법, 그리고 ssl 로 replication(동기화) 하기 참고3 : Configuring MySQL to Use Encrypted Connections","link":"/mariadb-enable_tls_2-client-4b6a88c2e5be/"},{"title":"MariaDB 클라언트-서버 TLS&#x2F;SSL 암호화 연결(1)","text":"MySQL / MaraiDB 서버에 TLS 를 활성화 해서 암호화 통신을 할 수 있다. MySQL (MariaDB도 동일함)에서는 서버-클라이언트 사이에 전송되는 데이터를 TLS (이전 SSL) 프로토콜을 이용하여 암호화하여 DB 정보가 노출되지 않게 방지할 수 있다. SSL을 통해서 Replication Master - Slave 도 가능하다. 글 타래: MariaDB 클라언트-서버 TLS/SSL 암호화 연결(1) MariaDB 클라언트-서버 TLS/SSL 암호화 연결(2) MariaDB 클라언트-서버 TLS/SSL 암호화 연결(3) 글 진행 순서: 사설 CA 인증서 생성 클라이언트 인증서 생성 사설 CA 인증서 설정 1. 사설 CA 인증서 생성openssl을 사용해서 ssl_cert, ssl_key, ssl_ca 에 사용하는 서버용 사설 인증서를 생성한다. openssl을 이용한 사설 인증서 생성에 대해서는 HTTPS 를 위한 Private SSL 기사도 참조할 수 있다.이 글에서는 아래 참고1, 참고2 를 적용했다. 인증서는 사설 CA(Certificate Authority)용 인증서, 서버용, 클라이언트용 총 3가지를 만든다. 인증서 저장 위치 생성12(SERVER) $ sudo mkdir /etc/ssl/mysql(SERVER) $ cd /etc/ssl/mysql 생성한 TLS 인증서는 MySQL/MariaDB 의 my.cnf 설정파일의 변수를 3가지 설정한다. ssl_cert 시스템 변수: 서버 인증서(X509) 경로 지정 ssl_key 시스템 변수: 서버 개인키 경로 지정 ssl_ca 혹은 ssl_capath 시스템 변수: Self-signed CA certificate CA 키 경로 openssl 사설 CA 인증서 생성저장 위치 /etc/ssl/mysql 에서 관리용 CA 인증서 생성한다. 먼저 openssl에서 rsa 알고리즘으로 4096 크기 비밀키를 생성한다. 123(SERVER) $ sudo openssl genrsa -out ca-key.pem 4096Generating RSA private key, 4096 bit long modulus (2 primes)... 비밀키 파일 ca-key.pem 파일을 사용해서 CA인증서 ca.pem 파일로 생성한다. 비밀키로 CA를 위한 CSR(certificate signing request) 과정을 거쳐 ca.pem 을 생성해9서 필요한 인증서 정보를 묻는다. 123456789(SERVER) $ sudo openssl req -new -x509 -nodes -days 365000 -key ca-key.pem -out ca.pem...Country Name (2 letter code) [AU]: KRState or Province Name (full name) [Some-State]:SeoulLocality Name (eg, city) []:Organization Name (eg, company) [Internet Widgits Pty Ltd]:YOUR companyOrganizational Unit Name (eg, section) []: AdministrationCommon Name (e.g. server FQDN or YOUR name) []::mysql-admin.DOMAIN.nameEmail Address []: 현재까지 123(SERVER) $ ls -l-rw------- 1 root root 3243 Jul 16 15:04 ca-key.pem-rw-r--r-- 1 root root 1972 Jul 16 15:11 ca.pem 서버 인증서 생성서버용 인증서 생성한다. 단, openssl 명령 과정에서 Common Name 을 3가지 모두 다르게 해야 검증오류를 피할 수 있다. 12345678910111213141516(SERVER) $ sudo openssl req -newkey rsa:4096 -days 365000 -nodes -keyout server-key.pem -out server-req.pemCountry Name (2 letter code) [AU]:KRState or Province Name (full name) [Some-State]:SeoulLocality Name (eg, city) []:Organization Name (eg, company) [Internet Widgits Pty Ltd]:YOUR companyOrganizational Unit Name (eg, section) []:AdministrationCommon Name (e.g. server FQDN or YOUR name) []:server.DOMAIN.nameEmail Address []:Please enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []:... 현재 디렉토리 12345(SERVER) $ ls -l-rw------- 1 root root 3243 Jul 16 15:04 ca-key.pem-rw-r--r-- 1 root root 1972 Jul 16 15:11 ca.pem-rw------- 1 root root 3272 Jul 16 15:15 server-key.pem-rw-r--r-- 1 root root 1704 Jul 16 15:16 server-req.pem RSA 알고리즘으로 12(SERVER) $ sudo openssl rsa -in server-key.pem -out server-key.pemwriting RSA key CA 비밀키 ca-key.pem 를 사용해 X509 인증서를 사이닝한다. 1234(SERVER) $ sudo openssl x509 -req -in server-req.pem -days 365000 -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pemSignature oksubject=C = KR, ST = Seoul, O = Thinkbee company, OU = Administration, CN = admin.thinkbee.krGetting CA Private Key 12(SERVER) $ sudo openssl verify -CAfile ca.pem server-cert.pemserver-cert.pem: OK 현재 디렉토리 123456(SERVER) $ ls -l-rw------- 1 root root 3243 Jul 16 15:04 ca-key.pem-rw-r--r-- 1 root root 1972 Jul 16 15:11 ca.pem-rw-r--r-- 1 root root 1862 Jul 16 15:20 server-cert.pem-rw------- 1 root root 3243 Jul 16 15:19 server-key.pem-rw-r--r-- 1 root root 1704 Jul 16 15:16 server-req.pem 2. 클라이언트 인증서 생성클라이언트 인증서는 다음과 같은 용도로 사용한다. 단, openssl 명령 과정에서 Common Name 을 3가지 모두 다르게 해야 검증오류를 피할 수 있다. DB 서버와 별도로 존재하는 웹 서버에서 DB 서버로 SSL 통신을 할 때 웹 서버에 적용 접속하고자 하는 DB 서버와 별도의 리눅스 환경에서 mysql 클라이언트 프로그램으로 DB 서버에 접속할 때 클라이언트에 적용 Replication 에서 Master와 Slave 간의 SSL 통신을 하고자 할 때 Slave 서버에 적용 123456789(SERVER) $ sudo openssl req -newkey rsa:2048 -days 365000 -nodes -keyout client-key.pem -out client-req.pemCountry Name (2 letter code) [AU]:KRState or Province Name (full name) [Some-State]:SeoulLocality Name (eg, city) []:Organization Name (eg, company) [Internet Widgits Pty Ltd]:Organizational Unit Name (eg, section) []:Common Name (e.g. server FQDN or YOUR name) []::mysql-client.thinkbee.kr... 12(SERVER) $ sudo openssl rsa -in client-key.pem -out client-key.pemwriting RSA key 1234(SERVER) $ sudo openssl x509 -req -in client-req.pem -days 365000 -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pemSignature oksubject=C = KR, ST = Seoul, O = Internet Widgits Pty Ltd, CN = client-thinkbee.krGetting CA Private Key 12(SERVER) $ sudo openssl verify -CAfile ca.pem client-cert.pem client-cert.pem: OK 현재 디렉토리를 접근 권한을 조정한다. 12345678910(SERVER) $ sudo chown mysql.mysql *.*(SERVER) $ ls -l-rw-r--r-- 1 mysql mysql 3243 7월 16 15:43 ca-key.pem-rw-r--r-- 1 mysql mysql 1984 7월 16 15:46 ca.pem-rw-r--r-- 1 mysql mysql 1497 7월 16 15:51 client-cert.pem-rw-r--r-- 1 mysql mysql 1679 7월 16 15:51 client-key.pem-rw-r--r-- 1 mysql mysql 989 7월 16 15:50 client-req.pem-rw-r--r-- 1 mysql mysql 1838 7월 16 15:48 server-cert.pem-rw------- 1 mysql mysql 3243 7월 16 15:48 server-key.pem-rw-r--r-- 1 mysql mysql 1671 7월 16 15:47 server-req.pem 인증서의 내용 확인방법shell &gt; openssl x509 -text -in ca.pemshell &gt; openssl x509 -text -in server-cert.pemshell &gt; openssl x509 -text -in client-cert.pem 3. 사설 CA 인증서 설정my.cnf 에 TLS 를 위한 구성을 해야 한다. 주로 ssl_cert, ssl_key, ssl_ca 에 대한 인증서 파일을 지정해 준다. ssl_cert 시스템 변수: X509 인증서 경로 지정 ssl_key 시스템 변수: 서버 개인키 경로 지정 ssl_ca 혹은 ssl_capath 시스템 변수: Certificate Authority (CA) 경로 TLS 활성화참고3 의 mysql 설정파일 my.cnf 에 따르면 아래 변수가 설정되야 한다. 12345[mariadb]...ssl_cert = /etc/ssl/mysql/server-cert.pemssl_key = /etc/ssl/mysql/server-key.pemssl_ca = /etc/ssl/mysql/ca.pem 서버를 재시작한다. TLS 가 활성화 되었는지 환경변수로 확인할 수 있다. 1234567891011121314151617MariaDB [(none)]&gt; show variables like '%ssl%';+---------------------+--------------------------------+| Variable_name | Value |+---------------------+--------------------------------+| have_openssl | YES || have_ssl | YES || ssl_ca | /etc/ssl/mysql/ca.pem || ssl_capath | || ssl_cert | /etc/ssl/mysql/server-cert.pem || ssl_cipher | || ssl_crl | || ssl_crlpath | || ssl_key | /etc/ssl/mysql/server-key.pem || version_ssl_library | OpenSSL 1.1.1n 15 Mar 2022 |+---------------------+--------------------------------+10 rows in set (0.003 sec) 이렇게 구성한 TLS 인증서는 만료기간이 있다. 아래 같이 만료 기간을 확인 할 수 있다. 1234567&gt; SHOW STATUS LIKE 'Ssl_server_not%';+-----------------------+--------------------------+| Variable_name | Value |+-----------------------+--------------------------+| Ssl_server_not_after | Nov 16 06:48:41 3022 GMT || Ssl_server_not_before | Jul 16 06:48:41 2023 GMT |+-----------------------+--------------------------+ mysql client TLS 사용 접속mysql 클라이언트로 TLS 인증서를 사용해서 접속해 보자. 1(SERVER) $ mysql -u root -p -h localhost --ssl=TRUE --ssl-ca=/etc/ssl/mysql/ca.pem --ssl-cert=/etc/ssl/mysql/client-cert.pem --ssl-key=/etc/ssl/mysql/client-key.pem 접속한 클라인트에서 status 를 살펴보면 TLS 로 접속한 내역을 SSL: Cipher in use is TLS_AES_256_GCM_SHA384 항목으로 확인할 수 있다. 12345678910111213141516171819202122232425MariaDB [(none)]&gt; status--------------mysql Ver 15.1 Distrib 10.11.2-MariaDB, for debian-linux-gnu (aarch64) using EditLine wrapperConnection id: 315Current database:Current user: root@localhostSSL: Cipher in use is TLS_AES_256_GCM_SHA384Current pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 10.11.2-MariaDB-1:10.11.2+maria~deb11 mariadb.org binary distributionProtocol version: 10Connection: Localhost via UNIX socketServer characterset: utf8mb4Db characterset: utf8mb4Client characterset: utf8mb3Conn. characterset: utf8mb3UNIX socket: /run/mysqld/mysqld.sockUptime: 6 min 54 secThreads: 69 Questions: 2386 Slow queries: 0 Opens: 37 Open tables: 30 Queries per second avg: 5.763-------------- 참고 OpenSSL을 이용한 사설 인증서 생성 MariaDB 외부접속시 ssl 사용법, 그리고 ssl 로 replication(동기화) 하기 Configuring MySQL to Use Encrypted Connections","link":"/mariadb-enable_tls_1-50b5d39df89f/"},{"title":"Jupyter 기반 환경에서 Multiprocess 실행시 print 출력 차이.","text":"jupyter notebook에서 실행하면 차일드 프로세스로 실행한 print() 로 출력하는 결과를 확인할 수 업다. print 는 std out 에 출력하도록 되어 있다. 자식 프로세스에서 print 를 호출하면 spawn 을 사용해서 호출되어서 출력되지 않는다. 차일드 프로세스 print 문제아래 코드는 아주 간단하게 메인 프로세스에서 새 프로세스를 생성하고 실행한다. 123456789from multiprocessing import Processdef func(msg): print(msg)if __name__ == &quot;__main__&quot;: proc = Process(target=func, args=('Hello multiproess',)) proc.start() proc.join() 이 코드는 소스로 쉘에서 실행하거나 Web 기반의 jupyterlab 에서 실행하면 아무 문제이 print 문이 잘 작동하고 출력 결과가 나온다. 12&gt;&gt;&gt; ! python mutiprocess1.pyHello multiproess print 의 Multiprocessing 에서 문제는 링크 참고1 을 읽어보기를 권한다. 이 글에서는 테스트한 내용을 정리만 했다. 원인아래 링크 참고1 기사에서 설명을 자세히 하고 있다. 보통 파이썬에서 차일드 프로세스를 시작할 때는 'fork', 'spawn', 'forkserver' 방법이 있다고 한다. 그런데 spawn 으로 차일드 프로세스를 실행하면 std io 출력 버퍼가 자동으로 비워지지 않는다(print는 기본으로 flush가 되지 않는다). 그러다 보니 차일드 프로세스가 종료 하면서 자동으로 gabage collection에 의해 버퍼에 남아 있는 메시지가 사라지는 것이다. 해결 방법 메시지 버퍼가 사라지기 전에 flush 를 한다. fork 기반의 프로세스를 생성한다. 1. flush 사용 메시지 버퍼가 사라지기 전에 flush 를 한다. 이를 해결하기 위해 모든 print 의 출력은 즉시 flush 되도록 flush=True 옵션을 사용할 수 있다고 한다. 12def func(msg): print(msg, flush=Yes) 이 방법은 VS code 현재 jupyter 확장에서는 효과가 없다. flush 란?std io 의 버퍼 처리 흐름은 글 파일 I/O 버퍼링 을 살펴보고, python에서 print 같은 표준 출력의 flush에 대해서 이글 의 그림을 참고한다. 2. fork 기반의 프로세스를 생성한다.지원되는 프로세스 시작 방법은 아래 같이 확인이 가능하다. 1234import multiprocessing as mpmp.get_start_method() # 현재 start 메서드mp.get_all_start_methods() # 모든 start 메서드 아래 같이 start method 를 fork 로 강제 사용할 수 있다. 123import multiprocessing as mpmp.set_start_method('fork') # 현재 start 메서드 브라우저 기반의 jupyter 실행환경은 'fork', 'spawn', 'forkserver' 를 모두 가능하다. 하지만 현재 VS code 의 jupyter 확장은 에서는 spawn 만 지원하고 있다. fork, spawn링크 침고2 에 있는 글에서 Fork, Spawn 에 대한 설명을 읽어보자. Forking 포크한 부모 프로세스의 이미지를 그래도 사용한다. Spwaning 포크한 부모 프로세스와 다르게 새 이미지로 갱신한다. sleep 으로 지연하면?VS code 환경에서 아래 같이 sleep 으로 지연을 주어 봤지만 해결이 안된다. 12345678def func(msg): print(msg, flush=True) time.sleep(1)if __name__ == &quot;__main__&quot;: proc = mp.Process(target=func, args=('Hello multiproess',)) proc.start() proc.join() 아래 같이 join 전에 sleep 으로 지연 123456789def func(msg): print(msg, flush=True) time.sleep(1)if __name__ == &quot;__main__&quot;: proc = mp.Process(target=func, args=('Hello multiproess',)) proc.start() time.sleep(1) proc.join() 결론현재 테스트한 VS Code 의 jupyter 확장 버전은 아래 같다. Windows VS code, Jupyter Extension v2023.6.1101941928 v2023.7.1001901100 만약 VS code 에서 Multiprocess 디버깅시 다른 logger 라이브러리 등을 이용해야 할 것 같다. 참고참고1 : How to print() from a Child Process in Python 참고2 : fork, vfork 그리고 posix_spawn 이야기 참고3 : foring, spawning 이미지","link":"/jupyterlab-multiprocess_print-483b37e7a2c3/"},{"title":"Windows Terminal에서 miniconda&#x2F;ananconda Profile 사용","text":"Anaconda / Miniconda 를 설치하고 윈도우즈에서 실행시 바로가기로 사용하는 방법을 정리했다. 모든 Commandline, Powershell 에서 conda 명령을 사용하려면 환경변수 PATH 에 지정을 해야 한다. 이 글에서는 바로가기를 사용하면 PATH 환경변수를 활용하지 않고도 쉽게 사용할 수 있다. Anaconda/Miniconda 설치 프로그램으로 설치를 하면 바로가기를 만들어 준다. 여기서 힌트를 얻으면 된다. 바로가기 속성을 사용해 파워쉘로 conda 환경을 초기화 하기 위해서는 conda-hook.ps1 실행이 필요하다. 설치한 Anaconda 시작프로그램의 속성을 통해 알 수 있다. 보통 설치된 아래 위치에 있다. C:\\Users\\USERID\\miniconda3\\shell\\condabin\\conda-hook.ps1 PowerShell윈도우 기본 파워쉘과 Powershell 7 으로 바로가기 설정을 보면, conda-hook.ps1 을 포함해 바로가기 아이콘 속성에 파워쉘을 통해 실행하도록 설정하면 된다. PowerShell 7powershell 7 으로 Miniconda3 의 base 가상환경 기반 쉘을 실행한다. 1&quot;C:\\Program Files\\PowerShell\\7\\pwsh.exe&quot; -ExecutionPolicy ByPass -NoExit -Command &quot;&amp; 'C:\\Users\\USERID\\miniconda3\\shell\\condabin\\conda-hook.ps1' ; conda activate 'C:\\Users\\USERID\\miniconda3' &quot; 기본 PowerShell 버전1%windir%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -ExecutionPolicy ByPass -NoExit -Command &quot;&amp; 'C:\\Users\\USERID\\miniconda3\\shell\\condabin\\conda-hook.ps1' ; conda activate 'C:\\Users\\USERID\\miniconda3' &quot; Command Line윈도우 Command 로 anaconda / miniconda 를 실행하려면 아래 같이 activate.bat 배치를 실행하면 된다. 1%windir%\\System32\\cmd.exe &quot;/K&quot; C:\\Users\\daddy\\miniconda3\\Scripts\\activate.bat C:\\Users\\daddy\\miniconda3 Windows Terminal 프로파일 설정윈도우 터미널에 새 프로파일 추가시 랜덤한 GUID 값이 필요하다. 터미널에서 New-Guid 명령으로 발행해 사용한다. 12345PS&gt; New-GuidGuid----9f2a1a27-fe9b-4421-ba19-6cea57188b17 PowerShell 7 버전guid 는 New-Guid 로 발행해서 등록하면 된다. 123456789101112{ &quot;commandline&quot;: &quot;C:\\\\Program Files\\\\PowerShell\\\\7\\\\pwsh.exe -ExecutionPolicy ByPass -NoExit -Command \\&quot;&amp; 'C:\\\\Users\\\\USERID\\\\miniconda3\\\\shell\\\\condabin\\\\conda-hook.ps1' ; conda activate 'C:\\\\Users\\\\daddy\\\\miniconda3' \\&quot;&quot;, &quot;guid&quot;: &quot;{fe2a1a27-9efb-4421-ba19-6cea57188b17}&quot;, &quot;name&quot;: &quot;Miniconda3 64bit(ps7)&quot;, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;},{ &quot;commandline&quot;: &quot;C:\\\\Program Files\\\\PowerShell\\\\7\\\\pwsh.exe -ExecutionPolicy ByPass -NoExit -Command \\&quot;&amp; 'C:\\\\Users\\\\USERID\\\\anaconda3\\\\shell\\\\condabin\\\\conda-hook.ps1' ; conda activate 'C:\\\\Users\\\\daddy\\\\anaconda3' \\&quot;&quot;, &quot;guid&quot;: &quot;{3f2k7199-d35c-44e5-b82d-7cd5442175fc}&quot;, &quot;name&quot;: &quot;Anaconda 64bit(ps7)&quot;, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;}, 윈도우 기본 PowerShell 버전12345678910111213{ &quot;commandline&quot;: &quot;%windir%\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -ExecutionPolicy ByPass -NoExit -Command \\&quot;&amp; 'C:\\\\Users\\\\USERID\\\\miniconda3\\\\shell\\\\condabin\\\\conda-hook.ps1' ; conda activate 'C:\\\\Users\\\\daddy\\\\miniconda3' \\&quot;&quot;, &quot;guid&quot;: &quot;{573e44d9-1ff5-4f3f-b083-1b2fd9a6a575}&quot;, &quot;name&quot;: &quot;Miniconda3 64bit&quot;, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;},{ &quot;commandline&quot;: &quot;%windir%\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -ExecutionPolicy ByPass -NoExit -Command \\&quot;&amp; 'C:\\\\Users\\\\USERID\\\\anaconda3\\\\shell\\\\condabin\\\\conda-hook.ps1' ; conda activate 'C:\\\\Users\\\\daddy\\\\anaconda3' \\&quot;&quot;, &quot;guid&quot;: &quot;{f441f482-8cf6-47ed-9a9c-fc40df46c9ac}&quot;, &quot;name&quot;: &quot;Anaconda 64bit&quot;, &quot;startingDirectory&quot;: &quot;%USERPROFILE%&quot;},","link":"/windows-conda-shell-cbeeac74bbce/"},{"title":"Pandas - Pivot, Stack, Unstack, Melt","text":"Pandas 에서 2차원 data를 Stack, unstack, melt 를 이용해 복합 인덱스를 사용할 수 있고 Pivot 을 이용해 특정 데이터 중심의 2차원 데이터로 생성할 수 있다. Pivot Stack &amp; Unstack Melt 12import pandas as pdimport numpy as np 2차원 테이블행과 열로 구성된 데이터 집합 1234567df = pd.DataFrame( {'foo' : ['One','One','One','Two','Two','Two'], 'bar': ['A','B','C','A','B','C'], 'baz': [1,2,3,4,5,6] , 'zoo': ['x','y','z','q','w','t']})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } foo bar baz zoo 0 One A 1 x 1 One B 2 y 2 One C 3 z 3 Two A 4 q 4 Two B 5 w 5 Two C 6 t Pivot피봇/피봇 테이블은 2차원 데이터 열에서 공통된 부분을 중심으로 새 테이블 집합을 형성하게 해준다. 피봇은 index, columns, values 라는 이름을 가진 세 가지 parameter를 취한다. 이러한 각 파라미터의 값으로 원래 표에 열 이름을 지정해야 한다. foo, bar, baz, zoo 컬럼 중에서 foo 에 대해서 정리를 하고 bar 를 컬럼으로 지정하면 아래와 같다. 12df_pivot = df.pivot_table(index='foo', columns='bar', values='baz')df_pivot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bar A B C foo One 1 2 3 Two 4 5 6 ex) nba 데이터를 포지션의 연령별 연봉 테이블로 전환12dfnba = pd.read_csv('../data/nba.csv')dfnba .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Name Team Number Position Age Height Weight College Salary 0 Avery Bradley Boston Celtics 0.0 PG 25.0 6-2 180.0 Texas 7730337.0 1 Jae Crowder Boston Celtics 99.0 SF 25.0 6-6 235.0 Marquette 6796117.0 2 John Holland Boston Celtics 30.0 SG 27.0 6-5 205.0 Boston University NaN 3 R.J. Hunter Boston Celtics 28.0 SG 22.0 6-5 185.0 Georgia State 1148640.0 4 Jonas Jerebko Boston Celtics 8.0 PF 29.0 6-10 231.0 NaN 5000000.0 ... ... ... ... ... ... ... ... ... ... 453 Shelvin Mack Utah Jazz 8.0 PG 26.0 6-3 203.0 Butler 2433333.0 454 Raul Neto Utah Jazz 25.0 PG 24.0 6-1 179.0 NaN 900000.0 455 Tibor Pleiss Utah Jazz 21.0 C 26.0 7-3 256.0 NaN 2900000.0 456 Jeff Withey Utah Jazz 24.0 C 26.0 7-0 231.0 Kansas 947276.0 457 NaN NaN NaN NaN NaN NaN NaN NaN NaN 458 rows × 9 columns 1pd.options.display.float_format = &quot;{:,.2f}&quot;.format 컬럼의 데이터에 공통된 모습이 많이 보인다. 이 중에서 포지션을 기준으로 나이에 따른 연봉을 본다고 가정하면 포지션을 인덱스로하고 나이를 컬럼으로 지정하면 아래와 같다. 12# 포지션의 연령별 연봉 테이블dfnba.pivot_table(index='Position', columns='Age', values='Salary') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age 19.00 20.00 21.00 22.00 23.00 24.00 25.00 26.00 27.00 28.00 ... 31.00 32.00 33.00 34.00 35.00 36.00 37.00 38.00 39.00 40.00 Position C NaN 5,143,140.00 1,571,000.00 3,476,698.20 2,121,999.50 4,532,003.33 10,881,995.00 3,041,850.82 5,004,260.50 7,635,761.83 ... 10,338,218.00 8,208,695.50 9,500,000.00 6,258,000.00 7,448,760.00 947,276.00 NaN 222,888.00 NaN 5,250,000.00 PF NaN 2,369,838.00 2,397,408.00 1,601,105.80 2,399,120.50 2,577,551.44 2,195,476.60 7,228,086.75 9,217,098.43 5,268,839.17 ... 5,323,787.00 14,346,365.00 2,630,241.40 6,469,277.50 2,624,593.50 2,877,470.00 6,666,667.00 NaN NaN 8,500,000.00 PG NaN 3,316,290.00 1,944,080.00 2,381,130.00 1,627,769.00 4,652,526.50 5,422,085.80 10,038,174.80 5,944,070.17 5,021,965.17 ... 7,467,596.40 4,082,425.33 2,226,179.67 8,395,104.00 NaN 2,170,465.00 NaN NaN 947,726.00 250,750.00 SF NaN 1,979,976.00 1,404,480.00 2,401,364.60 2,760,134.36 5,067,491.60 3,382,640.73 7,322,325.20 10,532,567.00 1,996,608.71 ... 10,960,320.25 9,720,195.75 NaN 261,894.00 947,276.00 1,721,559.75 25,000,000.00 3,376,000.00 NaN NaN SG 1,930,440.00 1,749,840.00 2,215,710.43 2,055,241.00 1,388,251.18 3,205,720.53 1,782,834.89 9,872,690.29 4,815,524.62 6,354,000.00 ... 7,085,000.00 2,041,138.00 2,233,533.33 12,579,269.50 3,512,173.75 3,311,138.00 NaN 1,880,638.00 4,088,019.00 NaN 5 rows × 22 columns Stack &amp; Unstack2차원 테이블은 행 과 열이 순차적 값으로 교차하게 되어 있다. 스택은 컬럼의 값을 아래-위로 배치를 시킨다고 상상이 된다. 그래서 스택과 언스택은 이렇게 생각된다. stack : 2차원 컬럼의 내용을 수직방향으로 쌓는 구조, 즉 새로운 인덱스가 더해진다. unstack : 인덱스 구성요소를 한 단계 컬럼으로 만들며 수평방향으로 쌓게 한다. stack pandas reshaping 1234567df_single_level = pd.DataFrame( [['Mostly cloudy', 10], ['Sunny', 12]], index=['London', 'Oxford'], columns=['Weather', 'Wind'])df_single_level .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Weather Wind London Mostly cloudy 10 Oxford Sunny 12 index와 weather, wind 라는 컬럼을 stack을 호출하면 weather-wind 관련 인덱스를 생성하고 데이터를 나열한다. 1df_single_level.stack() London Weather Mostly cloudy Wind 10 Oxford Weather Sunny Wind 12 dtype: object 다른 데이터를 살펴보자. 123456789101112# MultiIndextuples = list( zip( *[ [&quot;bar&quot;, &quot;bar&quot;, &quot;baz&quot;, &quot;baz&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;qux&quot;, &quot;qux&quot;], [&quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;], ] ))index = pd.MultiIndex.from_tuples(tuples, names=[&quot;first&quot;, &quot;second&quot;])df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[&quot;A&quot;, &quot;B&quot;])df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one -1.301694 -0.013259 two -0.197846 0.879890 baz one 0.718211 -0.739434 two -0.140217 0.071260 foo one -1.142268 -2.606413 two 1.119145 0.109402 qux one -0.504167 -1.703280 two 1.064976 1.011060 위 데이터는 stack()을 하면 A, B 컬럼이 MultiIndex 로 추가되며 A, B 컬럼 데이터 포인트가 배치된다. 1df.stack() first second bar one A -1.301694 B -0.013259 two A -0.197846 B 0.879890 baz one A 0.718211 B -0.739434 two A -0.140217 B 0.071260 foo one A -1.142268 B -2.606413 two A 1.119145 B 0.109402 qux one A -0.504167 B -1.703280 two A 1.064976 B 1.011060 dtype: float64 12df2 = df[:4]df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one -1.301694 -0.013259 two -0.197846 0.879890 baz one 0.718211 -0.739434 two -0.140217 0.071260 12stacked = df2.stack()stacked first second bar one A -1.301694 B -0.013259 two A -0.197846 B 0.879890 baz one A 0.718211 B -0.739434 two A -0.140217 B 0.071260 dtype: float64 Unstack pandas reshaping 1stacked first second bar one A -1.301694 B -0.013259 two A -0.197846 B 0.879890 baz one A 0.718211 B -0.739434 two A -0.140217 B 0.071260 dtype: float64 1stacked.unstack() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one -1.301694 -0.013259 two -0.197846 0.879890 baz one 0.718211 -0.739434 two -0.140217 0.071260 레벨을 지정 1stacked.unstack(1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } second one two first bar A -1.301694 -0.197846 B -0.013259 0.879890 baz A 0.718211 -0.140217 B -0.739434 0.071260 1stacked.unstack(2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B first second bar one -1.301694 -0.013259 two -0.197846 0.879890 baz one 0.718211 -0.739434 two -0.140217 0.071260 1 Meltmelt() 는 ID 변수를 기준으로 원래 데이터셋에 있던 여러개의 칼럼 이름을 ‘variable’ 칼럼에 위에서 아래로 길게 쌓아놓고, ‘value’ 칼럼에 ID와 variable에 해당하는 값을 넣어주는 식으로 데이터를 재구조화합니다. 123456789cheese = pd.DataFrame( { &quot;first&quot;: [&quot;John&quot;, &quot;Mary&quot;], &quot;last&quot;: [&quot;Doe&quot;, &quot;Bo&quot;], &quot;height&quot;: [5.5, 6.0], &quot;weight&quot;: [130, 150], })cheese .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } first last height weight 0 John Doe 5.50 130 1 Mary Bo 6.00 150 12# colums중 height, weight 를 row 로 융합cheese.melt(id_vars=['first','last']) # first, last 인덱스로 나머지 컬럼은 value 로 치환 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } first last variable value 0 John Doe height 5.50 1 Mary Bo height 6.00 2 John Doe weight 130.00 3 Mary Bo weight 150.00 1cheese.melt(id_vars=['first','last'], value_name='quantity') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } first last variable quantity 0 John Doe height 5.50 1 Mary Bo height 6.00 2 John Doe weight 130.00 3 Mary Bo weight 150.00 1 참고 pandas.DataFrame.stack","link":"/pd-Stack_Unstack_Melt-9d0bcd365efe/"},{"title":"VSCode 에서 languageserver 확인","text":"VS Code에서 Jupyterlab 3.x를 사용하는데 classic jupyter notebook 에서 가능하던 content assistance 기능이 작동을 하지 않았다. 상황Jupyterlab, classic jupyter notebook 에서 가능하던 content assistance 기능으로 속성/모듈/함수/도움말 등의 지원이 가능했다. Jupyterlab에서 노트북 셀의 tab &amp; shift tab 그림> 그런데 Visual studio code 에서 .ipynb 노트북 파일을 열어 사용하면 이런 기능이 안되고 있어서 궁금했다. 구글 검색으로 스택오버플로우에 올라온 기사를 보니 settings.json 을 보면 python language server 설정을 해야 한다고 한다. 현재는 Default 상태로 선택되어 있어서 그렇다고 한다. 그래서 Pylance 를 지정했다. languageserver 를 지정하고 재시작한 후 살펴보니 잘 된다. Language Server extension 이란?language-server-extension-guide 에서 설명한 바로는 여러 프로그래밍 언어에 대해서 강력한 편집 경험을 제공하고자 한다. 아래 그림에서 languageserver 의 효과를 설명하고 있다. 왼쪽 같이 LSP 가 없으면 각 편집기에서 직접 언어 엔진을 가동해야 한다. 그런데 오른쪽 깥이 LSP를 사용하면 하나의 서버를 통해서 여러 편집기에서 언어의 특성을 활용할 수 있다는 설명 이다.","link":"/vscode-language-server-24eec7ce2732/"},{"title":"Pandas&#x2F;Numpy 숫자의 출력 옵션 조정","text":"numpy 와 pandas 에서 수를 출력할 때 형식, 크기 및 범위를 설정할 수 있다. 간단히 보면 아래 테이블 같이 형식을 바꿔준다. column 변환 column 1e6 precision 1,000,000 1.1e-6 format 0.1 아래 요약한 옵션 방법을 사용해서 Numpy 와 Pandas에 있는 숫자를 출력할 때 표현방법, 표기법, 환률, 정밀도 등을 변경해 사용할 수 있다 numpy 출력 형식 변경numpy 숫자 출력 형식 변경numpy.set_printoptions 을 사용할 수 있다. 12numpy.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, suppress=None, nanstr=None, infstr=None, formatter=None, sign=None, floatmode=None, *, legacy=None) 현재 출력형식 확인np.get_printoptions() 으로 현재 상태를 출력할 수 있다. 12345678910111213&gt; np.get_printoptions(){'edgeitems': 3, 'threshold': 1000, 'floatmode': 'maxprec', 'precision': 8, 'suppress': False, 'linewidth': 75, 'nanstr': 'nan', 'infstr': 'inf', 'sign': '-', 'formatter': None, 'legacy': False} Numpy 에서 실수 Float 의 출력 형식을 바꾸는 몇가지 사례를 보자 - formatter 이용12import numpy as npnp.set_printoptions(formatter={'float_kind': lambda x: &quot;{0:0.3f}&quot;.format(x)}) - precision 이용123&gt; np.set_printoptions(precision=4)&gt; np.array([1.123456789])[1.1235] - threshold 이용개수가 많은 아이템을 출력할 때 요약해 출력할 수 있다. 123&gt; np.set_printoptions(threshold=5)&gt; np.arange(10)array([0, 1, 2, ..., 7, 8, 9]) numpy.printoptions 사용numpy.printoptions 를 with 구문과 함께 사용해 제한된 출력 조정을 할 수 있다. 출력시 printoptions 를 with 구문과 사용할 수 있다. set_printoptions 의 인자를 동일하게 적용할 수 있다 precision, threshold, edgeitems, linewidth, suppress, nanstr, infstr, formatter, sign, floatmode 1numpy.printoptions(*args, **kwargs)[source] 소수점 출력 변경 123456&gt; np.array([2.0]) / 3array([0.66666667])&gt; with np.printoptions(precision=3):&gt; print( np.array([2.0]) / 3 ) pandas 숫자 출력 형식 변경pandas에서 몇 가지 옵션을 바꾸는 방법을 정리해 보자. pandas의 옵션은 pd.options 를 사용한다. pd.options.display출력의 형태, 표기를 변경하는 것은 pd.options.display 아래에 있다. 여기서 사용할 수 있는 옵션은 describe_option() 으로 확인할 수 있다. 1234567&gt; pd.describe_option()compute.use_bottleneck : bool Use the bottleneck library to accelerate if it is installed, the default is True Valid values: False,True [default: True] [currently: True] ... - row, column 출력 개수 조정 pd.options.display.max_rows : 표를 출력할 때 최대 행 수입니다. pd.options.display.min_rows : 표를 출력할 때 최소 행 수입니다. 12345import pandas as pd&gt; pd.options.display.max_rows60&gt; pd.options.display.min_rows10 min_row, max_row에 직접 대입하면 해당 옵션의 현재 값이 변경된다. 123&gt; pd.options.display.min_rows=100&gt; pd.options.display.min_rows100 max_rows에 값을 입력하면 테이블의 최대 행수를 바꿀 수 있다. 이미지 참조 1 123&gt; pd.options.display.max_rows = 100&gt; pd.options.display.max_rows100 - pd.get_option(), pd.set_option() 함수pd.get_option() 함수를 이용해서 옵션인자에 대한 정보를 확인할 수 있다. 12&gt; pd.get_option('min_rows')100 get_option은 옵션 이름의 일부만 일치해도 된다. 12&gt; pd.get_option('min_r')100 max_rows 수를 설정한다. set_option도 일부만 일치해도 된다. 123456&gt; pd.set_option('max_rows', 20)&gt; pd.options.display.max_rows20&gt; pd.set_option('max_r', 50)&gt; pd.options.display.max_rows50 - 컬럼의 폭 조정display.max_colwidth 는 보통 50~70자 정도 정해져 있다. 컬럼에 표시되는 텍스트가 50자가 넘으면 ... 줄임 표시가 나타난다. 12&gt; pd.options.display.max_colwidth50 - chop_thresholdchop_threshold 는 값의 크기 한계를 지정해서 이 값보다 작은 수는 모두 0으로 표시한다. 123456&gt; pd.options.display.chop_threshold = 0.99&gt; pd.DataFrame({'x': [10, 1, 0.1]})&gt; print(x)0 10.01 1.02 0.0 숫자 포매팅다양한 사례는: https://pandas.pydata.org/docs/user_guide/options.html#number-formatting - float_formatfloat_format 는 실수 값을 출력시 소수점의 출력의 정밀도를 조정할 수 있다. 아래 람다 함수 lambda x: f'{x:.1f} 는 실수 x를 받아 소수점 첫째 자리까지 출력해 준다. 1234&gt; pd.options.display.float_format = lambda x: f'{x:.1f}'&gt; pd.DataFrame({'x': [3.141592]})x0 3.1 또한 set_option 을 사용할 수 있다. 1&gt; pd.set_option('display.float_format', '{:.2f}'.foramt ) 금액 단위에 사용하는 천단위 구분을 위해서 {:,.2f} 형식을 사용하면 화폐 단위를 추가하고 천단위 구분자를 추가해 주고 소수점 2자리수 정밀로를 지정한다. 12345&gt; pd.set_option('display.float_format', '${:,.2f}'.format )&gt; pd.DataFrame({'x': [10000000.0, 34589234.4]}) x0 $10,000,000.001 $34,589,234.40 - precision실수의 소수점은 precision 로 과학적 표기법으로 변환할 자릿수를 지정한다. 아래와 같이 하면 소수점 셋째 자리 밑으로는 과학적 표기법으로 표시합니다. 1234&gt; pd.options.display.precision = 3&gt; pd.DataFrame({'x': [0.5], 'y': [0.0005]})x y0 0.5 5.000e-04 과학적 표기법으로 3.000e-04는 3.000 이다. 자릿수가 아주 작거나 큰 수를 표기할 때 유용합니다. - 설정 초기화 reset_option()설정을 초기화할 때 사용한다. 1234# chop_threshold 옵션 초기화pd.reset_option('display.chop_threshold')# float_format 옵션 초기화pd.reset_option('display.float_format') - 옵션 설명 describe_option()pd.describe_option(OPTIONS) 를 사용하면 해당 옵션에 대한 설명을 출력해 준다. 12345&gt; pd.describe_option(&quot;max_rows&quot;)display.max_rows : int If max_rows is exceeded, switch to truncate view. Depending on `large_repr`, objects are either centrally truncated or printed as a summary view. 'None' value means unlimited. 참고1: Try These Pandas Display Configurations 2: Pandas options","link":"/pandas-numpy-display_format-5e6e2759a37b/"},{"title":"Hexo - icarus theme 설치: git기반","text":"이전 글 Hexo: icarus 테마 git기반 설치와 업그레이드 에 변경과 configurationsfile 을 더한 내용이다. static file 기반 블로엔진인 Hexo에서 테마로 icarus 를 사용하려고 한다. 여기서는 icarus theme를 git으로 설치한다. 그리고 최신 버전으로 업그레이드 하는 과정을 살펴본다. 또한 icarus theme의 구성 파일에 대해서 좀 더 세부적으로 살펴본다. Icarus theme git 설치 Configuration files Upgrade 1. Icarus theme git 설치icarus 테마는 getting-started-with-icarus 에 설명이 되어 있다. 여기서는 git 을 클론해서 사용해 보도록 하겠다. - git cloneicarus 릴리즈 페이지 https://github.com/ppoffice/hexo-theme-icarus/releases 를 확인해서 원하는 버전 번호를 찾는다. hexo 프로젝트 폴더에 들어가서 아래 같이 5.0.0 버전을 지정해서 클론을 수행한다. 12$ cd PROJECT_FOLDER$ git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus -b 5.0.0 --depth 1 클론한 결과는 아래 같은 폴더 구조를 갖는다. 123456themes/icarus ├── include ├── languages ├── layout ├── scripts └── source - 설정이제 hexo의 구성 파일 _config.yml 에 테마를 icarus 로 지정한다. 12#_config.ymltheme: icarus 그리고 icarus 구성 파일 _config.icarus.yml 에 먼저 버전을 명시하고 icarus 테마 관련 설정을 진행한다. 1version: 5.0.0 Configuration filesIcarus theme의 구성파일은, jyekyll 의 구성요소 + icarus 구성 파일로 제공한다. 구성 파일을 통해서 여러 형식의 화면 표현을 가능하게 한다. _config.yml 와 같은 위치에 있으면 된다. 아래는 구성파일의 우선순위 순서로 작성되어 있다: _config.yml: 사이트 구성 파일 (jekyll 의 기본 구성파일) hexo _config.yml _config.icarus.yml: Icarus theme 기본 구성파일. 레이아웃 구성 파일 _config.post.yml : 글 내용 POST 레이아웃 화면/위젯 구성 _config.page.yml : 페이지의 레이아웃 화면/위젯 구성 Jykell 의 Post/page front-matter (Deprecated) Legacy theme configuration file at themes/icarus/_config.yml (Deprecated) Legacy layout configuration file at themes/icarus/_config.post.yml and themes/icarus/_config.page.yml Layout Configuration Files레이아웃 구성은 icarus theme 의 구성파일과 같은 구조를 갖는다. 모든 블로그 포스트의 레이아웃을 위해서 _config.post.yml 파일을 참조한다. 그리고 _config.page.yml 은 사용자 지정 페이지를 위한 레이아웃에 적용된다. _config.icarus.yml 파일: 세 개의 컬럼으로 사이트의 레이아웃을 배치한다.12345678910widgets: - type: recent_posts position: left - type: categories position: right - type: tags position: right _config.post.yml 파일 POST는 위젯 위치를 left 로 두어서 위젯+본문의 두개 컬럼으로 구성된다. 12345678910widgets: - type: recent_posts position: left - type: categories position: left - type: tags position: left Post/Page Front-matter어떤 페이지/포스트에서 사이트/레이아웃 구성을 오버라이드 하려면 해당 포스트(글) 혹은 페이지의 Front-matter 로 구성해 사용하면 된다. 작성한 포스트 source/_post/some-post.md 에 선언한 Front-matter 구성. 12345678title: My first postdate: '2015-01-01 00:00:01'article: highlight: theme: atom-one-dark---# Some Post some-post.md 의 Front-matter 는 아래 사항을 오버라이드한다. _config.post.yml, _config.icarus.yml 의 article.highlight 를 atom-one-dark 로 재구성한다. 단, font-matter에서 title, date, updated, comments, layout, source, photos, and excerpt 등은 재정의 되지 않는다. Site Configuration File앞서 설명한 icarus 테마, 레이아웃, font matter 파일을 사이트 구성파일을 재정의 한 것이다. 3. Upgrade다른 버전의 icarus theme 로 업그레이드를 하려면 기존 폴더를 백업해 두고 다시 git clone을 통해 다운로드하고 _config.icarus.yml 구성 파일에 버전과 내용을 변경해서 사용하면 된다. 예를 들어 앞서 5.0.0 버전을 백업하고 5.1.1 버전으로 업그레이드 한다면 아래 같이 기존 irarus 를 icarus_5.0.0 같이 백업해 두고 새 버전이 잘 적응되는지 확인후 정리하면 된다. 12$ cd PROJECT_FOLDER/theme$ mv icarus icarus_5.0.0 이어서 새 버전을 git clone 한다. 1$ git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus -b 5.1.1 --depth 1 hexo의 구성 파일 _config.icarus.yml 에 새 icarus 테마 버전을 명시한다. 1version: 5.1.1 hexo 서버를 재시작해 정상적으로 동작하는지 확인한다. 그런데 필요한 npm 모듈 업그레이들 요구한다. 1234567891011121314151617$ hexo serverINFO Validating configInferno is in development mode.INFO ======================================= ██╗ ██████╗ █████╗ ██████╗ ██╗ ██╗███████╗ ██║██╔════╝██╔══██╗██╔══██╗██║ ██║██╔════╝ ██║██║ ███████║██████╔╝██║ ██║███████╗ ██║██║ ██╔══██║██╔══██╗██║ ██║╚════██║ ██║╚██████╗██║ ██║██║ ██║╚██████╔╝███████║ ╚═╝ ╚═════╝╚═╝ ╚═╝╚═╝ ╚═╝ ╚═════╝ ╚══════╝=============================================ERROR Package hexo-component-inferno's version (1.1.0) does not satisfy the required version (^2.0.2).ERROR Please install the missing dependencies your Hexo site root directory:ERROR npm install --save hexo-component-inferno@^2.0.2ERROR or:ERROR yarn add hexo-component-inferno@^2.0.2 요구에 따라 업그레이드 해주면 된다. 1$ npm install --save hexo-component-inferno@^2.0.2 정상적으로 업그레이드 되어서 server가 실행되는 것을 확인할 수 있다. 단, hexo clean 이후 에러를 만날 수 있어 보인다. 업그레이드 후 db.json 에러 대응clean 해서 새로 생성하기 위해서 clean 명령후 generate 를 2번 정도 실행하면 보통는 db.json 에러가 없어지는데 업그레이드 후 아래 같이 계속 발생한다. 123INFO === Registering Hexo extensions ===FATAL Error: [hexo-include-markdown] Could not open db.json . at ReadFileContext.callback (/Users/qkboo/work-blog/thinkbee.github.io/node_modules/hexo-include-markdown/lib/orverwriteCache.js:22:15) 블로그 solved-hexo-include-markdown 를 따라 다음 같이 처리했다. 1234#$ npm install hexo-include-markdown --save# clean &amp; generate$ hexo clean;echo &quot;{}&quot; &gt; db.json;hexo generate Upgrade to Icarus 5.2.12023/7월 Icarus 5.2.1 로 업그레이드 진행 1git clone https://github.com/ppoffice/hexo-theme-icarus.git icarus -b 5.2.1 _config.icarus.yml 에 icarus theme 버전을 명시한다. 1version: 5.2.1 서버를 재시작하고 확인한다. npm 모듈등… 문제가 없이 잘 진행된다. 참고 User guide: configurations","link":"/hexo03-icarus-install_new-17451b868f1a/"},{"title":"Python - 파이썬 프로젝트 패키징과 배포하기","text":"파이썬에서 작업한 소스를 공개/비공개 배포하기 위해서 패키징을 하는 방법을 요약, 정리했다. 파이썬 모듈 배포하기이 글은 setuptools, builds 그리고 PyPI 업로드를 위한 twine 를 사용하고 있다. [핵심 용어] PyPi, Python Package Index: 파이썬 사용자를 위한 오픈소스 패키지의 공개 저장소 일명 PyPi PyPa, 파이썬 패키징 위원회: 표준 패키징 도구/메타 데이터/파일 형식 표준을 GitHub 와 Bitbucket 을 통해서 여러 패키징 도구, 문서, 이슈 추적기를 관리하고 있다. distutils: 1998년/파이썬 표준 라이브러리 최초의 빌드 및 배포 시스템. 대부분 직접 사용이 단계적으로 폐지되고 있다. distutils는 파이썬 3.10부터 deprecated, 3.12에서 삭제될 예정. setuptools : 2004 공개/ distutils 의 드롭인(drop-in) 대체품. distutils 와 큰 차이는 다른 패키지에 대한 의존성을 선언할 수 있다. [pyproject.toml]: 2016년 setuptools의 메타 파일 setup.py 의존성을 피하고자 독립한 빌드용 선언적 메타정보 파일. wheel: distutils/setuptools 에 bdist_wheel 명령을 추가하는 프로젝트이다. 파이썬 라이브러리를 바이너리 확장을 포함/크로스 플랫폼 바이너리 패키징 형식 지원 (“휠”,”휠 파일”, PEP 427 정의). 도구 설치setuptools 기반 배포도구 설치 1python -m pip install setuptools wheel twine 파이썬 패키징https://packaging.python.org/en/latest/tutorials/packaging-projects/ 내용을 요약, 정리, 보충한다. 프로젝트 생성 패키징 수행하면 별도의 가상환경을 생성해서 진행한다. 프로젝트를 패키징하는 과정을 위해서 packaging_tutorial 폴더 아래에 같은 구조를 갖는다. 12345packaging_tutorial/└── src/ └── example_package_YOUR_USERNAME_HERE/ ├── __init__.py └── example.py example_package_YOUR_USERNAME_HERE : 프로젝트 이름이고 중복하지 않게 한다. __init__.py : 빈 파일로 폴더를 패키지로 인식하게 한다. example.py : 모듈. example.py 모듈 소스. 12def add_one(number): return number + 1 패키징용 파일 생성배포를 위한 프로젝트의 구성을 위해 패키징에 필요한 파일을 추가한 구조는 아래 같다. 123456789packaging_tutorial/├── LICENSE├── pyproject.toml├── README.md└── src/│ └── example_package_YOUR_USERNAME_HERE/│ ├── __init__.py│ └── example.py└── tests/ LICENSE : 라이센서 선언 pyproject.toml : 프로젝트 배포 프로젝트 생성에 사용하는 프론트엔드 빌드도구 pip, 백엔드 밸드도구 build README.md tests/ : 테스트 파일용 공간. Leave it empty for now. 패키징의 프론트엔드, 백엔드는 참조의 5번 항목을 살펴보자. pyproject.toml 구성보통 파일 내용은 아래 항목으로 구성한다. 이 파일은 TOML 형식의 구조를 따르고 있다. 여기에 대해서는 아래 참조 4번 항목 내용을 보기 바란다. 123456789[build-system]...[project]...[project.urls]... 빌드 도구를 명시하는 명세서 pyproject.toml에 setuptools 를 사용한 예이다. 123[build-system]requires = [&quot;setuptools&gt;=61.0&quot;]build-backend = &quot;setuptools.build_meta&quot; requires : 빌드용 도구 지시. build-backend : 프론트엔드 (pip)에서 빌드에 사용하는 백엔드 도구 다음은 Hatching 이란 빌드 도구를 사용한 예이다. 123[build-system]requires = [&quot;hatchling&quot;]build-backend = &quot;hatchling.build&quot; 메타 정보를 포함한 간단한 pyproject.toml 구성 결과. 12345678910111213141516171819202122[build-system]requires = [&quot;setuptools&gt;=61.0&quot;]build-backend = &quot;setuptools.build_meta&quot;[project]name = &quot;example_package_YOUR_USERNAME_HERE&quot;version = &quot;0.0.1&quot;authors = [ { name=&quot;Example Author&quot;, email=&quot;author@example.com&quot; },]description = &quot;A small example package&quot;readme = &quot;README.md&quot;requires-python = &quot;&gt;=3.7&quot;classifiers = [ &quot;Programming Language :: Python :: 3&quot;, &quot;License :: OSI Approved :: MIT License&quot;, &quot;Operating System :: OS Independent&quot;,][project.urls]&quot;Homepage&quot; = &quot;https://github.com/pypa/sampleproject&quot;&quot;Bug Tracker&quot; = &quot;https://github.com/pypa/sampleproject/issues&quot; 자세한 메타 정보 내역은 프로젝트 메타정보 정의를 참조한다. 주요 메타 정보의 인자: [project]: requires-python : 패키지가 요구하는 최소 파이썬 버전 명시 classifiers: pip가 인지하는 패키지에 대한 정보 README.md / LICENSE 파일README.md 파일에 패키지 모듈를 설명한다. 12345# Example PackageThis is a simple example package. You can use[Github-flavored Markdown](https://guides.github.com/features/mastering-markdown/)to write your content. LICENSE 파일에 저작권을 명시한다. 123Copyright (c) 2018 The Python Packaging AuthorityPermission is hereby granted, free of charge, to any person obtaining a copy 배포 묶음 생성하기배포를 위한 build 도구를 설치한다. 1python3 -m pip install --upgrade build packaging_tutorial 폴더 아래 pyproject.toml 파일이 있는 위치에서 배포를 위한 build 명령으로 소스를 패키징을 한다. build 를 수행하면 별도의 venv 가상환경을 생성해서 의존성에 명시된 setuptools 등을 설치하고 빌드를 진행한다. 1234567&gt; python3 -m build* Creating venv isolated environment...* Installing packages in isolated environment... (setuptools&gt;=61.0)......removing build\\bdist.win-amd64\\wheelSuccessfully built example_package_YOUR_USERNAME_HERE-0.0.1.tar.gz and example_package_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl 이 명령의 결과로 dist 폴더에 우리 프로젝트에 대한 배포용 패키징으로 소스 패키징 .gz 파일, built distribution 패키징 .whl 2개의 파일이 생성된다. 123dist/├── example_package_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl└── example_package_YOUR_USERNAME_HERE-0.0.1.tar.gz pip 로 wheeels 설치하기pip 에서 built distribution 파일을 직접 설치할 수 있다. installing-from-wheels 참조. 다음은 우리 프로젝트의 wheel 패키징을 설치한다. 1python -m pip install example_package_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl 혹은 provides_extras 메타 정보를 사용해 추가 설치를 한다면, 1python -m pip install './somepackage-1.0-py2.py3-none-any.whl[my-extras]' Upload처음 PyPi 에 업로드를 하려면 아래 2가지 단계를 거쳐서 진행해 본다. https://test.pypi.org/account/register/ 에서 등록 실제 pypi 가 아닌 튜토리얼과 테스트를 위한 곳. PyPi 업로드를 완성하려면 PyPI API token 을 발급받아야 한다. https://test.pypi.org/manage/account/#api-tokens PyPI에 업로드가 완료되면 pip 를 통해서 패키지를 설치할 수 있다. 업로드를 위해서 Twin 패키지를 설치하고 사용해야 한다. 1python3 -m pip install --upgrade twine twine 모듈을 사용해서 dist/ 아래의 모든 소스/휠 패키징 묶음을 업로드할 수 있다. 지금은 testpypi 에 업로드를 해보자. 1python3 -m twine upload --repository testpypi dist/* 업로드시 username은 __token__ 사용. 패스워드는 발급받은 pypi- 으로 시작하는 token 값. 업로드 진행은 아래 같을 것이다. 1234567Uploading distributions to https://test.pypi.org/legacy/Enter your username: __token__Uploading example_package_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 kB • 00:01 • ?Uploading example_package_YOUR_USERNAME_HERE-0.0.1.tar.gz100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 kB • 00:00 • ? 여기서 repository로 testpypi 를 지정했으므로 업로드한 결과는 다음 같이 확인할 수 있다. https://test.pypi.org/project/example_package_YOUR_USERNAME_HERE 저장소에서 설치하기위에 testpypi 에 업로드한 패키지를 설치하려면 아래 같이 --index-url 로 저장소를 지정해서 사용한다. 1python3 -m pip install --index-url https://test.pypi.org/simple/ --no-deps example-package-YOUR-USERNAME-HERE PyPI 에 업로드마지막으로 실제 패키지를 PyPI에 업로드하려면 https://pypi.org 등록을 하고, 등록한 사용자 아이디를 사용하고 --repository 인자를 제외하고 업로드하면 된다. 1python3 -m twine upload dist/* 통합 메타 정보로서 pyproject.toml 활용테스트, 코드 포맷팅 등에 대한 정보로 활용한다. 대표적으로는 코드 포맷팅 도구인 black, 테스트용 프레임워크인 pytest 등이 pyproject.toml에 설정 값을 저장하고 있다 - 파이썬 패키징의 역사, blog 12345# pyproject.toml of black[tool.black]line-length = 88target-version = ['py36', 'py37', 'py38']include = '\\.pyi?$' 다음이후에 다른 빌드 도구들, 테스트 도구들을 다뤄보자. poetry: Poetry를-사용하여-가상환경-만들기 poetry를 사용한 파이썬 dependency관리 참고 파이썬 모듈 배포하기, python.org Tool recommendations, python.org 주요 패키징에 필요한 도구 안내 파이썬 패키징의 역사, blog TOML의 이해와 기본 활용, itworld Python package의 build frontend 와 backend","link":"/python-packaging-start-48993e24137b/"},{"title":"bitbuket 에 SSH key 등록하기","text":"github, bitbucket 같은 클라우드 사이트에 Client 프로그램으로 SSH 접속을 위해서는 SSH 키 쌍 생성하고 클라우드 사이트에 등록해야 한다. 보통 github, bitbucket 등 같은 SSH 접근을 지원하는 사이트는 ssh-agent forwarding 방식을 사용한다. 클라이언트에서 ssh 키 쌍을 생성 클라이언트에 개인키를 ssh-agent 에 등록 클라우드 서비스에 공개키를 등록 클라이언트 프로그램에서 ssh 사용시 ssh-agent 등록한 개인키로 암호화 여기서는 bitbucket 을 예로 들고 있다. https://support.atlassian.com/bitbucket-cloud/docs/configure-ssh-and-two-step-verification/ 과정은 bitbucket 을 예로 들었지만 github 도 유사한 과정을 거친다. github에서 Key 등록에 대해서는 링크를 참조한다. github 에 SSH key 등록하기 SSH 구성과 2단계 인증Git Credential Manager (GCM) 를 git client 에서 bitbucket 에 접속해 사용하는데 이용할 수 있다. SSH 구성을 하지 않고 bitbucket 을 사용하려면 GCM 을 사용하면 된다. Git Credential Manager 단, GCM works over HTTPS, not SSH. 그래서 git clone https://{username}@bitbucket.org/{workspace}/{repository}.git 이렇게 요청해야 한다. 설명에 따라서 먼저 ssh host key 를 생성하고 bitbucket 에서 사용하는 개인용 ssh key 를 만든다. 이후 bitbucket 에 등록하면 된다. SSH Client Keys저장소에 접근하는 url은 HTTPS or SSH 에 따라 달라진다. HTTPS https://&lt;repo_owner&gt;@bitbucket.org/&lt;accountname&gt;/&lt;reponame&gt;.git SSH git@bitbucket.org:&lt;repo_owner&gt;/&lt;reponame&gt;.git or ssh://git@bitbucket.org/&lt;repo_owner&gt;/&lt;reponame&gt;.git bitbucket은 암호 알고리즘으로 keys: Ed25519, ECDSA, RSA, and DSA 를 지원한다. 예를 들어 아래 같이 생성한 공개키를 사용할 수 있다. 1234567891011#Ed25519 (ed25519) / 256$ ssh-keygen -t ed25519 -b 256# ECDSA (ecdsa) / 256$ ssh-keygen -t ecdsa -b 256# RSA (rsa) / 2048$ ssh-keygen -t rsa -b 2048# DSA / DSS (dsa) / 1024$ ssh-keygen -t dsa -b 1024 SSH Host Key 생성아래는 bitbucket 서버의 공개키 이다. 123256 SHA256:FC73VB6C4OQLSCrjEayhMp9UMxS97caD/Yyi2bhW/J0 bitbucket.org (ECDSA)256 SHA256:ybgmFkzwOSotHTHLJgHO0QN8L0xErw6vd0VhFA9m3SM bitbucket.org (ED25519)2048 SHA256:46OSHA1Rmj8E8ERTC6xkNcmGOw9oFxYr0WF6zWW8l1E bitbucket.org (RSA) 해당 공개키가 적적할지 확인은 다음 같이 curl 로 테스트해볼 수 있다. 1curl https://bitbucket.org/site/ssh 개별키 생성ssh 를 사용해서 bitbucket 클라우드에 접근하려면 사용하는 클라이언트에서 SSH 로 개인키와 공개키를 생성해야 한다. SSH 키를 생성하려면 아래 과정이 필요하다. Open SSH 설치 SSH 서비스 SSH 키 생성 여기서 Linux/macOS 그리고 Windows 11 에서 키 쌍을 생성해서 bitbucket에 등록하는 과정을 살펴보겠다. Windows 11에서 키 생성Windows 11 에서 Git 이 설치되어 있다고 가정. 123&gt; get-command gitApplication git.exe 2.38.1.1 C:\\Program Files\\Git\\cmd\\git.exe Openssh 확인 12&gt; ssh -VOpenSSH_for_Windows_8.6p1, LibreSSL 3.4.3 ssh 명령 위치 확인 1&gt; Get-Command ssh 결과 ssh 명령을 git config 로 ssh 명령을 지정 1git config --global core.sshCommand C:/Windows/System32/OpenSSH/ssh.exe SSH agent 시작git 이 ssh 키를 사용하려면 SSH agent 가 시작되어야 한다. 보통 Git for windows 와 Windows 11 이후 Windows OpenSSH 를 사용하므로 Windows OpenSSH 사용자는 다음 같이 agent를 확인하고 시작한다. 12345&gt; Get-Service ssh-agentStatus Name DisplayName------ ---- -----------Stopped ssh-agent OpenSSH Authentication Agent ssh-agent 서비스를 시작 하려면 Windows service에서 OpenSSH Authenticate Agent 서비스를 시작해 두어야 한다. 속성에서 시작으로 한다. 서비스가 정상적으로 시작되면 아래 명령으로 시작/종료 그리고 재시작을 할 수 있다. - 시작 안되어 있으면 알수없는 에러가 난다. 1&gt; Start-Service ssh-agent Git for windows 를 사용하면 Git for windows의 bash 터미널 에서 다음 같이 확인하고 시작한다. 1$ ps -a | grep ssh-agent ssh-agent 를 시작한다. 1$ eval $(ssh-agent) 에이젼트가 시작되면 git client 에서 ssh 정보를 얻을 수 있다. bitbucket에 사용할 SSH key pair를 생성ssh-keygen.exe로 키 쌍, 비밀키/공개키를 생성한다. 키를 생성시 bitbucket 계정의 e-mail 을 포함해 생성한다. 생성시 사용자 홈 디렉토리 .ssh 디렉토리에서 작업한다. 1&gt; ssh-keygen.exe -t rsa -b 4096 -C &quot;EMAIL&quot; -f &quot;KEY_FILE&quot; EMAIL: bitbucket 계정 이메일 KEY_FILE: 파일 이름. 보통 bitbucket_work .ssh 디렉토리에 키 쌍 KEY_FILE 과 KEY_FILE.pub 이 생성된다. 12345678910&gt; dir .ssh Directory: C:\\Users\\daddy\\.sshMode LastWriteTime Length Name---- ------------- ------ -----a--- 2023-06-25 오후 6:11 3381 bitbucket_work-a--- 2023-06-25 오후 6:11 744 bitbucket_work.pub-a--- 2020-11-08 오전 12:12 1675 id_rsa-a--- 2020-11-08 오전 12:12 404 id_rsa.pub 이제 키를 SSH Agent 에 등록하자. SSH Agent 에 키 등록키 파일을 SSH Agent 에 등록한다. KEY_FILE 은 비밀키 파일을 지정하면 된다. 1&gt; ssh-add ~/.ssh/KEY_FILE 그리고 명확하게 bitbucket 에 해당 키를 사용하도록 ~/.ssh/config 에 아래 같이 등록한다. 123Host bitbucket.org AddKeysToAgent yes IdentityFile ~/.ssh/KEY_FILE macOS / LinuxOpenssh 확인 12$ ssh -VOpenSSH_8.2p1 macOS, OpenSSL 1.1.1f 31 Mar 2020 ssh 명령이 없으면 macOS는 brew 로 설치한다. 1$ brew install openssh Linux 는 apt, dnf, pacman 을 사용해 설치한다. 1$ sudo apt update &amp;&amp; sudo apt install openssh-client SSH agent 시작git 에서 ssh 키를 사용하려면 SSH agent 가 시작한다. bash 터미널 에서 다음 같이 확인하고 시작한다. 1$ ps -a | grep ssh-agent ssh-agent 를 시작한다. 1$ eval $(ssh-agent) 이 명령을 ~/.bashrc, ~/.zshrc, ~/.profile, 등에 등록해 둔다. 에이젼트가 시작되면 git client 에서 ssh 정보를 얻을 수 있다. bitbucket에 사용할 SSH key pair를 생성ssh-keygen.exe로 키 쌍, 비밀키/공개키를 생성한다. 키를 생성시 bitbucket 계정의 e-mail 을 포함해 생성한다. 사용자 홈 디렉토리 .ssh 디렉토리에서 작업한다. 1$ ssh-keygen -t rsa -b 4096 -C &quot;EMAIL&quot; -f &quot;KEY_FILE&quot; EMAIL: bitbucket 계정 이메일 KEY_FILE: 파일 이름. 보통 bitbucket_work .ssh 디렉토리에 키 쌍 KEY_FILE 과 KEY_FILE.pub 이 생성된다. 12345678$ ls -l .sshMode LastWriteTime Length Name---- ------------- ------ -----a--- 2023-06-25 오후 6:11 3381 bitbucket_work-a--- 2023-06-25 오후 6:11 744 bitbucket_work.pub-a--- 2020-11-08 오전 12:12 1675 id_rsa-a--- 2020-11-08 오전 12:12 404 id_rsa.pub 이제 키 쌍를 SSH Agent 에 등록하자. SSH Agent 에 키 등록키 파일을 SSH Agent 에 등록한다. KEY_FILE 은 비밀키 파일을 지정하면 된다. 1$ ssh-add ~/.ssh/KEY_FILE 그리고 명확하게 bitbucket 에 해당 키를 사용하도록 ~/.ssh/config 에 아래 같이 등록한다. 123Host bitbucket.org AddKeysToAgent yes IdentityFile ~/.ssh/KEY_FILE Bitbucket Cloud with your public keybitbucket 을 위해 생성한 키 쌍에서 공개키 KEY_FILE.pub 를 bitbucket 의 계정에 등록해 주어야 한다. Settings -&gt; Personal Settings Secutiry -&gt; SSH Keys -&gt; Add key 생성한 키 쌍에서 bitbucket_work.pub 같이 공개키를 등록하는데, 공개키 파일 내용을 복사해 붙여넣기를 하면 된다. cat 명령 등으로 내용을 복사한다. 12345&gt; cat .\\.ssh\\bitbucket_work.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDo+7VGfxlhxFsy0Edu+PPmqngJVzwLQuLPanOi5x8t2yu7RmFNlEfU32AgA7vkoLno98XFZaUZ3ZjMwVu7LWeLMNczx5nH//......+v7ttamzvFe8idOtCjJszG5l8rn4poIN2E24AWGvCGbzs55WRXY/amYEqP5/maH0NT+pYM2ZMV7Nt8Jb86iQ== james@thinkbee.kr 사이트의 Add key 창에 붙여 넣는다. 이제 새 SSH 키가 등록되었다. 클라이언트에서 bitbucket 에 SSH 접속이 가능한지 테스트한다. 단, 모든 SSH 연결은 최초 접속시 호스트 접속 여부를 묻는다. 아래 같이 bitbucket.org 접속시 접속 여부를 묻는 다이얼로그가 나온다. 123456789$ ssh -T git@bitbucket.orgThe authenticity of host 'bitbucket.org (104.192.141.1)' can't be established.ED25519 key fingerprint is SHA256:ybgmFkzwOSotHTHLJgHO0QN8L0xErw6vd0VhFA9m3SM.This key is not known by any other namesAre you sure you want to continue connecting (yes/no/[fingerprint])? yesWarning: Permanently added 'bitbucket.org' (ED25519) to the list of known hosts.authenticated via ssh key.You can use git to connect to Bitbucket. Shell access is disabled 결과적으로 아래 같이 결과가 출력되면 성공한 상태다. 123authenticated via ssh key.You can use git to connect to Bitbucket. Shell access is disabled 이제 git 클라이언트에서 HTTPS, SSH 를 통해서 bitbucket 과 ssh 연결이 가능하다. git 클라이언트로 push, pull 등을 수행할 수 있다. 참고 https://support.atlassian.com/bitbucket-cloud/docs/configure-ssh-and-two-step-verification/ github 에 SSH key 등록하기","link":"/bitbucket-ssh_key%EB%93%B1%EB%A1%9D-131a9df6053f/"},{"title":"github 에 SSH key 등록하기","text":"github, bitbucket 같은 클라우드 사이트에 Client 프로그램으로 SSH 접속을 위해서는 SSH 키 쌍 생성하고 클라우드 사이트에 등록해야 한다. 보통 github, bitbucket 등 같은 SSH 접근을 지원하는 사이트는 ssh-agent forwarding 방식을 사용한다. 클라이언트에서 ssh 키 쌍을 생성 클라이언트에 개인키를 ssh-agent 에 등록 클라우드 서비스에 공개키를 등록 클라이언트 프로그램에서 ssh 사용시 ssh-agent 등록한 개인키로 암호화 여기서는 github 에 ssh key 등록 과정을 요약하고 있다. Connect with SSH github을 예로 들었지만 bitbucket 도 유사한 과정을 거친다. bitbucket 에 SSH key 등록하기 SSH 구성과 SSH 인증먼저 ssh host key 를 생성하고 github 과 사용할 개인 key 를 만든다. 개인키를 ssh-agent 방식으로 등록하고 공개키를 github 에 등록하면 된다. ssh-agent 키 관리로컬 머신에서 사용하는 SSH Key 쌍에 대한 접근을 ssh-agent 를 통해서 진행한다. managing deploy keys 에 설명되어 있다. 에이전트 전달은 로컬 개발 컴퓨터에서 사용하는 것과 동일한 SSH 키를 사용합니다. 단 사용자 클라이언트에 SSH에 있어야 합니다 SSH Client Keys저장소에 접근하는 url은 HTTPS or SSH 에 따라 달라진다. HTTPS https://&lt;repo_owner&gt;@github.com/&lt;accountname&gt;/&lt;reponame&gt;.git SSH git@github.com:&lt;repo_owner&gt;/&lt;reponame&gt;.git or ssh://git@github.com/&lt;repo_owner&gt;/&lt;reponame&gt;.git github은 암호 알고리즘으로 keys: Ed25519, ECDSA, RSA, and DSA 를 지원한다. 예를 들어 아래 같이 생성한 공개키를 사용할 수 있다. 12345678#Ed25519 (ed25519) / 256$ ssh-keygen -t ed25519 -b 256# ECDSA (ecdsa) / 256$ ssh-keygen -t ecdsa -b 256# RSA (rsa) / 2048$ ssh-keygen -t rsa -b 4096 개별키 생성ssh 를 사용해서 github 에 접근하려면 사용하는 클라이언트에서 SSH 로 개인키와 공개키를 생성해야 한다. SSH 키를 생성하려면 아래 과정이 필요하다. Open SSH 설치 SSH 서비스 SSH 키 생성 여기서 Linux/macOS 그리고 Windows 11 에서 키 쌍을 생성해서 github에 SSH Key를 등록하는 과정을 살펴보겠다. Windows 11에서 키 생성Windows 11 에서 Git 이 설치되어 있다고 가정. 123&gt; get-command gitApplication git.exe 2.38.1.1 C:\\Program Files\\Git\\cmd\\git.exe Openssh 확인 12&gt; ssh -VOpenSSH_for_Windows_8.6p1, LibreSSL 3.4.3 ssh 명령 위치 확인 1&gt; Get-Command ssh 결과 ssh 명령을 git config 로 ssh 명령을 지정 1git config --global core.sshCommand C:/Windows/System32/OpenSSH/ssh.exe SSH agent 시작git 이 ssh 키를 사용하려면 SSH agent 가 시작되어야 한다. 보통 Git for windows 와 Windows 11 이후 Windows OpenSSH 를 사용하므로 Windows OpenSSH 사용자는 다음 같이 agent를 확인하고 시작한다. 12345&gt; Get-Service ssh-agentStatus Name DisplayName------ ---- -----------Stopped ssh-agent OpenSSH Authentication Agent ssh-agent 서비스를 시작 하려면 Windows service에서 OpenSSH Authenticate Agent 서비스를 시작해 두어야 한다. 속성에서 시작으로 한다. 서비스가 정상적으로 시작되면 아래 명령으로 시작/종료 그리고 재시작을 할 수 있다. - 시작 안되어 있으면 알수없는 에러가 난다. 1&gt; Start-Service ssh-agent Git for windows 를 사용하면 Git for windows의 bash 터미널 에서 다음 같이 확인하고 시작한다. 1$ ps -a | grep ssh-agent ssh-agent 를 시작한다. 1$ eval $(ssh-agent) 에이젼트가 시작되면 git client 에서 ssh 정보를 얻을 수 있다. github에서 사용할 SSH key pair를 생성ssh-keygen.exe로 키 쌍, 비밀키/공개키를 생성한다. 키를 생성시 bitbucket 계정의 e-mail 을 포함해 생성한다. 생성시 사용자 홈 디렉토리 .ssh 디렉토리에서 작업한다. 1&gt; ssh-keygen.exe -t ed25519 -b 4096 -C &quot;EMAIL&quot; -f &quot;KEY_FILE&quot; EMAIL: github 계정 이메일 KEY_FILE: 파일 이름. 보통 bitbucket_work 참고: Ed25519 알고리즘을 지원하지 않는 레거시 시스템을 사용하는 경우 다음을 사용합니다. 1&gt;$ ssh-keygen -t rsa -b 4096 -C &quot;EMAIL&quot; -f &quot;KEY_FILE&quot; .ssh 디렉토리에 키 쌍 KEY_FILE 과 KEY_FILE.pub 이 생성된다. 12345678910&gt; dir .ssh Directory: C:\\Users\\daddy\\.sshMode LastWriteTime Length Name---- ------------- ------ -----a--- 2023-06-25 오후 6:11 3381 bitbucket_work-a--- 2023-06-25 오후 6:11 744 bitbucket_work.pub-a--- 2020-11-08 오전 12:12 1675 id_rsa-a--- 2020-11-08 오전 12:12 404 id_rsa.pub 이제 키를 SSH Agent 에 등록하자. SSH Agent 에 키 등록키 파일을 SSH Agent 에 등록한다. KEY_FILE 은 비밀키 파일을 지정하면 된다. 1&gt; ssh-add ~/.ssh/KEY_FILE 그리고 명확하게 github 에 해당 키를 사용하도록 ~/.ssh/config 에 아래 같이 등록한다. 123Host github.com AddKeysToAgent yes IdentityFile ~/.ssh/KEY_FILE macOS / LinuxOpenssh 확인 12$ ssh -VOpenSSH_8.2p1 macOS, OpenSSL 1.1.1f 31 Mar 2020 ssh 명령이 없으면 macOS는 brew 로 설치한다. 1$ brew install openssh Linux 는 apt, dnf, pacman 을 사용해 설치한다. 1$ sudo apt update &amp;&amp; sudo apt install openssh-client SSH agent 시작git 에서 ssh 키를 사용하려면 SSH agent 가 시작한다. bash 터미널 에서 다음 같이 확인하고 시작한다. 1$ ps -a | grep ssh-agent ssh-agent 를 시작한다. 1$ eval $(ssh-agent) 이 명령을 ~/.bashrc, ~/.zshrc, ~/.profile, 등에 등록해 둔다. 에이젼트가 시작되면 git client 에서 ssh 정보를 얻을 수 있다. github에 사용할 SSH key pair를 생성ssh-keygen.exe로 키 쌍, 비밀키/공개키를 생성한다. 키를 생성시 bitbucket 계정의 e-mail 을 포함해 생성한다. 사용자 홈 디렉토리 .ssh 디렉토리에서 작업한다. 1$ ssh-keygen -t rsa -b 4096 -C &quot;EMAIL&quot; -f &quot;KEY_FILE&quot; EMAIL: bitbucket 계정 이메일 KEY_FILE: 파일 이름. 보통 bitbucket_work 참고: Ed25519 알고리즘을 지원하지 않는 레거시 시스템을 사용하는 경우 다음을 사용합니다. 1&gt;$ ssh-keygen -t rsa -b 4096 -C &quot;EMAIL&quot; -f &quot;KEY_FILE&quot; .ssh 디렉토리에 키 쌍 KEY_FILE 과 KEY_FILE.pub 이 생성된다. 12345678$ ls -l .sshMode LastWriteTime Length Name---- ------------- ------ -----a--- 2023-06-25 오후 6:11 3381 bitbucket_work-a--- 2023-06-25 오후 6:11 744 bitbucket_work.pub-a--- 2020-11-08 오전 12:12 1675 id_rsa-a--- 2020-11-08 오전 12:12 404 id_rsa.pub 이제 키 쌍를 SSH Agent 에 등록하자. SSH Agent 에 키 등록키 파일을 SSH Agent 에 등록한다. KEY_FILE 은 비밀키 파일을 지정하면 된다. 1$ ssh-add ~/.ssh/KEY_FILE 그리고 명확하게 bitbucket 에 해당 키를 사용하도록 ~/.ssh/config 에 아래 같이 등록한다. 123Host github.com AddKeysToAgent yes IdentityFile ~/.ssh/KEY_FILE github 에 public key 등록하기github 계정의 SSH and GPG keys에서 등록해 주어야 한다. 키 쌍 중 공개키 KEY_FILE.pub 내용을 등록해 준다. Settings -&gt; Personal Settings ' > cat 명령 등으로 내용을 복사한다. 사이트의 Add key 창에 붙여 넣는다. 클라이언트에서 github SSH 접속이 가능한지 테스트한다. 단, 모든 SSH 연결은 최초 접속시 호스트 접속시 접속 여부를 묻는 다이얼로그가 나온다. https://docs.github.com/ko/authentication/connecting-to-github-with-ssh/testing-your-ssh-connection 결과적으로 아래 같이 결과가 출력되면 성공한 상태다. 123$ $ ssh -T git@github.comHi USER! You've successfully authenticated, but GitHub does not provide shell access. 이제 git 클라이언트에서 HTTPS, SSH 를 통해서 github 과 ssh 연결이 가능하다. git 클라이언트로 push, pull 등을 수행할 수 있다. 참고 Connect with SSH, github SSH 연결 테스트, github bitbucket 에 SSH key 등록하기","link":"/github-ssh_key%EB%93%B1%EB%A1%9D-654a33b9f5e1/"},{"title":"Jupyterlab 의 extension 을 설치하고 build 시 npm 에러.","text":"jupyterlab 의 확장 모듈을 다운받아 설치시 nodejs 실행 환경이 제공되야 한다. jupyterlab 확장 build errorjupyterlab 의 확장 모듈을 다운받아 설치하다 보면 npm 과 연계한 프로그램이 많다. 아래 같은 nodejs 관련 에러를 발생한다. 123456daddy&gt; jupyter lab build......An error occurred.RuntimeError: npm dependencies failed to installSee the log file for details: C:\\Users\\USERID\\AppData\\Local\\Temp\\jupyterlab-debug-4kr1lkn1.log 결론으로 현재 jupyterlab 을 실행하는 환경에서 nodejs 버전이 설치되어 있고 jupyterlab extensions가 활성화 되어 있다면 해당 로그 파일을 확인해 보면 대부분 nodejs 버전이 일치하지 않아서 아래 같은 로그를 기록하고 있어 보인다. 12error readable-stream@4.3.0: The engine &quot;node&quot; is incompatible with this module. Expected version &quot;^12.22.0 || ^14.17.0 || &gt;=16.0.0&quot;. Got &quot;14.15.0&quot;error Found incompatible module. nodejs 버전을 업그레이드 하고 빌드를 수행하니 잘 된다.","link":"/jupyterlab_extension_build_npm_error-1b7523ac01f3/"},{"title":"Docker CLI 요약","text":"docker cli 명령을 정리 이미지 소스 docker clidocker cli는 docker 명령 뒤에 docker commands 로 도커를 제어한다. 그리고 대상 컨테이너를 지정하고 컨테이너에서 실행 할 수 있는 명령형식으로 구성되어 있다. 1docker [docker commands] [container] [container command] Use the Docker command line docker search 이미지 검색Docker hub에서 이미지를 검색한다. 1docker search busybox Docker hub에서 상위 몇개 정도만 검색하고 싶을때 limit 옵션을 사용한다. 1docker search busybox --limit 5 Docker hub에서는 이미지 중 별점을 검색한다. 12345# 최소 별정 50인 이미지docker search busybox --filter=stars=50# 별점이 3인 이미지docker search --filter stars=50 busybox 정규 빌드 버전만 지시하려면 is-official 옵션 사용 12docker search --filter is-official=true --filter stars=50 busybox --format 옵션을 사용해 출력되는 내용을 필터링 할 수 있다. 다음은 별점만 출력하는 예이다. 1docker search --format &quot;{{.Name}}: {{.StarCount}}&quot; nginx pull 이미지를 다운로드 한다Docker image를 내려 받는다. 이미지 이름 뒤에 :[version] 을 붙이면 지정한 버전을 내려 받고, latest 를 붙이면 최신 버전을 대상으로 한다. 1docker pull nginx:latest images 다운로드 이미지Docker에서 다운로드 받는 이미지를 확인한다. docker images는 모든 이미지를 보여준다. 1$ docker images 특정 이미지만 지시할 수 있다. 1$ docker images nginx run 이미지를 컨테이너로 실행한다.Docker image를 컨테이너로 생성하고, 실행합니다. 1docker run -p 8080:8080 nginx 옵션: 12345`-p`: Local과 Container 와 port를 연결하는 옵션`-i`: interactive (대화방식)`-t`: Pseudo-tty (콘솔 및 터미널 환경)`— name`: 실행 컨테이너 이름을 지정합니다.`-d`: 백그라운드에서 실행되는 옵션입니다. docker image를 실행하고 bash 쉘을 연다. 1docker run -i -t --name nginx nginx bash ps 컨테이너 목록을 확인Docker 컨테이너 목록을 확인합니다. 12$ docker ps$ docker ps -a 옵션: 12`-a` : 실행 중이 아닌 컨테이너까지 확인`-q` : 컨테이너의 CONTAINER ID 만 표시 start 컨테이너를 시작한다.중단되어 있는 컨테이너를 실행합니다. 12docker start nginxnginx attach 컨테이너 연결실행중인 Docker Container 의 standard input, output, error streams 에 연결한다. 1docker attach nginx docker attach 명령 사용 사례. exec 컨테이너 명령 실행Docker Container의 쉘의 명령어을 실행할 수 있다. 1docker exec nginx ls 옵션 12345-d, --detach : 명령을 detach mode, 백그라운드로 실행-e, --env : 환경변수 설정하고 실행-it [SHELL]: iteractive tty 옵션. 사용할 shell을 지시한다, 보통 bash-u, --user: User ID, UID-w, --workdir: 작업 디렉토리 지정 다음은 nginx 컨테이너의 bash 쉘을 실행한다. 1docker exec -it nginx bash 다음은 nginx 컨테이너를 qkboo 사용자 쉘로 연결한다. 1docker exec -it -u qkboo nginx bash inspect 컨테이너 상세 정보Docker Container에 상세 정보를 확인 한다. 1docker inspect nginx 옵션 --format : 필터링 1docker inspect --format='{{range .NetworkSettings.Networks}} stop 컨테이너 종료ps 명령으로 실행중인 컨테이너 아이디와 이름을 확인하고 아이디를 준다. 123docker psdocker stop e417951d25fd 이름으로 종료시 --name 옵션 사용 1docker stop --name nginx2 rm 컨테이너를 삭제한다.Docker Container 삭제합니다. 삭제할때는 실행 상태가 아닌 컨테이너만 가능합니다. 1docker rm nginx 강제 삭제시 -f 옵션 사용. rmi 이미지를 삭제한다.Docker image를 삭제 하는데 이미지가 중첩된 경우가 많기 때문에 링크 같이 untag 한 후 사용한다. rim example 123docker rmi fd484f19954fdocker rmi test2:latest 혹은 -f 옵션으로 중첩된 이미지를 모두 함께 삭제 할 수 있다. 1docker rmi -f fd484f19954f 참고 Use the Docker command line docker Docker CLI 정리, blog","link":"/docker_cli_summary-84ee2a15f3e2/"},{"title":"MySqLI CLI 주요 명령","text":"mysql CLI 에서 사용하는 관리자 명령을 요약한다. create user, grant, drop, delete, remove MySqLI CLI Client 로 접속하기1mysql [-h서버] -u아이디 -p 데이터베이스명 데이터베이스 스키마1mysql&gt; SHOW DATABASES; use 명령을 사용하여 사용할 데이터베이스/스키마를 선택 1mysql&gt; USE TESTDB; 선택된 데이터베이스 안의 테이블 확인 12mysql&gt; SHOW TABLES;mysql&gt; SHOW TABLES LIKE 't%'; # t로 시작하는 테이블 특정 스키마 혹은 테이블의 생성 쿼리를 출력 12mysql&gt; SHOW CREATE DATABSE SAKILA;mysql&gt; SHOW CREATE TABLE STUDENTS; 데이터베이스의 생성 및 삭제1mysql&gt; CREATE DATABASE testdb CHARACTER SET utf8 COLLATE utf8_general_ci; utf8_general_ci 는 대소문자를 구분하지 않는다. 대소문자를 구분하려면 binary 타입으로 지정. 예) “utf8_bin” 캐릭터셋과 COLLATE 를 생략하면 서버 설치시 지정한 기본 값으로 설정 1mysql&gt; CREATE DATABASE testdb; 스키마 제거 1mysql&gt; DROP [SCHEMA]DATABASE testdb; 시스템 환경 확인서버의 환경 변수 123mysql&gt; SHOW VARIABLES;mysql&gt; SHOW VARIABLES LIKE 'innodb_%'; 지원하는 문자세트 123456mysql&gt; SHOW CHARACTER SET;mysql&gt; SHOW CHARACTER SET LIKE 'utf%';-- 환경변수에서 확인mysql&gt; SHOW VARIABLES LIKE 'c%'; 1234567지원하는 콜레이션```sqlmysql&gt; SHOW COLLATION;mysql&gt; SHOW COLLATION WHERE Charset = 'utf8mb4'; 실행 프로세스 확인현재 접속자를 확인하고, lock 이 걸린 프로세스를 죽이거나 하는 작업 프로세스 리스트보기 12345678mysql&gt; SHOW PROCESSLIST;+------+-----------+----------------------+-----------+---------+------+---------------------------------+------------------------------------------------------------------------------------------------------+----------+| Id | User | Host | db | Command | Time | State | Info | Progress |+------+-----------+----------------------+-----------+---------+------+---------------------------------+------------------------------------------------------------------------------------------------------+----------+| 1371 | dbkmart | 205.22.168.143:29762 | yourdb | Sleep | 2673 | | NULL | 0.000 || 프로세스 죽이기(프로세스 아이디는 리스트에 나오는 Id.) 1mysql&gt; kill 프로세스아이디 외부 파일 실행하기첫 번째는 mysql cli 에 지정하여 실행하는 방법 123$ mysql -u dbuser -p testdb &lt; insert.sqlEnter password: **** 두 번째 방법을 mysql cli에서 source 명령을 사용 1mysql&gt; SOURCE C:\\Users\\USERID\\insert.sql; User &amp; Privileges사용자 dbmysql 스키마의 user 테이블을 사용한다. SELECT Host,User,plugin,authentication_string FROM mysql.user; 사용자 추가사용자를 생성시 호스트 주소에 ‘%’, ‘localhost’로 호스트 범위를 지정한다 123mysql&gt; CREATE USER 'USERID'@'localhost' IDENTIFIED BY 'password';mysql&gt; CREATE USER 'USERID'@'%' IDENTIFIED BY 'password';mysql&gt; FLUSH PRIVILEGES; grant 명령: [권한 부여]사용자가 특정 자원에 접근하기 위해서 grant 명령 사용. 1GRANT ALL PRIVILEGES ON DB이름.테이블이름 TO 아이디@호스트 IDENTIFIED BY '비밀번호' with grant option; ALL PRIVILEGES : 모든 권한 추가 SELECT, INSERT, UPDATE, DELETE, … : 권한을 일부분을 추가 with grant option : GRANT를 사용할 수 있는 권한 추가 Grant 로 주어지는 권한은 여기 grant: privilege-levels 명령에서 찾을 수 있다. 아래는 userid 사용자가 특정 sampledb 에만 모든 권한을 부여하고 있다. 12mysql&gt; GRANT ALL PRIVILEGES ON sampledb.* TO 'USERID'@'localhost';mysql&gt; FLUSH PRIVILEGES; 다음 GRANT 명령에서 ALL PRIVILEGES ON *.* 는 모든 권한(ALL PRIVILEGES)을 모든 스카마의 모든 테이블 *.* 에 준다는 의미. 12mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'USERID'@'localhost' WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES; WITH GRANT OPTION 의 의미는 다른 사용자에게 자신이 가진 권한을 주거나 회수할 수 있다는 의미. ALL PRIVILEGES 부분에는 SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, INDEX, ALTER 등 권한 명칭을 콤마로 분리해서 나열하는 방식으로 특정 권한만을 줄 수도 있다. [권한 제거]권한을 없앨때는 REVOKE 명령을 사용한다. 두가지 형식을 사용한다. 123REVOKE priv_type ON db.tables FROM user[,user] ...REVOKE ALL PRIVILEGES, GRANT OPTION FROM user [, user] ... 아래 명령으로 ‘localhost’ 에서 접속가능한 ‘testdbuser’ 에게서 모든 권한을 제외한다. 1mysql&gt; REVOKE ALL PRIVILEGES *.* FROM 'USERID'@'localhost'; GRANT 명령과는 달리 REVOKE 명령은 모든 권한을 제거해도 mysql.user 테이블 사용자 정보는 완전히 삭제되지 않는다. 사용자 정보의 완전한 제거를 원한다면 DROP USER 명령을 사용한다. 1mysql&gt; DROP USER 'USERID'@'localhost'; 권한 조회사용자별 권한 확인 1mysql&gt; SHOW GRANTS FOR 'USERID'@'HOST'; 접속된 계정 권한 확인 1mysql&gt; SHOW GRANTS FOR CURRENT_USER; DataDump문자셋은 mysql&gt; show variables like 'c%' 를 이용해 확인! 1mysql&gt; mysqldump -u [username] –p[password] --default-character-set=utf8 -N --routines --skip-triggers --databases [database_name] &gt; [dump_file.sql] 사례: 문자셋 latin1 데이터 덤프https://itzone.tistory.com/711 — grant: privilege-levels : https://mariadb.com/kb/en/grant/#privilege-levels","link":"/mysql-admin-cli-c4134cfe1788/"},{"title":"Python 에서 secret 키 값 이용하기 - json","text":"크롤링, 데이터 베이스 연결등에 사용자 인증번호를 사용하는데 코드 자체에 아이디/비밀번호를 입력해서 사용하면 유출의 염려가 있으므로 이를 외부 파일에 두고 관리하고자 한다. 여러가지 방법이 있겠지만 여기서는 json 을 사용한다. key:value 형식의 properties, 윈도우 ini 같은 형식을 지원하는 configparser 모듈도 좋은 선택 같다. json 이용 키 관리외부에 아래 형식의 secret 파일을 생성한다. 디렉토리: .api_keys/ 폴더 사용 파일: secret_keys.json secret_keys.json123456789101112131415{ &quot;naver.com&quot; : { &quot;userid&quot;: &quot;UR_ID&quot;, &quot;password&quot; :&quot;votmdnjem&quot; }, &quot;apple.net&quot;: { &quot;userid&quot;: &quot;UR_ID&quot;, &quot;password&quot; : &quot;votmdnjem&quot; }, &quot;api.twitter.com&quot;: { &quot;CONSUMER_KEY&quot; : &quot;unJgTOc0aZkk7NoX4LlD5g&quot;, &quot;CONSUMER_SECRET&quot;:&quot;uHdmctDcPM66s9OasrKnr2x3pu88&quot;, &quot;ACCESS_TOKEN&quot; : &quot;98948674-J9auHiBiOGoWUJOzRafp&quot;, &quot;ACCESS_TOKEN_SECRET&quot; : &quot;kKgT9tlSY2rCIAbWJrCEEiTsR37&quot; }, &quot;my_database&quot; : { &quot;userid&quot; : &quot;UR_ID&quot;, &quot;password&quot; : &quot;votmdnjem&quot;}} 파일 사용json 모듈을 사용해서 해당 파일을 읽으면 키:값 형식으로 참조해서 사용할 수 있다. 1234import jsonwith open('../../.api_keys/secret_keys.json') as f: secrets = json.loads(f.read()) 이렇게 읽어들인 json 은 dict 같이 사용할 수 있다. 1DB_USER, DB_PW = secrets['my_database']['userid'], secrets['my_database']['password']","link":"/python_secret_file-bfd5b37c220c/"},{"title":"MariaDb 10&#x2F; MySQL 8 - data 디렉토리 변경 (Ubuntu)","text":"data 폴더 위치를 변경해 이동한다. 여기서는 MariaDB 를 사용하고 있다. rsync 를 사용해서 복사한다. 위치 이동my.cnf 에 있는 기본 디렉토리를 /data 폴더로 변경하고 적용한다. 기본 data 디레토리 확인 my.cnf 에서 datadir 로 지정된 항목을 찾아 보자. 12~$ grep datadir /etc/mysql/mariadb.conf.d/*/etc/mysql/mariadb.conf.d/50-server.cnf:#datadir = /var/lib/mysql 기본으로 Ubuntu 종류에서는 /var/lib/mysql 를 기본 데이터 디렉토리로 지정하고 있다. data 디렉토리를 /data 로 변경한다. my.cnf 를 수정해서 /data로 변경하자 1~$ sudo vi /etc/mysql/mariadb.conf.d/50-server.cnf data 폴더 권한 mysqld / mariadbd 데몬은 mysql 사용자, mysql 그룹으로 사용권이 실행되고 있다. 데이터베이스에서 접근하는 모든 자원(폴더, 파일, 로그 등등)은 mysql 사용자로 접근이 가는해야 한다. 그래서 /data 디렉토리 권한을 변경한다. mysql 사용자와 그룹 확인한다. 12345$ grep mysql /etc/passwdmysql:x:111:117:MySQL Server,,,:/nonexistent:/bin/false$ grep mysql /etc/groupmysql:x:117: 소유권을 mysql 사용자로 변경한다. 12345$ sudo chown -R mysql:mysql /data[sudo] 암호:$ ls -al /datadrwxr-xr-x 3 mysql mysql 4096 5월 6 22:35 .drwxr-xr-x 20 root root 4096 5월 6 17:15 .. data 이동 rsync 를 사용해서 /var/lib/mysql 데이터를 /data 아래로 복사한다. 1$ sudo rsync -avzph /var/lib/mysql/ /data/ mysqld 데몬을 재시작하고 확인한다. 1234$ sudo systemctl restart mysql$ sudo systemctl status mysql● mariadb.service - MariaDB 10.11.2 database server 데이터베이스에 접속해 데이터를 확인해 보자. @@datadir 환경변수를 출력해서 /data 가 출력되면 my.cnf 의 설정이 잘 구성된 상태를 확인할 수 있다. 12345678$ sudo mysql -u root -p&gt; select @@datadir;+-----------+| @@datadir |+-----------+| /data/ |+-----------+ rsync 로 복사한 실제 데이터들은 각 스키마에서 확인해 보자.","link":"/mariadb-data_dir_change-878fcb84a58d/"},{"title":"[git] Sparse Checkout","text":"git checkout 은 보통 브랜치의 모든 구조를 가져온다. checkout 은 다음 링크 설명을 보고 이해해 보자, visual-git-guide:checkout Sparse checkout 은 checkout 전체 대상중 일부 만을 checkout 할 수 있다. git sparse checkout 기능은 Git 2.25.0 이상부터 사용이 가능하다. Sparse checkout 이해git 블로그 글 Bring your monorepo down to size with sparse-checkout 의 그림 설명을 빌려오자. 다음 원격 레포지토리가 있다고 가정하자 전체 디렉토리 중에서 client/android 부분만 checkout 을 하고 싶다. 다음 같이 클론을 하고 sparse-checkout 을 초기화 한 후에 대상인 client/android 디렉토리를 sparse-checkout 하면 해당 디렉토리만 다운로드한다. 1234git clone https://github.com/tensorflow/examples.gitcd examplesgit sparse-checkout init --conegit sparse-checkout set client/android sparse-checkout 을 수행하면 해당 디렉토리 컨텐츠만 남게 된다. 사용 방법사용시 몇가지 사례가 있다. 방법1첫번째 방법으로 git 레포지토리를 클론한 후에 대상 파일/폴더를 지정하고 sparse-checkout 을 수행한다. 1git clone https://github.com/tensorflow/examples.git spase-checkout 을 수행하기 위해서 초기화 하고 대상이 되는 파일/폴더를 지정한다. 1234cd examplesgit sparse-checkout init --conegit sparse-checkout set lite/examples/object_detection/android_play_servicesgit pull origin master 희소 체크아웃을 사용하도록 git 인스턴스를 구성하면 지정한 파일/폴더만 남게 된다. 방법2레포지토리를 클론하지 않고 클라이언트에서 초기화 후 sparse-checkout 으로 대상 디렉토리를 지정한 후에 pull 을 수행한다. 원격 레포지토리를 지정한다. 1234mkdir &lt;repo&gt;cd &lt;repo&gt;git initgit remote add -f origin &lt;url&gt; spase-checkout 을 수행하기 위해서 초기화 하고 대상이 되는 파일/폴더를 set 으로 지정한다. 여러 파일/디렉토리를 추가할 수 있다. 12git sparse-checkout init --conegit sparse-checkout set lite/examples/object_detection/android pull 을 수행한다. 1234git pull origin masterFrom https://github.com/tensorflow/examples * branch master -&gt; FETCH_HEADUpdating files: 100% (61/61), done. 방법3방법2와 동일하지만 설정 파일을 통해서 수행하는 점만 다르다. 1234mkdir &lt;repo&gt;cd &lt;repo&gt;git initgit remote add -f origin &lt;url&gt; 원격 레포지토리를 지정하고 git 설정에 추가한다. 1git config core.sparseCheckout true checkout 하려는 파일과 폴더를 sparse-checkout 파일에 추가한다. 여러 파일/디렉토리를 추가할 수 있다. 12echo &quot;lite/examples/object_detection/android&quot; &gt;&gt; .git/info/sparse-checkoutecho &quot;lite/examples/bert_qa/android&quot; &gt;&gt; .git/info/sparse-checkout pull 을 수행한다. 1git pull origin master 참고 visual-git-guide: checkout Bring your monorepo down to size with sparse-checkout git-sparse-checkout git 사용, qkboo git 입문 git 발전","link":"/git-sparse_checkout-cd8f7ebc1855/"},{"title":"pip&#x2F;conda Proxy 사용하기","text":"회사 등에서 방화벽을 사용하는 경우 pip / conda 저장소에서 패키지 설치가 안되는 경우가 있다. 또한 방화벽 안에서 설치할 경우 SSL verification error 에러 발생으로 설치가 안되기도 한다. 이런 경우 직접 pip 혹은 conda 설치가 안되는 경우에 프락시 지정을 해서 사용이 가능하다. conda proxy.condarc 파일과 conda 명령 옵션으로 사용할 수 있다. .condarc 파일사용자 홈디렉토리 .condarc 파일에 proxy 구성을 한다. Using the .condarc conda configuration file 파일에 proxy_servers 구성해 사용한다. 123proxy_servers: http: http://IP_ADDRESS:8080 https: https://IP_ADDRESS:8080 ssl_verify: SSL verification error방화벽 때문에 파이썬 패키지를 설치할 때 SSL 인증 오류(SSL verification error)가 생겨 곤란할 때가 있다. 만약 프락시 인증서가 필요하면 pip 인증서를 추가하면 ssl verification 에러를 피할 수 있다. 1234proxy_servers: http: http://IP_ADDRESS:8080 https: https://IP_ADDRESS:8080ssl_verify: %programdata%\\pip\\dscert.crt conda --set 옵션 사용설정 파일 대신 conda 명령에서 --set 옵션을 사용하면 설정 파일을 편집해서 저장이 된다. 1conda config --set [설정내용] 다음은 ssl_verify 에 pip 인증서를 추가하거나 False 로 제외하고 사용하고 있다. 1conda config --set ssl_verify False 명령에서 즉시 사용할 때는 --add 옵션을 사용한다. pip proxypip 명령은 명려에서 옵션 pip proxy 옵션을 사용하거나 설정 파일 pip.ini 로 구성할 수 있다. pip Configuration pip.inipip는 사용자 구성에서 아래 같이 윈도우: %HOMEPATH%\\pip\\pip.ini 리눅스/맥: $HOME/.pip/pip.conf trusted-host 를 구성해 준다. 123456[global]proxy=http://IP_ADDRESS:8080trusted-host = pypi.python.org pypi.org files.pythonhosted.org ssl certSSL 의 경우 cert 옵션을 사용할 수 있다. 123456[global]cert=C:\\Users\\user\\pip\\cert.crtproxy=http://IP_ADDRESS:8080trusted-host = pypi.python.org pypi.org files.pythonhosted.org pip 명령 사용명령으로 직접 proxy 를 지정할 수 있다. 1pip install --proxy https://{proxy}:{port} {BINARY} 다음 같인 trusted-host 등도 지정 할 수 있다. 1pip install --upgrade --proxy https://IP_ADDRESS:8080 --trusted-host pypi.python.org --trusted-host pypi.org --trusted-host files.pythonhosted.org matplotlib numpy openpyxl xlrd xlwt pandas","link":"/pip_conda_Proxy-a4f7cea039ca/"},{"title":"HTTPS 를 위한 Private SSL","text":"Web server certificates 과정 Securing a web site with a server certificate 단계 비밀키를 생성한다. 비밀키로 CSR certificate siging requests 을 생성한다. CSR 을 CA 로 사인한다. 사인한 CERT 를 받고 설치한다. 1. 비밀키를 생성한다.rsa 를 사용해 4096크기 비밀키를 생성한다. 12345# cd /etc/ssl/private # openssl genrsa -out my_rsa.key 4096Generating RSA private key, 4096 bit long modulus (2 primes)# chmod 0600 private/my_rsa.key 1# chmod 0600 private/my_rsa.key Public Key 생성1명령: openssl rsa -in [private key 파일명] -pubout -out [파일명] 1# openssl rsa -in my_rsa.key -pubout -out my_rsa.pub 2. Create a CSR(certificate signing request) from this key,인증서 발급을 위한 필요한 정보를 담고 있는 인증서 신청서를 작성한다. 1명령어 : openssl req -new -key [private key 파일명] -out [파일명] 비밀키에서 CSR 파일 작성을 요청하면 아래 내용을 묻는다. 1# openssl req -new -sha256 -key ./my_rsa.key -out ./my_rsa.csr 1# openssl req -new -key private.key -out private.csr 인증서 발급을 위한 필요한 정보를 담고 있는 인증서 신청 형식 데이터 이다. Country Name (국가코드) KR State or Province Name (시/도의 전체이름) Seoul Locality Name (시/군/구 등의 이름) Songpa-gu Organization (회사이름) XXXX Organization Unit (부서명) Server Common Name (SSL 인증서를 설치할 서버의 Full Domain) www.xxxx.com Common Name 에는 인증서를 설치할 사이트의 도메인의 이름을 넣어야 한다. (ip, port, http, https 포함불가능) 4. CA 인증한 CRT 인증서 만들기CSR 을 CA에서 인증해 CRT 파일을 생성한다. 여기서는 비밀키와 CSR 요청서를 바탕으로 CRT 인증서를 생성한다. 1명령어 : openssl req -x509 -days [기간] -key [private key 파일명] -in [csr 파일명] -out [파일명] -days [기간] x509 를 이용하고 365일 사용 가능한 crt 인증서를 생성한다. 1openssl req -x509 -days 365 -key my_rsa.key -in my_rsa.csr -out my_rsa.crt -days 365 생성한 혹은 CA에서 받은 CRT 파일은 아래 같이 확인해 볼 수 있다. 1openssl x509 -text -in yourdomain.crt -noout 5. CRT 파일을 PEM 파일로 변환한다.1openssl x509 -in mycommoncrt.crt -out mycommonpem.pem -outform PEM [Tip] 인증서 Config 파일 (test.conf)위에서 만들다 보면 계속 같은 내용을 써야 한다. 그래서 그 부분을 파일로 만들어 놓고 csr, crt 생성할때 사용하면 된다. 12345678910111213141516171819202122[req]default_bits = 2048prompt = nodefault_md = sha256req_extensions = req_extdistinguished_name = dn[dn]C=KRST=SeoulL=SeoulO=COMPANYOU=DEVemailAddress=test@test.comCN = testmachine[req_ext]subjectAltName = @alt_names[alt_names]IP.1 = 111.111.111.111DNS.1 = test.com csr 을 생성한다. 1openssl req -new -key private.key -out private.csr -config test.conf csr, crt 파일을 생성한다. 1openssl req -x509 -days 365 -key private.key -in private.csr -out mycommoncrt.crt -days 365 -config test.conf 그리고 이렇게 해서 인증서를 만들었을때 subjectAltName 이 안들어간다 . 그 부분이 필요할 경우에는 이렇게 명령어를 사용하면 된다. 1openssl req -x509 -days 365 -key private.key -in private.csr -out mycommoncrt.crt -days 365 -config test.conf -extensions req_ext openssl 팁 몇가지CRT 파일 확인openssl x509 -text -noout -in &lt;인증서파일&gt; : 인증서 내용을 볼수 있다. Verifying Your Keys Match123openssl pkey -pubout -in .\\private.key | openssl sha256openssl req -pubkey -in .\\request.csr -noout | openssl sha256openssl x509 -pubkey -in .\\certificate.crt -noout | openssl sha256 NGINX 웹 서버 TLS 암호화 추가개인키와 TLS 인증서 crt 파일을 사용한다. 12$ sudo mkdir /etc/nginx/tls/private$ mv my_rsa.key my_rsa.crt /etc/nginx/tls/private 개인 키는 /etc/nginx/tls/private/my_rsa.key 파일에 저장됩니다. 개인 키 및 CSR(인증서 서명 요청) 생성 및 CA(인증 기관)에서 인증서 TLS 인증서는 /etc/nginx/tls/private/example.com.crt 파일에 저장됩니다. 1234567server { listen 443 ssl; server_name www.thinkbee.kr; root /home/qkboo/Home/www/thinkbee.kr/; ssl_certificate /etc/nginx/tls/private/my_rsa.crt; ssl_certificate_key /etc/nginx/tls/private/my_rsa.key;} 참고 Howto – Install a self signed web server certificate openssl quick reference guide Openssl로 SSL 을 위한 인증서 발급하기 (HTTPS),blog Nginx - HTTPS and Certificate SSL,blog NodeJS와 Nginx 웹 서버,blog","link":"/20230428-HTTPS_Private_SSL-4271241fb2d7/"},{"title":"parted로 Partition, Format하기","text":"새 디스크 / USB 저장장치를 리눅스 계열에서 사용하고자 할 때. 디스크 확인 lsblklsblk 명령은 디바이스 장치가 마운트 된 곳을 출력해 준다. 12345678NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTloop0 7:0 0 63.3M 1 loop /snap/core20/1828loop1 7:1 0 91.8M 1 loop /snap/lxd/23991sda 8:0 0 119.2G 0 disk├─sda1 8:1 0 1M 0 part├─sda2 8:2 0 1G 0 part /boot└─sda3 8:3 0 118.2G 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 118.1G 0 lvm / 새 디스크 장치(SSD, HDD, USB 등) 를 붙이고 다시 확인하면 새로운 디스크는 sd[a-z] 형식으로 표현된다. 아래 sdb 는 현재 파티션이 1개 존재하는 상태이다. 1234567891011$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTloop0 7:0 0 63.3M 1 loop /snap/core20/1828loop1 7:1 0 91.8M 1 loop /snap/lxd/23991sda 8:0 0 119.2G 0 disk├─sda1 8:1 0 1M 0 part├─sda2 8:2 0 1G 0 part /boot└─sda3 8:3 0 118.2G 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 118.1G 0 lvm /sdb 8:16 0 931.5G 0 disk└─sdb1 8:17 0 931.5G 0 part [USB 장치] USB 장치는 mmcblk[0-9] 형식으로 표시된다. 참고 Raspberry Pi:mmcblk 123456789$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 119.2G 0 disk├─sda1 8:1 0 84.5G 0 part└─sda6 8:6 0 28.9G 0 part /mmcblk0 179:0 0 7.5G 0 disk├─mmcblk0p2 179:2 0 6.8G 0 part /media/qkboo/ROOT├─mmcblk0p3 179:3 0 486.1M 0 part└─mmcblk0p1 179:1 0 200M 0 part /media/qkboo/EFI parted 사용파티션 및 포맷을 위해 마운트된 파티션을 언마운트 한다. parted 는 상호작용 프롬프트에서 사용하거나 단일 명령어로 사용할 수 있다. parted 프롬프트 사용[ext4 파티션 생성] 1234567891011121314151617sudo parted /dev/sdb(parted) printNumber Start End Size File system Name Flags 1 0.00GB 32.0GB 32.0GB(parted) mklabel gptWarning: The existing disk label on /dev/sda will be destroyed and all data onthis disk will be lost. Do you want to continue?Yes/No? y(parted) unit GB(parted) mkpart primary 0 1000.0GB #디스크 크기 입력(parted) printNumber Start End Size File system Name Flags 1 0.00GB 32.0GB 32.0GB primary lvm(parted) quit [fat32 파티션 생성] USB 스토리지는 아래 같이 나타난다. 다음은 USB 파티션에 fat32 파일시스템을 프롬프트로 생성하고 있다. 12345sudo parted /dev/mmcblk0(parted) mklabel msdos(parted) mkpart primary fat32 1MiB 100%(parted) set 1 boot on(parted) quit 쉘에서 parted 명령 사용parted 를 쉘 명령으로 사용해 단계별로 파티션을 생성할 수 있다. 123sudo parted /dev/mmcblk0 rm 1sudo parted /dev/mmcblk0 rm 2sudo parted /dev/sdc mkpart primary ext3 4MiB 100% Format, Mount &amp; fstab생성한 파티션에 시스템 지원 파일 시스템을 생성해야 한다. 해당 파일 시스템으로 파티션을 포맷한 후에 지정한 디렉토리에 마운트를 해서 사용하면 된다. 지속적인 사용을 위해서 /etc/fstab 에 파티션을 마운트 포인트로 등록하면 재시동 후에도 동일한 폴더에 마운트 된다. mkfsmkfs 명령은 파일 시스템에 따랴서 -t 옵션에 파일시스템을 지시하거나 mkfs.[FS] 형식을 명령을 바로 쓰기도 한다. 다음을 sdb1 파티션을 ext4 로 포맷하고 있다. 1sudo mkfs -t ext4 /dev/sdb1 [USB vfat 파일시스템 생성] 1sudo mkfs -V -t vfat /dev/mmcblk0p1 fstab 에 등록/etc/fstab 에 새로 포맷한 디스크 경로를 추가 한다. 123456# HDD/dev/sdb1 /Home2 ext4 defaults 0 1# USB LV volume/dev/vg_usb/dbvol /data ext4 defaults 0 1/dev/vg_usb/workvol /home/pi/work ext4 defaults 0 1 참고 Raspberry Pi:mmcblk, qkboo SD Card 포맷 및 디스크 이미지 사용하기, qkboo Linux LVM2,qkboo","link":"/linux-disk-partition_format-a1ed845ba2be/"},{"title":"Duplicate class ... in module kotlin-stdlib-1.8.0","text":"모듈 build.gradle 에서 모듈의 dependencies 의존성을 잘못 선택하면 여러 에러가 발생하는데. 이번에 최신버전 등으로 건드리면 만나는 에러중 하나가 Depllicated 같은 에러인거 같다. 원래 의존성은 아래 같다. 123456dependencies { implementation 'androidx.appcompat:appcompat:1.6.1' // CameraX core library def camerax_version = '1.2.0-alpha04' implementation &quot;androidx.camera:camera-core:$camerax_version&quot; Android Studio의 Assistance 가 build.gradle 에서 의존성 모듈에 대한 최신버전이 제시되었다. 아래 같이 변경했다. 1234dependencies { // CameraX core library def camerax_version = '1.3.0-alpha03' // '1.2.0-alpha04' implementation &quot;androidx.camera:camera-core:$camerax_version&quot; 그래해 해당 모듈의 최신버전으로 선택했더니 아래같은 에러가 발생했다. 그랬더니 그림 같은 에러가 발생하게 되었다. 원래 버전 혹은 해당 Minor 최신버전으로 변경하니 문제가 사라졌다. 123dependencies { def camerax_version = '1.2.1' implementation &quot;androidx.camera:camera-core:$camerax_version&quot; 모듈 들의 의존성 버전은 조심해서 건드리자…ㅎㅎ","link":"/duplicate_class_kotlin-stdlib-1.8.0-915d09c76edf/"},{"title":"WSL2 잘 사용하기","text":"WSL2 이용 Linux 사용시 쓸만한 팁 wsl 사용 명령 wsl 하위 시스템 디렉토리 wsl 구성 파일 wsl 외부 디스크 마운트 하기 1. wsl 사용 명령윈도우즈 하위 시스템 목록12345# Linux용 Windows 하위 시스템의 목록PS&gt; wsl -l# Linux용 Windows 하위 시스템의 상태를 표시PS&gt; wsl --status 윈도우즈 하위 시스템 리셋하위 시스템 배포본을 지정해 종료한다. 1234PS&gt; wsl -lUbuntu-20.04(기본값)PS&gt; wsl -t Ubuntu-20.04 shutdown모든 하위 시스템을 종료 시키려면 --shutdown 명령을 사용한다. --shutdown 명령은 실행 중인 모든 배포과 WSL 2 경량 유틸리티 가상 머신을 즉시 종료한다. 1PS&gt; wsl --shutdown 2. Windows 하위 시스템 디렉토리윈도우즈와 하위 시스템의 디렉토리를 탐색기에서 직접 접근하기윈도우즈에서 네트워크 경로로 WSL 하위 시스템 디렉토리를 접근할 수 있다. 1\\\\wsl$\\&lt;Distribution&gt;: 예를 들어 하위 시스템 이름이 Ubuntu-20.04 이고 계정이 qkboo 이라면 탐색기에서 qkboo 계정의 홈디렉토리를 이렇게 접그할 수 있다. 1\\\\wsl$\\Ubuntu-20.04\\home\\qkboo 아래는 윈도우즈 탐색기에서 wsl 홈디렉토리를 접근한 캡쳐 화면인다. 터미널에서 홈디렉토리 탐색기 열기터미널에서 윈도우즈 탐색기를 직접 열 수 있다. 1$ explorer.exe . 3. WSL 고급 설정 구성배포본 구성 파일 wsl.conf 와 전역 구성 파일 .wslconfig 이 있다. wsl config file 전역 구성 파일 .wslconfig 위치: C:\\Users\\&lt;UserName&gt;\\.wslconfig 커널 메모리 크기 프로세서 개수 스왑 디버그 콘솔 등등. https://learn.microsoft.com/ko-kr/windows/wsl/wsl-config#wslconfig wslconfig 예제 파일 1234567891011121314151617181920212223242526272829303132# Settings apply across all Linux distros running on WSL 2[wsl2]# Limits VM memory to use no more than 4 GB, this can be set as whole numbers using GB or MBmemory=4GB # Sets the VM to use two virtual processorsprocessors=2# Specify a custom Linux kernel to use with your installed distros. The default kernel used can be found at https://github.com/microsoft/WSL2-Linux-Kernelkernel=C:\\\\temp\\\\myCustomKernel# Sets additional kernel parameters, in this case enabling older Linux base images such as Centos 6kernelCommandLine = vsyscall=emulate# Sets amount of swap storage space to 8GB, default is 25% of available RAMswap=8GB# Sets swapfile path location, default is %USERPROFILE%\\AppData\\Local\\Temp\\swap.vhdxswapfile=C:\\\\temp\\\\wsl-swap.vhdx# Disable page reporting so WSL retains all allocated memory claimed from Windows and releases none back when freepageReporting=false# Turn off default connection to bind WSL 2 localhost to Windows localhostlocalhostforwarding=true# Disables nested virtualizationnestedVirtualization=false# Turns on output console showing contents of dmesg when opening a WSL 2 distro for debuggingdebugConsole=true 배포본 구성 파일 wsl.conf 위치: /etc/wsl.conf wsl1, wsl2 배포본에 대한 구성을 지정한다. 단, Windows 빌드 17093 이상에서만 사용할 수 있다. systemd 지원 automount 지원DrvFS 지원interop 설정 등등 wsl.conf 구성 설정 wsl.conf 예제 123456789101112131415161718192021222324252627282930313233# Automatically mount Windows drive when the distribution is launched[automount]# Set to true will automount fixed drives (C:/ or D:/) with DrvFs under the root directory set above. Set to false means drives won't be mounted automatically, but need to be mounted manually or with fstab.enabled = true# Sets the directory where fixed drives will be automatically mounted. This example changes the mount location, so your C-drive would be /c, rather than the default /mnt/c. root = /# DrvFs-specific options can be specified. options = &quot;metadata,uid=1003,gid=1003,umask=077,fmask=11,case=off&quot;# Sets the `/etc/fstab` file to be processed when a WSL distribution is launched.mountFsTab = true# Network host settings that enable the DNS server used by WSL 2. This example changes the hostname, sets generateHosts to false, preventing WSL from the default behavior of auto-generating /etc/hosts, and sets generateResolvConf to false, preventing WSL from auto-generating /etc/resolv.conf, so that you can create your own (ie. nameserver 1.1.1.1).[network]hostname = DemoHostgenerateHosts = falsegenerateResolvConf = false# Set whether WSL supports interop process like launching Windows apps and adding path variables. Setting these to false will block the launch of Windows processes and block adding $PATH environment variables.[interop]enabled = falseappendWindowsPath = false# Set the user when launching a distribution with WSL.[user]default = DemoUser# Set a command to run when a new WSL instance launches. This example starts the Docker container service.[boot]command = service docker start 4. wsl 외부 디스크 마운트 하기윈도우즈 wsl 에서 리눅스 파티션 혹은 USB 파티션 디스크를 마운트해서 사용하려고 한다. https://learn.microsoft.com/en-us/windows/wsl/wsl2-mount-disk 관리자 모드에서 Powershell 을 연다. 파워쉘에서 연결된 디스크 목록을 확인한다. 1234567PS&gt; GET-CimInstance -query &quot;SELECT * from Win32_DiskDrive&quot;DeviceID Caption Partitions Size Model-------- ------- ---------- ---- -----\\\\.\\PHYSICALDRIVE0 ST2000DM008-2FR102 1 2000396321280 ST2000DM008-2FR102\\\\.\\PHYSICALDRIVE1 WDS500G3X0C-00SJG0 4 500105249280 WDS500G3X0C-00SJG0\\\\.\\PHYSICALDRIVE2 ATA HGST HTS721010A9 USB Device 1 1000202273280 ATA HGST HTS721010A9... 관리자 모드 PowerShell 에서 마운트할 Device ID를 마운트 한다. --bare 를 사용해 마운트 여부를 확인할 수 있다. 1PS&gt; wsl --mount \\\\.\\PHYSICALDRIVE2 --bare WSL 리눅스 터미널에서 디스크를 확인한다. 아래 같이 마운트를 실행한다. 1234PS&gt; wsl --mount \\\\.\\PHYSICALDRIVE2 -type ext4디스크가 '/mnt/wsl/PHYSICALDRIVE2'(으)로 탑재되었습니다.참고: /etc/wsl.conf에서 automount.root 설정을 수정한 경우 위치가 달라집니다.디스크를 분리하고 분리하려면 'wsl.exe --unmount \\\\.\\PHYSICALDRIVE2'을 실행하십시오. 파티션을 마운트 한다면 1234PS&gt; wsl --mount \\\\.\\PHYSICALDRIVE2 -p 1 # partition 1디스크가 '/mnt/wsl/PHYSICALDRIVE2p1'(으)로 탑재되었습니다.참고: /etc/wsl.conf에서 automount.root 설정을 수정한 경우 위치가 달라집니다.디스크를 분리하고 분리하려면 'wsl.exe --unmount \\\\.\\PHYSICALDRIVE2'을 실행하십시오. 연결된 디스크가 sdd 에 표시된다. 1234567~$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 363.1M 1 disksdb 8:16 0 8G 0 disk [SWAP]sdc 8:32 0 256G 0 disk /mnt/wslg/distrosdd 8:48 0 931.5G 0 disk└─sdd1 8:49 0 931.5G 0 part 어떠 파일 시스템인지 확인하려면 lsblk -f 명령을 사용한다. 12345678~$ lsblk -fNAME FSTYPE LABEL UUID FSAVAIL FSUSE% MOUNTPOINTsda ext4sdb swap 44bcbb9a-3a2c-44db-99e4-9c14dec69098 [SWAP]sdc ext4 3255683f-53a2-4fdf-91cf-b4c1041e2a62 159.1G 32% /mnt/wslg/distrosdd└─sdd1 ext4 9b3c51ab-a49b-41c7-a105-fb9d47a86476(3.11.1)qkboo@desktop-goyangi:~$ df 명령으로 확인해 보자, 12345678910s$ df -hFilesystem Size Used Avail Use% Mounted onnone 16G 4.0K 16G 1% /mnt/wsldrivers 465G 397G 69G 86% /usr/lib/wsl/driversnone 16G 0 16G 0% /usr/lib/wsl/lib/dev/sdc 251G 80G 160G 34% /.../dev/sdd1 917G 852G 19G 98% /mnt/wsl/PHYSICALDRIVE2p1","link":"/wsl2-usage-2b45762ab581/"},{"title":"","text":"Opensuse errorEmergency Mode 로 들어간 경우 “systemctl –failed -l 1journalctl -b http://susepaste.org/? 사이트에 올린다. btrfs check –repair /dev/sda6","link":"/opensuse-show-error-4330d8d15348/"},{"title":"[요약] 영상 분야에서의 인공지능 발달 단계에 따른 데이터와 모델의 변화","text":"다음 2개의 글을 요약하고 설명을 추가로 검색해 요약해 두었다. 인공지능 학습용 영상 데이터 기술 동향, IITP 주간기술동향 1988호, 임철홍 영상 분야에서의 인공지능 발달 단계에 따른 데이터와 모델의 변화, IITP 주간기술동향 2071호, 김혜진_한국전자통신연구원 책임연구원 2023/01/15 요약 작성 1 [요약] 영상 분야에서의 인공지능 발달 단계에 따른 데이터와 모델의 변화IITP 주간기술동향 2071호등록자 / 영상 분야에서의 인공지능 발달 단계에 따른 데이터와 모델의 변화 김혜진_한국전자통신연구원 책임연구원 I. 발전1세대 1950년대에서 80년대에 이르기까지의 규칙ㆍ지식에 기반을 둔 추론 시스템 2세대 제프리 힌튼(Geoffrey Hinton)과 얀 리쿤(Yann LeCun), 요슈아 벤지오(Yoshua Bengio)에 의해 시작된 특정 문제에 국한된 데이터셋으로부터 학습을 통해 습득하는 AI 2세대라 할 수 있다 3세대 범용적인 문제를 해결할 수 있는 인공지능 인공지능 하이프 사이클 II. AI 2세대의 데이터최근 2세대 AI 들은 널리 알려진 형태로, 다양한 분야에서 데이터를 모으려는 노력을 바탕으로 발전되고 있다. 다양한 공개 데이터세트를 비교해 공개된 데이터셋에서 성능에 대한 비교를 포함하는 것이 거의 필수 요소가 되었다. 이미지 분류 데이터 세트인공지능 학습용 영상 데이터 기술 동향, IITP, 주간기술동향 1988 에 정리 MNIST 숫자 10종류에 대해 7만 장의 이미지로 구성되어 있다 ImageNet 영상 downstream task에서 pretrained network로 사용되고 있는 데이터셋 중 하나로, 1,000종류, 14,197,122의 이미지로 구성되어 있다. CIFAR CIFAR-10, CIFAR-100으로 각각 10종류, 600장과 100종류,60,000장의 이미지가 있다 영상에서 객체 검출 데이터 세트이미지의 상황을 이해하여 캡션 등을 자동으로 생성하기 위한 연구가 진행되면서 다중 객체 인식을 기반으로 장면 설명, 객체 간의 관계 등의 데이터가 필요하게 되었다 MS COCO[1], PASCAL VOC 2012[2] 등이 객체 검출을 목적으로 구축된 데이터셋이다. 구글 Open Image STANDFORD와 YAHOO의 Visual Genome 객체 검출 알고리즘으로 널리 알려진 R-CNN, YOLO 계열의 알고리즘들도 모두 이 데이터셋을 기반으로 개발되었다.[1][2] MS COCO (Common Object in COntext)이미지의 객체 인식, 분할, 캡션 인식을 위한 공개된 데이터 셋이다. 330,000개의 이미지에서 80개 분류 1,500,000개의 객체 인스턴스를 가지고 있다. Flickr의 이미지를 기반으로 학습과 테스트가 진행되었다 COCO 홈페이지 데이터 셋 메뉴에서 explorer를 선택하면 직접 데이터 셋을 볼 수가 있는데, 위 그림 처럼 선택된 분류 객체가 분할된 이미지를 볼 수 있다. 앞에 있는 것은 ‘person’이 선택되어 사람 객체가 분할되어 보이며, 뒤에 있는 것은 ‘car’가 선택되어 자동차 객체가 분할되어 보인다. [2] 데이터 셋은 이미지 원본파일과 이를 설명하는 annotation 파일로 구성된다. annotation 파일은 captions, instances, person_keypoints 파일로 구성되며,json 형태로 되어 있다. 각 json 파일은 전체 이미지에 대해 하나로 구성되어 있어 크기 매우 크다. annotation 에는 개체에 대한 정보가 info, license, images, annotations, categories 등으로 제공된다. https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch Open ImageOpen Image는 구글에서 공개한 오픈 이미지 데이터 셋이다. 이미지 수준 레이블(image-level labels), 객체 경계 상자(object bounding boxes), 객체 분할 마스크(segmentation masks), 시각적 관계(visual relationships), 나레이션(localized narratives)을 포함하는 데이터 이다. 2016년 처음 공개 Introducing the Open Images Dataset 2018년 V4 Announcing Open Images V4 and the ECCV 2018 Open Images Challenge 2020년 2월 V6 Open Images V6 — Now Featuring Localized Narratives Open Image V4Open Image V4는 9,178,275개의 이미지에서 30,113,078개의 이미지 수준 레이블과 15,440,132개의 객체 경계 상자를 가지고 있으며, 374,768개의 시각적 관계를 나타내고 있다. Flickr 에서 고해상도, creative common, crowd sourcing 라이센스 위주로 수집 이미지 분류는 구글 데이터셋 JFT 의 19,794개 분류 체계 Announcing Open Images V4 and the ECCV 2018 Open Images Challenge Bounding Box객체 경계 상자는 이미지에서 객체 인식에 활용되기 위한 정보이다. 그림 - google ai blog 바운딩 박스를 통해서 객체 경계 상자에 나타난 객체들은 서로 관계를 맺고 있으며, Open Image에서 이들의 시각적 관계가 아래 같이 같이 점선박스로 보여진다. 그림 - google ai blog: https://ai.googleblog.com/2020/02/open-images-v6-now-featuring-localized.html Open Image V5Open Image V5에서는 350개 카테고리의 2,800,000개의 객체 분할 마스크가 추가되었다 Open Image V6Open Image V6에서는 675,000개의 나레이션이 추가되었다. Open Images V6 — Now Featuring Localized Narratives 나레이션은 이미지를 설명하는 캡션과 음성 설명이 포함되어 있고 음성 설명과 캡션에 해당하는 사물이나 동작등을 마우스로 그린 트레이스가 포함되어 있다 Visual GenomeVisual Genome은 지식 베이스의 이미지 데이터 셋으로 이미지의 구조를 언어와 연결하려고 노력하고 있다. 108,077개의 이미지에 5,400,000개의 지역 설명과 3,800,000 개의 객체, 2,800,000개의 속성, 2,300,000개의 관계로 구성되어 있다. 데이터 셋은 지역 설명(region descriptions), 객체(Objects), 속성(attributes), 관계(relationships), 지역 그래프(region graphs), 장면 그래프 (Scenegraphs) 및 질문답변으로 구성되어 있다 그림 - https://paperswithcode.com/paper/visual-genome-connecting-language-and-vision/ 지역 설명은 객체의 상태나 동작을 나타내고 있으며, 이들은 객체와 속성으로 나누어 설명되며, 각각 그래프의 형태로 간단하게 표현될 수 있다. 이미지의 여러 지역(region)은 합쳐져서 전체 장면 설명을 하는 장면 그래프로 표현된다. 1 1 의미론적 분할(Semantic Segmentation)이미지 분류와 객체 검출과도 연관이 깊은분야로, Cityscapes[3], ADE20K[4], PASCAL VOC2012[5] 등이 있다 Cityscapes는 도시 환경에서의 의미론적 분할을 ADE20K는 sky, road, grass, person,car, bed 등 150종목에 대한 장면 중심의 영상 분할을 다룬다. PASCAL Context는 PASCALVOC 2010의 확장판으로 400종 이상의 레이블을 제공한다. 거리 추정이미지와 영상에서 빼놓을 수 없는 분야 중 하나로 실외 거리 추정을 위해서는 KITTI 데이터셋[6]이 실내는 NYU v2[7] 데이터셋이 널리 활용되어 왔다 이미지 생성 분야2세대 AI는 데이터가 충분할수록 성능 향상을 기대할 수 있는 학습 기반 인공지능으로 이미지 생성 분야는 이러한 데이터를 “생성” 하는 데 활용을 기대할 수 있기 때문에 데이터 관점에서 2세대 AI에서의 이룬 괄목할 만한 성과 중 하나라 할 수 있다. 널리 알려진 이미지 생성 데이터셋으로는 CelebA 10,177명의 유명인사에 대한 202,599 얼굴이미지로 이루어졌다. FFHQ 연령, 인종, 다양한 배경 변화를 가진 70,000 고해상도 영상들로 이루어졌다. III. 데이터 부족에 대한 논의기존에 AI 연구는 빅데이터를 가정하고 있으나 실제 데이터 분석 사례에서는 빅데이터가 아닌 경우가 많다.데이터가 적고 레이블에 일관성이 없는 경우에는 모델을 아무리 개선을 한다고 해도(즉, model-centric 접근 방식을 적용) 성능을 개선하기 어렵다는 것을 2021년 3월 25일 Deep Learning AI에서 주최한 앤드류 응 교수가 보여주었다. 대응 이러한 문제를 해결하기 위해 컴퓨터 비전 분야의 저명한 학회인 CVPR(Computer Vision and Pattern Recognition) 학회에서는 2020년부터 2022년에 걸쳐 limited labeled data와 관련된 워크샵을 다루었으며, 합성 데이터를 만들어 데이터 부족 문제를 극복하려는 많은 시도가 있었다. BMW와 같은 자동차 제조업체뿐만 아니라, 은행, 공장, 병원, 로봇 등 다양한 분야에서 이러한 합성 데이터를 기반으로 AI 모델 학습에 적용하고 있다 가트너, 미래는 합성데이터2021년 6월 보고서에 따르면 2030년에는 AI의 대부분의 데이터가 합성 데이터를 기반으로 생성될 것으로 보고, 2024년까지 AI 및 분석에 사용되는 데이터의 60%가 이 합성데이터를 사용할 것이라고 예측 실제 데이터를 얻는 비용이 인건비 수준에서 많게는 수십억에 이르는 문제가 있기 때문이다. 반면에, 합성 데이터를 만들어 더욱 정확한 레이블을 얻을 수 있는 경우도 많다. 예를 들어, 거리 추정 데이터의 경우 센서의 정확도가 한계가 있어 픽셀에 매핑되는 거리 레이블의 정확도가 떨어진다. 반면, 합성 데이터의 경우에는 모든 픽셀에서 높은 정확도의 거리 레이블링 데이터를 얻을 수 있다. 즉, 합성데이터는 앞서 언급한 앤드류 응 교수가 지적한 레이블의 품질 저하 문제를 일으키지 않기 때문에 더 정확한 모델 학습이 가능할 수 있다. 합성데이터합성 데이터를 얻는 방법에는 시뮬레이션으로 얻는 방법, AI 기법(GAN, VAE, Normalizing Flow) 또는 도메인 랜덤화 등이 널리 알려져 있다. 최근에는 확산 모델(Diffusion model)[15]과 NeRF[16]의 등장으로 한층 더 정교해졌다 대표적인 확산 모델로 오픈 AI의 DALL-E 2의 백본 모델이 있다. 확산 오토인코더(Diffusion Autoencoder)와 같이 의미론적 의미가 있는 확산 모델도 제안 NeRF는 기존의 방법들이 시점에 대한 변화를 주기 어려웠던 점에 반해, 차량 앞면을 보고, 뒷면을 생성할 수 있는 등 다양한 시점에서의 영상을 생성할 수 있다. 더 나아가, 2D 이미지에서 3D 이미지를 생성함으로써 영상의 스케일 변화까지 줄 수 있어 데이터 합성에 있어 큰 전환점을 마련하였다 DALL-E 2 backbone Model이미지와 텍스트의 관계를 학습하고, 이를 통해, 영상에 다양한 변화를 줄 수 있게 했을 뿐만 아니라 텍스트를 통해 고해상도의 이미지를 생성 부족한 데이터 문제를 극복하기 위한 방법으로 자기지도학습(self-supervised learning) 방법자기지도학습 방법은 비지도학습과 유사하게 레이블 없는 데이터셋에서 사용자가 직접 정의한 작업(pretext task)를 목표로 학습시키게 된다. 이 때, 이 작업은 데이터에서 레이블로 사용될 수 있는 정보를 활용하여 지도학습처럼 학습시키게 되어 데이터 부족 문제를 우회적으로 풀 수 있게 된다. IV. AI 3세대를 지향하는 디딤돌 데이터셋의 등장자기주도학습 데이터세트 하나의 태스크에 국한되어 있지 않은 응용성을 가진 데이터셋이 점점 더 다양하게 등장하고 있다. 이러한 현상은 영상 내에서만 국한되지 않고, 텍스트를 포함하고 더 나아가 구조화된 데이터, 3D 신호 데이터 등 점점 더 다양한 데이터셋을 포함하는 방향으로 확장되고 있다. 이렇게 이기종의 빅데이터를 학습시키게 되면 파운데이션 모델(foundation model)을 얻을 수 있게 된다. 이러한 파운데이션 모델은 대규모 데이터로 사전학습되어 다른 모델에 지식을 전달해 줄 수 있는 모델을 의미한다 자기주도학습이 비지도학습과 달리 지도학습에 견줄 수 있는 성능을 획득하게 된 것은 Pretext task 단계에서 큰 데이터셋을 활용할 수 있는 덕분이다. KITTI 데이터셋KITTI 데이터셋은 거리 추정을 포함한 2D/3D 객체 검출, 도로 환경에서의 의미론적 분할 정보, 주행거리계(odometry), 도로 환경에서 객체 추적, 차선 검출 등 다양한 정보를 포함하고 있다.KITTI 데이터셋이 자율주행을 위해 필요로 하는 데이터셋을 포함하고 있어 자율주행 기술 발전에 공헌한 바가 크기때문이다 주요 블로그 글 KITTI 데이터 세트 KITTI 데이터 세트/데이터 분해 설명 파운데이션 모델:파운데이션 모델은 스탠포드의 인간중심 인공지능연구소에서 2021년 처음으로 대중화한 용어로 소개되었다. 그러나 파운데이션 모델의 가능성은 먼저 초거대 AI로 불리는 모델들인 BERT, DALL-E 2, GPT-3로부터 시작되었다. 초거대 AI는 초기에는 언어모델에 국한되었으나, 점차 이미지를 함께 포함하는 모델로, 또는 다양한 언어를 포함하는 모델로 확장되고 있다 초거대 AI초거대 AI는 초기에는 언어 모델에 국한되었으나, 점차 이미지를 함께 포함하는 모델로, 또는 다양한 언어를 포함하는 모델로 확장되고 있다([표 4] 참조) 최근 발표된 GODEL은 주제를 변경하고 학습시에 주어지지 않은 이벤트에 대한 질문에 응답할 수도 있고, 구조화되지 않은 텍스트를 통해 검색할 수 있게 하며, 대화식 질문에도 응답이 가능한 모델로 인공지능 3세대의 자격요건에 한층 더 가까워졌다. GODEL(Grounded Open Dialogue Model)가상비서나 챗봇과 같은 대화 에이전트가 레스토랑 추천과 같은 주제별 전문 지식을 제공하는 것 외에도 지역의 역사나 최근 스포츠 경기에 대한 대화에 참여할 수 있다면 어떨까? 또한 에이전트의 응답이 최근의 이벤트와 이슈를 지속적으로 반영한다면 어떨까? 고델은 마이크로소프트가 2019년에 발표한 최초의 대규모 사전 훈련 언어 모델인 DialoGPT의 개선된 대화형 언어 모델이다. 고델은 응답할 수 있는 쿼리 유형과 가져올 수 있는 정보 소스에 제한이 없는 대화 에이전트를 만드는 것을 목적으로 한다. https://www.microsoft.com/en-us/research/project/godel/ 기사/블로그: 마이크로소프트, 비학습 데이터로 응답하는 언어 모델 “고델(GODEL)” 공개 마이크로소프트에 따르면 고델은 대화 에이전트에 대화 내용 뿐만 아니라 훈련에 사용된 데이터에 포함되지 않은 외부 정보를 기반으로 응답을 생성할 수 있는 기능을 제공한다. 지역의 레스토랑에 대한 추천을 얘기하는 갑자기 최근에 발생한 토네이도에 대한 얘기를 했을때 웹에서 관련 정보를 가져와 응답하고 원래 주제로 돌아 가려고 하는 내용을 보여준다. 그림 - https://www.microsoft.com/en-us/research/blog/godel-combining-goal-oriented-dialog-with-real-world-conversations/ 대용량 데이터 세트의 구축이 초거대 AI 개발 근간초거대 AI의 개발은 근간이 되는 대용량 데이터셋이 구축된 덕분이다. 구글의 경우 18억 건의 데이터셋을 구축했고 오픈 AI의 경우 10억 건 수준으로 알려져 있다[25]. 카카오 브레인은 정제를 거친 20억 건 수준의 이미지ㆍ테스트 데이터를 구축하고 있다[26]. 영상을 중심으로 하는 파운데이션 모델은 비전-언어 사전학습 모델(Vision-Language Pretraining:VLP)의 형태로 CLIP, Florence, CoCa 등이 알려져 있다. Open AI의 CLIP은 이미지와 자연어 4억 개 쌍의 관계를 학습한 것이다. 마이크로소프트의 Florence 모델은 30억 개의 이미지-텍스트 쌍의 데이터에 이 중 필터링을 통해 9억 쌍을 얻은 FLOD-9M 데이터셋을 구축하여 학습한 모델이다. 구글의 CoCa는 다양한 벤치마크에서 우수한 성능을 보였을 뿐만 아니라 ImageNet에서의 Zero-shot 성능이 86.3%로 매우 우수한 성능을 얻었다. Zero-shot에서의 우수한 성능은 다양한 하위 과제에서 높은 성능을 얻을 가능성을 보여준다. 즉, 영상만의 대용량보다는 언어 데이터와 쌍을 이루어 학습함으로써 더욱 좋은 표현력을 얻을 수 있게 되었다. 양질의 충분한 데이터 문제인공지능 모델은 양질의 데이터만 충분하다면 문제를 해결할 수 있다는 생각이 널리 퍼져 있다. 한편, 양질의 데이터는 비용 문제, 레이블링의품질 문제, 보안 등으로 충분한 확보가 어려움도 널리 공감을 받고 있다. 합성 데이터 알고리즘들의 발전과 파운데이션 모델에 기반하여 적응(adaptation)에 필요한 적은 데이터만 확보하면 되도록 하는 기술의 발전으로 제3세대 인공지능은 스스로 문제에 대한 데이터를 확보 할 수 있는 AI로 한 걸음씩 다가가고 있다 [1]: 인공지능 학습용 영상 데이터 기술 동향, IITP 주간기술동향 1988호, 임철홍 [2]: 영상 분야에서의 인공지능 발달 단계에 따른 데이터와 모델의 변화, IITP 주간기술동향 2071호, 김혜진_한국전자통신연구원 책임연구원","link":"/%EC%98%81%EC%83%81%EB%B6%84%EC%95%BC%EC%97%90%EC%84%9C%EC%9D%98_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EB%B0%9C%EB%8B%AC_%EB%8B%A8%EA%B3%84%EC%97%90_%EB%94%B0%EB%A5%B8_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80%EB%AA%A8%EB%8D%B8%EC%9D%98_%EB%B3%80%ED%99%94,IITP,%EC%A3%BC%EA%B0%84%EA%B8%B0%EC%88%A0%EB%8F%99%ED%96%A52071%ED%98%B8-af3a1ae10287/"},{"title":"Hexo: icarus 테마 git기반 설치와 업그레이드","text":"2023-07-09에 작성한 Hexo - icarus theme 설치: git기반 가 최신 글이다. Hexo 의 테마인 icarus 를 git 을 통해 설치하고 원하는 버전으로 업그레이드 하는 과정을 살펴본다. Icarus theme git 설치 Upgrade 1. Icarus theme git 설치icarus 테마는 getting-started-with-icarus 에 설명이 되어 있다. 여기서는 git 을 클론해서 사용해 보도록 하겠다. - git cloneicarus 릴리즈 페이지 https://github.com/ppoffice/hexo-theme-icarus/releases 를 확인해서 원하는 버전 번호를 찾는다. hexo 프로젝트 폴더에 들어가서 아래 같이 5.0.0 버전을 지정해서 클론을 수행한다. 12$ cd PROJECT_FOLDER$ git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus -b 5.0.0 --depth 1 클론한 결과는 아래 같은 폴더 구조를 갖는다. 123456themes/icarus ├── include ├── languages ├── layout ├── scripts └── source - 설정이제 hexo의 구성 파일 _config.yml 에 테마를 icarus 로 지정한다. 12#_config.ymltheme: icarus 그리고 icarus 구성 파일 _config.icarus.yml 에 먼저 버전을 명시하고 icarus 테마 관련 설정을 진행한다. 1version: 5.0.0 2. Upgrade다른 버전의 icarus theme 로 업그레이드를 하려면 기존 폴더를 백업해 두고 다시 git clone을 통해 다운로드하고 _config.icarus.yml 구성 파일에 버전과 내용을 변경해서 사용하면 된다. 예를 들어 앞서 5.0.0 버전을 백업하고 5.1.1 버전으로 업그레이드 한다면 아래 같이 기존 irarus 를 icarus_5.0.0 같이 백업해 두고 새 버전이 잘 적응되는지 확인후 정리하면 된다. 12$ cd PROJECT_FOLDER/theme$ mv icarus icarus_5.0.0 이어서 새 버전을 git clone 한다. 1$ git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus -b 5.1.1 --depth 1 hexo의 구성 파일 _config.icarus.yml 에 새 icarus 테마 버전을 명시한다. 1version: 5.1.1 hexo 서버를 재시작해 정상적으로 동작하는지 확인한다. 그런데 필요한 npm 모듈 업그레이들 요구한다. 1234567891011121314151617$ hexo serverINFO Validating configInferno is in development mode.INFO ======================================= ██╗ ██████╗ █████╗ ██████╗ ██╗ ██╗███████╗ ██║██╔════╝██╔══██╗██╔══██╗██║ ██║██╔════╝ ██║██║ ███████║██████╔╝██║ ██║███████╗ ██║██║ ██╔══██║██╔══██╗██║ ██║╚════██║ ██║╚██████╗██║ ██║██║ ██║╚██████╔╝███████║ ╚═╝ ╚═════╝╚═╝ ╚═╝╚═╝ ╚═╝ ╚═════╝ ╚══════╝=============================================ERROR Package hexo-component-inferno's version (1.1.0) does not satisfy the required version (^2.0.2).ERROR Please install the missing dependencies your Hexo site root directory:ERROR npm install --save hexo-component-inferno@^2.0.2ERROR or:ERROR yarn add hexo-component-inferno@^2.0.2 요구에 따라 업그레이드 해주면 된다. 1$ npm install --save hexo-component-inferno@^2.0.2 정상적으로 업그레이드 되어서 server가 실행되는 것을 확인할 수 있다. 단, hexo clean 이후 에러를 만날 수 있어 보인다. 업그레이드 후 db.json 에러 대응clean 해서 새로 생성하기 위해서 clean 명령후 generate 를 2번 정도 실행하면 보통는 db.json 에러가 없어지는데 업그레이드 후 아래 같이 계속 발생한다. 123INFO === Registering Hexo extensions ===FATAL Error: [hexo-include-markdown] Could not open db.json . at ReadFileContext.callback (/Users/qkboo/work-blog/thinkbee.github.io/node_modules/hexo-include-markdown/lib/orverwriteCache.js:22:15) 블로그 solved-hexo-include-markdown 를 따라 다음 같이 처리했다. 1234#$ npm install hexo-include-markdown --save# clean &amp; generate$ hexo clean;echo &quot;{}&quot; &gt; db.json;hexo generate","link":"/hexo02-icarus-install-6a03e08f0fce/"},{"title":"R 시작하기, 2022","text":"R과 R Studio 를 설치하고 R 의 기본환경을 이해하기 위해 정리한다. old version: R 소개R은 벨 연구소 Becker 등에 의해 개발됐던 S language를 기반으로 통계 계산, 시각화를 위한 프로그래밍 언어를 포함한 개발환경이다. S language를 이용한 Insightful사의 S+는 S 언어를 이용한 상업용 소프트웨어이고, R은 공개소프트웨어 기반의 소프트웨어 이다. 예) Excel, SPSS, SAS, HLM, MPlus 등 통계 프로그램 R 학습 자료 K-MOOC: 데이터과학을 위한 R프로그래밍, 이혜선 (포항공과대학교) R프로그래밍및실습, Jinseog Kim (동국대학교) 설치R 프로그래밍 엔진은 R 을 다운로드하고 GUI 도구로 R Studio를 사용할 수 있다. CRAN mirror http://r-project.org 에서 R Download 한다. http://r-project.org R Studio IDE Old Version RStudio 설치 http://www.RStudio.com Download R 시작하기R 은 console을 통해 프로그래밍을 하거나 외부 에디터에서 작성한 소스를 컴파일해서 실행 할 수 있다. R 엔진을 IDE 를 통해서 개발한 코드를 실행하고 테스트 할 수 있다. macOS에서 R 시작시 다음 같은 경고를 보이면 macOS FAQ를 참고해 설정을 해주어야 한다. &gt; [그림. ] R과 R Studio 화면R promptR을 실행하면 명령 입력 프롬프트 &gt; 을 볼 수 있다. 프롬프트에서 한 줄에 하나 혹은 한문장의 명령이 입력되고 실행된다. 1234567&gt; print(&quot;Hello World&quot;)&gt; Factorial(10) # 계산 기능&gt; Rep(x=&quot;hello&quot;, times=5)&gt; Rep(times=5) : Error…&gt; Plot(10,10)&gt; Plot(c(5,7), c(20, 30))&gt; Plot(runif(100), runif(100)) # runif()는 랜덤 넘버 생성 함수 프롬프트 &gt; 에 명령을 입력하고 엔터키를 실행이 되지만 코드 블럭 괄호((),{},[])가 닫히지 않으면 프롬프트에 + 에 연결해서 계속 입력할 수 있다. 1234567[Workspace loaded from ~/work-R/R기본사용/.RData]&gt; print('hello r studio'+ 'greeting me'Error: unexpected string constant in:&quot;print('hello r studio''greeting me'&quot; R Studio IDE R Studio IDE에서 작성 가능한 R 프로그래맹 편집기 종류를 살펴보면, R Notebook 코드 작성중 package 요구 R 이용R 사용 환경에 도움이 되는 구성을 살펴보자 한글 폰트 지정나눔고딕코딩 폰트를 다운받아 설치한다. R 환경설정에서 Nanum font 사용한다. help() 사용R에서 도움말을 통해 함수, 형식, 등의 정보를 얻을 수 있다. 1&gt; help(“함수명”) 패키지를 로드하지 않은 함수의 도움말 보기 1&gt; help.search(“함수명”) 내가 얻은 패키지는 어떤 것인가? 1&gt; help(package=”알고싶은 패키지명”) 주요 도움말 명령 사용 12345678910&gt; help() # 도움말 창&gt; help(ls) # 함수 ls()에 대한 도움말&gt; ?ls # 도움말 단축키 ?로 help(ls) 호출&gt; help(&quot;&gt;&quot;) # R의 예약어, 연산자 등은 &quot;&quot;로&gt; help(&quot;for&quot;) # 묶는다.&gt; #특정 패키지에 대한 도움말 요청&gt; help(package=&quot;datasets&quot;)&gt; # 일반 검색어를 이용해 도움말 검색&gt; help.search(&quot;Latex&quot;)&gt; ??&quot;Latex&quot; 샘플로 제공하는 예제를 사용할 수 있도록 검색을 지원한다. 1234567&gt; example(&quot;formula&quot;)formul&gt; class(fo &lt;- y ~ x1*x2) # &quot;formula&quot;[1] &quot;formula&quot;formul&gt; foy ~ x1 * x2 objectR은 동적 객체 방식을 사용한다. 아래는 hello 변수를 선언하고 값을 대입한다. 이렇게 대입되면 R에서 객체로 다뤄진다. 123&gt; hello &lt;- “안녕하세요&quot; #유니코드 문자열&gt; hello[1] “안녕하세요&quot; 동적 객체이기 때문에 새로운 변수 값을 대입할 수 있다. 123&gt; hello &lt;- 100 + 200&gt; hello[1] 300 숫자형식의 데이터를 가지고 문자형으로 다시 대입할 수 있다. 123&gt; hello &lt;- 'this is a text'&gt; hello[1] &quot;this is a text&quot; 객체와 객체를 이용해서 연산도 할 수 있다. 1234&gt; test1 &lt;- 1&gt; test2 &lt;- 2&gt; test1 + test2[] 3 논리형식의 데이터를 이용해 참/거짓을 이용할 수 있다. 12&gt; Object1 &lt;- TRUE # 논리형&gt; Object2 &lt;- FALSE ls() : 객체 목록ls()는 사용한 객체들의 목록을 반환해 준다. 123&gt; x &lt;- 1&gt; y &lt;- 1:10&gt; ls() rm(): R 객체를 삭제1234&gt; x &lt;- 1&gt; y &lt;- 1:10&gt; rm(x,y)&gt; ls() WorkspaceR에서 작업공간(workspace)에 사용자가 R을 이용하여 수행하는 자료와 분석 프로시져 등을 포함하게 된다. getwd(): 현재 워크스페이스 경로 setwd(PATH): 지정한 PATH로 현재 워크스페이스를 지정한다. list.files(PATH): 경로의 파일 목록을 반환 객체 저장작업공간은 저장할 수 있다. 저장을 실행하면 작업 디렉토리에 .RData 라는 파일이 생성된다. 12&gt; help(&quot;save.image&quot;) # 도움말을 살펴보며 진행&gt; save.image() R의 종료를 위해서는 명령문 프롬프트에서 **q()**를 실행하던가 메뉴로부터 “종료”를 선택한다.종료시 워크스페이스에 작업된 자료를 저장할 수 있다. R패키지: R의 확장기능 이용search()는 설치된 R패키지들을 확인하는 명령 1234search()## [1] &quot;.GlobalEnv&quot; &quot;package:stats&quot; &quot;package:graphics&quot;## [4] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot;## [7] &quot;package:methods&quot; &quot;Autoloads&quot; &quot;package:base&quot; library(): R에 설치된 모든 패키지 및 설명library() 명령은 라이브러리를 현재 환경에 로딩해 준다. 12library()library(package_name): 패키지를 현재 R세션으로 로딩 예를 들어 MASS 패키지를 로딩하는 명령을 보자 1library(MASS) # MASS 패키지를 로드 새로운 패키지를 설치할 수 있다. 1install.packages(): R에 새로운 패키지 설치 stringr 패키지를 설치한다. 1install.packages(&quot;stringr&quot;) R 객체 이용하기R 객체에는 아래와 같은 종류들이 있음 atomic(상수) vector(벡터) matrix(행렬) list(리스트) data.frame(데이터프레임) function(함수) operator(연산자) … 데이터 객체 (data object): R 객체 중 데이터 객체 : atomic, vector, matrix, data.frame 객체의 이름객체명 표시방법: 알파벳문자, ’_‘,’.’, 숫자의 조합 주석한 줄을 인터프리터가 해석하지 않고 패스하는 라인 코멘트(주석문) # 를 사용한다 12a &lt;- 1b_1 &lt;- 10 # &lt;-는 left assignment 벡터R의 최소 단위는 벡터 정수(1), 실수(5.8271), 문자(‘A’) 문자열(“hello”)는 스칼라이다.벡터는 {1,2,3,4,5,6}과 같이 스칼라가 여러 개 모인 것이이다. 한 개의 스칼라 값을 가진 벡터를 선언한다. 1&gt; a &lt;- 5 객체에 다른 객체 넣기 1234567&gt; object1 &lt;- 1&gt; object2 &lt;- 2&gt; object1[1] 1&gt; object1 &lt;- object2&gt; object1[1] 2 객체에 다른 객체 넣기 123456&gt; object1 &lt;- 1&gt; object1 &lt;- 2&gt; object1 &lt;- object2&gt; object2 &lt;- 100&gt; object1[1] 2 함수 계산 결과를 객체에 넣기 12345678910111213141516&gt; Excel1 &lt;- read.csv(“example_student.csv”)&gt; Object1 &lt;- sum(1,8,4,5,9)Object1 : 27&gt; A &lt;- c(1,3,5,6,9) # 벡터에 대해A : 1,3,5,6,9&gt; A &lt;- 1Is.vector(a): TrueA &lt;- c(1,2,5)Is.vector(a): True&gt; A &lt;- c(“첫번째”, “두번째”, “세번째”)A : ??? Package 관리외부에서 제공하는 모듈을 Install, Update, Library 명령으로 관리할 수 있다. 패키지 설치는 Install 그리고 사용할 때는 Library 명령을 사용하고 패키지 갱신에 Update 명령을 사용한다. 패키지 관리패키지 설치과 업데이트 1234&gt; install.packages(&quot;패키지명&quot;) # 패키지 설치&gt; library(&quot;패키지명&quot;) # 패키지 불러들이기 (사용)&gt; require(&quot;패키지명&quot;) #&gt; update.packges('패키지명') # 패키지 갱신 설치된 패키지 목록 보기123&gt; Library()&gt; installed.packages()&gt; Install.packages()[, c(“Packages”, “version”, “License”)] 필수 패키지1234567891011Install.packages(“rgl”) # 3D 그래프 보여주는 패키지Install.packages(“ggplot2”)Install.packages(“ggthemes”)Install.packages(“data.table”)Install.packages(“devtools”)Install.packages(“KoNLP”)Install.packages(“dplyr”)Install.packages(“plyr”)Install.packages(“reshape2”)Install.packages(“scales”)Install.packages(“stringr”) Github로 패키지 설치하기개발자가 베타 버전을 github에 공개하는 경우Knitr 패키지는 R에서 html, pdf, MS-Word 문서를 만들 수 있음고 https://github.com/yihui/knitr 에서 배포한다. 1234&gt; Install.packages(“devtools”)Library(“devtools”)&gt; install_github(“yihui/knitr”) RStudio UTF8 지원 참조 http://dev.epiloum.net/1546 http://xmlarchive.org/hrc/wp-content/uploads/2012/12/r_book_mac_v3.pdf","link":"/r_rstudio-installation-2022-2c921ad2c784/"},{"title":"github 의 Profile README 이용","text":"Profile README깃헙 레포지토리를 깃헙 사용자 이름과 동일하게 생성하고 README.md 를 추가하면 프로필 리드미로 사용할 수 있다. https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-profile/customizing-your-profile/managing-your-profile-readme 사용자 이름과 같은 레포지토리를 생성하고 README.md 를 추가 사용자에 대한 설명을 적은 README.md 이렇게 추가한 프로필 README 는 Overview 에 나타나게 된다.","link":"/github-Profile_README-b923c52f5706/"},{"title":"github 레포지토리에 collaborator 추가하고 머지하기","text":"프로젝트를 위해서 레포지토리에 새 참여자를 추가하고, 브랜치를 생성해서 관리하는 과정. 참여자 관리레포지토리 Settings 에서 Collaborators 페이지에서 참여자를 관리할 수 있다. Collaborator 에 추가할 github 사용자를 검색 Collaborators 추가 사용자 목록 사용자는 알림에 Collaborator 에 추가되어 허용할지를 등록 요청받은 collaborator 을 받아들인다 Collaborator 사용자가 새로운 파일을 추가한다. &lt;img src=’https://i.imgur.com/2i1UOyD.png&gt; 레포지토리 브랜치의 새로운 변경/추가/삭제가 발생하면 Pull request 를 요청해야 한다. Collaborator로 참가한 사용자는 pull request 하고 merge도 할 수 있지만 정책으로 main 관리자가 하도록 하자. 새 브랜치 사용pull request 와 merge 를 위한 정책 구성. Collaborator도 merge 할 수 있지만 팀장/관리자가 merge 하도록 정책을 정한다. Pull request 와 merge 새 브랜치를 생성한다 새 브랜치에서 작업을 수행한다. 새 브랜치에 변경된 내용을 pull request 할 수 있다. 새 브랜치에 변경된 내용을 pull request 할 수 있다. 사용자/관리자는 새 브랜치에 변경된 내용을 pull request 할 수 있다. 관리자/팀장은 새 브랜치에 변경된 내용을 merge 한다. 관리자/팀장은 새 브랜치에 변경된 내용을 merge 한다. 관리자/팀장은 사용한 브랜치는 제거해 레포지토리를 정리한다.","link":"/github-collaborators_merge-831e25689845/"},{"title":"WSL 에서 CUDA 사용을 위한 User Guide","text":"CUDA on WSL User Guide 2021/12/05 일 현재 1. WSL 이란네이티브 리눅스 앱을 Windows 11 and later OS build 에서 실행할 수 있는 Windows Subsystem for Linux 이다. WSL 1 vs. WSL 2WSL2 is the second generation of WSL that offers the following benefits: Linux applications can run as is in WSL2. WSL 2 is characteristically a VM with a Linux WSL Kernel in it that provides full compatibility with mainstream Linux kernel allowing support for native Linux applications including popular Linux distros. Faster file system support and that’s more performant. WSL 2 is tightly integrated with the Microsoft Windows operating system, which allows it to run Linux applications alongside and even interop with other Windows desktop and modern store apps. 2. NVIDIA GPU Accelerated Computing on WSL 2WSL 2에서 마이크로소프트는 NVIDIA CUDA 및 기타 컴퓨팅 프레임워크와 기술과 함께 데이터 과학, 머신러닝 및 추론 솔루션을 위한 GPU 가속 컴퓨팅을 가능하게 하는 GPU 반가상화 기술을 도입했다. WSL 유사 환경 또는 WSL 2에서 CPU 개입을 줄이면서 GPU에서 더 많은 병렬 작업을 파이프라인으로 수행할 수 있으므로 거의 네이티브에 가까운 성능을 제공한다. NVIDIA 드라이버 지원은 CUDA 및 관련 컴퓨팅 소프트웨어 스택에서 멈추지 않습니다. 다이렉트 ML 지원과 함께 DX12 API를 지원하여 WSL 2에서 그래픽을 활성화하는 DirectX 지원이 있습니다. Illustration of the possibilities with NVIDIA CUDA software stack on WSL 2 3. WSL2 시작WSL2 요구사항 Geforce, Quadro 제품 계열에서 Pascal 또는 최신 GPU 구조를 WDDM모드로 SKU를 사용할 수 있다. 최신 WSL 커널 로 5.10.16.3 이상을 권장한다. (최소 4.19.121+ 이상) Windows 11 에서는 윈도우 인사이더 프로그램 가입이 필요 없다. Windows 10 에서는 윈도우 인사이더 프리뷰 프로그램이 필요하다. Step 1: Install NVIDIA Driver for GPU Support윈도우 11 그래픽 드라이버로 NVIDIA GeForce Game Ready or NVIDIA RTX Quadro 를 설치한다. https://developer.nvidia.com/cuda/wsl Do not install any Linux display driver in WSL. 3.3. Step 2: Install WSL 2윈도우 터미널 / 커맨드 라인 / 파워쉘 에서 WSL을 설치 1wsl.exe --install Ensure you have the latest WSL kernel: 1wsl.exe --update 3.4. Setting Up a Linux Development Environment기본으로 WSL2는 Ubuntu 가 설치되어 온다. 다른 배포본은 MS store에서 설치. wsl 시작. 1wsl.exe 업데이트를 위한 WSL 명령: https://docs.microsoft.com/en-us/windows/wsl/install https://docs.microsoft.com/en-us/windows/wsl/basic-commands 4. Getting Started with CUDA on WSL 2WSL2에서 CUDA 를 지원하려면 CUDA Toolkit이 설치되고 cuDNN도 설치해야 한다. 4.1 WSL에서 CUDA Toolkit을 설치한다WSL 2 에서 CUDA application을 실행하려면 CUDA toolkit for Linux 를 설치해야 한다. https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=WSL-Ubuntu&amp;target_version=2.0&amp;target_type=deb_local CUDA Toolkit 11.5 를 다운로드하고 설치한다. 1234567wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pinsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600wget https://developer.download.nvidia.com/compute/cuda/11.5.1/local_installers/cuda-repo-wsl-ubuntu-11-5-local_11.5.1-1_amd64.debsudo dpkg -i cuda-repo-wsl-ubuntu-11-5-local_11.5.1-1_amd64.debsudo apt-key add /var/cuda-repo-wsl-ubuntu-11-5-local/7fa2af80.pubsudo apt-get updatesudo apt-get -y install cuda 4.2 cudnn 설치CUDA Toolkit 버전에 대응하는 cuDNN 을 설치해야 한다. https://developer.nvidia.com/rdp/cudnn-download https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#install-linux 11.5 는 최신 cuDNN8.3 을 설치한다. 123sudo apt install libcudnn8sudo apt install libcudnn8-devsudo apt-get install libcudnn8-samples 4.3 CUDA 애플리케이션윈도우에 CUDA 애프리케이션이 있아면 다음 같이 WSL에서 실행해 보자 123$ cd /mnt/c/Users/&lt;username&gt;/Desktop$ cp /mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.5/extras/demo_suite/deviceQuery.exe ~/$ ./deviceQuery.exe 12345678910111213141516171819202122(tf25gpu_p39)~$ nvidia-smiSun Dec 5 02:29:22 2021+-----------------------------------------------------------------------------+| NVIDIA-SMI 510.00 Driver Version: 510.06 CUDA Version: 11.6 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 NVIDIA GeForce ... On | 00000000:09:00.0 On | N/A || 0% 43C P8 20W / 320W | 1179MiB / 11264MiB | N/A Default || | | N/A |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+ 4.4 Building CUDA SamplesCUDA 샘플을 빌드해서 실행해 보자. 1234567891011121314151617181920212223242526272829303132333435363738(tf25gpu_p39)/usr/local/cuda-11.5/samples/4_Finance/BlackScholes$ ./BlackScholes[./BlackScholes] - Starting...GPU Device 0: &quot;Pascal&quot; with compute capability 6.1Initializing data......allocating CPU memory for options....allocating GPU memory for options....generating input data in CPU mem....copying input data to GPU mem.Data init done.Executing Black-Scholes GPU kernel (512 iterations)...Options count : 8000000BlackScholesGPU() time : 0.234201 msecEffective memory bandwidth: 341.586668 GB/sGigaoptions per second : 34.158667BlackScholes, Throughput = 34.1587 GOptions/s, Time = 0.00023 s, Size = 8000000 options, NumDevsUsed = 1, Workgroup = 128Reading back GPU results...Checking the results......running CPU calculations.Comparing the results...L1 norm: 1.741792E-07Max absolute error: 1.192093E-05Shutting down......releasing GPU memory....releasing CPU memory.Shutdown done.[BlackScholes] - Test SummaryNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.Test passed(tf25gpu_p39)/usr/local/cuda-11.5/samples/4_Finance/BlackScholes$ 참고 https://docs.nvidia.com/cuda/wsl-user-guide/index.html CUDA Toolkit 버전에 대응하는 cuDNN 을 설치해야 한다. https://developer.nvidia.com/rdp/cudnn-download https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#install-linux Tensforflow on WSL2: https://rosypark.tistory.com/313 CUDA WSL User Guide","link":"/WSL2-NVIDIA_CUDA-cb53f02017e1/"},{"title":"Windows Powershell: 관리자 administrator 계정 활성화와 Openssh 서버 활성화","text":"외부에서 원격접속해서 관리자 명령을 실행하려면 관리자 권한이 필요하다. 윈도우 파워쉘에서 openssh 설치하고 시작/재시작 등의 작업을 위해서는 administrator 계정이 활성화 되어야 한다. openssh windows server 설치 administrator 계정 활성화 원격 ssh 접속 Powershell Openssh 설치윈도우 파워쉘에서 openssh 설치 https://docs.microsoft.com/ko-kr/windows-server/administration/openssh/openssh_install_firstuse administrator 계정명령행을 관리자 권한으로 실행하고 아래 명령 수행. 어드민 계정이 활성화 상태로 변경됩니다.어드민 계정이 활성화되어 있기 때문에 Administrator 계정으로 로그인이 가능해집니다. 윈도우즈 administrator 활성화administrator 게정을 활성화 하려면 파웨쉘을 관리자로 실행해 다음 같이 실행한다. 1&gt; net user administrator /active:yes 패스워드 변경은 사용자 계정 변경에서 ‘다른 계정 관리’ 관리자 권한으로 실행할 명령 앞에 runas 명령을 붙여 실행한다. 파워쉘에서 관리자로 명령을 실행하려면 runas 명령을 사용한다. 1runas.exe /savecred /user:administrator &quot;%sysdrive%\\testScripts\\testscript1.ps1&quot; 참고 openssh 서버 구성: https://docs.microsoft.com/ko-kr/windows-server/administration/openssh/openssh_server_configuration https://docs.microsoft.com/ko-kr/powershell/scripting/learn/remoting/ssh-remoting-in-powershell-core?view=powershell-7.1 윈도우즈 서비스 만들기: https://docs.microsoft.com/ko-kr/dotnet/framework/windows-services/walkthrough-creating-a-windows-service-application-in-the-component-designer","link":"/Win-Powershell_ssh_server-efe30db39ed6/"},{"title":"Python : pyenv-windows 와 Jupyterlab 환경","text":"pyenv-windows 와 Jupyterlab 환경 pyenv-windows 설치파워셀에서 설치 스크립트를 실행해서 설치하는 과정으로 정리되어 있다. 사이트: https://github.com/pyenv-win/pyenv-win 준비 테스트 Windows 10 Home 21H1 / 19043.928 Microsoft Visual C++ 2015-2019 Redistribution pip version 22.1 혹은 22.0 상태 주의Windows 최신 (Windows 11 등) pip 22.3 이상인 경우 Microsoft Visual C++ Build Tools 를 설치해야 한다. 이어지는 Microsoft C++ Build Tools 설치 참조해 설치한다. PowerShell 스크립트 실행 모드 확인외부 스크립을 실행할 수 있기 위해서는 ExecutionPolicy가 unrestricted 상태여야 한다. PowerShell을 관리자 모드로 실행해 다음과 같이 입력 12&gt; ExecutionPolicy &lt;-- 현재 상태 확인Restricted &lt;-- 모든 스크립트 막은 상태 모드 변경을 위해 다음 명령 실행 1&gt; Set-ExecutionPolicy Unrestricted 모드 변경 확인 12&gt; ExecutionPolicy &lt;-- 현재 상태 확인Unrestricted &lt;-- 모든 스크립트 허용 상태. 모드가 Unrestricted 상태에서 pyenv-win 을 설치한다. pyenv-win 설치pyenv-win 설치 항목에서 파워쉘을 통해 스크립트 실행을 통해 설치한다. 모든 방법들은 윈도우 홈 디렉토리의 .pyenv/ 폴더 아래에 실행 스크립을 위치한다. 인스톨러다음 파워쉘 스크립트를 파워쉘에서 실행한다. 12Invoke-WebRequest -UseBasicParsing -Uri &quot;https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1&quot; -OutFile &quot;./install-pyenv-win.ps1&quot;; &amp;&quot;./install-pyenv-win.ps1&quot; 만약 Unauthorized Script 에러가 나면 PowerShell 스크립트 실행 모드 확인 같이 Unrestricted 모드로 설정해야 한다. 실행하면 %USERPROFILE%/.pyenv 아래에 관련 파일을 다운로드 한다. 설치 완료후 파워쉘에서 pyenv 명령을 실행하면 아래 같이 도움말 화면이 나오면 성공이다. Microsoft C++ Build Tools 설치pip versions 22.3 이상 업그레이드 혹은 설치를 하면 Redistribution 패키지 설치로는 해결이 안된다. pip v22.1 까지는 Microsoft Visual C++ 2015-2019 Redistribution 로도 충분하다. 다음 사이트에서 build tools 을 다운로드 받아 설치한다. https://visualstudio.microsoft.com/visual-cpp-build-tools/ 설치시 아래 옵션을 선택해 설치한다. Python 배포본 설치이제 pyenv 를 사용해서 Python 3.10, Python 3.9 버전을 설치해 보자. 설치 가능한 버전은 pyenv install -l 명령으로 확인 가능하다. 아래 같이 파워셀에서 필요한 버전을 필터링해 확인해 보자. 12345678PS &gt; pyenv install -l | findstr 3.9..3.9.113.9.12-win323.9.123.9.13-win323.9.13 원하는 버전의 버전 번호를 입력해 설치한다. 윈도우 버전의 배포본이 pyenv 의 가상환경 폴더 밑에 설치 된다. 이어서 바로 Python 3.9 버전도 설치해 보자. 윈도우 버전 배포본 설치가 진행된다. pyenv 에서 설치한 Python 3.10, Python 3.9 를 설치 확인을 해보자 Jupyter-Lab 설치3.9 버전을 글로벌로 지정했다. 1PS C:\\Users\\andro&gt; pyenv global 3.9.12 pyenv 가능한 버전 확인 123PS C:\\Users\\andro&gt; pyenv versions 3.10.4 *3.9.12 현재 파워쉘의 파이썬 버전을 3.10 으로 지정했다. 123PS C:\\Users\\andro&gt; pyenv shell 3.10.4PS C:\\Users\\andro&gt; python -VPython 3.10.4 venv 모듈로 가상환경을 생성하고 활성화 한다. 123PS C:\\Users\\andro&gt; python -m venv .venv/jupyter_p310PS C:\\Users\\andro&gt;.\\.venv\\jupyter_p310\\Scripts\\activate(jupyter_p310) PS C:\\Users\\andro&gt; jupyter-lab 설치 12(jupyter_p310) PS C:\\Users\\andro&gt; pip install jupyterlabCollecting jupyterlab Jupyter-lab에서 사용할 notebook 공간 생성 1(jupyter_p310) PS C:\\Users\\andro&gt; mkdir jupyter-work jupyter-lab 실행 1234567891011(jupyter_p310) PS C:\\Users\\andro&gt; jupyter-lab --no-browser .\\jupyter-work\\...[I 2022-05-24 03:27:03.847 ServerApp] Serving notebooks from local directory: C:\\Users\\andro\\jupyter-work[I 2022-05-24 03:27:03.847 ServerApp] Jupyter Server 1.17.0 is running at:... To access the server, open this file in a browser: file:///C:/Users/andro/AppData/Roaming/jupyter/runtime/jpserver-4664-open.html Or copy and paste one of these URLs: http://localhost:8888/lab?token=866bdd9bed841f4dafc5c431a7ffcd4b01f516e4583f38d7 or http://127.0.0.1:8888/lab?token=866bdd9bed841f4dafc5c431a7ffcd4b01f516e4583f38d7[W 2022-05-24 03:28:04.189 LabApp] Could not determine jupyterlab build status without nodejs","link":"/pyenv-windows_Jupyterlab-0511d957cdca/"},{"title":"[HTS API] 대신증권 CybosPlus Python API 준비","text":"국내 증권사들 중에서 주식거래 HTS 를 통해서 API 를 지원하고 있다. 여기서는 대신증권 CybosPlus 를 사용해보려고 한다. 대신증권 CybosPlus 설치 32bit Miniconda환경 JupyterLab 시작 Powershell Openssh 설치 원격으로 접속시 증권 HTS API 와 Jupyter Lab 환경HTS에서 제공하는 OpenAPI 를 사용해서 주식 정보 및 주문을 처리할 수 있다. 여기서는 Jupyter lab 으로 윈도우 머신에 설치된 Open API 를 지원하는 HTS 사용하는 과정을 정리했다. 증권사별 API 비교 “” 키움 증권 대신 증권 이베스트 증권 제공방식 OCX COM COM, DLL 파이썬 보통 좋음 보통 API사용성 보통 좋음 좋음 API거래 수수료 0.015% (HTS수준) 0.015% (HTS수준)월정액 15000+0.0088% 0.015% (HTS수준) 사전 준비 대부분 윈도우용 COM API 를 지원하는 HTS 는 32bit 기반의 Python 환경. 32bit Miniconda2 를 설치해서 사용하겠다. 대신증권 CybosPlus 설치대신증권의 API 서비스인 CybosPlus 를 사용한다. Cybos 5 설치 Python2.7 32bit 환경인 Miniconda 32bit 버전 설치 Cybos 5 설치설치를 하고 CybosPlus 로 인증서를 통해서 로그인한다. HTS 가동과 연결HTP 프로그램은 보통 자동으로 관리자 모드로 실행된다. 이 API를 사용하는 파이썬 프로그램도 역시 관리자 모드로 실행되야 한다. 32bit Miniconda2 환경윈도우 머신에 Python2.7 기반 32bit 용 Miniconda 를 설치한다. 그리고 필요에 따라 64bit miniconda 를 설치한다. 설치하게 되면 32비트 버전은 Miniconda2, 64비트 버전은 miniconda3 으로 구분할수 있다. 대신증권 가상환경관리자 권한으로 HTS 를 실행하기 때문에 Python을 통한 API 호출도 관리자 권한이 필요하다. 관리자 권한으로 miniconda 를 실행하고 대신증권 가상환경을 생성한다. 메뉴에서 miniconda 쉘을 실행하면 아래같이 나타난다. 123(base) C:\\Windows\\system32&gt;(base) C:\\Windows\\system32&gt;d:(base) D:\\&gt; conda create -n daeshin_hts jupyter 대신증권 API를 사용하기 위해서 가상환경을 설정한다. 테스트/응용을 위해서 jupyter 환경을 구성한다. 1234567891011(base) D:\\&gt;conda env list# conda environments:#base * C:\\Users\\daddy\\miniconda2daeshin_hts C:\\Users\\daddy\\miniconda2\\envs\\daeshin_hts C:\\Users\\daddy\\miniconda3 C:\\Users\\daddy\\miniconda3\\envs\\deeplearning C:\\Users\\daddy\\miniconda3\\envs\\ml C:\\Users\\daddy\\miniconda3\\envs\\tf2 C:\\Users\\daddy\\miniconda3\\envs\\tf25 C:\\Users\\daddy\\miniconda3\\envs\\tf26 JupyterLab 시작필요한 패키지를 설치하고 jupyterlab 을 실행한다. 먼저 가상환경을 활성화 한다. 1(base) &gt; conda activate daeshin_hts 패키지 설치가상환경을 활성화 하고 jupyterlab numpy scipy matplotlib 패키지를 설치한다. 1(daeshin_hts) &gt; conda install jupyterlab numpy scipy matplotlib 콘다 가상환경이 생성된 후에 가상환경을 활성화 한다. Jupyter Lab을 시작한다. 1(daeshin_hts) &gt; jupyter lab WORK_FOLDER JupyterLab Config원격 접속등을 위해서 비밀번호를 사용한다. 그러기 위해서 구성 파일을 통해서 비밀번호, 포트 번호등을 설정해야 한다. generate-configJupyter Lab 에서 설정 파일을 생성한다. 다음 명령으로 각각 $HOME/.jupyter/ 위치에 jupyter_notebook_config.py 파일이 생성된다. 1(daeshin_hts)&gt; jupyter lab --generate-config jupyter_notebook_config.py 설정 파일에 비밀번호를 추가하려면 비밀번호를 생성하는데 jupyter 명령과 python 명령에서 생성하는 2가지 방법이 있다. 1) jupyter 명령으로 패스워드 생성첫번째로 아래는 쥬피터 폴더에 있는 파일 ‘jupyter_notebook_config.json’에 패스워드를 생성해 준다. 123(daeshin_hts)$ jupyter notebook password Enter password:Verify password:[NotebookPasswordApp] Wrote hashed password to $HOME\\.jupyter\\jupyter_notebook_config.json 위 명령으로 jupyter_notebook_config.json에 암호가 생성되면 “”sha1:723c…” 로 시작하는 패스워드 해시코드를 복사한 후 jupyter_notebook_config.py 파일의 c.NotebookApp.password 항목에 입력을 한다. 2) python 명령으로 비밀번호 생성비밀번호 설정 다른 방법으로 파이썬에서 passwd 모듈을 실행해서 비밀번호를 얻을 수 있습니다. 1234567(daeshin_hts)$ python&gt;&gt; from notebook.auth import passwd&gt;&gt; passwd()&gt;&gt; Enter password:&gt;&gt; Verify password:'sha1:********' 출력되는 sha1 암호문자열을 복사해서 사용하시면 됩니다. 12345[jupyter_notebook_config.py]c.NotebookApp.password = 'sha1:*********' # 외부 접속시 사용할 비밀번호c.NotebookApp.ip = '*' # 어디서든 접속 가능c.NotebookApp.port = 8888 # 접속에 사용할 포트 Powershell Openssh 설치윈도우에 원격 접속해서 HTS를 위한 파이썬 가상환경에서 jupyterlab을 실행할 필요가 있다. 이때 윈도우 파워쉘에서 openssh 설치하고 연결한 후에 administrator 계정으로 관리자 모드로 jupyhter 를 실행한다. https://docs.microsoft.com/ko-kr/windows-server/administration/openssh/openssh_install_firstuse 윈도우즈 administrator 활성화대신 hts 에 접속하기 위해서는 관리자 권한이 필요하다. ssh로 윈도우즈 계정 로그인은 되지만 hts 활설화를 위해서 administrator 게정을 활성화 한다. 파웨쉘을 관리자로 실행해 다음 같이 실행한다. 1(daeshin_hts)&gt; net user administrator /active:yes jupyter-lab을 runas 명령으로 실행한다. 123(daeshin_hts)&gt; runas /env /user:administrator &quot;jupyter-lab.exe .\\Jupyter-HTS\\&quot;administrator의 암호 입력:jupyter-lab.exe .\\Jupyter-HTS&quot;을(를) 사용자 &quot;DESKTOP-GOYANGI\\administrator&quot;(으)로 시작하려고 합니다. 참고 openssh 서버 구성: https://docs.microsoft.com/ko-kr/windows-server/administration/openssh/openssh_server_configuration https://docs.microsoft.com/ko-kr/powershell/scripting/learn/remoting/ssh-remoting-in-powershell-core?view=powershell-7.1 윈도우즈 서비스 만들기: https://docs.microsoft.com/ko-kr/dotnet/framework/windows-services/walkthrough-creating-a-windows-service-application-in-the-component-designer","link":"/HTS_CyBosPlus_Jupyter-8f8530e26664/"},{"title":"IntelliJ Communication 사용한 Springboot 시작","text":"2022/8/10: 첫번째 버전. 첫번째 스프링 부트https://start.spring.io/ 사이트에 접속해 아래 같이 프로젝트 구성을 선택한다. 그리고 오른쪽 의존성 버튼을 눌러 Initializr 에서 의존성 플러그인을 추가한다. Dependencies 추가Web 관련해 보통은 Web, Dev tools 와 Lombok 플러그인을 지정한다. Generate 로 샘플 프로젝트 다운로드Initializr 에서 구성을 완료하고 의존성 모듈을 추가한 후에 Generate 버튼을 누르면 압축된 프로젝트가 다운로드 된다. 이 압축 파일을 풀어서 Intellij 에서 연다. runsrc/main 에서 java 파일을 열면 실행 버튼이 활성화 된다. index.html 파일 추가하기src/main/resources/static 폴더에 index.html 파일을 추가한다. 파일에 HTML 로 아래 같이 입력한다. 프로젝트에 컨트롤러 추가하기Spring Web 의존성을 추가해서 라이브러리를 설치하면 웹 관련 컨트롤러를 사용하기 좋다. 다음 같인 프로젝트에 컨트롤러 패키지를 추가하고 SampleController 클래스를 추가한다. 어노테이션으로 RestController 를 지정한다. hello 메서드를 작성한다. Uri 연계를 위해서 Mapper 어노테이션을 지정한다. 이제 http://localhost:4000/hello 주소를 요청한다. 실행 가능한 배포본 만들기스프링 프로젝트는 Tomcat 같은 WAS 가 필요하고 이를 배포하는 방법이 필요했다. 스프링 부트는 단독으로 실행 가능한 웹 애플리케이션을 jar 형태로 제작하고 사용하는 것이 가능하다. Gradle 을 사용해서 몇 번의 클릭만으로 실행 가능한 웹 애플리케이션을 제작할 수 있다 물론 실행을 위해서는 Java 환경이 필요한다. Gradle Task 사용Gradle view 의 task 에서 bootjar 항목을 실행한다. 프로젝트의 build 폴더의 lib 폴더에 프로젝트 이름+0.01-SNAPSHOT.jar 실행 파일이 생성되어 있는 것을 확인할 수 있다. 이 jar 를 다운로드해서 java 로 실행해 보자 1java -jar PROJECT-0.0.1-SNAPSHOT.jar","link":"/Sprinboot-01-start-springboot_intellij-1d6af025258d/"},{"title":"Python : pip 명령 proxy 지정","text":"방화벽 등으로 직접 pip 혹은 conda 설치가 안되는 경우에 프락시 지정을 해서 사용이 가능하다. Anaconda proxy사용자 홈디렉토리 .condarc 파일에 proxy 구성을 한다. 만약 프락시 인증서가 필요하면 인증서를 추가한다. 1234proxy_servers: http: http://IP_ADDRESS:8080 https: https://IP_ADDRESS:8080 ssl_verify: %programdata%\\pip\\dscert.crt pippip 명령은 명려에서 옵션 pip proxy 옵션을 사용하거나 pip.ini 로 구성할 수 있다. 1pip install --upgrade --proxy https://IP_ADDRESS:8080 --trusted-host pypi.python.org --trusted-host pypi.org --trusted-host files.pythonhosted.org matplotlib numpy openpyxl xlrd xlwt pandas 사용자 정의 폴더pip는 사용자 구성에서 아래 같이 폴더: ~/pip pip.ini1234567[global]cert=C:\\Users\\user\\pip\\cert.crtproxy=http://IP_ADDRESS:8080trusted-host = pypi.python.org pypi.org files.pythonhosted.org","link":"/python-pip_proxy%EC%84%A4%EC%A0%95-80f84ee595a7/"},{"title":"WSL 파일시스펨, 네트워크","text":"WSL 파일시스템윈도우와 WSL 사이의 파일 시스템 공유 WSL 데이터 공간Windows에 WSL 패키지는 아래의 Packages 폴더 안의 어딘가에 위치한다. 1C:\\Users\\[사용자명]\\AppData\\Local\\Packages\\ Ubuntu 깔았다면 Packages폴더 아래에 Ubuntu라는 단어가 들어간 폴더명이 보일 것이다. 바로 그 폴더가 Ubuntu WSL의 위치다. 1234567891011PS C:\\Users\\daddy&gt; ls .\\AppData\\Local\\Packages\\Mode LastWriteTime Length Name---- ------------- ------ ----d----- 2020-11-01 오후 10:45 1527c705-839a-4832-9118-54d4Bd6a0c89_cw5n1h2txyewyd----- 2020-11-01 오후 10:31 ActiveSyncd----- 2020-11-12 오전 8:07 adobe.acrobatreaderdc.protectedmoded----- 2020-11-01 오후 10:45 c5e2524a-ea46-4f67-841f-6a9465d9d515_cw5n1h2txyewyd----- 2021-02-16 오후 7:52 CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgscd----- 2021-02-17 오후 4:58 CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgscd----- 2020-11-01 오후 10:45 E2A4F912-2574-4A75-9BB0-0D023378592B_cw5n1h2txyewy 위 패키지 경로에서 LocalState 폴더 안의 rootfs 폴더가 바로 WSL1의 Root와 동일한 경로이다. 12345PS C:\\Users\\daddy&gt; ls .\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc\\LocalState\\Mode LastWriteTime Length Name---- ------------- ------ -----a---- 2021-02-17 오후 5:34 1206910976 ext4.vhdx 권한문제윈도우와 리눅스는 서로 다른 권한 매커니즘을 가지므로 윈도우 탐색기 상에서 그냥 WSL 경로로 파일을 옮기면 권한이 이상해진다. 가능하면 WSL 로그인후에 사용한다. 탐색기로 홈디렉토리 열기현재 Working Directory를 네크워크를 통해 Windows 탐색기로 여는 방법아래의 명령어를 WSL에서 실행하면 현재 작업 중인 위치를 네트워크 연결을 통해서 Windows에서 열어준다. 1explorer.exe . WSL 네트워크DHCPhttps://stackoverflow.com/questions/61002681/connecting-to-wsl2-server-via-local-network 참고 https://coding-groot.tistory.com/101 https://webdir.tistory.com/545?category=754606 https://blog.aaronroh.org/118 https://stackoverflow.com/questions/61002681/connecting-to-wsl2-server-via-local-network","link":"/WSL-%ED%8C%8C%EC%9D%BC-d6fe8b8d2bbf/"},{"title":"WSL 설치","text":"WLS 설치https://docs.microsoft.com/ko-kr/windows/wsl/install-win10#manual-installation-steps https://www.44bits.io/ko/post/wsl2-install-and-basic-usage WSL 에러가상머신 에러wsl2 코드 4294967295 Windows 기능 추가/삭제를 이용해 1 Linux 하위시스템, 2 가상머신 껏다 켜는 방법https://bluenotes.kr/272 wls2 삭제후 재 설치https://hyelmy.github.io/%EB%81%84%EC%A0%81%EB%81%84%EC%A0%81/honeytips2/ https://blogger.pe.kr/853 재시작여러가지 방법이 있지만 대부분의 Windows에서 동작하는 방법은 먼저 PowerShell을 관리자 권한으로 열고 다음 명령을 실행하면 됩니다. 1Restart-Service LxssManager Windows 10 버전 1903/19H1 (빌드 18362) 이상 부터는 명령 프롬프트(CMD)를 열고 다음 명령어만 간단히 입력함으로서 WSL 시스템을 종료할 수 있습니다. wsl -t [배포판 이름]예를 들어 Ubuntu 20.04를 설치하였다면 wsl -t ubuntu를, Debian을 설치하였다면 wsl -t debian과 같이 사용하시면 됩니다. 추가로 Windows 10 버전 2004/20H1 (빌드 18917) 이상 부터는 명령 프롬프트에서 다음 명령어를 사용하여 모든 WSL 시스템을 한 번에 종료할 수 있습니다. 가령 Ubuntu와 Debian 머신이 구동되고 있다면 아래 명령어로 모두 종료 시킬 수 있습니다. wsl –shutdown 1234567(base) PS C:\\Users\\daddy&gt; wsl -lLinux용 Windows 하위 시스템 배포:Ubuntu-20.04(기본값)(base) PS C:\\Users\\daddy&gt; wsl -t Ubuntu-20.04(base) PS C:\\Users\\daddy&gt;(base) PS C:\\Users\\daddy&gt; wsl -t Ubuntu-20.04 --shutdown(base) PS C:\\Users\\daddy&gt; 주요 명령 WSL 버전 확인하기 (cmd창에서) 123wsl -l -vwsl -- list --verbose 우분투 배포판 버전 변경하는 명령어 1wsl --set-version Ubuntu-20.04 2 우분투 종료 명령어wsl -t Ubuntu-20.04 새로 설치하는 리눅스 배포판에 wsl2로 변경 wsl –set-default-version 2 WSL2 활성화 (Power shell 상)dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestartdism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart wsl IP 주소 1wsl hostname -I 네트워크sshhttps://learn.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse?tabs=gui DHCPhttps://stackoverflow.com/questions/61002681/connecting-to-wsl2-server-via-local-network 참고 https://blog.aaronroh.org/118 https://stackoverflow.com/questions/61002681/connecting-to-wsl2-server-via-local-network 고정 IPhttps://netmarble.engineering/wsl2-static-ip-scheduler-settings/ https://blog.dalso.org/linux/wsl2/11430 1 배치 파일을 만들어서 작업 스케쥴러에 추가해 재시동시 다시 설정한다. 12wsl -d Ubuntu-20.04 -u root ip addr add 192.168.254.10/24 broadcast 192.168.10.255 dev eth0 label eth0:1netsh interface portproxy add v4tov4 listenport=8585 listenaddress=0.0.0.0 connectport=8585 connectaddress=192.168.254.10 1","link":"/WSL%EC%84%A4%EC%B9%98_%EC%82%AC%EC%9A%A9-f9b128834761/"},{"title":"blog 안내","text":"2023/07/10: Permalink 수정기존 /YYYY/m/d/article_file_name/ 형식에서 article_file_name-hash 형식으로 변경한다. 2022/2/24지킬 기반 gitpages 으로 운영하던 블로그를 Hexo 를 사용해서 운영하려고 이전하고 있습니다. 다행이 이전 게시물은 그대로 이전이 되서 손실은 없을 것 같네요 곧 쉽게 사용하게 되면 밀린 블로그 포스팅을 계속하겠습니다. 총총 2022/2/24 2022/2/26: 사이드바 조정.","link":"/hello-world-46fdbf561d28/"},{"title":"pyenv 기반 Anaconda 사용하기","text":"PyEnv + Anacondapyenv 와 Anaconda 를 사용하려고 한다. pyenv로 배포본을 관리를 하고, 특정 Local 에서 Anaconda 를 사용하려고 한다. 개발환경은 Ubuntu 16.04 or later Windows 7 or later macOS 10.12.6 (Sierra) or later (no GPU support) Raspbian 9.0 or later Pyenv 로 기본 python 환경을 사용하고 더해서 Anaconda 를 설치해서 사용하려고 한다. 1. pyenv - Anaconda 설치Pyenv로 설치 할 anaconda 버전을 확이한다. 1$ pyenv install -l | grep anaconda anaconda 를 설치한다 12$ pyenv install anaconda3-2021.05... Anaconda 활성화1234$ pyenv versions system* 3.9.5 (set by /home/qkboo/.pyenv/version) anaconda3-2021.05 Local 명령을 사용해서 특정 디렉토리에서만 anaconda 환경을 쓰려고 한다. 1234~$ cd Jupyter-ML~$ pyenv local anaconda3-2021.05$ cat .python-versionanaconda3-2021.05 Anaconda init쉘 환경에서 conda 를 사용하기 위해서 환경변수를 초기화 해야 하는데 다음 명령으로 실행한다. 123456789101112131415$ conda init bashno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/condabin/condano change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/condano change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/conda-envno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/activateno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/deactivateno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/etc/profile.d/conda.shno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/etc/fish/conf.d/conda.fishno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/shell/condabin/Conda.psm1no change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/shell/condabin/conda-hook.ps1no change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xontrib/conda.xshno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/etc/profile.d/conda.cshmodified /Users/qkboo/.bash_profile==&gt; For changes to take effect, close and re-open your current shell. &lt;== 위 명령은 아래 환경 변수가 작용된다. 12345NACONDA_HOME=/Users/who/anaconda3PATH=$PATH:$ANACONDA_HOME/binexport ANACONDA_HOMEexport PATH 쉘을 다시 열면 쉘 프롬프트가 변경된다. 1(base) ~$ 파이썬 버전 확인다른 디렉토리에서는 글로벌 파이썬이 실행된다. 12(base) qkboo@desktop-goyangi:~$ pyenv which python/home/qkboo/.pyenv/versions/3.9.5/bin/python Anaconda 로 지정한 로컬 디렉토리로 이동하면 해당 파이썬 환경이 사용된다. 12(base) qkboo@desktop-goyangi:~/Jupyter-ML$ pyenv which python/home/qkboo/.pyenv/versions/anaconda3-2021.05/bin/python","link":"/pyenv-Anaconda%EB%B3%91%ED%96%89%EC%82%AC%EC%9A%A9-c14b2f455472/"},{"title":"pyenv 와 Anaconda 병행 사용","text":"PyEnv + Anaconda개발환경은 Ubuntu 16.04 or later Windows 7 or later macOS 10.12.6 (Sierra) or later (no GPU support) Raspbian 9.0 or later pyenv 와 pyenv-virtualenv 기반으로 Anaconda 를 사용하려고 한다. pyenv로 배포본을 관리를 하고, pyenv-virtualenv와 conda 환경의 가상환경을 이용한다. pyenv-Anaconda 환경 ananconda 와 miniconda anaconda &amp; miniconda 복합환경 1. pyenv - Anaconda 설치설치할 anaconda 버전을 확이한다. 1$ pyenv install -l |grep anaconda anaconda 를 설치한다 - 시간이 많이 걸린다. 1234$ pyenv install anaconda3-5.3.1Downloading Anaconda3-5.3.1-MacOSX-x86_64.sh.sh...-&gt; https://repo.continuum.io/archive/Anaconda3-5.3.1-MacOSX-x86_64.sh... anaconda3-5.3.1 버전을 전역에서 사용하도록 한다. 1$ pyenv global anaconda3-5.3.1 global로 지정하고 버전을 확인해 보면 1234$ pyenv versions system 3.8.1* anaconda3-5.3.1 (set by /Users/qkboo/.pyenv/version) 일반적으로 Anaconda 만을 사용한다면 설치후 사용자 쉘 환경에서 conda 를 사용하기 위해서 환경변수를 초기화 해야 하는데 다음 명령으로 실행한다. 123456789101112131415$ conda init bashno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/condabin/condano change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/condano change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/conda-envno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/activateno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/deactivateno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/etc/profile.d/conda.shno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/etc/fish/conf.d/conda.fishno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/shell/condabin/Conda.psm1no change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/shell/condabin/conda-hook.ps1no change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xontrib/conda.xshno change /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/etc/profile.d/conda.cshmodified /Users/qkboo/.bash_profile==&gt; For changes to take effect, close and re-open your current shell. &lt;== 위 명령은 아래 환경 변수가 작용해서 conda 의 가상환경을 다루는 쉘 스크립을 실행해 준다. 12345NACONDA_HOME=/Users/who/anaconda3PATH=$PATH:$ANACONDA_HOME/binexport ANACONDA_HOMEexport PATH 쉘을 다시 열면 쉘 프롬프트가 변경된다. 1(base) qkboo@ ~$ pyenv 기반 Anaconda 사용그런데 pyenv 에서 다른 배포본과 Ananconda 를 같이 사용한다면 conda 초기 환경이 아주 불편할 수 있어서 아래 같이 conda 가상환경 시작을 불가능하게 해야 한다. init conda, the following command write scripts into your shell init file automatically 1234conda init# disable init of env &quot;base&quot;conda config --set auto_activate_base false 보통 conda init 를 해주면 쉘 스크립의 마지막 위치에 삽입된다. 그러므로 .bash_profile 에 있는 pyenv 초기화가 항상 마지막에 실행되도록 하자. 1 pyenv 와 anaconda 환경의 전환 정리Examples of managing virtual environments. 123456# virtual environments from pyenvpyenv install 3.6.9pyenv virtualenv 3.6.9 new-envpyenv activate new-envpyenv deactive# You can also use `pyenv local` 12345# virtual environments from condaconda create -n new-env python=3.6conda env listconda activate new-envconda deactivate 1 1 anaconda 패키지와 환경관리를 할 수 있는 conda 명령어 몇가지를 소개 1234567891011// 아나콘다의 버전 확인conda --version// 아나콘다 버전 업데이트conda update conda// 설치된 패키지 리스트conda list// conda 통해 설치 가능한 패키지 검색conda search &quot;tensorflow&quot; conda에서 개발 준비하기Anaconda 설치가 완료되면 conda 명령으로 TensorFlow를 사용할 환경을 구성하고 사용해 보자. 가상환경 생성123456789101112131415161718$ conda create -n tensorflow_env...The following packages will be downloaded: package | build ---------------------------|----------------- pip-20.0.2 | py37_1 1.9 MB tensorboard-2.0.0 | pyhb38c66f_1 3.3 MB ...The following NEW packages will be INSTALLED: _tflow_select: 2.3.0-mkl ...Proceed ([y]/n)? 또한 python= 인자로 파이썬 버전을 지정할 수 있다. 1$ conda create -n tensorflow python=3.8 현재 생성한 가상환경을 확인해 보자, 12345(base)$ conda env list# conda environments:#base * /Users/qkboo/.pyenv/versions/anaconda3-5.3.1deep-learning /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/envs/deep-learning 새로만든 conda 가상환경을 활성화 한다. 12$ conda activate tensorflow_env(tensorflow_env) qkboo@ ~$ 가상환경에서 Jupyter Notebook 을 설치한다. jupyter notebook 설치활성화한 가상환경에서 Jupyter Notebook 을 설치한다. 1(tensorflow_env)$ conda install jupyter notebook 필요시 nb-extension 설치 12345678910(tensorflow_env)$ conda install -c anaconda-nb-extensions nb_condaCollecting package metadata (repodata.json): doneSolving environment: done## Package Plan ## environment location: /Users/qkboo/.pyenv/versions/anaconda3-5.3.1/envs/deep_learning added / updated specs: - nb_conda 2. anaconda &amp; miniconda 복합환경현재 시스템에 pyenv로 파이썬 환경이 anaconda, miniconda 그리고 python 3.9 등이 중복되어 설치되어 있다. pyenv 가 중심이 되어 conda 를 다루기 위해서 miniconda 를 우선으로 구성되어 있다. shell 스크립트 부분이다. 12345678910111213141516171819# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;# !! Contents within this block are managed by 'conda init' !!__conda_setup=&quot;$('/Users/qkboo/.pyenv/versions/miniconda3-latest/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)&quot;if [ $? -eq 0 ]; then eval &quot;$__conda_setup&quot;else if [ -f &quot;/Users/qkboo/.pyenv/versions/miniconda3-latest/etc/profile.d/conda.sh&quot; ]; then . &quot;/Users/qkboo/.pyenv/versions/miniconda3-latest/etc/profile.d/conda.sh&quot; else export PATH=&quot;/Users/qkboo/.pyenv/versions/miniconda3-latest/bin:$PATH&quot; fifiunset __conda_setup# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;# Pyenvexport PYENV_ROOT=&quot;$HOME/.pyenv&quot;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot; 현재 pyenv 로 설치한 파이썬 환경을 살펴보면, 12345678910111213141516171819qkboo@ ~$ pyenv versions system 3.8.1* 3.8.7 (set by /Users/qkboo/.pyenv/version) 3.8.7/envs/opencv4 3.8.7/envs/tf2_build 3.9.1 anaconda3-5.3.1 anaconda3-5.3.1/envs/opencv3 anaconda3-5.3.1/envs/opencv4 anaconda3-5.3.1/envs/py27 miniconda3-latest miniconda3-latest/envs/deep_learning miniconda3-latest/envs/django3 miniconda3-latest/envs/tf24_cpu miniconda3-latest/envs/tf2_p37 miniconda3-latest/envs/tkinter opencv4 tf2_build conda 툴을 사용하는 anaconda, miniconda 가 혼재된 환경에서 pyenv로 가상환경을 즉시 활성화 시키면 conda 명령 실행에 혼선을 일으킨다. 예를 들어 위의 가상환경 anaconda3-5.3.1/envs/opencv4 을 pyenv로 활성화 하고 python, conda 명령을 실행해 보면 12345~$ pyenv shell opencv4~$ pyenv versionopencv4 (set by PYENV_VERSION environment variable)~$ which python/Users/qkboo/.pyenv/shims/python 가상환경의 python 위치를 확인해 보고, conda 명령을 찾아 보자, 123456789~$ pyenv which python/Users/qkboo/.pyenv/versions/opencv4/bin/python$ pyenv which condapyenv: conda: command not foundThe `conda' command exists in these Python versions: anaconda3-5.3.1 miniconda3-latest pyenv 환경 아래 2개의 conda 때문에 혼선이 나타난다. 예를 들어 현재 쉘 환경에서 파이썬 환경 ananconda3-5.3.1 을 사용하도록 하고, conda 를 확인해 보면 명확하게 해당 파이썬 환경의 anaconda 의 가상환경을 가르키지만! conda env 명령의 결과는 다르게 나타낸다.anaconda 뒤에 minicond를 설치해서 miniconda 가상환경이 우선으로 나타난다. 123456789101112~$ pyenv shell anaconda3-5.3.1~$ pyenv which conda/Users/qkboo/.pyenv/versions/anaconda3-5.3.1/bin/conda~$ conda env list# conda environments:#base * /Users/qkboo/.pyenv/versions/miniconda3-latestdeep_learning /Users/qkboo/.pyenv/versions/miniconda3-latest/envs/deep_learningdjango3 /Users/qkboo/.pyenv/versions/miniconda3-latest/envs/django3tf24_cpu /Users/qkboo/.pyenv/versions/miniconda3-latest/envs/tf24_cputf2_p37 /Users/qkboo/.pyenv/versions/miniconda3-latest/envs/tf2_p37tkinter /Users/qkboo/.pyenv/versions/miniconda3-latest/envs/tkinter 그래서 가상환경 활성화시 가상환경 디렉토리를 지정해서 사용하자! 그래서 anaconda 와 miniconda 환경을 활성화 시키려면 shell, local, system 명령을 통해 설치된 파이썬 환경을 활성화 하고, 해당 파이썬 환경에서 가상환경을 다루는 것이 좋다. 예를 들어 현재 쉘 환경에서 파이썬 환경 ananconda3-5.3.1 을 사용하도록 실제 가상환경 위치를 지정해서 활성화 한다. 12~$ conda activate .pyenv/versions/anaconda3-5.3.1/envs/opencv4/(opencv4) ~$","link":"/pyenv_3Venv_Anaconda-3193bd01844a/"},{"title":"pyenv-virtualenv 사용","text":"pyenv-virtualenvvirtualenv를 사용하면 파이썬 런타임의 독립성을 한층 더 높일 수 있습니다. pyenv가 파이썬 버전을 관리하는 기능을 제공한다면, virtualenv는 파이썬 구동 환경을 관리합니다. pyenv를 이용하면 컴퓨터에 파이썬 버전 별로 1개의 파이썬 런타임을 설치하고 관리할 수 있습니다. virtualenv를 사용하면 파이썬 버전을 세분화하여 여러 개별 환경으로 구분하여 관리하는 기능을 제공합니다. 예를 들어서 python 3.5.2 런타임을 여러개 구성할 수 있고, 애플리케이션 별로 할당할 수 있습니다. 따라서, pyenv와 virtaulenv를 사용하면 매우 효과적입니다. 이러한 이유로 pyenv의 virtualenv 플러그인을 사용하는 것이 일반적입니다. pyenv-virtualenv 프로젝트는 https://github.com/yyuu/pyenv-virtualenv 에서 개발되고 있습니다. pyenv-virtualenv 설치pyenv-virtualenv는 OS별로 다음과 같이 설치할 수 있습니다. macOSpyenv-virtualenv 설치: homebrew OS X는 homebrew를 이용하여 설치할 수 있습니다. 1$ brew install pyenv-virtualenv 리눅스 pyenv-virtualenv 설치pyenv를 pyenv-installer로 설치할 때 pyenv-virtualenv 설치가 포함됩니다. pyenv-installer로 pyenv가 설치되었다면 별도의 조치가 필요 없습니다. pyenv로 virtualenv 생성다음과 같은 명령으로 파이썬 환경을 구성합니다. 1$ pyenv virtualenv &lt;vertualenv-name&gt; 은 생략 가능합니다. 버전을 생략할 경우 현재 시스템 버전으로 가상환경이 설정됩니다. virtualenv 플러그인으로 만든 가상환경인 경우 activate, deactivate 명령을 이용하여 활성화/비활성화합니다. 가상환경을 활성화/비활성화를 위해서는 다음 명령을 사용합니다. 1$ pyenv activate &lt;vertualenv-name&gt; 가상환경 종료는 다음 명령을 사용합니다. 1$ pyenv deactivate 가상환경을 삭제할 경우 다음과 같은 명령을 사용합니다. 1$ pyenv uninstall &lt;version&gt;/&lt;vertualenv-name&gt; 버전을 설치해 봤으니 그 버전 위에 올라갈 virtualenv를 설치해보도록 하자. test라는 이름을 가진 virtualenv를 3.5.2버전 위에 설치해보자. pyenv virtualenv [VERSION_NAME] [VIRTUALENV_NAME] 형식으로 입력해주면 된다. 1$ pyenv virtualenv 3.5.2 test_virtualenv 12345$ pyenv versions* system (set by PYENV_VERSION environment variable) 3.5.2 3.5.2/env/test_virtualenv versions명령어로 3.5.2 위에 test_virtualenv라는 환경이 설치된 것을 확인할 수 있다. 쓰고있는 버전을 옮기려면 똑같이 shell 명령어를 사용하면 된다. activate명령어를 이용해도 된다. 1$ pyenv shell[or activate] test shell 명령어는 Python의 버전과 virtualenv에 모두 적용할 수 있는 명령어이고, activate 명령어는 virtualenv에만 사용이 가능하다. shell을 이용해서 다른 버전이나 virtualenv를 사용중이라면 pyenv shell system을 이용하여 기본 버전으로 되돌아올 수 있고, activate를 이용하여 virtualenv를 사용중이라면 pyenv deactivate를 이용하여 사용중인 virtualenv에서 나올 수 있다. requirements.txt 생성test를 하나의 Python 프로젝트라고 생각하자. 이곳에 프로젝트에 필요한 package들을 설치해야 한다. pip로 Django를 설치하고, freeze로 package들 목록을 추출해보자. 12$ pip install django$ pip freeze &gt; requirements.txt requirements.txt에 Django==1.10.1라고 현재 설치된 package가 적혀있다. 이는 pyenv파일에 독립적으로 설치된 package이고, 다른 virtualenv나 버전으로 옮기면 사용할 수 없게 된다. 이로써 의존성 관리 문제를 해결 하게 된 것이다. 다른 개발 환경에서 프로젝트에 설치된 패키지를 동기화하려면 virtualenv를 만들고, shell명령어로 사용 설정을 한 뒤에, requirements.txt파일을 받아서 다음과 같은 명령어를 입력한다. 1$ pip install -r requirements.txt requirements.txt라는 이름은 반드시 정해진 것이 아니라 package목록을 담는 파일이름으로 관습적으로 사용하는 것이다. 귀차니즘: autoenv pyenv-virtualenv의 단점은 가상환경을 활성화하기 위해서 pyenv activate를 실행해야 한다는 것입니다. autoenv는 Python 프로젝트 진입시점시에 자동으로 virtualenv 환경 로딩하는 기능을 제공합니다. 가상 환경 활성화에 대한 귀차니즘을 없앨수 있습니다. 프로젝트 홈페이지는 다음과 같습니다. https://github.com/kennethreitz/autoenv설치 autoenv 설치위에까지가 Python에만 종속되는 내용이었고, 이번에 설치할 autoenv는 Python뿐만 아니라 모든 명령어에 적용할 수 있다. 다음과 같은 명령어로 설치한다. $ brew install autoenv이번에도 .bash_profile에 설정을 해줘야한다. 다음과 같은 내용을 맨 밑에 넣어준다. source $(brew –prefix autoenv)/activate.shautoenv를 이용한 자동화 autoenv는 터미널에서 디렉토리에 접근할 시에, .env파일을 찾아서 그 내용을 자동으로 실행시켜주는 간단한 기능이다. 그렇다면 test디렉토리를 만들어서, 디렉토리에 들어올 때 바로 test_virtualenv virtualenv로 설정되게 해보자! 명령어 한 줄을 입력하는 귀찮음을 덜 수 있는 것이다. $ mkdir test_virtualenv$ cd test_virtualenv$ vim .env.env파일안에 다음과 같은 내용을 입력하자. pyenv shell test_virtualenv제일 먼저 디렉토리에 들어가게 되면, .env의 내용을 실행할 것인지 물어보게 된다. 이 때 ‘y’를 입력해서 계속 실행되게 해야한다. 이제 터미널에서 test폴더에 들어갈 때마다 자동으로 test_virtualenv virtualenv를 쓰게 될 것이다! autoenv는 이것 뿐만 아니라 다른 분야에도 무궁무진하게 적용할 수 있다. bash prompt아래같이 bash 프롬프트에 가상환경을 표시해 주는 스크립이다. 출처: https://gist.github.com/frnhr/dba7261bcb6970cf6121 참고 https://github.com/pyenv https://github.com/pyenv/pyenv-virtualenv https://towardsdatascience.com/managing-virtual-environment-with-pyenv-ae6f3fb835f8 http://taewan.kim/post/python_virtual_env/","link":"/pyenv_2Virtualenv-874a43f707f6/"},{"title":"pyenv 설치","text":"Python 의 pyenv 기반 개발환경 데모 환경은 OS X와 리눅스로 한정합니다. 파이썬에는 Python 2와 Python 3이 공존하고, 파이썬 별로 다수의 서브 버전이 존재합니다. 또한, 파이썬 커뮤니티는 엄청난 수의 패키지를 만들고 공유하고 있습니다. 이러한 패키지들은 개별적으로 여러 버전을 갖고 있습니다. Python의 dependency 관리Node 모듈으로 만들어지는 Javascript 프로젝트는 package.json으로 Dependency를 관리하고, Ruby 프로젝트는 gemfile실행파일으로 관리한다. 그렇다면 Python은 이 문제를 어떻게 해결할까? Python은 Virtual Environment 를 지원하는 툴으로 이 문제를 해결한다. 각 프로젝트마다 쓰일 가상 환경(virtual environment)를 생성하여 그 프로젝트에 해당되는 Python을 활성화 한 후에 실행시킨다. 또한 가상 환경 안에 설치된 package들은 python의 freeze 명령어를 통해서 requirements.txt라는 파일로 추출되고, 이것을 git같은 버전 관리 도구로 관리하면, 새로운 개발 환경에서도 쉽게 이를 동기화시킬 수 있다. pyenv란 무엇인가?pyenv란 여러 버전의 Python을 쉽게 바꿔서 쓸 수 있게 해주는 도구이다. 예를 들면 3.5.2버전을 쓰다가, 명령어 한 줄로 2.7.12로 버전을 바꾸어서 쓸 수 있게 해준다. 이는 python-virtualenv와 같이 쓰면 더욱 활용도가 높아진다. 단, 윈도우는 지원을 안하고 별도의 [pyenv-win[(https://github.com/pyenv-win/pyenv-win) 을 사용할 수 있다. 여기 다루는 파이썬 가상환경에 대한 툴은 다음과 같이 요약할 수 있습니다. pyenv 파이썬 버전을 관리하는 툴. 하나의 컴퓨터에 다양한 파이썬 버전을 설치하고 관리. 프로젝트 홈페이지: https://github.com/pyenv/pyenv pyenv-virtualenv virtualenv은 파이썬 환경을 격리하는 툴. pyenv-virtualenv은 virtualenv의 pyenv 확장 플러그인. 파이썬 버전과 라이브러리의 완전한 격리 환경을 제공. autoenv autoenv는 디렉터리 이동 시 실행되는 스크립트 pyenv-virtualenv 사용 시 불편한 수작업을 자동화. 특정 프로젝트 폴더로 들어가면 .env파일 실행하여 가상환경 활성화. pip 파이썬 라이브러리를 관리. pyenv 설치사전 준비Python 3.4 이상은 요구한다. pip로 virtualenv 를 설치가 필요하다. 개발환경은 Ubuntu 16.04 or later Windows 7 or later macOS 10.12.6 (Sierra) or later (no GPU support) Raspbian 9.0 or later macOS 설치필요 조건pyenv를 OS X(맥)에 설치하기 위해서는 xcode command line tools과 zlib가 먼저 설치되어 있어야 합니다. xcode command line tools과 zlib를 OS X에서 설치하는 명령은 다음과 같습니다. 두 명령을 터미널 상에서 실행합니다. 12$ sudo xcode-select --install$ brew install homebrew/dupes/zlib macOS Homebrew 설치macoS는 homebrew 를 설치해서 사용하는 것을 가정하고 homebrew로 시스템 python 을 설치한다 pyenv를 OS X(맥)에 설치하기 위해서는 xcode command line tools과 zlib가 먼저 설치되어 있어야 합니다. xcode command line tools과 zlib를 OS X에서 설치하는 명령은 다음과 같습니다. 두 명령을 터미널 상에서 실행합니다. 12$ sudo xcode-select --install$ brew install homebrew/dupes/zlib 123$ /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;export PATH=&quot;/usr/local/bin:/usr/local/sbin:$PATH&quot;$ brew update pyenv 설치: macOS맥 네이티브로 pyenv를 사용해 Anaconda를 설치하고 텐서플로를 설치해 보자 12brew updatebrew install pyenv pyenv 업그레이드는 다음 명령을 사용합니다. 1$ brew upgrade pyenv 환경변수pyenv 경로 설정을 위해 아래를 .bash_profile 에 추가한다. 1234export PYENV_ROOT=&quot;$HOME/.pyenv&quot;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;# pyenv 초기화$eval &quot;$(pyenv init -)&quot; CentOS, Oracle Linux, RHEL 설치https://github.com/pyenv/pyenv/wiki#suggested-build-environment 사전 준비사항RedHat 계열 혹은 Debian 계열에서 아래 같은 패키지가 필요할 수 있다. https://github.com/pyenv/pyenv/wiki#suggested-build-environment Yum 설치 12$ sudo yum install -y zlib-devel bzip2 bzip2-devel \\ readline-devel sqlite sqlite-devel openssl-devel xz xz-devel curl git 우분투 환경에서는 다음과 같은 패키지를 설치합니다. 123sudo apt-get updatesudo apt-get install --no-install-recommends make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev pyenv 설치: Linux리눅스에서 pyenv 설치는 원격 스크립트 pyenv-installer를 사용한다. https://github.com/pyenv/pyenv-installer pyenv-installer 를 이용하여 pyenv를 설치하면, 다음과 같은 pyenv 플러그인도 설치됩니다. pyenv-doctor pyenv-pip-rehash pyenv-update pyenv-virtualenv pyenv-which-ext pyenv-installer는 pyenv 설치 스크립트 입니다. rbenv-installer의 스타일을 빌려서 만든 것입니다. pyenv-installer는 리눅스용 쉘 스크립트 파일입니다. pyenv-installer를 이용하여 pyenv를 설치하기 위해서는 curl과 git이 사전에 설치되어 있어야 합니다. 1curl https://pyenv.run | bash pyenv.run 이 실행이 안되면 다른 설치 명령은 다음과 같습니다. 12$ curl -L \\https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer \\ 설치후 아래 같이 경로 추가 메시지가 나온다. 123456# Load pyenv automatically by adding# the following to ~/.bashrc:export PATH=&quot;/home/qkboo/.pyenv/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot;eval &quot;$(pyenv virtualenv-init -)&quot; pyenv를 최신 버전으로 업데이트해야 할 경우 다음 명령을 수행합니다. 1$ pyenv update 환경변수 적용 및 업데이트다음 명령을 터머널에서 수행하여 환경변수를 등록합니다. 이 명령으로 아래 코드가 bash를 사용하는 상황을 가정합니다. zsh를 사용하실 때는 “~/.bash_profile“을 “~/.zshrc“로 변경하여 실행해야 합니다. 1234$ echo 'export PYENV_ROOT=&quot;$HOME/.pyenv&quot;' &gt;&gt; ~/.bash_profile$ echo 'export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;' &gt;&gt; ~/.bash_profile$ echo 'eval &quot;$(pyenv init -)&quot;' &gt;&gt; ~/.bash_profile$ source ~/.bash_profile pyenv 사용pyenv는 다음과 형태로 실행됩니다. pyenv {sub-command} [{parameters}….]pyenv가 제공하는 서브 명령은 다음과 같습니다. 서브 명령 설명 local 현재 디렉터리에 python 버전 확인 및 python 버전 지정 global 전역으로 설정된 python 버전 shell shell에 파이썬 버전을 지정 install python-build를 이용하여 파이썬 버전을 설치 uninstall 지정한 버전의 파이썬을 삭제 version 현재 활성화된 파이썬 버전 출력 versions pyenv로 설치되어 이용 가능한 버전을 출력 which 활성화된 파이썬 명령의 위치 출력 whence 지정한 명령을 포함하는 모든 파이썬 버전 출력 버전 설치pyenv로 설치할 수 있는 버전의 목록을 보려면 다음과 같은 명령어를 입력한다. 1$ pyenv install --list [list들]엄청나게 많은 버전들이 있을텐데, 여기서는 현재 최신 버전인 3.5.2버전을 설치하도록 하겠다. (목록에서 위로 올리다 보면 있다) 1$ pyenv install 3.5.2 이렇게 하면 설치가 완료된다. 설치하는데에 시간이 조금 오래 걸린다. 설치된 목록을 확인하려면 다음과 같은 명령어를 입력한다. 1234$ pyenv versions* system (set by PYENV_VERSION environment variable) 3.5.2 shell 명령설치된 버전은 pyenv versions 명령으로 나타나고, 버전 이름 맨 앞의 *표시는 현재 사용하고 있는 Python버전이다. 현재 쉘에서 다른 버전으로 옮기려면 shell 명령어를 입력한다. 1$ pyenv shell 3.5.2 UninstallThis is handy because removing these versions is trivial: 1$ rm -rf ~/.pyenv/versions/2.7.15 Of course pyenv also provides a command to uninstall a particular Python version: 1$ pyenv uninstall 2.7.15 Global &amp; Local시스템 수준의 버전 지정은 global 명령과 local 명령으로 지정할 수 있다. global 글로벌 설정pyenv를 시스템 수준의 python 버전을 설정해서 시스템의 기본 파이썬 버전으로 지정할 때 유용하다. 다음은 컴퓨터의 글로벌 파이썬 버전을 파이썬 2.7.12에서 새로 설치한 파이썬 3.5.3으로 변경하는 예입니다. 아래 명령을 수행한 후, python을 실행하면 Python 3.5.3 버전이 실행됩니다 123$ pyenv versions* system 3.5.3 (set by /Users/qkboo/.pyenv/version) 123456789$ python --version ## 현재 파이썬 버전Python 2.7.12$ pyenv global 3.5.3 ## 글로벌 파이썬 설정 변경$ python --version ## 현재 파이썬 버전Python 3.5.3$ pyenv versions ## pyenv 활성 버전 확인 system* 3.5.3 (set by /Users/qkboo/.pyenv/version)$ global 명령을 내리면 ~/.pyenv/version 파일을 해당 버전으로 지정한다 local 로컬 설정특정 디렉터리에 활성화되는 파이썬 버전을 지정할 수 있습니다. 그리고 로컬 디렉토리 이외에서는 global 설정이 적용됩니다. 다음은 pyenv global과 pyenv local을 사용하는 방법의 예시입니다. 1234567891011121314151617181920212223$ pyenv versions ## global 설정 3.5.3 system 2.7.13* 3.5.3 (set by /home/opc/.pyenv/version)$ python -V ## Global 파이썬 버전Python 3.5.3$ mkdir py2.7$ cd py2.7/$ pyenv local 2.7.13 ## local 설정 2.7.13[py2.7]$ python -VPython 2.7.13[py2.7]$ ls -altotal 12drwxrwxr-x 2 opc opc 4096 Sep 8 01:47 .drwx------. 10 opc 500 4096 Sep 8 01:47 ..-rw-rw-r-- 1 opc opc 7 Sep 8 01:47 .python-version[py2.7]$ cat .python-version ## local 설정 파일2.7.13[py2.7]$ cd .. ## global 설정 3.5.3$ python -VPython 3.5.3[opc@b4b8b6 ~]$ “pyenv local“를 실행하면 해당 디렉터리에 .python-version 파일이 생기고 이 파일에 활성화될 파이썬 버전이 기록됩니다. Test suitePro Tip: A great way to get peace of mind that the version of Python you just installed is working properly is to run the built-in test suite: 12$ pyenv global 3.8-dev$ python -m test This will kick off lots of internal Python tests that will verify your installation. You can just kick back and watch the tests pass. Using your environment in IDEsIf you are not as sehell person, you can also use pyenv with your favourite IDE. Many editors and IDEs are aware of pyenv environments and will detect them for you. Then you will be able to select the environment for your current workspace from a dropdown menu. 참고 http://taewan.kim/post/python_virtual_env/ https://realpython.com/intro-to-pyenv/#using-pyenv-to-install-python","link":"/pyenv_1%EC%86%8C%EA%B0%9C%EC%84%A4%EC%B9%98-078a148a14ec/"},{"title":"Jupyterlab 에서 password 생성해 systemd 서비스 이용","text":"Jupyter Lab - systemd 운영jupyterlab 을 Itel 기반의 Ubuntu 시스템에 설치하고 시스템 서비스로 등록하는 과정. Ubuntu 18.04 node.js Anaconda 2020 Restart your shell so the path changes take effect. You can now begin using pyenv. 1exec &quot;$SHELL&quot; Anaconda 배포본 설치 (Ubuntu)우분투용 다운로드 https://www.anaconda.com/products/individual#linux 다움로드안 쉘 스크립트를 시작한다. 1bash ~/Downloads/Anaconda3-2020.02-Linux-x86_64.sh To control whether or not each shell session has the base environment activated or not, run conda config –set auto_activate_base False or True. To run conda from anywhere without having the base environment activated by default, use conda config –set auto_activate_base False. This only works if you have run conda init first. Anaconda 를 설치하면 대부분의 패키지가 내장되어 있다. 설치후 최신 conda 환경 base를 갱신해 준다. 1conda update -n base -c defaults conda nvm으로 Node.js 설치 https://github.com/nvm-sh/nvm#installing-and-updating nvm 설치 1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.0/install.sh | bash 스크립트로 설치를 완료하면 쉘 시작시 nvm 환경을 구성하기 위해서아래 스크립이 자동으로 현재 쉘 스크립트 파일 끝에 추가된다. 만약 아래 스크립이 추가 안되면 아래 스크립트를 (~/.bash_profile, ~/.zshrc, ~/.profile, or ~/.bashrc).)에 추가한다. 12export NVM_DIR=&quot;$([ -z &quot;${XDG_CONFIG_HOME-}&quot; ] &amp;&amp; printf %s &quot;${HOME}/.nvm&quot; || printf %s &quot;${XDG_CONFIG_HOME}/nvm&quot;)&quot;[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \\. &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm node.js 설치 123456~$ nvm ls-remote v14.0.0 v14.1.0 v14.14.0 v14.15.0 (LTS: Fermium) v14.15.1 (Latest LTS: Fermium) lts 최신 버전 14.0을 설치한다. 12345678~$ nvm install --lts 14.15.1Downloading and installing node v14.15.1...Downloading https://nodejs.org/dist/v14.15.1/node-v14.15.1-linux-x64.tar.xz...######################################################################### 100.0%Computing checksum with sha256sumChecksums matched!Now using node v14.15.1 (npm v6.14.8)Creating default alias: default -&gt; lts/* (-&gt; v14.15.1) node 버전을 확인 12~$ node --versionv14.15.1 Conda 에서 jupyterlab 설치Anaconda 나 Miniconda 를 설치하고 가상환경을 하나 생성한다. 1234$ conda create -n tf2 jupyterlab numpy scipy matplotlib tensorflow$ conda activate tf2(tf2) ~$ JupyterLab 실행가상환경에서 jupyterlab 을 외부에서 접속 가능하도록 실행하자. 1(base) $ jupyter-lab --no-browser --ip=* --port=8888 ~/Jupyter-Notebook/ LabConfig 디렉토리12345678910111213$ jupyter --pathsconfig: /home/qkboo/.jupyter /home/qkboo/anaconda3/envs/py3/etc/jupyter /usr/local/etc/jupyter /etc/jupyterdata: /home/qkboo/.local/share/jupyter /home/qkboo/anaconda3/envs/py3/share/jupyter /usr/local/share/jupyter /usr/share/jupyterruntime: /home/qkboo/.local/share/jupyter/runtime JupyterLab 환경 설정jupyter 의 config 파일을 통해서 인증과 구성을 하자. jupyterlab 3.x 버전: jupyter_server_config.py jupyterlab 2.x 버전: jupyter_notebook_config.py Jupyter Lab 에서 설정 파일을 생성한다. 다음 명령으로 각각 $HOME/.jupyter/ 위치에 jupyter_server_config.py 파일이 생성된다. 12(tf2)$ jupyter lab --generate-configWriting default config to: /home/qkboo/.jupyter/jupyter_server_config.py 패스워드 사용jupyter_notebook_config.py 설정 파일에 비밀번호를 추가하려면 비밀번호를 생성해야 한다. 아래 명령으로 생성한다. 1234(tf2)$ jupyter lab passwordEnter password:Verify password:[NotebookPasswordApp] Wrote hashed password to $HOME\\.jupyter\\jupyter_server_config.json jupyter_server_config.json 파일로 암호가 생성된다. 생성한 암호를 jupyter_server_config.py 파일의 c.ServerApp.password 항목에 입력해 준다 12345[jupyter_server_config.py]c.ServerApp.password = 'sha1:*********' # 외부 접속시 사용할 비밀번호c.ServerApp.ip = '*' # 어디서든 접속 가능c.ServerApp.port = 8888 # 접속에 사용할 포트 Jupyter Lab 3.x 버전 123456789c.ServerApp.base_url = '/notebook'c.ServerApp.enable_mathjax = Truec.ServerApp.password = ''c.ServerApp.ip = '*'c.ServerApp.port = 8888c.ServerApp.port_retries = 10c.ServerApp.open_browser = Falsec.ServerApp.tornado_settings = {&quot;websocket_max_message_size&quot;: 400 * 1024 * 1024} Jupyter Notebook, Jupyterlab 2.x 버전: 123456789c.NotebookApp.base_url = '/notebook'c.NotebookApp.enable_mathjax = Truec.NotebookApp.password = ''c.NotebookApp.ip = '*'c.NotebookApp.port = 8888c.NotebookApp.port_retries = 10c.NotebookApp.open_browser = Falsec.NotebookApp.tornado_settings = {&quot;websocket_max_message_size&quot;: 400 * 1024 * 1024} systemd 구성nodejs, jupyter lab 을 시스템 시작 서비스로 등록한다. node.js 경로, jupyterlab 을 위한 시작 환경이 필요하다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닛 파일에 아래 같이 파이썬 환경을 포함해 작성한다. 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 유닛 파일: /etc/systemd/system/jupyter.service 12345678910111213141516171819[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pid# nodejs pathEnvironment=&quot;PATH=/home/qkboo/.nvm/versions/node/v12.18.0/bin/:/usr/local/bin:/ usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin&quot;# anaconda: tf2ExecStart=/home/qkboo/anaconda3/envs/tf2/bin/jupyter-lab --config /home/qkboo/Home/mybook_config.pyUser=qkbooGroup=qkbooWorkingDirectory=/home/qkboo/Home/Jupyter-Notebook/Restart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 유닛 파일 등록과 시작jupyter.service 파일을 등록한다. 1$ sudo systemctl enable jupyter 등록한 유닛 파일을 확인해 보자. 123$ sudo systemctl list-unit-files | grep jupyterjupyter_book.service disabled enabledjupyter.service enabled enabled 그리고 데몬을 리로드 한다. 12$ sudo systemctl daemon-reload$ sudo systemctl start jupyter 실행한 서비스를 종료하려면 1$ sudo systemctl stop jupyter 실행 상태를 확인한다. 1$ sudo systemctl status jupyter 유닛 파일 등록 해지12$ sudo systemctl disable jupyterRemoved /etc/systemd/system/multi-user.target.wants/jupyter.service. 서비스 상태해당 서비스 상태 확인 1$ sudo systemctl status jupyter 구동에 실패한 서비스 보기 1$ sudo systemctl list-units --state=failed enabled 상태인 서비스 목록 1$ sudo systemctl list-units --state=enabled","link":"/JupyterLab_password_systemd-8a92e2396833/"},{"title":"Tensorflow 2 : Build on macOS","text":"2021년, macOS에서 최신 tensorflow 를 사용해 보려고 빌드과정을 거쳐 보았다. macOS: build tesorflow https://www.tensorflow.org/install/source#macos_1 https://wgtech.github.io/posts/2019/05/29/Lets-Build-Tensorflow-CPU-With-Your-Mac/ https://knowm.org/compiling-tensorflow-from-source-on-macos/ 준비 python brew 등으로 최신 파이썬 설치 여기서는 가상환경에서 설치한다 가정 pyenv, venv, conda … 가상환경이 아닌 시스템 환경이면 --user 이용. 유틸 설치 numpy, wheel, keras_preprocessing 설치 가상환경이 아닌 시스템 환경이면 --user 이용. tensorflow 2.4.1 requires numpy~=1.19.2, but you have numpy 1.18.0 which is incompatible. 12pip install -U pip numpy wheelpip install -U keras_preprocessing --no-deps 설치된 패키지를 확인 123$ pip freezeKeras-Preprocessing==1.1.2numpy==1.20.0 Xcodexcode-select –install Xcode installed on your macOS，Then execute the command： 1sudo xcodebuild -license accept What flags are supported by my CPU? To check the instruction sets supported by your CPU, check the output of the following commands: macOS1$ sysctl -a | grep &quot;machdep.cpu.*features:&quot; Linux1$ cat /proc/cpuinfo | grep flags Bazel 설치tensorflow/configure.py 파일에서 BAZEL 버전을 찾는다. 이중 MAX 로 지시한 Bazel 버전을 사용한다. 123_TF_CURRENT_BAZEL_VERSION = None_TF_MIN_BAZEL_VERSION = '3.1.0'_TF_MAX_BAZEL_VERSION = '3.99.0' https://docs.bazel.build/versions/4.0.0/install-os-x.html 를 참고해서 https://github.com/bazelbuild/bazel/releases 에서 MIN, MaX 사이의 적합한 installer 버전을 설치한다. 다운로드다운로드한다. 예를 들어 3.7.2 버전의 sh 설치 파일은 bazel-3.7.2-installer-darwin-x86_64.sh 이다. 12$ export BAZEL_VERSION=3.7.2$ curl -fLO &quot;https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh&quot; Run the installerRun the Bazel installer as follows: 12chmod +x &quot;bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh&quot;./bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh --user --user 플래그로 설치시 환경변수에 지정 1export PATH=&quot;$PATH:$HOME/bin&quot; 12~$ bazel --versionbazel 3.7.2 bazel 설치: brew~$ brew install bazel 빌드텐서플로우 소스를 준비해서 bazel 을 사용해 빌드한다. 소스 준비1234567$ git clone https://github.com/tensorflow/tensorflow.git'tensorflow_src'에 복제합니다...remote: Enumerating objects: 1081830, done.remote: Total 1081830 (delta 0), reused 0 (delta 0), pack-reused 1081830오브젝트를 받는 중: 100% (1081830/1081830), 648.00 MiB | 5.20 MiB/s, 완료.델타를 알아내는 중: 100% (881614/881614), 완료.Updating files: 100% (24312/24312), 완료. v2.3.2 빌드git 체크아웃 123456789$ git tag0.12.0-rc0...v2.3.0v2.3.1v2.3.2$ git checkout v2.3.2 필요한 유틸리티 패키지 설치 12345678$ python -VPython 3.8.7$ pip install -U pip wheel$ conda install &quot;numpy&gt;=1.8,&lt;1.19&quot;$ pip install -U keras_preprocessing --no-deps configureconfigure 쉘 스크립이 LFCR 로 되어 ㅇㅣㅆ어서 CR로 변경해야 한다. 12$ mv configure configure.orig$ sed $'s/\\r$//' configure.orig &gt; configure configure 12345678910111213141516171819202122232425262728293031323334353637383940414243$ ./configureYou have bazel 3.7.2 installed.Please specify the location of python. [Default is /Users/qkboo/.pyenv/versions/tf2_build/bin/python3]:Found possible Python library paths: /Users/qkboo/.pyenv/versions/tf2_build/lib/python3.8/site-packagesPlease input the desired Python library path to use. Default is [/Users/qkboo/.pyenv/versions/tf2_build/lib/python3.8/site-packages]Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: nNo OpenCL SYCL support will be enabled for TensorFlow.Do you wish to build TensorFlow with ROCm support? [y/N]: nNo ROCm support will be enabled for TensorFlow.Do you wish to build TensorFlow with CUDA support? [y/N]: nNo CUDA support will be enabled for TensorFlow.Do you wish to download a fresh release of clang? (Experimental) [y/N]: nClang will not be downloaded.Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native -Wno-sign-compare]:Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: nNot configuring the WORKSPACE for Android builds.Do you wish to build TensorFlow with iOS support? [y/N]: yiOS support will be enabled for TensorFlow.Preconfigured Bazel build configs. You can use any of the below by adding &quot;--config=&lt;&gt;&quot; to your build command. See .bazelrc for more details. --config=mkl # Build with MKL support. --config=monolithic # Config for mostly static monolithic build. --config=ngraph # Build with Intel nGraph support. --config=numa # Build with NUMA support. --config=dynamic_kernels # (Experimental) Build kernels into separate shared objects. --config=v2 # Build TensorFlow 2.x instead of 1.x.Preconfigured Bazel build configs to DISABLE default on features: --config=noaws # Disable AWS S3 filesystem support. --config=nogcp # Disable GCP support. --config=nohdfs # Disable HDFS support. --config=nonccl # Disable NVIDIA NCCL support.Configuration finished 빌드 시작Intel 기반의 macOS에서 기본 배포되는 tensorflow@2.0 을 설치하고 tensorflow 를 실행하면, 1234567891011(tf2_p37)~$ pythonPython 3.7.9 (default, Aug 31 2020, 07:22:35)[Clang 10.0.0 ] :: Anaconda, Inc. on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt;&gt;&gt;&gt; tf.add(1,2).numpy()2021-02-01 14:11:37.000601: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: SSE4.1 SSE4.2 AVX AVX2 FMATo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.2021-02-01 14:11:37.001166: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.3 특화 명령 을 –copt 부분에 명시해서 빌드한다. bazel build: Intel CPU 특화 명령 세트빌드할 때 아래와 같이 cpu option을 추가로주면 해당 cpu에 대해 최적화된 빌드로 진행됩니다. 아래의 copt 들은 머신마다 다르며, tensorflow warning을 보고 적절히 추가해주면 됩니다. 1$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package pip에 배포된 패키지와 동일하게 진행할 것이라면… 1bazel build –config=opt //tensorflow/tools/pip_package:build_pip_package GPU로 Tensorflow를 사용하고 싶다면… (위에 반드시 CUDA 옵션 선택 메시지에서 Y를 눌러야합니다. 그리고 아래와 같은 명령어를 입력하세요.) 1$ bazel build –config=opt –config=cuda //tensorflow/tools/pip_package:build_pip_package GPU cuda 를 포함한 빌드와 CpU 특화 를 함께 1$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda //tensorflow/tools/pip_package:build_pip_package 패키지 빌드pip 패키지를 생성하기 .whl 설치 패키지를 생성한다.패키지 추출 1./bazel-bin/tensorflow/tools/pip_package/build_pip_package ../tensorflow_pkg v2.4.1 빌드12345678910$ git tag0.12.0-rc0...v2.4.0v2.4.0-rc0v2.4.0-rc1v2.4.0-rc2v2.4.0-rc3v2.4.0-rc4v2.4.1 1git checkout v2.4.1 configure 로 CPU 기반 지원을 구성한다. 1234567891011121314151617181920212223242526272829303132333435363738394041$ ./configureYou have bazel 3.7.2 installed.Please specify the location of python. [Default is /Users/qkboo/.pyenv/versions/miniconda3-latest/bin/python3]: /Users/qkboo/.pyenv/versions/tf2_p38/bin/pythonFound possible Python library paths: /Users/qkboo/.pyenv/versions/tf2_p38/lib/python3.8/site-packagesPlease input the desired Python library path to use. Default is [/Users/qkboo/.pyenv/versions/tf2_p38/lib/python3.8/site-packages]Do you wish to build TensorFlow with ROCm support? [y/N]: nNo ROCm support will be enabled for TensorFlow.Do you wish to build TensorFlow with CUDA support? [y/N]: nNo CUDA support will be enabled for TensorFlow.Do you wish to download a fresh release of clang? (Experimental) [y/N]: nClang will not be downloaded.Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -Wno-sign-compare]:Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: nNot configuring the WORKSPACE for Android builds.Do you wish to build TensorFlow with iOS support? [y/N]: yiOS support will be enabled for TensorFlow.Preconfigured Bazel build configs. You can use any of the below by adding &quot;--config=&lt;&gt;&quot; to your build command. See .bazelrc for more details. --config=mkl # Build with MKL support. --config=mkl_aarch64 # Build with oneDNN support for Aarch64. --config=monolithic # Config for mostly static monolithic build. --config=ngraph # Build with Intel nGraph support. --config=numa # Build with NUMA support. --config=dynamic_kernels # (Experimental) Build kernels into separate shared objects. --config=v2 # Build TensorFlow 2.x instead of 1.x.Preconfigured Bazel build configs to DISABLE default on features: --config=noaws # Disable AWS S3 filesystem support. --config=nogcp # Disable GCP support. --config=nohdfs # Disable HDFS support. --config=nonccl # Disable NVIDIA NCCL support.Configuration finished 파이썬 실행 가능을 확인하고 configure 후 빌드한다. 123456789101112$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package......INFO: Build options --action_env and --python_path have changed, discarding analysis cache.INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (406 packages loaded, 31116 targets configured).INFO: Found 1 target...Target //tensorflow/tools/pip_package:build_pip_package up-to-date: bazel-bin/tensorflow/tools/pip_package/build_pip_packageINFO: Elapsed time: 16525.185s, Critical Path: 542.13sINFO: 18390 processes: 150 internal, 18240 local.INFO: Build completed successfully, 18390 total actions macbook pro 15(2015), 8GB 에서 약 5시간 소요. 패키지 빌드pip 패키지를 생성하기 .whl 설치 패키지를 생성한다. 1234./bazel-bin/tensorflow/tools/pip_package/build_pip_package ../tensorflow_pkg$ $ ls -l ../tensorflow_pkg/-rw-r--r-- 1 qkboo admin 167M 2 1 13:54 tensorflow-2.4.1-cp38-cp38-macosx_11_0_x86_64.whl 패키지 설치그리고 현재 파이썬 환경에 텐서 플로우를 설치한다 12345$ pip install ../tensorflow_pkg/tensorflow-2.4.1-cp38-cp38-macosx_11_0_x86_64.whl...Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.1 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 markdown-3.3.3 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7 six-1.15.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.3 werkzeug-1.0.1 wrapt-1.12.1 빌드 후에 소스 트리 디렉토리에서 벗어나 설치된 텐서 플로우를 확인해 보자. 12345678910111213141516171819$ cd ~$ python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; tf.add(1, 2).numpy()3&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')&gt;&gt;&gt; hello.numpy()b'Hello, TensorFlow!'&gt;&gt;&gt; t = tf.constant('logcg')2020-01-18 20:04:43.088104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fefdc983db0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:2020-01-18 20:04:43.088134: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version","link":"/tf2-build-macos-4f64b71906a9/"},{"title":"[OpenCV] virtualenv 이용 설치","text":"OpenCV 설치OpenCV 를 파이썬 기본 패키지 관리자 pip 와 venv 가상환경을 이용해서 윈도우즈, 맥 및 리눅스에서 OpenCV 를 설치하는 과정을 살펴보겠다. 윈도우즈에서 macOS에서 Linux에서 1) 윈도우즈 pip 기반 OpenCV 설치윈도우 기반에서 OpenCV 를 사용하기 위해서 pip 기반으로 설치를 해보자. whl 파일로 설치윈도우에서 opencv를 빌드된 버전을 설치하기 위해서 https://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv 에 있는 .whl 파일을 다운로드 받느다. 1&gt; pip install c:\\downloads\\opencv_python‑3.3.1‑cp36‑cp36m‑win_amd64.whl pipOpenCV의 main module만 사용한다면 아래처럼 설치하면 됩니다. 1&gt; pip install opencv-python 만약 main module과 extra module을 같이 사용하고 싶다면 아래처럼 설치합니다. 1&gt; pip install opencv-contrib-python 2) virtualenv 가상환경에서 openCV 설치Python 가상환경과 Opencv파이썬 개발시 virtualenv 를 사용한다면 OpenCV 라이브러리를 연결해 줄 필요가 있다. virtualenv 가상환경 생성시 파이썬 라이브러리는 복사가 안된다 그래서 가상환경 생성후에 cv2.so 라이브러리를 링크해줄 필요가 있다. 가상환경에 cv2.so 연결하기python2 가상환경 cv3python2 가 있고, 여기에 OpenCV 를 사용하려면 다음 같이 cv2.so 라이브러리를 링크해 준다. 12$ cd ~/.virtualenvs/cv3python2/lib/python2.7/site-packages/$ ln -s /usr/local/lib/python2.7/dist-packages/cv2.so cv2.so 역시 python3 가상환경 cv3python3 가 있다면 python3 라이브러리에 있는 cv2.so 라이브러리를 링크해 준다. 12$ cd ~/.virtualenvs/cv3python3/lib/python3.4/site-packages/$ ln -s /usr/local/lib/python3.4/dist-packages/cv2.cpython-34m.so cv2.so 또한 cv2.so를 사용하기 위해서 각 가상환경에 numpy를 설치해 준다. Raspberry Pi 2에서 numpy를 pip로 설치할 때 약 10분 이상 소요된다. 12345$ workon cv3python2(cv3python2) :~/ $ pip install numpy$ workon cv3python3(cv3python3) :~/ $ pip install numpy 마직막으로 파이썬을 실행하고 cv2를 테스트한다. 12345678(cv3python3) ~/$ pythonPython 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; cv2.__version__'3.1.0'&gt;&gt;&gt; OpenCV 테스트https://cinema4dr12.tistory.com/1283 파이썬을 실행해 cv2 라이브러리를 사용해 보자. 12345678$ pythonPython 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; cv2.__version__'3.1.0'&gt;&gt;&gt; 시스템에서 파이썬이 두 개 이상 설치되어 있으면 일반적을 Python2.7 버전이 기본 파아썬 이다. 12345678$ python3Python 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; cv2.__version__'3.1.0-dev'&gt;&gt;&gt; 참조 installing-opencv-3-1-0-on-ubuntu Install OpenCV3 for both Python2, Pytnon3 Install OpenCV3.0 and Python3.4","link":"/opencv3-install(virtualenv)-68da66ad7982/"},{"title":"[OpenCV] anaconda 이용 설치","text":"OpenCV 설치OpenCV 를 설치하기 위해서 소스 빌드, 패키지 설치 방법이 있다. 여기서 pip 기반 가상환경 그리고 Anaconda 를 사용한다는 가정에서 윈도우즈, 맥에서 OpenCV 를 설치하는 과정을 살펴보겠다. 윈도우즈에서 macOS에서 Linux에서 1) 윈도우즈에서 OpenCV 설치윈도우 기반에서 OpenCV 를 사용하기 위해서 Anaconda 배포본을 사용하는 것이 가장 쉽다. whl 파일로 설치윈도우에서 opencv를 빌드된 버전을 설치하기 위해서 https://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv 에 있는 .whl 파일을 다운로드 받느다. 1&gt; pip install c:\\downloads\\opencv_python‑3.3.1‑cp36‑cp36m‑win_amd64.whl pipOpenCV의 main module만 사용한다면 아래처럼 설치하면 됩니다. 1&gt; pip install opencv-python 만약 main module과 extra module을 같이 사용하고 싶다면 아래처럼 설치합니다. 1&gt; pip install opencv-contrib-python conda 명령으로 설치하기Anaconda 3가 설치되어 있다면 명령어 한 줄 입력만으로도 거의 최신 버전(글 작성시 버전 3.6.0)의 Python-OpenCV 라이브러리를 설치할 수 있다: 1&gt; conda install -c conda-forge opencv conda-forge에 등록되어 있는 OpenCV 라이브러리에 대한 상세한 설명은 링크를 통해 확인할 수 있습니다. 필요한 경우, python virtualenv를 생성하여 개발환경 패키지를 관리할 수 있다. OpenCV 3.3의 가장 큰 변화는 Deep Learning in OpenCV 라고 할 수 있겠습니다. 해당 링크에서 Deep Learning 관련 추가된 사항을 확인할 수 있습니다. 이외에 자세한 변경 로그는 OpenCV Change Logs Version:3.3을 참고하시면 되겠습니다. 여담으로 최신 버전 OpenCV 3.3.1 버전 이후에는 JavaScript Interface가 추가되어 인터랙티브 웹-기반 OpenCV 어플리케이션 구현이 공식적으로 가능해졌다고 한다. OpenCV 테스트https://cinema4dr12.tistory.com/1283 파이썬을 실행해 cv2 라이브러리를 사용해 보자. 12345678$ pythonPython 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; cv2.__version__'3.1.0'&gt;&gt;&gt; 시스템에서 파이썬이 두 개 이상 설치되어 있으면 일반적을 Python2.7 버전이 기본 파아썬 이다. 12345678$ python3Python 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; cv2.__version__'3.1.0-dev'&gt;&gt;&gt; Python 가상환경과 Opencv파이썬 개발시 virtualenv 를 사용한다면 OpenCV 라이브러리를 연결해 줄 필요가 있다. virtualenv 가상환경 생성시 파이썬 라이브러리는 복사가 안된다 그래서 가상환경 생성후에 cv2.so 라이브러리를 링크해줄 필요가 있다. 가상환경에 cv2.so 연결하기python2 가상환경 cv3python2 가 있고, 여기에 OpenCV 를 사용하려면 다음 같이 cv2.so 라이브러리를 링크해 준다. 12$ cd ~/.virtualenvs/cv3python2/lib/python2.7/site-packages/$ ln -s /usr/local/lib/python2.7/dist-packages/cv2.so cv2.so 역시 python3 가상환경 cv3python3 가 있다면 python3 라이브러리에 있는 cv2.so 라이브러리를 링크해 준다. 12$ cd ~/.virtualenvs/cv3python3/lib/python3.4/site-packages/$ ln -s /usr/local/lib/python3.4/dist-packages/cv2.cpython-34m.so cv2.so 또한 cv2.so를 사용하기 위해서 각 가상환경에 numpy를 설치해 준다. Raspberry Pi 2에서 numpy를 pip로 설치할 때 약 10분 이상 소요된다. 12345$ workon cv3python2(cv3python2) :~/ $ pip install numpy$ workon cv3python3(cv3python3) :~/ $ pip install numpy 마직막으로 파이썬을 실행하고 cv2를 테스트한다. 12345678(cv3python3) ~/$ pythonPython 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; cv2.__version__'3.1.0'&gt;&gt;&gt; Gstreamer1$ sudo apt install python3-gst-1.0 참조 installing-opencv-3-1-0-on-ubuntu Install OpenCV3 for both Python2, Pytnon3 Install OpenCV3.0 and Python3.4","link":"/opencv3-install(conda)-41d1e62fd092/"},{"title":"[OpenCV] Source build","text":"OpenCV를 사용하는데 여러 방법이 있겠지만 SBC 컴퓨터들에서 소스로 빌드해서 사용해야할 경우가 있다. OpenCV 소스 빌드여기서 OpenCV를 개발 도구와 라이브러리들과 함게 소스를 빌드해서 사용하는 방법을 살펴보겠습니다. Raspberry Pi 3: Raspbian Jessie Odroid C2: Armbian ROCK64: Armbian 빌드는 OpenCV 3.1.1 버전을 대상으로 수행했다. OpenCV3.1 빌드로 설치http://docs.opencv.org/3.1.0/df/d65/tutorial_table_of_content_introduction.html OpenCV 3.1를 빌드하는데 필요한 패키지 GCC 4.4.x or later CMake 2.8.7 or higher Git GTK+2.x or higher, including headers (libgtk2.0-dev) pkg-config Python 2.6 or later and Numpy 1.5 or later with developer packages ( python-dev, python-numpy) ffmpeg or libav development packages: libavcodec-dev, libavformat-dev, libswscale-dev [optional] libtbb2 libtbb-dev [optional] libdc1394 2.x [optional] libjpeg-dev, libpng-dev, libtiff-dev, libjasper-dev, libdc1394-22-dev 그리고 VideoStreaming이 필요하면 gstramer 필요. 패키지 설치기존 패키지로 설치되 opencv가 있으면 제거한다. 12$ sudo apt remove libopencv$ sudo apt remove opencv 최신 소프트웨어 상태로 업데이트 합니다. 12$ sudo apt update$ sudo apt upgrade 먼저 컴파일러와 빌드 관련 패키지를 설치합니다. 12$ sudo apt install build-essential$ sudo apt install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev GTK 개발용 라이브러리는 GUI를 구성할 때 필요하다. 1$ sudo apt install libgtk-3-dev 이미지 처리에 필요한 패키지를 설치한다. 1$ sudo apt install libgphoto2-dev libjpeg-dev libtiff-dev libtiff5-dev libjasper-dev libpng12-dev libpng-dev libtbb2 libtbb-dev 필요하다면 비디오 입출력 관련한 패키지를 설치해야 한다. OpenCV에서 비디오 파일을 읽는데 필요하다. 1$ sudo apt install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libdc1394-22-dev 필요하면 스트리밍 처리에 필요한 gstreamer를 설치한다. 1$ sudo apt install gstreamer-1.0 OpenCV 안에서 다양한 최적화 작업에 필요한 다음 패키지를 설치한다. 1$ sudo apt install libatlas-base-dev gfortran 마지막으로 파이썬에서 사용한다면 꼭 numpy 를 설치해야 한다. numpy 는 pip로 설치해야 한다. OpenCV Python에서 이미지를 NumPy의 다차원배열로 표현해 사용하고 있다: 시스템에 Python2.7과 python3.4가 설치되어 있다면, 각 pip버전을 명시해서 각각 설치해야 하는 듯 하다. numpy가 제대로 인식이 안되면 Opencv용 python 모듈이 빌드가 안된다. Raspbian jessie 2016-09-23 버전 이후에는 numpy가 기본으로 설치되어 있다. 12~$ sudo pip2 install numpy~$ sudo pip3 install numpy Raspberry Pi 2에서 numpy를 pip로 설치할 때 약 10분 이상 소요된다. 혹은 업그레이드 해준다. 12$ sudo pip2 install --upgrade numpy$ sudo pip3 install --upgrade numpy numpy 설치후 다음 같이 제대로 동작하는지 확인해 보자 1234567891011$:~ $ python2...$:~ $ python3Python 3.4.2 (default, Oct 19 2014, 13:31:11)[GCC 4.9.1] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; np.__version__'1.10.4'&gt;&gt;&gt; 파이썬에서 사용하려면 다음 같이 파이썬 관련 라이브러리가 필요 1$ sudo apt install python-dev python3-dev python-numpy python3-numpy 개발환경을 apt 방식으로 구성했다면, numpy도 apt로 설치 할 수 있다 – 왠지 잘 안됐다.$ sudo apt install python-numpy 마지막으로 파이썬에서 matplotlib를 이용한다면 python3-gtk 패키지를 설치해 준다. 1$sudo apt install python3-gtk Opencv 다운로드 및 빌드 확경 구성1234$ cd ~$ git clone https://github.com/Itseez/opencv.git$ cd opencv$ git checkout 3.1.0 빌드를 설정하기 위해서 build폴더를 만든다. 파이썬 환경이 있는 cv 가상환경 build 를 준비 123~$ cd opencv~$ mkdir build~$ cd build 빌드를 수행 12345678910111213141516~$ cmake -D CMAKE_BUILD_TYPE=RELEASE \\-D CMAKE_INSTALL_PREFIX=/usr/local \\-D INSTALL_C_EXAMPLES=OFF \\-D INSTALL_PYTHON_EXAMPLES=ON \\-D BUILD_EXAMPLES=ON .....-- Python 2:-- Interpreter: /usr/bin/python2.7 (ver 2.7.9)---- Python 3:-- Interpreter: /usr/bin/python3.4 (ver 3.4.2)---- Python (for build): /usr/bin/python2.7 위 스크립은 OpenCV 3.1.0의 CMake 빌드 버그로, OpenCV 3.0.0 까지 -D INSTALL_C_EXAMPLES=ON으로 빌드했지만 3.1.0에서는 -D INSTALL_C_EXAMPLES=OFF로 해야한다.또한 opencv_contrib 모듈을 함께 빌드한다면 -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules를 함께 사용한다. 컴파일과 설치그리고 컴파일 한다. 12345678~(cv)$ make -j4 # RPi2...[100%] Built target example_ocl_tvl1_optical_flowreal 173m22.432suser 165m58.970ssys 5m7.060s 싱글로 make시 Raspberry Pi 2 에서 빌드시 약 3시간 소요.-j 옵션을 이용시 45분 이상 절약. 빌드된 결과중에 python2, python3 관련해서 라이브러리가 제대로 빌드되었는지 라이브러리 폴더를 확인한다. 12$ ls lib/cv2.so$ ls lib/python3/cv2.cpython-34m.so 이 두 라이브러리가 생성되 있으면 빌드가 제대로 된 것이다. 이제 로컬 시스템에 설치를 한다. 보통 Python2.7과 Python3.4가 함께 설치되 상태일 수 있는데 이 경우 시스템에 기본 Python2.7 환경을 기반으로 설치가 된다. 12345678910(cv)$ sudo make install...-- Installing: /usr/local/include/opencv2/contrib/detection_based_tracker.hpp-- Installing: /usr/local/lib/python2.7/dist-packages/cv2.so-- Set runtime path of &quot;/usr/local/lib/python2.7/dist-packages/cv2.so&quot; to &quot;/usr/local/lib&quot;-- Installing: /usr/local/lib/python2.7/dist-packages/cv.py-- Installing: /usr/local/lib/libopencv_stitching.so.2.4.11...(cv)$ sudo ldconfig 설치된 opencv 패키지 버전을 확인한다. 12$ pkg-config --modversion opencv3.1.0 cv2.soPython2.7이 함께 설치되어 있는 경우 빌드시 Python3.x의 site-packages에 파일 cv2.cpython-34mu.so 로 설치되어 있다. 이 파일은 실제 파이썬 바인딩으로 실제 파이썬 환경에서 이 라이브러리가 필요하기 하다. Python3 가상환경에서 이 파일 심볼릭 링크를 cv 환경에 cv2.so라는 이름으로 연결해 준다. 파이썬은 관행적으로 opencv 라이브러리를 cv2.so 파일로 표현하고 있다. python3의 경우 라이브러리 이름을 cv2로 링크해 준다. 1234$ cd /usr/local/lib/python3.4/dist-packages$ lscv2.cpython-34m.so numpy numpy-1.11.2.egg-info$ sudo ln -s cv2.cpython-34m.so cv2.so","link":"/opencv3-build-c0adf4252264/"},{"title":"macOS에서 Jekyll 설치와 Minimalmistake Theme","text":"이 글은 github pages 를 통해서 블로그를 할 수 있도록 다음 작업을 한다: 로컬에 ruby를 기반으로한 jekyll 을 설치한다. github pages 와 연동한다. markdown 으로 작성한 문서를 github pages 에 올린다. jekylljekyllrb.com 의 가이드에 따라 github page에서 블로그로 사용하고자 한다. 설치Ruby 개발 도구가 반드시 필요 - 여기서 macOS 에서 블로그 작업을 한다고 가정한다. macOS는 Ruby 최신 버전이 제공되고 있다. 여기선 Homebrew 로 루비를 설치하고 사용한다. Ruby 환경Ruby 개발 도구가 반드시 필요한데 다음 같이 rbenv 이라는 가상 개발 환경으로 설치하는게 깔끔하다. Ruby 가상개발환경을 설치한다. Install HomebrewHomebrew 를 설치한다. 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Homebrew 를 통해 ruby 최신 버전을 설치한다. 2020년 3월 현재 2.7.0 을 설치하겠다. 그리고 환경변수 PATH 에 추가해 준다. 1echo 'export PATH=&quot;/usr/local/opt/ruby/bin:$PATH&quot;' &gt;&gt; ~/.bash_profile ruby 버전을 확인한다. 12$ ruby -vruby 2.7.0p0 (2019-12-25 revision 647ee6f091) [x86_64-darwin19] jekyll 설치Jekyll 을 설치시 시스템의 ruby gem 의 로컬 혹은 글로벌 설치를 선택해야 한다. 가능하면 로컬 설치를 권장하므로 여기서 로컬 설치만 다룬다. 글로벌 설치는 여기 Global Install을 참조한다. 로컬 설치bundler gem은 다른 Ruby gem을 관리하는 gem으로 gem과 gem 버전, 의존성을 지키게 해준다. gem 으로 설치한다. 1234567$ gem install --user-install bundler jekyllFetching bundler-2.1.4.gemWARNING: You don't have /Users/qkboo/.gem/ruby/2.7.0/bin in your PATH, gem executables will not run.Successfully installed bundler-2.1.4... 현재 루비 버전을 확인후 버전의 앞 두자리 숫자를 아래 경로에 XX 에 추가한다. 12$ ruby -vruby 2.7.0p0 (2019-12-25 revision 647ee6f091) [x86_64-darwin19] 루비 버전 앞 두 자리를 아래 경로 X.X 에 입력해 실행한다. 1$ echo 'export PATH=&quot;$HOME/.gem/ruby/X.X.0/bin:$PATH&quot;' &gt;&gt; ~/.bash_profile 쉘을 다시 시작한 후 홈 디렉토리에서 gem 경로를 확인한다. 1$ gem env 설치한 jekyll 버전을 확인한다. 12$ jekyll -vjekyll 4.0.0 which jekyll1/Users/qkboo/.gem/ruby/2.7.0/bin/jekyll jekyll 사용jekyll 명령으로 블로그 사이트를 생성, 갱신, 삭제 등이 가능하다. https://jekyllrb.com/docs/#instructions 새 사이트를 구성한다. 123$ jekyll new my-siteRunning bundle install in /home/qkboo/ 이렇게 생성된 사이트는 아래 같은 구조를 갖는다: 12345678my-site/ ├── Gemfile ├── Gemfile.lock ├── _config.yml ├── _posts │ └── 2016-12-04-welcome-to-jekyll.markdown ├── about.md └── index.md 여기에 bundle로 Gem을 설치한다. 12$ cd my-site$ bundle install 그리고 다음 같이 서버를 실행하면 블로그를 구성할 수 있는 config.yml 파일을 생성한다. 123456$ bundle exec jekyll serveServer address: http://127.0.0.1:8080/ Server running... press ctrl-c to stop.Ctrl+C Ctrl+C 종료 시키고 my-site/_config.yml 파일에 다음 같이 외부에서 접속 가능하게 해준다. 123# deploymenthost: 0.0.0.0port: 5000 이렇게 해주어야 외부에서 브라우저로 접근할 수 있다. 1$ bundle exec jekyll serve macOS에서 jekyll로 실행한 서버가 4000 포트에서 대기중인지 확인 1$ sudo lsof -i :4000 bundle 명령bundle 명령을 사용해 jekyll 을 실행할 수 있다. 또한 URL Root 위치를 –baseurl 로 변경 1$ bundle exec jekyll serve -w --baseurl '/' Port 변경 1$ bundle exec jekyll serve -w --baseurl '/' --port 4000 디버그 메시지 출력 –trace: 1$ bundle exec jekyll serve -w --trace gem list jekyll RubyGem으로 jekyll 관리RubyGem 을 사용하기 위해 gem 명령으로 사용한다: 1$ jekyll --version 설치한 지킬 또는 gem 패키지 목록은 다음의 명령으로 확인할 수 있다. 123$ gem listor$ gem list jekyll # jekyll 목록 RubyGems 으로 gem 버전을 찾을 수 있다. 1$ gem search jekyll --remote 지킬 특정 버전을 사용하고 싶다면 아래와 같은 옵션을 주면 된다. (예, 1.5.1) 1$ gem install jekyll -v 1.5.1 지킬 삭제는 아래와 같다. 1$ sudo gem uninstall jekyll 특정 버전 삭제는 아래와 같다. (예, 1.5.1) 1$ gem uninstall jekyll -v 1.5.1 다양한 지킬 버전이 설치되어 있을 때 최신 버전 제외 모두 삭제는 아래와 같다. 1$ sudo gem cleanup jekyll 지킬 버전 업데이트는 아래와 같다. gem update를 사용하는 것이 좋다. 123$ sudo gem updateor$ sudo gem update jekyll 위의 내용들은 아래의 명령을 통해 도움을 얻을 수 있다. 1$ gem help gem-based themes에서는 assets, _layouts, _includes, _sass 디렉토리가 테마의 gem에 있다. MathJaxLaTex 같은 수학 수식을 지원하려면 _include/head.html 같은 위치에 MathJax 를 포함한다. 1234&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; git-pages 연동하기참조 Jekyll Installation:macOS Jekyll Quickstart","link":"/2020-03-06-jekyll-mmtheme-macos-2dc78e96c76c/"},{"title":"HTTPS를 위한 공인인증서 - Let&#39;s Encrypt 발급","text":"2020-06-02: 매뉴얼 방식 수정2020-02-02: 최초 작성{:.right-history} Nginx 서버에서 HTTPS 사용할 수 있는 공인인증서를 발급해 설치하려고 한다. 여기서는 Lets Encrypt 무료 공인인증서 발급을 다룬다. letsecrypt 공인인증서는 3개월 정도 기간만 사용 가능하고 갱신해야 한다. **단독 도메인을 호스팅하는 개인 서버에서 Nginx**에 적용해 본다. 인증서는 개별 도메인 혹은 와일드카드 인증서 로 도메인 안의 모든 호스트를 포함하는 두 종류로 발급이 가능하다. Let’s EncryptLet’s Encrypt 는 https://letsencrypt.org 에서 여러 인터넷 관련 업체의 후원을 받아 운영하고 있다. LetsEncrypt 발급발급을 위해 리눅스/맥 쉘 기반의 Certbot 유틸리티를 사용하거나 웹 기반으로 가능하다. 여기서는 Certbot 를 사용해서 Let’s Encrypt 와일드 카드 인증서를 발급해 보겠다. 인증서를 발급 받기위해서는 Let’s Encrypt 인증서를 자동으로 생성하고 관리하는 패키지인 certbot 를 먼저 설치해야 한다. 우분투/데비안에서 설치우분투/데이안 같은 리눅스 환경에서 설치하고 구성했다. 기타 다른 오에스 배포판은 아래 사이트에서 설치 명령어를 참고하자. https://certbot.eff.org/ Certbot 설치: 1234$ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update certbot 관련 Apache, Nginx 용 파이썬 모듈을 설치한다. Nginx 를 운영한다면 12$ sudo apt-get install python-certbot3-nginx #python3$ sudo apt-get install python-certbot-nginx Apache2 를 운영한다면, 12$ sudo apt-get install python-certbot3-apache #python3$ sudo apt-get install python-certbot-apache 와일드카드 인증서 발급와일드카드 인증서는 도메인의 호스트 단위에서 여러 서브 도메인까지 지원하는 인증서이다. 예를 들어 example1.kr 도메인의 하위 도메인 abc.example1.kr, 1234.example1.kr 등에 모두 적용하고자 할 때 와일드 카드 인증서를 발급하는 것이다. 이 인증서를 발급 하기 위해서는 도메인 서버를 다루거나 호스팅 기관의 도메인 관리 도구를 통해서 *DNS 레코드* 에 부가적인 정보를 추가해야 한다. 발급 요청시 letsencrypt 는 세 가지 방법으로 webroot와 Standalone, DNS의 3가지 방식으로 적절한 요청을 확인하는 검증 절차를 통해 발급을 인증서를 인가한다. webroot : 도메인 호스트 서버에 임의 Url에 접근해 검증. standalon: DNS: 도메인의 DNS 서버에 TXT 필드에 임의의 값 통해 검증. webroot 방식웹루트 방식으로 진행하기 전에 먼저 nginx 를 종료해 둔다. 1# systemctl stop nginx 다음 certbot 명령에서 수동모드로 도메인 example1.kr 도메인의 와일드카드 인증서와 호스트 example1.kr 에 대해 명령을 실행한다. 1# certbot certonly --manual -d &quot;*.example1.kr&quot; -d &quot;example1.kr&quot; 수동모드 진행을 시작하면 IP 로깅을 묻는다. 12345678 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you're running certbot in manual mode on a machine that is notyour server, please ensure you're okay with that.Are you OK with your IP being logged?- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: Y 이어서 다음 같이 웹 사이트 접근 URL을 통해서 인증하도록 요구한다. 123456789101112- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Create a file containing just this data:AyTml9aa0IXw0RjNHERtktSxIxjFAkJvUOVis8dDRLQ.dSiF50fKKa4aji-OuIlgg62idngOi4nR6yzEHRaTLsIAnd make it available on your web server at this URL:http://example1.kr/.well-known/acme-challenge/kyTAl9aa0IXw0RjNHERtktSxIxjFAkJvUOVis8dDRLO...Enter 웹 서비스에 파일을 추가하고 내용에 데이터를 넣은후 ngixn 를 시작한다. 1# systemctl start nginx 서버측에 검증을 위해 http://example1.kr/.well-known/acme-challenge/kyTAl9aa0IXw0RjNHERtktSxIxjFAkJvUOVis8dDRLO 경로에 텍스트 파일에 내용을 입력한다. URL 준비가 되면 터미널에서 enter 를 입력하고 정상적으로 인증이 되면 아래 같이 결과를 출력해 준다. 12345678910111213141516Waiting for verification...Cleaning up challengesIMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/example1.kr/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/example1.kr/privkey.pem Your cert will expire on 2020-09-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run &quot;certbot renew&quot; - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 정상적으로 진행되면 인증서와 개인키 파일이 저장된다: /etc/letsencrypt/live/example1.kr/fullchain.pem /etc/letsencrypt/live/example1.kr/privkey.pem 이 파일을 nginx 서버에 설정에 구성하면 된다. DNS 방식 와일드카드 인증서 요청다음 certbot 명령은 도메인 *.example1.com 의 와일드카드 인증서를 요청한다. 12345678910111213# certbot certonly --manual --preferred-challenges dns -d &quot;*.example1.com&quot; -d &quot;example1.com&quot;Saving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator manual, Installer NoneEnter email address (used for urgent renewal and security notices) (Enter 'c' tocancel): gangtai.goh@gmail.comSaving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator manual, Installer NoneObtaining a new certificatePerforming the following challenges:dns-01 challenge for example1.com IP 로깅을 묻는다. 1234567891011---NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you're running certbot in manual mode on a machine that is notyour server, please ensure you're okay with that.Are you OK with your IP being logged?---(Y)es/(N)o: y IP정보 수집 이후에 DNS의 TXT 레코드에 입력할 코드가 발급된다. 이 코드를 도메인 관리 도구에서 주어지 호스트명에 TXT 레코드에 입력한다. 예) 아래는 _acme-challenge.example1.kr 라는 호스트 1234567891011121314---Please deploy a DNS TXT record under the name\\_acme-challenge.example1.kr with the following value:aOVF_X388V8fYECoTJyArawJ95VpUffyUWqH8Q8bJAaBefore continuing, verify the record is deployed.---Press Enter to ContinueWaiting for verification...Cleaning up challenges DNS 관리하는 곳에서 서브 도메인 _acme-challenge.example1.kr 에 위에 출력된 해시코드를 TXT 레코드 추가해 준다. 적용한 후 아래 같이 dig 같은 네임서버 명령으로 txt 레코드에 추가한 해시코드가 나오는지 확인하고 엔터로 진행한다. 123456$ dig txt _acme-challenge.example1.kr...;; ANSWER SECTION:_acme-challenge.example1.kr. 180 IN TXT &quot;aOVF_X388V8fYECoTJyArawJ95VpUffyUWqH8Q8bJAa&quot; 그리고 발급된 도메인 인증서가 저장된 위치가 나타난다. 1234567891011121314IMPORTANT NOTES:- Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/example1.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/example1.com/privkey.pem Your cert will expire on 2020-05-23. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew _all_ of your certificates, run &quot;certbot renew&quot;- If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 정상적으로 진행되면 인증서와 개인키 파일이 저장된다: /etc/letsencrypt/live/example1.kr/fullchain.pem /etc/letsencrypt/live/example1.kr/privkey.pem 이 파일을 nginx 서버에 설정에 구성하면 된다. Let’s Encrypt 자동갱신Let’s Encrypt 인증서는 발급받으면 기간이 사용할 수 있는 기간이 3개월이다. 계속해서 HTTPS 서비스를 운영하려면 인증서가 만료되기 전에 갱신을 해야 한다. certbot 명령으로 자동으로 갱신할 수 있는데 보통 크론에 등록해 두고 사용할 수 있다. root 권한이 필요하므로 root 계정의 cronttab에 아래와 같은 내용을 추가한다. 아래는 3개월 후 달의 1일에 명령을 실행을 등록했다. 10 0 1 1-12/3 * /bin/bash -l -c 'certbot renew --quiet' 혹은 매달 실행하려면 아래 같이 매달 1일 인증서 갱신 명령어를 실행하도록 해도 될 것 같다. 10 0 1 * * /bin/bash -l -c 'certbot renew --quiet' Nginx 설정nginx에 와일드 카드 도메인을 사용할 여러 가상호스트가 구성되어 있다는 가정에서 시작한다. HTTPS 적용하기와일드 카드 nginx.conf 파일에 SSL이 활성화 되었는지 확인한다. 123456### SSL Settings##ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLEssl_prefer_server_ciphers on; 실제 적용할 가상호스트 파일의 server 섹션에 다음 같이 인증서 파일을 활성화 한다. 가상호스트 파일이 여러개고 같은 서브 도메인이면 똑같이 적용해 주면 된다. 123456789101112server { listen [::]:443 ssl http2 ipv6only=on; listen 443 ssl http2; server_name www.exmaple1.com example1.com; ssl_certificate /etc/letsencrypt/live/example1.kr/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example1.kr/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; http 요청을 https에 리다이렉트다음 구성은 http://example1.com 로 들어오는 모든 연결을 https://example1.com 으로 전환하는 구성이다. VirtualHost 별로 아래와 같이 Port 80 에 대한 Server설정과 443에 대한 Server설정을 분리 Port 80 에 대해서는 301 Redirect 설정 Nignx 재시작 123456789101112server { listen 80; server_name example1.com example2.com; return 301 https://$host$request_uri;}server { listen [::]:443 ssl http2 ipv6only=on; listen 443 ssl http2; server_name example1.com example2.com; ...} 참고 Certbot: Debian Instruction Getting Started 문서 Let’s Encrypt Wildcard-certificate-with-certbot Wildcard-domain step-by-step nginx ssl 설정 Let’s Encrypt 인증서 발급 - Anapche/Nginx","link":"/Lets_Encrypt%EB%B0%9C%EA%B8%89-c616baa21b02/"},{"title":"Docker 기반 mongodb","text":"Docker 기반 mongodbOfficial : https://hub.docker.com/_/mongo/참조: https://github.com/dockerfile/mongodb 로컬에 “mongo_data” 라는 데이터 저장소가 있고 29817 포트로 실행하기를 한다면 다음 같다: 1$ docker run -d -p 29817:27017 -v /home/its/mongo_data:/data/db --name mongodb mongo 그리고 docker로 시작한 mongodb 컨테이너에 있는 mongo 를 사용해서 데이터베이스에 접속할 수 있다. 1$ docker exec -it mongodb mongo 인증 이용 1$ docker run -d -p 29817:27017 -v /home/its/mongo_data:/data/db --name mongodb mongo --auth admin 데이터에이스에서 사용자 관리 계정 등록 12$ docker exec -it mongodb mongo admin&gt; db.createUser({ user: 'jsmith', pwd: 'some-initial-password', roles: [ { role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; } ] });","link":"/docker-mongodb-8c17318072e6/"},{"title":"MongoDB 구성 설정과 사용자 인증 사용","text":"MongoDB에 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 Mongo Database 설정과 사용자 인증 사용이 문서는 MongoDB Community Edition 를 리눅스 플랫폼에서 시작과 운영에 필요한 구성 파일 mongod.conf 의 설정을 다루고 있다. 이를 통해 데이터베이스 서비스를 동작시키고, 인증한 사용자로서 클라이언트 프로그램으로 접속하기 위한 기본 인증방식을 구성하는 것을 정리하고 있다. Mongo Database 설정 기본인증 구성 이 글의 내용은 MongoDB Community Edition 3.6 이후 4.2 까지 사용이 가능하다. Mongo Database 설정우분투/데비안 계열은 설치시 mongod 데몬이 데이터베이스 운영에 필요한 여러 구성에 대한 설정을 위해서 /etc/mongod.conf 구성 파일을 사용한다. 구성 파일에 데이터베이스 구성에 필요한 여러 설정을 지정할 수 있다. mongodb 사용자와 디렉토리 퍼미션 확인 외부 접속 허용 여부 mongo client 접속 테스트 mongodb 인증 이제 실제 파일에 구성 내용을 설정하는데, 여기서는 mongod 의 기본인증 방법과 데이터 저장소에 대해서만 다룬다. mongod 설정MongoDB의 systemd 서비스는 보통 데이터베이스 구성 파일 /etc/mongod.conf 을 참조한다. mongod 서비스 상태를 확인해 보면 --config /etc/mongod.conf 옵션으로 구성 파일을 지시하고 있다. 123456789$ systemctl status mongod.service* mongod.service - MongoDB Database Server Loaded: loaded (/lib/systemd/system/mongod.service; disabled; vendor preset: enabled) Active: active (running) since Wed 2019-12-19 15:38:14 UTC; 3 weeks 6 days ago Docs: https://docs.mongodb.org/manual Main PID: 2051 (mongod) Memory: 191.3M CGroup: /system.slice/mongod.service `-2051 /usr/bin/mongod --config /etc/mongod.conf mongod.conf 파일을 살펴보자, mongod.conf 파일먼저 /etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. storage: 데이터 베이스 파일 저장 위치 및 방법 dbPath : 데이터베이스 스토리지 위치 systemlog: 로그 파일 및 로그 조작 방법 net: 네트워크 관련 bindIp: 서버 외에서 mongo 클라이언트가 접근하려면 IP 를 입력한다. 먼저 인증을 비활성화 한 구성을 하는데, 다음은 기본적인 mongod.conf 를 구성한 내용이다. 12345678910111213141516storage: dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 127.0.0.1,192.168.0.2 이제 mongo.conf 구성 파일이 준비되었으면 systemctl 로 mongod 데몬을 재시작한다.. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 간단한 구성 설정, 아직은 인증이 비활성화된 상태를 마련 했으면 사용자 인증을 통한 원격 접속을 살펴보자, mongo 기본인증보통 mongo 클라이언트 등에서 MongoDatabase 를 사용하기 위해서 클라이언트를 위한 인증을 제공해야 한다. 클라이언트를 위한 인증은 관리용 데이터베이스에서 데이터베이스 사용자를 등록하고 클라이언트가 등록한 사용자로 데이터베이스에 접속하는 방법을 사용한다. 인증을 추가하기 위해서 mongod의 mongo.conf 설정 파일에 접근 제어를 하지 않는 상태에서 mongo 클라이언트로 접속해서 기본인증을 위한 데이터베이스 사용자를 추가해 준다. Admin 사용자 생성mongod에 인증이 비활성화 상태에서 mongo 클라이언트로 접속에 성공하면 &gt; 프롬프트가 나온 후 use 명령으로 admin 데이터베이스로 전환한다. 12345$ mongo&gt;&gt; use adminswitched to db admin&gt; 1). admin 데이터베이스에서 관리자 role을 가진 사용자를 추가하고, 2). 사용할 데이터베이스의 사용자와 접근 제어를 추가해서 사용하기 위해서 작업한다. user administratoradmin 데이터베이스에 userAdmin role 혹은 userAdminAnyDatabase role을 가진 사용자 만든다. 다음은 admin 데이터베이스에서 사용자 admin 계정를 생성하고 있다. 12345678910111213&gt; use adminswitched to db admin&gt;&gt; db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() 사용자 패스워드 변경은 .changeUserPassword() 메서드를 사용한다. 1&gt; db.changeUserPassword(&quot;accountUser&quot;, &quot;SOh3TbYhx8ypJPxmt1oOfL&quot;) 사용자의 role 변경은 .grantRolesToUser() 메서드를 사용한다. 1&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}]) 혹은 updateUser() 를 사용할 수 있다: 1db.updateUser( &quot;appClient01&quot;, ... 현재 데이터베이스의 사용자를 출력한다. 123456789101112131415161718&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] admin 데이터베이스에 새로 생성한 admin 사용자로 로그인을 해보자. 그러기 위해서는 admin 데이터베이스에 인증 로그인을 한 후에 데이터 베이스를 생성하거나 사용할 수 있다. 인증 활성화mongod.conf 파일 안의 security 섹션에서 security.authorization 을 활성화 한다 12security: authorization: enabled 인증 활성화는 MongoDB v2.4이전에는 인증모드를 명령행의 --auth 옵션을 사용하고, v2.6 이후에서 mongod.conf 파일 사용할 때 security.authorization 를 활성화 하고 있다. systemd 로 서비스를 재시작 한다. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 이렇게 인증모드로 데이터베이스를 시작하면 인증 정보로 로그인해야 한다. 아래 같이 인증 정보없이 로그인 하면 데이터베이스 사용시 에러를 만난다. 123456$ mongo&gt; show dbs;Tue Sep 27 23:22:40.683 listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;unauthorized&quot; } at src/mongo/shell/mongo.js:46&gt;&gt; show usersTue Sep 27 23:22:44.667 error: { &quot;$err&quot; : &quot;not authorized for query on test.system.users&quot;, &quot;code&quot; : 16550 } at src/mongo/shell/query.js:128 이제 인증 모드에서 데이터베이스에 접속해야 한다. 인증모드로 접속데이터베이스 시스템에 접근제어가 활성화 되서 인증모드로 mongo 클라이언트 접속할 때는 옵션으로 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 앞서 생성해둔 admin 계정으로 접속해 보자, 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v4.2connecting to: mongodb://127.0.0.1:27017MongoDB server version: 4.2&gt; MongoDatabae는 데이터베이스 마다 인증한 사용자를 통해 조작을 하게 된다. 그래서 인증모드로 접속 되었지만, 어떤 데이터베이스에 비인증된 사용자로 접근하는 경우는 에러가 발생한다. 예를 들어서 admin 사용자로 인증 로그한 mongodb shell에서 아래 같이 비인증인 student 데이터베이스에 접근하면 에러가 난다: 12345&gt;&gt; use studentsswitched to db students&gt; show users2018-06-25T18:30:38.174+0900 E QUERY [thread1] Error: not authorized on students to execute command { usersInfo: 1.0, $db: &quot;students&quot; } : mongo 비인증 접근시위와 같이 로컬에서 mongo 클라이언트 접속하는 것 외에 외부에서 mongodb로 접근시 authentication을 적용한 상태라면 다음과 같은 URL로 접근할 수 있다: “username:password@HOST_NAME/mydb” 그러나 외부접근시 클라이언트 버전과 서버의 Credential 버전이 맞지 않은 경우 다음 같이 실패 메시지를 확인할 수 있다. 12&gt; 2016-05-16T00:53:10.338+0900 I ACCESS [conn2] Failed to authenticate student@student with mechanism MONGODB-CR: AuthenticationFailed: MONGODB-CR credentials missing in the user document&gt; 2016-05-16T00:53:10.352+0900 I NETWORK [conn2] end connection 220.121.140.59:51634 (0 connections now open) mongod 명령 사용보통 디버깅 목적으로 사용하기 위해서 systemd가 아닌 명령행에서 mongod 명령으로 로 MongoDB를 시작해 설정 파일 등이 제대로 동작하는지 확인할 수 있다. 다만 데이터베이스가 생성하는 데이터와 로그 파일의 접근권한이 실행한 사용자 계정으로 처리되어 퍼미션 문제가 발생할 수 있다. mongoDB v2.6 이후앞서 시작한 명령행 mongodb를 종료하고 명령라인에서 재시작 --auth 옵션을 붙여 시작한다. 1$ mongod --auth --port 27017 --dbpath /data/mongodata 접근제어 --auth 옵션으로 데이터베이스를 시작하면 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 이전 버전의 mongod 명령 mongoDB v2.4 인증모드로 시작``mongod` 명령라인으로 시작할 수 있다. 1$ sudo mongod --port 27017 --dbpath /data/mongodata mongoDB v2.4는 다음 같이 인증 모드로 시작한다. mongod 명령라인에서 --auth 옵션을 붙여 DB 인스턴스(mongod)를 시작 혹은 재시작한다. 1$ mongod --auth --port 27017 --dbpath /data/db1 혹은 mongod.conf 설정 파일에서 auth 를 활성화 한다. 1auth = true 참조[^1]: Install mongodb on Ubuntu","link":"/2019-12-20-mongodb-config-429e9771fa41/"},{"title":"MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu&#x2F;Debian Armbian","text":"MongoDB에 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 Install MongoDB 4.2 Community edition 설치이 문서는 Arm64 기반 CPU를 사용하는 Raspberry Pi, Odroid, PINE64, OrangePi 등 SBC 지원 보드 계열 위에서 Ubuntu/Debian 에서 설치 및 사용 가능한 MongoDB Community Edition 4.2 버전을 설치하고 구성하는 과정을 정리하고 있다. MongoDB Community Edition 버전 Amd64, Arm64 의 설치는 Install MongoDB Community Edition on Debian 에서 제공하고 있다. 하지만 Arm64를 지원하는 Odroid C2, PINE64, OragePi 등 SBC 브드의 Armbian, Ubuntu 오에스에서 MongoDB Community Edition 을 저장소에서 apt 명령으로 직접 설치가 안되서 작은 트릭 이 필요하다. MongoDB Community Edition 4.2 설치 systemd 사용이 가능한 mongod Unit 파일 구성 MongoDB Community Edition 은MongoDB Community Edition 은 다음 패키지를 지원하고 있다: mongodb-org : 다음 패키지를 설치하기 위한 메타 패키지 mongodb-org-server : mongod daemon 과 구성 및 초기 스크립트. mongodb-org-mongos : mongos daemon. mongodb-org-shell : mongo shell. mongodb-org-tools : MongoDB 유틸리티. mongoimport, bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop. 테스트한 플랫폼64bit Arm을 지원하는 Armbian/Ubuntu 배포본을 사용했다. Armbian 기반: PINE64: 64bit, Armbian Hardkernel Odroid C2: 64bit, Armbian 사전준비설치를 위해 MongoDB Community Edition 을 지원하는 저장소를 위한 키 저장소를 구성해 레포지토리 등록인증된 .dpkg, .apt 패키지를 설치하기 위해, 아래 처럼 서버의 키를 등록한다. 키 서버 등록Install MongoDB Community Edition on Debian 에 있는데로 apt 저장소를 위한 키 서버를 등록한다. 1$ wget -qO - https://www.mongodb.org/static/pgp/server-4.2.asc | sudo apt-key add - 사용한 키가 필요 없어서 키 서버 저장소 목록을 지우려면 apt-key 명령으로 삭제할 키 해시 8자리 코드를 확인한다. 1234$ sudo apt-key listpub 4096R/A15703C6 2016-01-11 [expires: 2018-01-10]uid MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt; 이 키를 삭제한다. 1$ sudo apt-key del A15703C6 MongoDB용 소스 리스트 추가키 서버를 등록했으면 apt의 source list에 mongodb repository를 등록해야 한다. Ubuntu 16.04, 18.04 그리고 Debian Stretch/Buster with Armbian 에서 MongoDB Community Edition에 대한 저장소 source list 를 아래 같이 등록해서 사용하겠다. 아래 명령은 /etc/apt/sources.list.d/mongodb-org-4.2.list 파일을 생성하고 apt 소스 목록을 추가한다. 단, 저장소의 구분 이름인 multiverse 를 꼭 지정해 주자. 1echo &quot;deb [ arch=arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.2 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.2.list 보통 APT 계열의 저장소를 위한 소스 리스트는 아래 같이 구성된다. deb URL 배포판명 구분명마지막 구분명은 쓰이는 용도에 따라 main, universe, multiverse 등으로 구분이 되어 있다. 설치apt 명령으로 저장소 소스의 캐시를 갱신하고 mongodb-org 커뮤니티 버전 mongodb를 설치한다. 12$ sudo apt update$ sudo apt install -y mongodb-org 설치 중에 mongodb 3.x, 4.x 버전은 데이터를 저장하는 파일 시스템으로 xfs 를 권장하고 있어서 경고 메시지를 출력하는데 일단 무시한다. apt로 특정 버전을 설치하려면 다음 같이 버전을 명시한다. 1$ sudo apt-get install -y mongodb-org=4.1 무사히 설치를 완료하면 systemd 의 유니트가 추가되어 mongod 서비스를 통해 관리할 수 있다. 설치 확인systemctl 로 mongod 데몬이 동작을 확인해 보자, systemctl 로 서비스를 종료했다 재시작 해보자 12$ sudo systemctl stop mongod.service$ sudo systemctl start mongod.service mongod 가 정상적으로 동작하는지 status 상태를 확인해 보자. 123456789$ systemctl status mongod.service* mongod.service - MongoDB Database Server Loaded: loaded (/lib/systemd/system/mongod.service; disabled; vendor preset: enabled) Active: active (running) since Wed 2019-12-19 15:38:14 UTC; 3 weeks 6 days ago Docs: https://docs.mongodb.org/manual Main PID: 2051 (mongod) Memory: 191.3M CGroup: /system.slice/mongod.service `-2051 /usr/bin/mongod --config /etc/mongod.conf 여기까지 Arm64 기반 Debian Buster인 Armbian 시스템에 Mongodb Community Edition 4.2 버전을 설치하는 과정을 진행했다. mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있는데, 연결을 위해 mondod.conf 라는 구성 파일을 다루어 보자. 설치 위치MongoDB Community Edition이 설치되면 요구되는 파일 및 폴더가 다음 위치에 생성된다. /var/lib/mongodb : 기본 데이터 파일 위치 /var/log/mongodb : 기본 로그 저장 폴더 /etc/mongod.conf : mongod 구성 파일. 로그, 데이터 위치 등을 변경 가능 이제 데이터베이스 시스템을 사용하기 위한 데이터 파일, 네트워크 구성 및 인증 방법을 구성해야 한다. 실제 데이터 베이스 운영을 위해서 구성 파일인 mongod.conf 파일을 사용이 필요하면 이어지는 글을 참조하자. Mongo Database 설정과 사용자 인증 사용 만약 MongoDB community edition을 위 방법같이 설치를 했는데 systemctl 명령으로 찾지 못하면 아래 systemd unit 파일에 대한 글을 참조해서 추가해 주면 된다. systemd unit 파일Armbian 에서 설치중 systemd unit 설정 파일과 MongoDB 시스템 계정 등이 생성되지 않는 경우가 있었다. mongodb-org 설치후 systemd Unit 파일이 /etc/init.d에 복사되지 않는 경우 여기서는 odroid-c2 armbian 설치 상태, 일반 리눅스 배포본은 잘 된다. systemd 를 사용하기 위해서 MongoDB 서버 Daemon을 위한 Unit 파일을 아래를 따라 손으로 생성해 주면 systemctl 명령으로 서비스를 관리할 수 있다. MongoDB Daemon 사용자 추가 Service Unit File 작성 활성화 퍼미션 확인 Run 1. MongoDB Daemon 사용자 추가mongod 데몬은 mongodb user account 계정으로 실행된다. systemctl 명령으로 mongod 를 시작하고 사용하기 위해서는 mongod-org 서비스를 위해서 사용자 mongodb 가 추가되야 한다. 만약 생성되지 않았으면, 새로 만든다. 1$ sudo adduser --disabled-password --gecos &quot;&quot; --no-create-home --disabled-password --disabled-login mongodb 2. systemd service entry데비안/우분투 에서 systemd 서비스 파일은 /lib/systemd/system/ 밑에 위치한다. Mongodb Community Edition 의 Unit 파일은 mongod.service 이다. Mongodb Community Edition 설치시 Unit 파일이 복사되는데 파일이 있는지 확인한다. 1$ ls -l /lib/systemd/system/mongod.service 만약 mongod.service 가 없으면 새로 생성해야 한다. Unit 파일다음은 Mongodb Community Edition 설치시 기본으로 제공되는 유니트 파일이다. 만약 mongod.service 파일이 없으면 /lib/systemd/system/mongod.service 에 생성해서 사용할 수 있다. 123456789101112131415161718192021222324252627282930313233[Unit]Description=MongoDB Database ServerDocumentation=https://docs.mongodb.org/manualAfter=network.target[Service]User=mongodbGroup=mongodbEnvironmentFile=-/etc/default/mongodExecStart=/usr/bin/mongod --config /etc/mongod.conf#PIDFile=/var/run/mongodb/mongod.pidPIDFile=/run/mongodb/mongod.pid# file sizeLimitFSIZE=infinity# cpu timeLimitCPU=infinity# virtual memory sizeLimitAS=infinity# open filesLimitNOFILE=64000# processes/threadsLimitNPROC=64000# locked memoryLimitMEMLOCK=infinity# total threads (user+kernel)TasksMax=infinityTasksAccounting=false# Recommended limits for for mongod as specified in# http://docs.mongodb.org/manual/reference/ulimit/#recommended-settings[Install]WantedBy=multi-user.target 3. 활성화mongod.service 가 있으면 활성화 여부, 즉 systemd 에 mongod.service 가 등록 됐는지 확인한다. /lib/systemd/system/mongod.service 파일을 다음 같이 활성화 시켜준다. 12$ sudo systemctl list-unit-files --type=service |grep mongodmongodb.service disabled disable 상태면 systemctl 명령으로 enable 시킨다. 12$ cd /lib/systemd/system$ sudo systemctl enable mongodb.service 4. 퍼미션 확인MongoDB Community Editon을 소스 빌드로 설치하면 데이터 및 로그 디렉토리를 생성하고 사용자 퍼미션이 설정되야 한다. 예를 들어 로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 시스템 몽고디비 사용자 mongodb 가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongodb.mongodb /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata 5. Runsystemctl 명령으로 mongod 를 시작한다. 12$ sudo systemctl start mongod$ sudo systemctl status mongod 실행한 mongod를 확인해 보면 12$ ps -ef |grep mongodmongodb 15385 1 1 12:06 ? 00:00:00 /usr/bin/mongod --config /etc/mongod.conf mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있다. 참조[^1]: Install mongodb on Ubuntu","link":"/2019-12-20-mongodb-4.2-install_arm64-d7c98dd6a70e/"},{"title":"openSUSE: firewalld","text":"firewalld 를 이용해서 방화벽을 구성해 보자. RedHat, Ubuntu, OpenSUSE LEAP 15.0 등은 시스템 기본 파이어월 관리자로 firewalld 를 제공한다고 한다. firewalldfirewalld 는 …. firewalld는 ufw 처럼 iptables 을 구성할 수 있다. [그림. Firewall Stack (redhat.com)] 네트워크를 지역 관리가 가능해서 다른 네트워크, 지역에 따라 다른 규칙으로 구성해서 사용할 수 있다.For example “Home” and “Office” where all communications with local machines are allowed, and “Public Wi-Fi” where no communication with the same subnet would be allowed. https://www.ctrl.blog/entry/ufw-vs-firewalld firewalld 설치OpenSUSE LEAP 15.0, RedHat, Ubuntu 등은 시스템 기본 파이어월 관리자로 firewalld 를 제공한다고 한다. 1$ sudo apt install firewalld Start firewalldTo start firewalld, enter the following command as root: 1systemctl start firewalld root 사용자로 시작한다. 12sudo systemctl enable firewalldsudo reboot For more information about the service status, use the systemctl status sub-command: 123456sudo systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: disabled) Active: active (running) since Thu 1970-01-01 09:01:48 KST; 48 years 6 months agosudo firewall-cmd --state Stop firewalldTo stop firewalld, enter the following command as root: 1systemctl stop firewalld To prevent firewalld from starting automatically at system start, enter the following command as root: 1systemctl disable firewalld To make sure firewalld is not started by accessing the firewalld D-Bus interface and also if other services require firewalld, enter the following command as root: 1systemctl mask firewalld 사용해 보기firewalld 는 명령라인 firewall-cmd 와 GUI로 firewall-config 명령을 지원한다. Zone 설정Get a list of all supported zones 1firewall-cmd --get-zones List all zones with the enabled features. 12345678910111213141516$ firewall-cmd --list-all-zones...public target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 기본으로 제공하는 Zone drop: Any incoming network packets are dropped, there is no reply. Only outgoing network connections are possible. block: Any incoming network connections are rejected with an icmp-host-prohibited message for IPv4 and icmp6-adm-prohibited for IPv6. Only network connections initiated within this system are possible. public: For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. external: For use on external networks with masquerading enabled especially for routers. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. dmz: For computers in your demilitarized zone that are publicly-accessible with limited access to your internal network. Only selected incoming connections are accepted. workFor use in work areas. You mostly trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. homeFor use in home areas. You mostly trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted. internalFor use on internal networks. You mostly trust the other computers on the networks to not harm your computer. Only selected incoming connections are accepted. trustedAll network connections are accepted. Zone 12sudo firewall-cmd --get-default-zonepublic 서비스This command prints a space separated list. Get a list of all supported services 1$ firewall-cmd --get-services This command prints a space separated list. Get a list of all supported icmptypes 1firewall-cmd --get-icmptypes 서비스를 제거하려면 1234# firewall-cmd --zone=public --remove-service=httpsuccessroot@odroidc2:/home/qkboo# firewall-cmd --zone=public --remove-service=httpssuccess Http, Ssh 방화벽 활성화http, https 를 공개 서비스를 지원하는 기본 존인 public에 추가한다. 123sudo firewall-cmd --add-service=sshsudo firewall-cmd --add-service=httpsudo firewall-cmd --add-service=https sudo firewall-cmd –zone=public –add-service=http –permanent 방화벽을 갱신한다 12firewall-cmd --reloadfirewall-cmd --state 혹은 zone을 지정해 추가한다. 1234sudo firewall-cmd --zone=web --add-service=sshsudo firewall-cmd --zone=web --add-service=httpsudo firewall-cmd --zone=web --add-service=httpssudo firewall-cmd --zone=web --list-all Likewise, we can add the DNS service to our “privateDNS” zone: 12sudo firewall-cmd --zone=privateDNS --add-service=dnssudo firewall-cmd --zone=privateDNS --list-all Zone 에 구성한 서비스 등은 런타임 혹은 완전히 방화벽에 구성할 수 있다. To change settings in both modes, you can use two methods:Change runtime settings and then make them permanent as follows: 12firewall-cmd &lt;other options&gt;firewall-cmd --runtime-to-permanent Set permanent settings and reload the settings into runtime mode: 12firewall-cmd --permanent &lt;other options&gt;firewall-cmd --reload 모든 구성 내용 확인: 1234567891011121314$ sudo firewall-cmd --list-allpublic target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 특정 zone 에 대한 내역을 출력한다: 123456789101112131415$ sudo firewall-cmd --zone=public --list-allpublic target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 참조https://www.linode.com/docs/security/firewalls/introduction-to-firewalld-on-centos/ FirewallD RedHat: Getting started with firewalld How to set up firewalld on CentOS 7 Firewalld configuration and usage","link":"/firewalld-92b3fc2b8647/"},{"title":"Armbian 기반 MongoDB 4.2 설치","text":"Armbian 을 사용하는 보드에서 mongodb 4.2 를 설치한다. 여기에 대한 자세한 내용은 아래 링크를 참조하고 있다. https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/#install-mongodb-community-edition GPG error1W: GPG error: https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.2 Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 4B7C549A058F8B6B 12345$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 3B4FE6ACC0B21F327C549A058F8B6Bgpg: key 4B7C549A058F8B6B: public key &quot;MongoDB 4.2 Release Signing Key &lt;packaging@mongodb.com&gt;&quot; importedgpg: Total number processed: 1gpg: imported: 1 1$ sudo apt install -y mongodb-org 설정mongod.conf 를 간단하게 다음 1234567891011121314storage: #dbPath: /var/lib/mongodb dbPath: /home/qkboo/Db-data/mongodb4 journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.lognet: port: 27017 bindIp: 127.0.0.1 https://docs.mongodb.com/manual/core/security-mongodb-configuration/ 인증명령으로 mongod 로 실행이 가능한 MongoDB Server는 기본적으로 보안 모델이 없이 실행된다. 따라서 별도의 인증 절차를 가지고 있지 않습니다. 이 때문에 2017년 1월에는 이런 약점을 노린 랜섬웨어가 발생하기도 했습니다. MongoDB는 되도록이면 외부로부터의 신뢰되지 않은 접속을 허용하지 않는, 보안에 문제가 되지 않는 환경에서 보안 모델 없이 실행하는 것을 지향하고 있으나, 어쨌든 MongoDB도 ID와 비밀번호로 접근하는 기본적인 보안 모델을 가지고 있으니 이를 통해 MongoDB Server에 인증 과정을 추가해 보도록 합시다. 비인증 모드에서 관리자 계정 생성 인증 접속 1. 비인증 관리자 계정 생성하기mongod로 별도의 보안 모델이 없는 MongoDB Server를 실행하고, MongoDB Shell에 접속합니다. 1234&gt; mongoMongoDB shell version v3.6.3connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.3 MongoDB에는 admin이라는 데이터베이스가 존재하며, 해당 데이터베이스에 사용자를 추가합니다. 123456&gt; use admin&gt; db.createUser({ user: 'username', pwd: 'password', roles: ['userAdminAnyDatabase']}) db.createUser()는 현재 사용하고 있는 데이터베이스(여기서는 admin)에 사용자를 추가합니다. 여기에는 사용자 이름, 비밀번호와 함께 권한(roles)을 array로 정의합니다. MongoDB에서 빌트인으로 제공하고 있는 권한은 MongoDB Built-In Roles에서 확인할 수 있습니다. 위에서 정의한 userAdminAnyDatabase는 어느 데이터베이스든 사용자를 생성하고 제거할 수 있다는 것을 의미합니다. 모든 권한을 가지게 하려면 root를 사용하면 되고, MongoDB 2.4 이하의 경우 db.addUser()를 통해 사용자를 추가합니다. mongod 인증하기만약 mongod 명령으로 실행하면 MongoDB Server를 실행하도록 한다. 1&gt; mongod --auth MongoDB Server 재시작하기Ubuntu와 같은 리눅스 시스템에서 service mongod start처럼 service를 이용할 경우, config 파일을 통해 실행됩니다. 이 경우 /etc/mongod.conf를 다음처럼 수정하고 재시작(service mongod restart)하면 됩니다. mongodb 4.x인증을 활성화 하려면 12security: authorization: enabled mongodb 3.xmongod.conf 를 사용하면 다음 옵션을 true 로 구성한다. 1auth = true 그리고 서비스를 재시작한다. 12$ sudo systemctl restart mongod.service 2. 인증 접속mongo 쉘에 접속하여 db.auth()를 사용하는 것입니다. 12345$ mongoMongoDB shell version v4.2.1connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodbImplicit session: session { &quot;id&quot; : UUID(&quot;177716fe-5b3c-41f6-bdae-d2584819abff&quot;) }MongoDB server version: 4.2.1 쉘에서 db.auth() 를 사용해 인증에 성공하면 1이 나오면 성공이다. 12345&gt; use adminswitched to db admin&gt; db.auth('admin', '!23456789');1&gt; 인증 접속이 되면 로그에 아래 같은 로그를 확인할 수 있다. 12019-12-02T09:49:24.392+0000 I ACCESS [conn3] Successfully authenticated as principal admin on admin from client 127.0.0.1:52370 명령행에서 접근인증과 함께 admin 데이터베이스로 접근하려면 아래 같이 명령어에 아이디와 비밀번호를 명시만 해 주면 된다. 1&gt; mongo admin -u username -p password --authenticationDatabase admin 아래 같이 mongo 명령행에서 인증을 통해 접속하면 test 라는 데이터베이스로 접속합니다. 123456$ mongo -u admin -pMongoDB shell version v4.2.1Enter password:...&gt;&gt; use admin 사용자 계정 만들기관리자 계정을 만들고 인증까지 수행 했으면, 일반 사용자를 만들어 데이터베이스를 사용하도록 해보자. 관리자 계정을 만들었던 것처럼 계정을 만들고자 하는 데이터베이스를 use 한 다음 db.createUser()를 실행하면 된다. 123456789&gt; use bookdiaryswitched to db bookdiary&gt; db.createUser({... user:'student',... pwd:'0123456789',... roles:['dbOwner']... });Successfully added user: { &quot;user&quot; : &quot;student&quot;, &quot;roles&quot; : [ &quot;dbOwner&quot; ] }&gt; dbOwner라는 권한은 해당 데이터베이스에 대한 모든 수정/삭제 권한을 가진다는 것을 의미합니다. 사용자 인증db.auth()를 통해 인증을 진행해 봅시다. 123&gt; db.auth('username', 'password')1&gt; 참고 MongoDB Community Edition 3.6 on Ubuntu MongoDB: Enable authentication","link":"/mongodb-armbinan-1e555c571a20/"},{"title":"openSUSE - 과학계산을 위한 Python, Jupyter Notebook","text":"이 글은 OpenSuse LEAP 15 에서 과학계산을 위한 파이썬 환경을 위한 Jupyter Notebook을 설치하는 과정을 요약하고 있다. 이 글에서는 시스템 패키지로 Python3, jupyter-notebook 을 설치하고, 파이썬 가상환경에서 과학계산 파이썬 모듈을 설치한 후에 Jupyter notebook 을 운영하도록 한다. 과학계산을 위한 Python Jupyter 환경 아래 같은 플랫폼에서 시스템 패키지 소프트웨어와 파이썬 모듈을 설치하는 과정이다. Raspberry Pi 3 openSUSE LEAP 42.3, 15.0, 15.1 Jupyter Notebook Python 그래프 matplotlib 및 pillow 이미지 라이브러리 과학계산 모듈: numpy, scipy 등 파이썬 가상환경 pandas Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux 설치시스템에 Python2, Python3 가 설치되었는지 확인: Python 환경openSUSE 15.0에서 파이썬은 python2, python3.6 시스템 패키지로 설치되어 있다. pip를 설치해 준다. 1sudo zypper in python3-pip pip 를 여러 버전 사용중이라면, 만약 python2-pip 도 사용중이고 pip를 pip3로 사용하려면 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. pattern devel 로 검색해 보면,,, 123456789101112131415161718192021222324sudo zypper install -t pattern develS | Name | Summary | Type--+----------------------+-------------------------------------+-------- | devel_C_C++ | C/C++ Development | patterni | devel_basis | Base Development | pattern | devel_gnome | GNOME Development | pattern | devel_ide | Integrated Development Environments | pattern | devel_java | Java Development | pattern | devel_kde | KDE Development | pattern | devel_kde_frameworks | KDE Frameworks Development | pattern | devel_kernel | Linux Kernel Development | pattern | devel_mono | .NET Development | pattern | devel_perl | Perl Development | pattern | devel_python | Python Development | pattern | devel_python3 | Python 3 Development | pattern | devel_qt4 | Qt 4 Development | pattern | devel_qt5 | Qt 5 Development | pattern | devel_rpm_build | RPM Build Environment | pattern | devel_ruby | Ruby Development | pattern | devel_tcl | Tcl/Tk Development | pattern | devel_web | Web Development | pattern | devel_yast | YaST Development | pattern 이 중에서 devel_basis, python 관련 개발용 모듈을 설치한다. 1sudo zypper install -t pattern devel_basis 파이썬 개발 모듈을 설치한다. 12sudo zypper install -t pattern devel_python devel_python3sudo zypper install python-distutils-extra curses 관련 파이썬 모듈을 설치해야 한다. python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 1sudo zypper in python-curses python3-curses matplotlibmatplot 을 설치하면 numpy, scipy, pillow python3-tk 등이 함께 설치된다. 123456789101112131415sudo zypper in python-matplotlib python3-matplotlib...다음 새 패키지가 설치됩니다. cups cups-client cups-filters ghostscript ghostscript-x11 libICE6 libSM6 libXt6 libavahi-glib1 libcupscgi1 libcupsimage2 libcupsmime1 libcupsppdc1 libopenjp2-7 libpoppler73 libqhull7-7_2_0 libqpdf21 libwebp6 libwebpdemux2 libwebpmux2 libxml2-tools parallel-printer-support poppler-data poppler-tools python-functools32 python-subprocess32 python-tk python2-Cycler python2-Pillow python2-matplotlib python2-matplotlib-tk python2-numpy python2-olefile python2-pyparsing python2-python-dateutil python2-pytz python2-six python3-Cycler python3-Pillow python3-matplotlib python3-matplotlib-tk python3-olefile python3-tk다음 권장 패키지가 자동으로 선택되었습니다. cups-filters ghostscript ghostscript-x11 libxml2-tools poppler-data poppler-tools python2-Pillow python2-matplotlib-tk python3-Pi numpy 개발자 패키지를 설치한다. 1sudo zypper in python2-numpy-devel python3-numpy-devel Jupyter NotebookJupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 여기서는 가상환경을 구성해 Jupyter 관련 패키지를 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 가상환경으로 venv 사용 설치Zeromq-devel 설치한다. libczmq5은 쥬피터 노트북에서 필요로 한다. LEAP 14는 libzmq3 다. 1sudo zypper install zeromq-devel libzmq5 jupyter notebook 을 시스템 패키지로 설치한다. 1234567891011121314151617181920212223242526272829303132sudo zypper in python3-jupyter_notebook...다음 새 패키지가 설치됩니다. ethtool libcmark0_28_3 libgfortran4 libibverbs libibverbs1 liblua5_1-5 libmlx4-1 libmlx5-1 libnuma1 libopenblas_openmp0 librdmacm1 libucm0 libucp0 libucs0 libuct0 libxslt1 mpi-selector openmpi openmpi-config openmpi-libs pandoc python-sip-common python3-Automat python3-Babel python3-Genshi python3-Jinja2 python3-MarkupSafe python3-PyNaCl python3-Pygments python3-Send2Trash python3-Twisted python3-asn1crypto python3-attrs python3-backcall python3-bcrypt python3-bleach python3-certifi python3-cffi python3-constantly python3-cryptography python3-cssselect python3-defusedxml python3-entrypoints python3-gevent python3-greenlet python3-html5lib python3-hyperlink python3-idna python3-incremental python3-ipython_genutils python3-jedi python3-jsonschema python3-jupyter_client python3-jupyter_core python3-jupyter_ipykernel python3-jupyter_ipyparallel python3-jupyter_ipython python3-jupyter_ipywidgets python3-jupyter_nbconvert python3-jupyter_nbformat python3-jupyter_notebook python3-jupyter_qtconsole python3-jupyter_widgetsnbextension python3-lxml python3-mistune python3-mpi4py python3-numpy python3-pandocfilters python3-paramiko python3-parso python3-pexpect python3-pickleshare python3-prometheus_client python3-prompt_toolkit python3-psutil python3-ptyprocess python3-py python3-pyOpenSSL python3-pyasn1 python3-pyasn1-modules python3-pycparser python3-pycrypto python3-pycurl python3-pymongo python3-pyserial python3-python-dateutil python3-pytz python3-pyzmq python3-service_identity python3-simplegeneric python3-simplejson python3-sip python3-terminado python3-testpath python3-tornado python3-traitlets python3-wcwidth python3-webencodings python3-zope.interface rdma-core다음 권장 패키지가 자동으로 선택되었습니다. ethtool openmpi-config pandoc python3-Genshi python3-Pygments python3-Twisted python3-cffi python3-gevent python3-jupyter_client python3-jupyter_ipykernel python3-jupyter_ipyparallel python3-jupyter_ipython python3-jupyter_ipywidgets python3-jupyter_nbconvert python3-jupyter_nbformat python3-jupyter_notebook python3-jupyter_qtconsole python3-lxml python3-mpi4py python3-numpy python3-paramiko python3-pexpect python3-psutil python3-py python3-pycurl python3-pymongo python3-service_identity python3-simplejson python3-tornado다음 패키지가 제안되지만 설치되지 않습니다. python3-jupyter_notebook-latex 가상환경 구성jupyter notebook 을 실행하고 사용할 파이썬 과학계산 모듈을 위한 가상환경을 구성한다. 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 1sudo pip install --upgrade pip 가상환경은 사용자 홈디렉토리의 .venv 폴더로 가정한다. python3, 파이썬 시스템 라이브러리를 함께 사용을 위해 –system-site-packages 옵션과 함께 jupyterscfy라는 가상환경을 생성한다. 12345~&gt; python3 -m venv --system-site-packages .venv/jupyterscfy~&gt; source .venv/jupyterscfy/bin/activate(jupyterscfy) ~&gt;(jupyterscfy) ~&gt; python --versionPython 3.6 가상환경의 pip 모듈을 최신버전으로 유지한다. 1(jupyterscfy) ~&gt; pip install --upgrade pip 실행jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. 123456789101112131415(jupyterscfy) ~&gt; jupyter notebook[I 01:15:02.799 NotebookApp] Writing notebook server cookie secret to /run/user/1000/jupyter/notebook_cookie_secret[I 01:15:21.630 NotebookApp] Loading IPython parallel extension[I 01:15:21.646 NotebookApp] Serving notebooks from local directory: /home/qkboo[I 01:15:21.646 NotebookApp] The Jupyter Notebook is running at:[I 01:15:21.647 NotebookApp] http://localhost:8888/?token=689ae860106f8a7274b50f68f69895420eab19064ebb8e69[I 01:15:21.648 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[W 01:15:21.708 NotebookApp] No web browser found: could not locate runnable browser.[C 01:15:21.710 NotebookApp] To access the notebook, open this file in a browser: file:///run/user/1000/jupyter/nbserver-8251-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=689ae860106f8a7274b50f68f69895420eab19064ebb8e69 jupyter notebook 을 종료하려면 Ctrl+C 로 인터럽트를 걸어준다. 1234567891011...^C[I 01:16:41.847 NotebookApp] interruptedServing notebooks from local directory: /home/qkboo0 active kernelsThe Jupyter Notebook is running at:http://localhost:8888/?token=689ae860106f8a7274b50f68f69895420eab19064ebb8e69Shutdown this notebook server (y/[n])? y[C 01:16:44.757 NotebookApp] Shutdown confirmed[I 01:16:44.760 NotebookApp] Shutting down 0 kernels(jupyterscfy) ~&gt; Scientific packagesnumpyscipymatplotlibpillow matplotlib는 외부 이미지를 png 형식만 지원한다. jpeg를 사용하려면 pillow 모듈을 설치한다. pillow 여기까지 설치하면 의존성에 관련한 아래 같은 여러 패키지가 함께 설치된다. requests : Python package provides a graceful interface for making HTTP requests, pil : provides Python imaging capabilities, scrapy : is a web scraping framework, geopy provides geocoding and geodesic distance functions, shapely provides 2D geometry manipulation, pyproj: provides cartographic transformations. In the second command, jupyter provides interactive coding notebooks, geopandas spatializes pandas, OSMnx lets you work with OpenStreetMap street networks. 이 패키지들은 별도로 설치를 하고자 하면 pip로 설치하거나 시스템 패키지로 다음 같이 설치 할 수 있다. Python2 1sudo apt-get install python-requests python-pil python-scrapy python-geopy python-shapely python-pyproj Python3 1sudo apt-get install python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj symbolic mathsymbolic mathematics 관련 패키지도 설치한다. 12sudo zypper install python-sympy python-nosesudo zypper install python3-sympy python3-nose Pandas 설치pandas 설치시 여러 번들이 필요해서 시스템 패키지가 아닌 conda 혹은 pip 로 설치한다. 123456$ time pip install pandas...real 118m4.118suser 114m47.176ssys 1m27.483s pandas를 pip로 설치시 Raspberry Pi 3의 OpenSuse 15.2 에서 실제 2시간 정도 걸린다. Pandas 로 지오 데이터 셋트를 다룰 예정이라면 백업현재까지 설치된 pip 모듈 목록을 저장하자. 1~&gt; pip freeze --local &gt; jupyter-requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567~&gt; jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} Jupyter 설정 이용jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123~&gt; jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py~&gt; cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1~&gt; jupyter-notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1~&gt; nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service Upgrade jupyter다음 같이 install 명령으로 업그레이드 할 수 있다. 1(jupyter)~&gt; pip install -U jupyter 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2019-09-05-OpenSuse-JupyterNotebook_scientific-0695b854f56f/"},{"title":"Raspberry Pi: mmcblk","text":"mmcblkSD/MMC card 는 MMC 서브시스템을 /dev/mmcblk{id} 형식으로 블럭 장치로 사용한다. dmesg 로 부트 메시지를 보면 SDHCI 인터페이스에 장착한 장치를 확인할 수 있다. 12345678910111213141516171819202122232425262728[ 0.789621] sdhci: Secure Digital Host Controller Interface driver[ 0.789628] sdhci: Copyright(c) Pierre Ossman[ 0.789999] sdhost-bcm2835 3f202000.sdhost: could not get clk, deferring probe[ 0.790252] sdhci-pltfm: SDHCI platform and OF driver helper[ 0.791051] ledtrig-cpu: registered to indicate activity on CPUs[ 0.791232] hidraw: raw HID events driver (C) Jiri Kosina[ 0.791461] usbcore: registered new interface driver usbhid[ 0.791467] usbhid: USB HID core driver[ 0.792448] vchiq: vchiq_init_state: slot_zero = 0xb6980000, is_master = 0[ 0.794533] Initializing XFRM netlink socket[ 0.794566] NET: Registered protocol family 17[ 0.794724] Key type dns_resolver registered[ 0.795223] Registering SWP/SWPB emulation handler[ 0.796192] registered taskstats version 1[ 0.796681] vc-sm: Videocore shared memory driver[ 0.796694] [vc_sm_connected_init]: start[ 0.802967] [vc_sm_connected_init]: end - returning 0[ 0.809343] 3f201000.serial: ttyAMA0 at MMIO 0x3f201000 (irq = 87, base_baud = 0) is a PL011 rev2[ 0.809410] console [ttyAMA0] enabled[ 0.811406] sdhost: log_buf @ b6913000 (f6913000)[ 0.889149] mmc0: sdhost-bcm2835 loaded - DMA enabled (&gt;1)[ 0.889333] of_cfs_init[ 0.889478] of_cfs_init: OK[ 0.890211] Waiting for root device /dev/mmcblk0p2...[ 0.956566] mmc0: host does not support reading read-only switch, assuming write-enable[ 0.958563] mmc0: new high speed SDHC card at address 59b4[ 0.959555] mmcblk0: mmc0:59b4 00000 14.9 GiB[ 0.961428] mmcblk0: p1 p2 메시지에서 보듯 mmc0 장치에 카드가 삽입되기 전에 인터럽트가 없다. 12$ cat /proc/interrupts |grep mmc86: 393 0 0 0 ARMCTRL-level 88 Edge mmc0 https://developer.toradex.com/knowledge-base/sd-mmc-card-(linux)","link":"/sdcard-mmcblk-01eaadd23a5e/"},{"title":"Raspberry Pi : Digital Signage","text":"Digital Signage라즈베리파이에서 슬라이드쇼 구현해 보자. py-slideshowhttps://github.com/cgoldberg/py-slideshow/ pyglet 으로 이미지를 패닝, 확대 효과를 가진 슬라이드 쇼. Screenly OSEScreenly Open Source Edition은 디지털 시그네이지 소프트웨어 이다. 소스: https://github.com/Screenly/screenly-ose Screenly OSE works on all Raspberry Pi versions, including Raspberry Pi Zero and Raspberry Pi 3 Model B. Disk imagesThe recommended installation method is to grab the latest disk image from here 라즈비안에서 설치Raspbian Lite 에서 설치를 할 수 있다. 먼저 sudo apt install -y network-manager 1234567891011$ bash &lt;(curl -sL https://www.screenly.io/install-ose.sh) _____ __ ____ _____ ______ / ___/_____________ ___ ____ / /_ __ / __ \\/ ___// ____/ \\__ \\/ ___/ ___/ _ \\/ _ \\/ __ \\/ / / / / / / / /\\__ \\/ __/ ___/ / /__/ / / __/ __/ / / / / /_/ / / /_/ /___/ / /___/____/\\___/_/ \\___/\\___/_/ /_/_/\\__, / \\____//____/_____/ /____/Screenly OSE requires a dedicated Raspberry Pi / SD card.You will not be able to use the regular desktop environment once installed.Do you still want to continue? (y/N) 1Would you like to use the experimental branch? It contains the last major changes, such as the new browser and migrating to Docker (y/N) It looks like NetworkManager is not installed. Please install it by running ‘sudo apt install -y network-manager’ and then re-run the installation. 1Would you like to perform a full system upgrade as well? (y/N) 설치를 시작하면 15분 이상이 소요된다.This installation will take 15 minutes to several hours, depending on variables such as: 12Installation completed.You need to reboot the system for the installation to complete. Would you like to reboot now? (y/N) pipresent python2 기반이고, 실행이 안됐다. https://pipresents.wordpress.com https://github.com/KenT2/pipresents-beep Requirements must use the latest version of Raspbian Stretch with Desktop (not the Lite version) must be run from the PIXEL desktop. must be installed and run from user Pi installrequired packages 12sudo apt install python-imaging python-pil.imagetk python-pexpectsudo apt install unclutter mplayer uzbl optional packages sudo pip install evdev (if you are using the input device I/O plugin)sudo apt-get install mpg123 (for .mp3 beeps) 1wget https://github.com/KenT2/pipresents-beep/tarball/master -O - | tar xz Dead-simple Digital menuhttps://github.com/angryrancor/ezdmb","link":"/digital-signage-c50c276d233a/"},{"title":"Python 과학계산을 위한 Jupyter Notebook - macOS","text":"과학계산을 위한 Jupyter 설치 및 구성까지 요약하고 있다. 과학계산을 위한 Python JupyterRaspberry Pi 3 위에 설치한 openSUSE LEAP 42.3 과 15.0 에서 과학계산을 위한 Python 개발환경과 Jupyter Notebook 환경을 정리한다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy 등 Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux Setup시스템에 Python2, Python3 가 설치되었는지 확인: macOS : Python2.7 python.org 설치python.org 에서 package 를 다운받아 설치한다. Uninstall package installerhttps://stackoverflow.com/questions/3819449/how-to-uninstall-python-2-7-on-a-mac-os-x-10-6-4/3819829#3819829 brew에서 Python 3 설치brew로 최신 3.7을 설치 1brew install python3 You can install Python packages withpip3 install They will install into the site-package directory /Users/qkboo/Library/Python/3.7/site-packages pip User SchemePython2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. virtualenv 와 virtualenvwrapperpip 를 업그레이드하고, 가상 개발환경에서 쥬피터 관련 모듈을 설치하고 관리하기 위해 pip로 virtualenv, virtualenvwrapper 설치한다. 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 1pip install --upgrade pip 그리고 virtualenv, virtualenvwrapper 설치하는데, 사용자의 .local 폴더에 설치하도록 한다. 1pip install --user virtualenv virtualenvwrapper 자동으로 추가되지 않으면, 다음 스크립을 .bashrc 에 추가해 준다. 123456789# set PATH for pipif [ -d &quot;$HOME/.local/bin&quot; ] ; then PATH=&quot;$HOME/.local/bin:$PATH&quot;fiVIRTUALENVWRAPPER_PYTHON=/usr/bin/python3export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource ~/Library/Python/3.7/bin/virtualenvwrapper.sh 로그아웃했다 로그인하면 mkvirtualenv, rmvirtualenv 등의 명령어 스크립이 설치된다. Scientific stack과학계산을 지원하는 Python 패키지를 설치한다. 1pip install --user numpy scipy matplotlib jupyter pandas sympy nose ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 여기서는 가상환경을 구성해 Jupyter 관련 패키지를 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 Jupyter 가상환경 사용시다음은 mkvirtualenv 명령으로 jupyter라는 가상환경을 python3, 시스템 패키지 사용을 위해 –system-site-packages 옵션으로 생성한다. 1234567891011mkvirtualenv -p python3 --system-site-packages jupyterRunning virtualenv with interpreter /usr/local/bin/python3Using base prefix '/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7'New python executable in /Users/qkboo/.virtualenvs/jupyter/bin/python3.7Also creating executable in /Users/qkboo/.virtualenvs/jupyter/bin/pythonInstalling setuptools, pip, wheel...(jupyter) $(jupyter) $ python --versionPython 3.4.6 가상환경 jupyter 에서 필수 모듈 numpy, scipy가 사용 가능한지 확인한다. 1234(jupyter) $ python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3(jupyter) $ python -c &quot;import scipy;print(scipy.__version__)&quot;0.16.0 그리고 pip로 Jupyter 가상환경에 Jupyter를 설치한다. 1(jupyter)$ pip install jupyter --user Python User scheme 에 설치시 macOS는 아래 위치에 설치되므로 경로에 추가한다. 1/Users/qkboo/Library/Python/3.7/bin jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. 현재까지 설치된 pip 모듈 목록을 저장하자. 1pip freeze --local &gt; jupyter-requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567$ jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter-notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service Upgrade jupyter여기서는 pip 가상머신을 이용하고 있고, virtualenv, virtualenvwrapper는 여기서 사용자 .local 환경에 설치했으므로 1pip install -U --user virtualenv virtualenvwrapper 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1(jupyter)$ pip install -U jupyter 1pip freeze —local &gt; requirements.txt 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2018-10-20-jupyter-scitific-macos-417f3f6ae7d7/"},{"title":"Photoshop - 찢어진 틈 사이의 이미지 콜라쥬 효과 만들기","text":"포토샵으로 Collages 를 만드는 과정을 해보았다. 찢어진 틈 사이의 이미지 콜라쥬 효과 만들기 1. 찢어진 틈 사이의 이미지 콜라쥬 효과 만들기스케치북을 찢은 사이로 사진이 보이게 하는 효과를 내보자. {:width=”800”} 배경사진 위에 찢은 스케치북 레이어를 두고, 복제한 사진을 연필 스케치 필터 효과를 준 후에, 클리핑 마스크를 적용하고 있다. 작업pixabay.com 에서 “찢어진 종이” ripped papers 로 검색해서 적당한 것을 찾아서 사용했다. {:width=”800”} 준비한 사진 위에 ripped paper를 배치한다. {:width=”800”} 먼저 1) 사진 이미지 레이어에서 Ctrl/Cmd+J키로 레이어를 복제해서, 레이어의 맨 위에 위치한다. 2) Filter &gt; Stylized &gt; Find Edges 효과를 준 후에 Desaturation으로 적절히 조절한다. 3) 마지막으로 레이어에서 오른쪽 클릭으로 클리핑마스크를 주고 Blend mode를 Multiply로 준다. Opacity를 줄여 보며 연필 스케치한 종이를 찢은 효과가 나도록 한다. {:width=”800”} 원 배경 사진 혹은 복제한 레이어는 Rasterized 한 상태여야 한다. (스마트 이미지는 Saturation 적용이 안된다) 참조 Ripped paper image 본인 배경사진","link":"/2018-08-16-collages-rippedimage-4d19c2608b81/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Service 관리","text":"Upgrade OpenSUSE LEAP 42.2 to LEAP 15https://en.opensuse.org/SDB:System_upgrade OpenSUSE LEAP 42.2를 LEAP 15.0으로 업그레이드 하려고 한다. [그림. 지원 중단 배포본 (OpenSUSE)] UpgradeUpdate repository다음 명령으로 현재 배포본의 Repository Url이 활성화 되어 있는지 확인한다. 12345678# zypper repos --uriRepository priorities are without effect. All enabled repositories share the same priority.# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-----------------------------------+-----------------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | openSUSE-Ports-Leap-42.2-Update | openSUSE-Ports-Leap-42.2-Update | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/update/42.2/2 | openSUSE-Ports-Leap-42.2-repo-oss | openSUSE-Ports-Leap-42.2-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/42.2/repo/oss/ 42.2 저장소 백업하고, 1# cp -Rv /etc/zypp/repos.d /etc/zypp/repos.d.Old 42.2 를 15.0 으로 변경하자, 1# sed -i 's/42.2/15.0/g' /etc/zypp/repos.d/* 업데이트 저장소 위치가 다르기 때문에 zypper repos --uri 에서 openSUSE-Ports-Leap-15.2-Update 를 삭제한다. 1zypper rr 1 그리고 openSUSE-Ports-Leap-15.0-Update 를 추가한다. 1zypper addrepo --check --refresh --name 'openSUSE-Leap-15.0-Update' http://download.opensuse.org/update/leap/15.0/oss/ repo-update 15.2 저장소가 제대로 들어갔는지 확인한다. 1234567# zypper repos --uriRepository priorities are without effect. All enabled repositories share the same priority.# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-----------------------------------+-----------------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | openSUSE-Ports-Leap-15.0-repo-oss | openSUSE-Ports-Leap-15.0-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/15.0/repo/oss/2 | repo-update | openSUSE-Leap-15.0-Update | Yes | ( p) Yes | Yes | http://download.opensuse.org/update/leap/15.0/oss/ 결과에서 repo-update 가 Enabled 컴럼이 Yes 인지 확인한다. 만약 No 라면 다음 명령으로 활성화 한다. 1zypper modifyrepo --enable repo-update Update repositoryzypper ref Distribution Upgrade12345678# zypper dup...613 packages to upgrade, 170 to downgrade, 340 new, 103 to remove, 6 to changearch.Overall download size: 658.0 MiB. Already cached: 0 B. After the operation,additional 774.1 MiB will be used.Continue? [y/n/...? shows all options] (y): y homepi64:~ # reboot[11840.081284] reboot: Restarting systemMMC: mmc@7e202000: 0, mmc@7e300000: 1Loading Environment from FAT… *** Warning - bad CRC, using default environment 진행중 42.2와 충돌하는 패키지가 표시되는데 모둔 1로 설치했다. 1234567891011124 Problems:Problem: nothing provides tar = 1.30 needed by tar-lang-1.30-lp150.2.3.2.noarchProblem: nothing provides python3-dbus-python needed by snapper-zypp-plugin-0.5.4-lp150.3.3.1.noarchProblem: nothing provides libgphoto2-6 = 2.5.18 needed by libgphoto2-6-lang-2.5.18-lp150.2.3.1.noarchProblem: nothing provides gpg2 = 2.2.5 needed by gpg2-lang-2.2.5-lp150.3.3.1.noarchProblem: nothing provides tar = 1.30 needed by tar-lang-1.30-lp150.2.3.2.noarch Solution 1: deinstallation of tar-lang-1.27.1-11.1.noarch Solution 2: keep obsolete tar-lang-1.27.1-11.1.noarch Solution 3: break tar-lang-1.30-lp150.2.3.2.noarch by ignoring some of its dependenciesChoose from above solutions by number or skip, retry or cancel [1/2/3/s/r/c] (c):1 재시동업그레이드를 설치한 후에 재시동 하면 약 5분 정도 펌웨어 등을 설치하는 과정을 거친다. 로그인해서 버전을 확인해 보자 qkboo@homepi64:~&gt; uname -aLinux homepi64 4.4.104-18.44-default #1 SMP Thu Jan 4 08:07:55 UTC 2018 (05a9de6) aarch64 aarch64 aarch64 GNU/Linux ~&gt; uname -aLinux homepi64 4.4.104-18.44-default #1 SMP Thu Jan 4 08:07:55 UTC 2018 (05a9de6) aarch64 aarch64 aarch64 GNU/Linux https://en.opensuse.org/SDB:Find_openSUSE_version","link":"/opensuse-upgrade-42.2-to-15-885e7b2f0e9f/"},{"title":"Getting Started &#96;firewalld&#96;","text":"RedHat, CentOS, Fedora 배포본 등에서 표준 방화벽 인터페이스로 제공되는 최신 FirewallD 사용을 시작해 보자. firewalld 패키지 설치는 각 배포본의 방법으로 설치하면 된다. 여기서는 OpenSUSE, Armbian 배포본을 설치한 시스템에서 firewalld 방화벽을 구성하고 설정하는 과정을 요약 정리했다. Getting Started - FirewallDsudo systemctl enable firewalldsudo reboot We can verify that the service is running and reachable by typing: sudo firewall-cmd –state firewalld는 Zone 을 기반으로 서비스, 포트, IP 주소 등을 다양한 규칙으로 혼합해 사용할 수 있다. 기본으로 지원하는 zone은 다음 같다. 12$ sudo firewall-cmd --get-zonesblock dmz drop external home internal public trusted work 그리고 permanent로 활성화된 Zone은 12345$ sudo firewall-cmd --get-active-zonesdrop sources: ipset:blacklisttrusted sources: 192.168.0.0/24 220.121.170.0/24 Public Zone에 Http, Ssh 서비스http, https 를 공개 서비스를 지원하는 기본 public zone에 추가한다. 123$ sudo firewall-cmd --add-service=ssh$ sudo firewall-cmd --add-service=http$ sudo firewall-cmd --add-service=https 혹은 zone을 지정해서 서비스를 추가할 수 있다. 123$ sudo firewall-cmd --zone=public --add-service=ssh$ sudo firewall-cmd --zone=public --add-service=http$ sudo firewall-cmd --zone=public --add-service=https 1$ sudo firewall-cmd --zone=public --remove-service=ssh public zone에 대한 정보를 출력한다. 1234567891011121314$ sudo firewall-cmd --list-allpublic target: default icmp-block-inversion: no interfaces: sources: services: ssh dhcpv6-client http https ports: protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Trusted Zone 관리1$ sudo firewall-cmd --zone=trusted --add-service=ssh trusted zone의 IP 범위를 소스로 지정할 수 있다. 12$ sudo firewall-cmd --zone=trusted --add-service=dns$ sudo firewall-cmd --zone=trusted --add-source=192.168.1.0/24 1firewall-cmd --zone=zone-name --remove-source=&lt;source&gt; Trusted Zone의 정보를 출력한다. 1$ sudo firewall-cmd --zone=trusted --list-all Port포트에 따라 는 프로토콜을 지정해 줄 수 있다. 지정되지 않으면 기본 TCP 포트가 구성된다. 1firewall-cmd --remove-port=port-number/port-type 대체 http 포트인 8080을 추가해 보자. 1sudo firewall-cmd --zone=public --add-port=8080/tcp mongodb 같은 내부 데이터베이스 포트를 trusted zone에 추가해 준다. 1sudo firewall-cmd --zone=trusted --add-port=27017/tcp 포트 범위를 지정해 구성할 수 있다. 1sudo firewall-cmd --zone=public --add-port=4990-4999/udp 포트를 제거할 수 있다. 1sudo firewall-cmd --zone=zone-name --remove-source-port=&lt;port-name&gt;/&lt;tcp|udp|sctp|dccp&gt; Zone에 구성된 포트 정보를 출력할 수 있다. 12sudo firewall-cmd --zone=public --list-portssudo firewall-cmd --zone=trusted --list-ports 여기까지 firewall-cmd 로 설정한 내용은 실행중(런타임) 방화벽으로 구성되어 사용된다. 재시동 등의 이벤트가 발생하면 내용이 사라지게 된다. 영구적으로 보존하기 위해서는 --permanent 옵션을 사용해야 한다. PermenentZone 에 구성한 서비스, 포트, 소스, 프로토콜 등에 대한 설정을 영구적으로 보존해려면 --permanent 옵션을 사용해야 한다. 영구적인 구성을 설정을 보존하려면 아래 두가지 방법을 사용한다. 먼저 firewall-cmd 로 실행중 제한 내용을 구성하고, --runtime-to-permanent 를 실행해 준다. 1firewall-cmd --runtime-to-permanent 다른 방법을 firewall-cmd 에 --permanent 옵션을 주고 실행하면 영구 보존되어 저장된다. 1firewall-cmd --permanent &lt;other options&gt; reload방화벽을 갱신한다 1234firewall-cmd --reloadfirewall-cmd --statefirewall-cmd --list-all #publicfirewall-cmd --permanent --list-all #permanent 참조Firewalld configuration and usage RedHat: Getting started with firewalld How to set up firewalld on CentOS 7","link":"/opensuse-firewalld-start-24ac71b81127/"},{"title":"Coordinate System","text":"https://varun.ca/polar-coords/ Coordinate system좌표시스템은 2D, 3D 공간 안에서 점들의 위치를 결정하는 수들을 사용하도록 한다. Cartesian Coordinate system가장 유명한 좌표 시스템은 데카르트 좌표 시스템이다. 숫자 x, y 점을 (x,y) 숫자 좌표 쌍으로 각 점을 위치하게 한다.SVG, Canvas, WebGL 그리고 Sketch &amp; Illustrator 에서 활용할 수 있다. {: width=”600”} Polar Coordinate System극좌표계는 2D 좌표 시스템으로 각 점이 r 과 \\(\\theta\\\\) 로 결정된다. r은 원점에서 원주까지 거리인 반지름이고 \\(\\theta\\) 는 {: width=”600”} Converting between Polar and Cartesian Coordinates삼각법을 사용한 아래 방정식으로 극좌표계 (r, \\\\(\\theta\\\\) )에서 데카르트 좌표계로 변환할 수 있다. 12float x = r * Math.cos(theta);float y = r * Math.sin(theta); Patterns아래 패턴은 모두 극좌표를 사용해 생성한 패턴이다. 데카르트 좌표는 사각 그리드 위에 배치하기 아주 좋은 선택이다. 만약 원 주변에 무언가를 배치하려면 극좌표이 우선 선택할 수 있다. 반지름 상수를 유지하기 때문에 각 점에 대한 각을 \\(angle = 360^{\\circ} * index / number of sides \\) 같이 계산한다. 아래 자바스크립트는 위 아이디어를 구현하고 있다. 위 그림에서 점의 바깥 가장자리 원은 points(12, 200) 을 사용해 생성했다. 그 다음 점들은 points(12, 175, 15) 를 사용했다. CodePen splash 가 이것을 사용해 구성했다. hl_lines1234567891011121314151617181920function points(count, radius, offset = 0) { const angle = 360 / count; const vertexIndices = range(count); return vertexIndices.map((index) =&gt; { return { theta: offset + degreesToRadians(offset + angle * index), r: radius, }; });}// number =&gt; [0, 1, 2, ... number]function range(count) { return Array.from(Array(count).keys());}function degreesToRadians(angleInDegrees) { return (Math.PI * angleInDegrees) / 180;} Polygon Generator보통 다각형(폴리곤)은 등각인 다각형으로 모든 측면이 같은 길이에 같은 각이다. 이것은 표준 다각형의 모든 정점은 원 위에 균등하게 배치된 점인 것이다. SVG 다각형을 생성하려면 points() 함수를 사용해 점의 목록을 생성한다. 그리고 점 사이를 연결한다. SVG에서 1234567891011121314151617/** * Usage with Vanilla JS/DOM: * polygonEl.setAttribute('points', polygon((5, 64, 18))); * * Usage with React: * &lt;polygon points={polygon((5, 64, 18)} /&gt; * * Usage with View: * &lt;polygon :points=&quot;polygon((5, 64, 18)&quot; /&gt; */function polygon(noOfSides, circumradius, rotation) { return points(noOfSides, circumradius, rotation).map(toCartesian).join(&quot; &quot;);}function toCartesian({ r, theta }) { return [r * Math.cos(theta), r * Math.sin(theta)];} 예) http://winkervsbecks.github.io/gemshttps://codepen.io/winkerVSbecks/pen/PmNJpJ 상대적 극좌표기본을 점을 (r,$$\\theta$$) 로 선언할 때 이것은 원점 (0,0)에 상대적이다. 결국 원점을 점 위치로 이동한 것 과 동일하므로 정점에 상대적으로 다루는 곡선의 위치로 선언해 사용한다. 12const x = cx + r * Math.cos(theta);const y = cy + r * Math.sin(theta); SVG 캔버스에서 어떤 위치에 가운데 위치한 다각형을 그리기 위해서 다각형 생성기를 수정한다. 123456789function polygon(noOfSides, circumradius, rotation, [cx = 0, cy = 0]) { return points(noOfSides, circumradius, rotation) .map((pt) =&gt; toCartesian(pt, [cx, cy])) .join(&quot; &quot;);}function toCartesian({ r, theta }, [cx, cy]) { return [cx + r * Math.cos(theta), cy + r * Math.sin(theta)];} 예) https://codepen.io/winkerVSbecks/pen/wrZQQm 회전극좌표를 이용한 사례중 어떤 점을 중심으로 회전하는 것을 생각할 수 있다. 여기 (cx, cy) 점이 회전하는 곳이다. 일정한 간격, 시간, 위치에 따라 \\(\\theta\\) 를 증가 혹은 감소 시키면 상대적 위치에서 점이 이동한다. 1234567x = cx + r * Math.cos(theta);y = cy + r * Math.sin(theta);// somewhere in an animation loopwindow.setInterval(() =&gt; { theta++;}, 1000 / 60); 예) https://codepen.io/Yakudoo/pen/aOEeXB 극좌표 곡선여기까지 개별 점 (위치)를 살펴보았다. 몇몇 점을 그룹지어 집합에 그룹지으 형상을 선언한다. 다각형 생성 함수를 사용해서 형상의 각 정점의 위치를 계산한다. 유사한 함수를 수학 방정식을 사용해 작성해서 복합 형상과 곡선을 생성할 수 있도록 한다. 2차원 곡선은 방정식 y = f(x) 형으로 묘사된다. 예를 들어 원의 방정식은 \\(x^2 + y^2 = r^2\\) 이다. 이것은 x와 상대적인 y 를 반복해서 자취(locus) 로 불리는 점의 집합을 생성할 수 있다. 각 점은 (x, f(x)) or (g(y), y) 형태를 가진다. 극좌표는 극좌표 곡선을 그릴 수 있다. 원의 극좌표 방정식은 r = 2 * cos(0) 이다. 극좌표 곡선 위에 점은 (r(0), 0) 형태를 갖는다. 1234567// examples of fn:// circle : 2 * Math.cos(theta)// blob thing : a * (1 - Math.cos(theta) * Math.sin(3 * theta))const r = fn(theta);const x = cx + r * Math.cos(theta);const y = cy + r * Math.sin(theta); https://codepen.io/winkerVSbecks/pen/pdVLPo EukleidesAll the diagrams in this post were created using a language called eukleides. It is a fantastic tool for making geometric drawings. Just look at this declarative API 😍 1234567c = circle(point(3, 0), 3)P = point(c, 170°)M = point(0, 0)N = point(6, 0)draw (M.N.P)label M, P, N right, 0.6","link":"/coordinate-system-2a0dac253d61/"},{"title":"Raspberry Pi : Upgrade OpenSUSE LEAP 42.2 to 42.3","text":"Raspberry Pi 3 에 설치해 사용중이던 openSUSE LEAP 42.2의 지원이 종료되어, 2019년가지 지원하는 LEAP 42.3으로 업그레이드하는 과정을 정리했다. openSUSE는 LEAP 15.0으로 최신 버전으로 배포하고 있다. 42.2에서 15.0으로 바로 업그레이드시 내가 해결 못하는 문제가 생겨서 42.3으로 업그레이드 했다. Upgrade OpenSUSE LEAP 42.2 to 42.3OpenSUSE LEAP 42.2 는 지원이 종료되어 42.3으로 업그레이드를 한다. {: width=”600”} [그림. 지원 중단 배포본 (OpenSUSE.com)] 업그레이드에 대한 과정은 [OpenSUSE System Upgrade](https://en.opensuse.org/SDB:System_upgrade) 에 나와있는데 42.3을 15.0으로 배포본 업그레이드 하는 과정과 일반 배포본에서 배포본 업그레이드가 설명되어 있어서 직접 시도하면서 정리했다. Upgrade 시작먼저 42.2 저장소 URI를 42.3 으로 변경한다. 42.3 Repository Uri현재 시스템의 Repository Uri를 확인해 보고 12345678$sudo zypper repos --uriRepository priorities are without effect. All enabled repositories share the same priority.# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-----------------------------------+-----------------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | openSUSE-Ports-Leap-42.2-Update | openSUSE-Ports-Leap-42.2-Update | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/update/42.2/2 | openSUSE-Ports-Leap-42.2-repo-oss | openSUSE-Ports-Leap-42.2-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/42.2/repo/oss/ 다른 저장소를 추가하지 않고 사용했다면 LEAP 42.2 배포본 저장소는 위와 같을 것이다. 현재 Uri인 저장소 백업하고, 1$sudo cp -Rv /etc/zypp/repos.d /etc/zypp/repos.d.Old 위 목록에서 openSUSE-Ports-Leap-42.2-repo-oss를 제거한다. 목록 번호로 제거할 수 있어서 rr 2 명령으로 제거한다. 1$sudo zypper rr 2 저장소 문자열 42.2 를 42.3 문자열로 치환한다 1$sudo sed -i s/42.2/42.3/ /etc/zypp/repos.d/* 여기에 앞에서 제거한 repo-oss 저장소를 LEAP 42.3을 위한 openSUSE-Leap-42.3-repo-oss 를 추가해 준다. 1$sudo zypper addrepo --check --refresh --name 'openSUSE-Leap-42.3-repo-oss' http://download.opensuse.org/ports/aarch64/distribution/leap/42.3/repo/oss/ repo-oss 새 저장소 Uri를 추가하고 배포본의 Repository Url를 출력해서 Enabled 컬럼이 활성화 되어 있는지 확인한다. 12345$sudo zypper repos --uri# | Alias | Name | Enabled | GPG Check | Refresh | URI--+-------------+-----------------------------+---------+-----------+---------+----------------------------------------------------------------------------1 | repo-oss | openSUSE-Leap-42.3-repo-oss | Yes | (r ) Yes | Yes | http://download.opensuse.org/ports/aarch64/distribution/leap/42.3/repo/oss/2 | repo-update | openSUSE-Leap-42.3-Update | Yes | (r ) Yes | Yes | http://download.opensuse.org/update/leap/42.3/oss/ 만약 출력한 저장소 목록에서 Enabled 컬럼이 No 라면 다음 명령으로 활성화 한다. 1$sudo zypper modifyrepo --enable openSUSE-Leap-42.3-repo-oss 이제 42.3을 위한 저장소 Uri가 정리되었다. 실제 배포본 버전을 업그레이드 하기 위해서는 dup 명령을 내려 실행해야 하지만 역시 42.2를 15.0으로 직접 배포본 업그레이드 했을 때 문제가 발생해서 설치된 패키지를 업르레이드하고 배포본 업그레이드를 진행했다. Distribution Upgrade먼저 저장소에서 패키지 목록을 최신으로 갱신하고, package upgrade를 진행해 준다. 12zypper refzypper up 오에스에서 사용하는 패키지가 많기 때문에 패키지 업그레이드 과정은 꽤 긴 시간이 필요하다. 과정중에 펌웨어 버전 충돌이 나오면 Yes 해준다. 1234567891011Checking for file conflicts: ............................................[error]Detected 1 file conflict:File /lib/firmware/brcm/brcmfmac43430-sdio.bin from install of kernel-firmware-20170530-20.1.noarch (openSUSE-Leap-42.3-Update) conflicts with file from package bcm43xx-firmware-20160301-2.1.noarch (@System)File conflicts happen when two packages attempt to install files with the same name but different contents. If you continue, conflicting files will be replaced losing the previous content.Continue? [yes/no] (no): yes 그리고 재시동을 해준다. package upgrade를 완료한 후에 Distribution upgrade를 수행하자 1zypper dup 재시동업그레이드를 설치한 후에 재시동 하면 약 5분 정도 펌웨어 등을 설치하는 과정을 거친다. 로그인 프롬프트에서 openSUSE Leap 42.3 이 보이면 성공한 것이다. 1234Welcome to openSUSE Leap 42.3 - Kernel 4.4.104-18.44-default (ttyS0).homepi64 login: 보안 패치openSUSE는 upgrade와 patch 를 분리해서 제공한다. 패치는 보안 사항에 관련한 것을 제공하고 있다. lp 로 다운로드 가능한 패치를 확인할 수 있다. 123456789101112131415161718# zypper lpRetrieving repository 'openSUSE-Leap-42.3-Update' metadata ..................[done]Building repository 'openSUSE-Leap-42.3-Update' cache .......................[done]Loading repository data...Reading installed packages...Repository | Name | Category | Severity | Interactive | Status | Summary--------------------------+--------------------+-------------+-----------+-------------+--------+-----------------------------------------------------------------------openSUSE-Leap-42.3-Update | openSUSE-2017-1268 | security | important | --- | needed | Security update for webkit2gtk3openSUSE-Leap-42.3-Update | openSUSE-2017-1425 | recommended | low | --- | needed | Recommended update for grub2openSUSE-Leap-42.3-Update | openSUSE-2017-940 | security | important | --- | needed | Security update for subversionopenSUSE-Leap-42.3-Update | openSUSE-2018-118 | security | important | --- | needed | Security update for webkit2gtk3openSUSE-Leap-42.3-Update | openSUSE-2018-234 | recommended | low | --- | needed | Recommended update for grub2openSUSE-Leap-42.3-Update | openSUSE-2018-241 | recommended | moderate | --- | needed | Recommended update for yast2, yast2-nfs-client, yast2-services-manageropenSUSE-Leap-42.3-Update | openSUSE-2018-586 | recommended | low | --- | needed | Recommended update for grub2Found 7 applicable patches:7 patches needed (3 security patches) 패치는 보안 이슈에 대한 것으로 해당 보안 이슈 정보 혹은 분류 등을 확인할 수 있다. 목록에서 Name 컬럼이 발생한 보안 사항 번호로 이 번호로 조회할 수 있다. 1zypper info openSUSE-2017-462 패키지 내용은 CVE(Common Vulnerabilities and Exposures)로 보고된 보안 사항을 적용한 내용을 자세히 보여주고 있다. 패치 중에서 Category로 검색할 수 있다. 다음 같이 security 분류만 검색할 수 있다. 123456789101112zypper lp --category securityLoading repository data...Reading installed packages...Repository | Name | Category | Severity | Interactive | Status | Summary--------------------------+--------------------+----------+-----------+-------------+--------+--------------------------------openSUSE-Leap-42.3-Update | openSUSE-2017-1268 | security | important | --- | needed | Security update for webkit2gtk3openSUSE-Leap-42.3-Update | openSUSE-2017-940 | security | important | --- | needed | Security update for subversionopenSUSE-Leap-42.3-Update | openSUSE-2018-118 | security | important | --- | needed | Security update for webkit2gtk3Considering 3 out of 7 applicable patches:3 patches needed (3 security patches) 패치를 전체를 설치하려면 1sudo zypper patch 혹은 패치 중에서 특정 패치만 설치할 수 있다. 1sudo zypper install patch:openSUSE-2017-1268 참조 OpenSUSE System Upgrade openSUSE Update &amp; Patch","link":"/opensuse-upgrade-42.2-to-42.3-feec12fbae95/"},{"title":"Naver ncloud 설정","text":"ncloud 서비스sudoer 설정새 사용자를 추가하고 suder 로 등록한 후에 사용한다. 우분투/데비안 계열 새 사용자 추가는 Odroid Install 문서를 참고한다. 새 사용자 등록adduser 추가할 사용자에 대한 정보를 하나씩 묻고, 사용자 홈 디렉토리가 생성된다. 추가한 사용자에 대한 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 편집이 된다 추가하고 패스워드를 입력한다. 12# adduser USERNAME# sudo passwd USERNAME 그리고 suder로 등록해 준다. sudoer 등록usermod 혹은 visudo 를 사용할 수 있다. 1# usermod -aG sudo USERNAME hostname 확인hostname 명령에 따라 현재 호스트 이름이 /etc/hosts 혹은 dns resolver에서 검색되야 한다. 12$ sudo systemcgl status nginxsudo: unable to resolve host ubuntu-84 위 같은 경고가 나타난다면 호스트 이름을 /etc/hosts 에 등록해 준다. ssh서버에 1$ ssh-keygen -t rsa -b 4096 -C &quot;USER@localhost&quot; 위 2 과정을 아래 명령 한 줄로 복사-&gt;붙여넣기를 동시에 할 수 있다. 클라이언트: 1cat ~/.ssh/id_rsa.pub | ssh &lt;USERNAME&gt;@&lt;IP-ADDRESS&gt; 'cat &gt;&gt; .ssh/authorized_keys' mongod-org 설치커뮤티티에디션 설치 네이버 NCloud에서 Micro server를 하나 생성한 후에, MongoDB Community Edition을 설치했고, ncloud의 Ubuntu 16.01 이미지로 서버를 생성한 후에 업그레이드해서 16.04.4 LTS 버전에서 설치했다. 설정mongodb 설정mongodb auth 현재 실행중인 mongod 를 종료한다. sudo systemctl stop mongod.service MongoDB 설정Mongo Database를 사용하기 위해서 데이터 파일 위치, 로그, 포트, Ip 주소 등에 대한 구성을 mongod.conf 에서 할 수 있다. 수정된 구성이 작동하는지 mongo 클라이언트로 접속해서 테스트한다. mongod.conf/etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. 123456789101112131415 dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 0.0.0.0 설정을 저장하고 명령 라인에서 MongoDB를 다시 시작한 후에 mongo client로 접속한다. 모든 인터페이스에 db 접속을 허용하면 bindIpAll: true 를 사용한다. 1$ sudo mongod --port 27017 --dbpath /var/lib/mongodb 이어서 클라이언트로 데이터베이스에 접속한다.접속에 성공하면 &gt; 프롬프트가 나온다. 12$mongo&gt; admin 계정mongod 에서 데이터베이스 및 사용자를 관리할 admin 이란 관리자를 추가하자 123&gt; use adminswitched to db admin&gt; 관자자의 권한과 역할을 선언한다. 12345678&gt;db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] } 사용자의 role 을 변경, 12345678910111213141516171819&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}])&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] 관리자 admin 계정을 admin 데이터베이스에 추가한 후에 mongo client로 admin 계정으로 로그인해서 … 터미널에서 시작한 mongod 를 종료한다. 수동으로 mongod 를 시작하면 root 계정으로 데이터 파일이 생성된다. systemctl로 서비스 시작 전에 data 폴더 퍼미션을 맞춰준다. Directory permissions로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 몽고디비 사용자가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongo.daemon /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata 데이터베이스 사용자 추가데이터베이스를 생성하고 해당 데이터베이스를 접속하는 사용자 계정을 추가하자. 수동으로 접근제어 –auth 옵션으로 데이터베이스를 시작하면, mongo 클리이언트 로그인시 -u , -p 와 –authenticationDatabase 를 지정해 주어야 한다. 1$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot; The following operation creates accountUser in the products database and gives the user the readWrite and dbAdmin roles. 123456789use productsdb.createUser( { user: &quot;accountUser&quot;, pwd: &quot;password&quot;, roles: [ &quot;readWrite&quot;, &quot;dbAdmin&quot; ] })```","link":"/naver-ncloud-b4e6108ee49b/"},{"title":"Raspberry Pi : Raspbian 설치준비","text":"이 글은 Raspberry Pi Programming 과정을 진행하며 강의한 자료를 바탕으로 공개강의를 위한 텍스트로 슬라이드쉐어, blog.thinkbee.kr 그리고 실제 과정을 영상 youtube 채널에 공개할 목적으로 작성한다. Install Rasbperry Pi 글타래는 아래 같이 구성되며 간단한 소개, Serial console, OS 설치, Service 구성 및 사용에 대해 작성했다. Raspberry Pi 설치준비 Install Raspbian OS Managing Service daemon Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter 2017-10-30: swap 추가, timezone 수정{:.right-history} Raspbery Pi OS 설치준비*Raspberry Pi(라즈베리파이)*에 Serial Console 을 연결하고, Raspbian, Ubuntu 등을 설치한 후에 라즈베리파이를 처음 설정하고 SSH 구성을 활성화 하겠다. 라즈베리파이에 OS를 설치하기 위해서는 NOOBS를 사용하거나 오에스 이미지를 다운받아 SD Card에 구워서 사용한다. 라즈베리파이는 다음과 같은 OS 배포본을 사용할 수 있다. 운영체제 특징 Raspbian (Debian) Raspberry Pi + Debian의 합성어, 가장 범용 OS. Arch Linux (A non-Linux Distribution) ARM 프로세서를 지원하는 Arch Linux RISC OS ARM 프로세서를 위한 실시가(RTOS) 운영체제 OpenElec XBMC 미디어 센터 지원을 위한 운영체제 RaspBMC XBMC 미디어 센터 지원을 위한 운영체제 Pidora Pi + Fedora 운영체제 **Raspbian(라즈비안)**은 라즈베리파이를 위한 데비안 리눅스로 가장 대중적인 데비안 리눅스, 우분투와 같은 사용자 경험을 제공해 주고 있다. Raspberry Pi 설치 준비Raspberry Pi의 GPIO에 배치된 UART Rx, Tx 포트와 시리얼 케이블의 Tx, Rx로 크로스 연결하면 시리얼 콘솔로 작동한다. 설치에 앞서 준비해야 할 것이 있다. Raspberry Pi 1, 2, 3 SD Memory Card: 8GB 이상, Class6 이상 USB to Serial Cable Raspberry PiRaspberry Pi의 GPIO에 배치된 UART Rx, Tx 포트와 시리얼 케이블의 Tx, Rx로 크로스 연결하면 시리얼 콘솔로 작동한다. {:with=”500”} SD Memory Card라즈베리파이는 SD Meory Card 카드에서 부팅 및 운영 하도록 되어 있다. NOOBS를 이용한다면 최소 8GB 다른 버전은 최소 4GB Class 4는 4MB/s 쓰기 속도, Class 10은 10MB/s 쓰기가 가능하지만 Class 10이 Class 4를 앞선다는 것을 보장하진 않는다. 라즈베리파이는 Class 6의 8GB 사용을 권장하고 있다. 그림. SDCardFormatter PCIe 지원 SD Card 규격 7.0 USB to Serial CableUSB 주변기기가 대중화 되면 컴퓨터에 Serial port가 사라진 후에 USB to TTL 혹은 USB to Serial 로 Serial 케이블을 사용해야 한다. 구글 검색을 해보면 DB-9 포트 형태, 보드 형태 및 Raspberry Pi 같은 SBC 보드의 GPIO 포트에 사용하기 좋은 Adarfruit 판매하는 핀 형태의 제품도 있다. {: width=”600” } 그림.USB to Serial Cable(구글 이미지 검색 캡쳐)","link":"/raspbian-1-prepare-097d8f2fa4e0/"},{"title":"Raspberry Pi : Install Raspbian","text":"Install Rasbperry Pi OS 글타래는 아래 같이 구성되며 OS 설치, Service 구성 및 사용에 대해 작성한다. Raspberry Pi 설치준비 Install Raspbian OS Managing Service daemon Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter 2017-10-30: swap 추가, timezone 수정{:.right-history} Install Raspbian OSRaspberry Pi(라즈베리파이)에 Raspbian, Ubuntu 등을 설치하고 Serial Console 을 이용해서, 라즈베리파이를 처음 설정하고 SSH 구성을 활성화 하겠다. 라즈베리파이에 OS를 설치하기 위해서는 NOOBS를 사용하거나 오에스 이미지를 다운받아 SD Card에 구워서 사용한다. 라즈베리파이는 다음과 같은 OS 배포본을 사용할 수 있다. 운영체제 특징 Raspbian (Debian) Raspberry Pi + Debian의 합성어, 가장 범용 OS. Arch Linux (A non-Linux Distribution) ARM 프로세서를 지원하는 Arch Linux RISC OS ARM 프로세서를 위한 실시가(RTOS) 운영체제 OpenElec XBMC 미디어 센터 지원을 위한 운영체제 RaspBMC XBMC 미디어 센터 지원을 위한 운영체제 Pidora Pi + Fedora 운영체제 **Raspbian(라즈비안)**은 라즈베리파이를 위한 데비안 리눅스로 가장 대중적인 데비안 리눅스, 우분투와 같은 사용자 경험을 제공해 주고 있다. Raspberry Pi 준비설치에 앞서 준비해야 할 것 이 있습니다. Raspberry Pi 1, 2, 3 OS 설치 SD Memory Card: 8GB 이상, Class6 이상 USB to Serial Cable SDCard에 대해라즈베리파이는 SD 호환 카드에서 작동하도록 되어 있다. NOOBS를 이용한다면 최소 8GB 다른 버전은 최소 4GB Class 4는 4MB/s 쓰기 속도, Class 10은 10MB/s 쓰기가 가능하지만 Class 10이 Class 4를 앞선다는 것을 보장하진 않는다. 라즈베리파이는 Class 6의 8GB 사용을 권장하고 있다. Mac: SDCardFormatter SDCard 사용시 주의 정품 SD Card 사용을 권장 전원은 품질이 좋아야. 라즈베리파이 보드의 TP1, TP2 전력을 측정해서 4.75v 이하면 품질이 좋은 전원으로 바꾸길. 더불어 좋은 품질의 USB 케이블을 사용해야 한다. 종료시 sudo halt 를 이용하도록 오버클록은 지양하도록 ### Download and Install OS 설치와 서비스 설치는 크게 아래 과정을 거친다. (1). Download OS Image, Etcher, sdFormatter (2). OS image 파일을 SD Card에 쓴다. SD Card로 부팅후에 (1). 모니터 혹은 시리얼 콘솔에서 raspi-conifg 로 시스템 구성을 마무리 (2). 서비스 설치 (1). Download OS Image, Etcher, sdFormatter라즈베리안 OS를 다운로드, Raspberry Pi Raspbian Download 링크에서 다운 받을 수 있다. 토렌트와 zip 형식으로 다운 받을 수 있습니다. 다운로드된 파일은 yyyy-mm-dd-raspbian-wheezy.zip 형식으로 다운로드가 된다. 디스크 이미지 파일 yyyy-mm-dd-raspbian-wheezy.img 이 zip으로 압축되어 있는데,이 이미지 파일을 SD Card에 복사해야 한다. 디스크 이미지를 쓰기위한 프로그램으로 오에스 이미지를 SD Card, Disk 등에 쓴다. 보통 아래 프로그램을 이용한다. Windows : Win32DiskImager Linux: ImageWriter macOS: dd 명령 모든 플랫폼: Etcher SD Memory Card Formatter 5.0 for SD/SDHC/SDXC 이 글에서는 디스크 이미지 쓰기Etcher 프로그램을 이용해서 오에스 이미지 파일을 SD Card에 쓰겠다. macOS, Windows, Linux 지원 여기까지 필요한 준비 사항은: Raspbian OS Image SD Card Formatter OS image 파일을 SD Card 쓰기Etcher를 실행하고 {:width=”640”} dd 를 사용한다면,다운받은 .zip 파일을 unzip으로 풀어 dd`로 SD Card에 이미지를 쓴다. 1unzip -p 2017-06-21-raspbian-stretch-lite.zip | sudo dd of=/dev/rdisk1 bs=4M; sync MacOS는 dd의 bs 옵션이 소문자로 받는다: bs=4m 다쓴 SD Card를 마운트 한다. ssh 활성화Raspbian 2016-11-25일 릴리즈 이후 기본으로 ssh가 비활성화 되어 있다. 그래서 처음 부팅후 ssh 접속이 필요하다면 부트 파티션에 ssh 파일을 생성해 주면된다. 12$ cd /boot$ touch ssh #### Serial console 여기서는 Serial console에서 네트워크 확인 및 초기 설정을 하고 ssh 로 서버에 로그인해서 시스템 구성을 진행한다. SD Card를 라즈베리파이에 꽃고 HDMI, Keyboard 및 Mouse 가 별도로 준비되어 있으면 직접 모니터를 보고 작업을 진행하면 좋다. USB to Serial 케이블을 사용해서 Raspberry Pi의 Serial Console에 연결한다. {:width=”640”} 그리고 시리얼 포트를 통해 tty 연결을 위해 터미널 프로그램에서 baud rate 115200 으로 연결한다. 아래는 macOS의 screen CLI 명령으로 usb serial 포트에 연결하고 있다. 1$ screen /dev/cu.usbserial 115200 이제 SD Card를 넣고 부팅을 하면, 터미널에 부트 단계가 진행되고 처음 5분 정도 소요된다. {:width=”640”} Raspberry Pi를 위한 이미지는 처음 계정은 root/linux 이다. 터미널에서 uname 은 aarch64 임을 확인 할 수 있다. 12root# uname -aLinux homepi 4.4.90-18.32-default #1 SMP Fri Oct 6 13:30:08 UTC 2017 (465b410) aarch64 aarch64 aarch64 GNU/Linux 처음으로 라즈베리파이에서 64bit 환경으로 운영해 볼 수 있게 됐다. Raspbian OS Image 복사맥/리눅스에서 dd 명령을 이용해서 이미지를 복사할 수 있습니다. sudo dd bs=1m if=path_of_your_image.img of=/dev/diskn bs: 한번에 읽어들일 사이즈를 의미 마지막 옵션인 ‘diskn’의 n은 SD Card의 번호로 SDCard Formater에서 기억하란 번호입니다. 여기서 번호가 2로 가정합니다.그리고 Mac OSX는 디스크가 /dev 경로에 두 가지 종류가 있습니다. /dev/disk# 버퍼 디바이스로 데이터가 부가적인 처리를 통해 사용합니다. /dev/rdisk# 저수준 경로로 빠르고 dd 명령을 사용할 때 완벽합니다. Class 4 SD card는 rdisk 경로를 사용할 때 20배 빠릅니다. 먼저 포맷터로 포맷한 디스크 마운트를 해제합니다. 맥의 디스크유틸리티를 이용해서 마운트를 해제합니다. 이미지가 있는 곳에서 dd 명령으로 라즈비안을 복사합니다.3.2GB 크기를 복사해서 9분~15분 정도의 시간이 소요됩니다. zip 압축 파일을 입력으로 다음 같이 dd 명령으로 sd card에 쓴다. 1$ unzip -p 2016-05-27-raspbian-jessie.zip | sudo dd of=/dev/rdisk1 bs=1m 압축을 푼후 1234567$sudo dd bs=1m if=2015-02-16-raspbian-wheezy.img of=/dev/rdisk23125+0 records in3125+0 records out3276800000 bytes transferred in 551.608702 secs (5940443 bytes/sec) rdisk 이용시 에러가 발생하면 disk를 사용합니다. 다음 링크에 설명한 방법을 바탕으로 설명해보겠습니다.참조: http://elinux.org/RPi_Easy_SD_Card_Setup Mac diskutil 과 dd 이용diskutil로 디스크 목록 확인해 SD카드 번호 확인 1diskutil list 1diskutil unmountDisk /dev/disk1 이미지 쓰기 1$ sudo dd bs=1m if=image.img of=/dev/rdisk[n] conv=noerror,sync 위 명령으로도 ‘Permission Denied’ 가 나오면, 이것은 SD 카드의 파티션 테이블이 덮어쓰기를 막고 있다는 의미로 이 경우 파티션 테이블을 제거해야 한다. 다음 같이 zero로 SDCard를 덮어쓰면 all partitions, master boot records, and data를 지운다. 진행 상황을 보려면 status=progress 로 알 수 있다. 1$ sudo dd bs=1m if=image.img of=/dev/rdisk[n] conv=noerror,sync status=progress SD card를 포맷하려면 1$sudo dd if=/dev/zero of=/dev/rdisk1 bs=4k count=1 bs: 한번에 읽어들일 byte를 의미 count: block 수 입니다. 혹은 랜덤 데이터로 지우려면 1$dd if=/dev/urandom of=/dev/sda bs=4k Mac의 diskutil을 사용하면 1sudo diskutil partitionDisk /dev/disk3 1 MBR &quot;Free Space&quot; &quot;%noformat%&quot; 100% 다운로드한 이미지는 zip 압축 파일로 저장된다. 다음 같이 명령 파이프를 이용하면 압축 파일을 풀지않고 디스크에 이미지를 쓸 수 있다. 123$ unzip -p 2016-09-23-raspbian-jessie.zip* | sudo dd of=/dev/rdisk1 bs=4mpassword: **** 이미지를 dd 명령으로 작성한 후에 카드를 추출한다: 1sudo diskutil eject /dev/rdisk3 https://www.raspberrypi.org/documentation/installation/installing-images/mac.md clone disk1$ sudo dd if=/dev/diskX conv=sync,noerror bs=4m | gzip -c &gt; /path/to/backup.img.gz 반대로 디스크를 디스크이미지로 만들려면 다음 같이 dd 를 사용할 수 있습니다.쓰기 전에 sd card의 마운트한 파티션을 마운트를 해제해야 합니다. $sudo dd bs=1m if=2015-02-16-raspbian-wheezy.img of=/dev/rdisk2 SDFormatter 이용SDCard Formatter 를 이용해서 SD Card를 포맷할 수 있습니다. 윈도우즈, 리눅스 및 맥을 지원합니다. https://www.sdcard.org/downloads/formatter_4/ 오에스에 맞는 버전을 다운로드하고 실행하면 설치를 합니다. SD Card를 컴퓨터에 삽입합니다. SDFormatter를 실행하고 다음 화면 처럼 SD card를 포맷할 수 있습니다. SDFormatter 라는 프로그램을 설치하여, 옵션의 FORMAT SIZE ADJUSTMENT 설정을 ON 으로 하여 SD카드를 포맷 SDCard Formatter에서 디스크 선택시 디스크 번호를 잘 기억해 두세요. 윈도우즈에서 라즈비안 복사하기윈도우XP/7/8 에서 다운로드한 라즈비안 OS를 SD카드로 복사하겠습니다. 아래 링크에서 ‘Win32 Disk Imager’를 다운받아 사용해야 합니다. Win32 Disk Imager win32diskimager를 실행하고 다운받은 ‘2015-03-15-raspbian-wheezy.zip’ 파일을 선택하고 SD카드 위치를 선택해 주면 됩니다. 그리고 Write버튼을 눌러주고 기다리면 복사를 시작합니다. 부팅IP 강제 지정CD Card를 마운트 하면 boot 파티션이 마운트 된다. boot 파티션에 있는 cmdline.txt 에 ip= 옵션을 추가해 강제로 IP 주소를 지정할 수 있다. 1dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline rootwait **ip=192.168.0.203** Serial Console Raspbian 은 boot 파티션에 있는 cmdline.txt 옵션으로 기본적으로 serial console을 사용하도록 하고 있다. 1dwc_otg.lpm_enable=0 console=ttyAMA0,115200 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline rootwait Mac Serial보통 FTDI USB 케이브을 다음 두 제품이 대부분이다. Prolific PL2303: PL2303 MacOSX FTDI USB Serial: FTDIUSBSerialDriver_v2_3.zip macOS Maverick 이후 FTDI 드라이버가 포함되어 있다.혹시 새 버전을 설치하거나 이전 버전이 설치되어 삭제하려면 [^6] 123$ cd /Library/Extensions/$ sudo rm -r PL2303.kext$ sudo rm -r ProlificUsbSerial.kext FTDI 케이블을 사용한다고 가정하고 맥에 USB to Serial 케이블을 연결하면 /dev 장치에 cu., tty. 장치 드라이버가 생성된다. 두 장치는 다른 점이 있다.[^5] /dev/tty.* 장치는 DCD (data-carrier-detect) 신호를 대기한다, 이것은 누군가 호출해 온다는 의미이다. /dev/cu.* 장치는 DCD를 추정하지 않고 항상 즉시 연결한다(응답 혹은 성공) FTDI 로 시리얼을 사용시는 cu. 장치를 사용하면 된다. 일반적으로 screenMac에서 screen 사용시 1screen /dev/cu.usbserial-XXXXXXXX 115200 시리얼 터미널에서 빠져나오려면 ‘ctrl-a, ctrl-' 를 순서데로 입력 Linux Serial terminalLinux machine에서 Usb to serial 케이블을 사용할 수 있는지 콘솔 메시지에서 Serial console이 있는 지 확인한다. 12345$ dmesg | egrep --color 'serial'[ 1969.914088] usbcore: registered new interface driver usbserial[ 1969.914139] usbcore: registered new interface driver usbserial_generic[ 1969.914175] usbserial: USB Serial support registered for generic[ 1969.918325] usbserial: USB Serial support registered for pl2303 장치 드라이버는 보통 /dev/ttyUSB0 장치로 연결된다. 12$ ls /dev/ttyUSB*/dev/ttyUSB0 dtermdtermAUR is a tiny serial communication program. If you invoke it without parameters, it will connect to /dev/ttyS0 at 9600 baud by default. The following example connect to /dev/ttyS0 at 115200 baud, with 8 data bits, no parity bit and 1 stop bit-times: 1$ dterm 115200 8 n 1 See its homepage[1] for more examples. Minicomminicom can be obtained from the official repositories. Start Minicom in setup mode: 1$ minicom -s Using the textual navigation menu, change the serial port settings to the following: 12Serial Device: /dev/ttyS0Bps/Par/Bits: 9600 8N1 Press Enter to exit the menus (pressing Esc will not save changes). Remove the modem Init and Reset strings, as we are not connecting to a modem. To do this, under the Modem and Dialing menu, delete the Init and Reset strings. Optionally save the configuration by choosing save setup as dfl from the main menu. Restart minicom with the serial cable connected to the target machine. To end the session, press Ctrl+A followed by Ctrl+X. picocompicocom is a tiny dumb-terminal emulation program that is very like minicom, but instead of mini, it is pico. The following example connect to ttyS0 at 9600 bps: 1$ picocom -b 9600 /dev/ttyS0 Note: if the backspace key won’t work properly try out this option: ‘–omap delbs’See its manual for detailed usage. Screenscreen is able to connect to a serial port. It will connect at 9600 baud by default: 1$ screen /dev/ttyS0 115200 To end the session, press Ctrl+a followed by k. 여러 사용자로 열려면 -R 옵션을 주고 다시 연다 1screen -R /dev/tty.usbserial-XXXXXXXX 115200 screen 명령 사용중 어떤 상황에서 세션이 멈춘 경우 종료 명령이 안된다. 이 경우 screen 세션을 찾고 가제 종료를 시도해 본다. Type screen -list to identify the detached screen session. 1234~$ screen -list There are screens on: 20751.Melvin_Peter_V42 (Detached)Note: 20751.Melvin_Peter_V42 is your session id. Get attached to the detached screen sessionscreen -r 20751.Melvin_Peter_V42Once connected to the session press Ctrl + A then type :quit Attached session 종료 1234$ screen -lsThere is a screen on: 2667.ttys003.gogangtaeui-MacBook-Pro (Attached)1 Socket in /var/folders/02/4qk5tfw527b9zqx92gtv4m980000gn/T/.screen. screen -S sessionname -p 0 -X quit 참고http://www.mostlynetworks.com/2014/11/os-x-yosemite-prolific-usb-drivers/http://www.mostlynetworks.com/2015/01/fixing-prolific-driver-os-x/https://wiki.archlinux.org/index.php/disk_cloning Archlinux-Working with serial console [^5]: Mac tty[^6]: Uninstall PL-2303 on macOS X","link":"/raspbian-2-os_install-0291355d691f/"},{"title":"[Open API] OpenweatherMap Open API","text":"OpenweatherMap날씨 정보를 제공하는 OpenAPI로 APi key를 발급받아 사용한다. https://www.openweathermap.org/ UsageOpenWeatherMap은 API 호출시 API Key를 APPID 파라미터로 전달한다. 예를 들어 서울의 날씨를 얻으려면 12api.openweathermap.org/data/2.5/weather?q={city name}api.openweathermap.org/data/2.5/weather?q={city name},{country code} 그러나 한 API Key로 10분에 1번 호출 해야 한다. API Key 4ecbcfa0c4210bfff11d93ea02cd9290 1http://api.openweathermap.org/data/2.5/weather?q=seoul,kr&amp;appid=4ecbcfa0c4210bfff11d93ea02cd9290 API 가입https://openweathermap.org/api 에서 원하는 API를 골라 Subscribe 한 후에 사용할 수 있다. 가입 자격에 따라서 API 호출 빈도가 달라진다. Weather dataJSONExample of API respond: 123456789101112131415161718192021222324252627282930313233343536373839404142{ &quot;coord&quot;: { &quot;lon&quot;: 126.98, &quot;lat&quot;: 37.57 }, &quot;weather&quot;: [ { &quot;id&quot;: 701, &quot;main&quot;: &quot;Mist&quot;, &quot;description&quot;: &quot;mist&quot;, &quot;icon&quot;: &quot;50n&quot; } ], &quot;base&quot;: &quot;stations&quot;, &quot;main&quot;: { &quot;temp&quot;: 276.15, &quot;pressure&quot;: 1013, &quot;humidity&quot;: 64, &quot;temp_min&quot;: 276.15, &quot;temp_max&quot;: 276.15 }, &quot;visibility&quot;: 11265, &quot;wind&quot;: { &quot;speed&quot;: 5.7, &quot;deg&quot;: 310 }, &quot;clouds&quot;: { &quot;all&quot;: 90 }, &quot;dt&quot;: 1523044560, &quot;sys&quot;: { &quot;type&quot;: 1, &quot;id&quot;: 7673, &quot;message&quot;: 0.0075, &quot;country&quot;: &quot;KR&quot;, &quot;sunrise&quot;: 1522962579, &quot;sunset&quot;: 1523008779 }, &quot;id&quot;: 1835848, &quot;name&quot;: &quot;Seoul&quot;, &quot;cod&quot;: 200} Parameters: coord coord.lon City geo location, longitude coord.lat City geo location, latitude weather (more info Weather condition codes) weather.id Weather condition id weather.main Group of weather parameters (Rain, Snow, Extreme etc.) weather.description Weather condition within the group weather.icon Weather icon id base Internal parametermainmain.temp Temperature. Unit Default: Kelvin, Metric: Celsius, Imperial: Fahrenheit.main.pressure Atmospheric pressure (on the sea level, if there is no sea_level or grnd_level data), hPamain.humidity Humidity, %main.temp_min Minimum temperature at the moment. This is deviation from current temp that is possible for large cities and megalopolises geographically expanded (use these parameter optionally). Unit Default: Kelvin, Metric: Celsius, Imperial: Fahrenheit.main.temp_max Maximum temperature at the moment. This is deviation from current temp that is possible for large cities and megalopolises geographically expanded (use these parameter optionally). Unit Default: Kelvin, Metric: Celsius, Imperial: Fahrenheit.main.sea_level Atmospheric pressure on the sea level, hPamain.grnd_level Atmospheric pressure on the ground level, hPawindwind.speed Wind speed. Unit Default: meter/sec, Metric: meter/sec, Imperial: miles/hour.wind.deg Wind direction, degrees (meteorological)cloudsclouds.all Cloudiness, %rainrain.3h Rain volume for the last 3 hourssnowsnow.3h Snow volume for the last 3 hoursdt Time of data calculation, unix, UTCsyssys.type Internal parametersys.id Internal parametersys.message Internal parametersys.country Country code (GB, JP etc.)sys.sunrise Sunrise time, unix, UTCsys.sunset Sunset time, unix, UTCid City IDname City namecod Internal parameter","link":"/openapi-openweathermap-2e5b7fc2d52e/"},{"title":"MongoDB Community Edition 3.6 on Ubuntu","text":"2018-06-22 내용 정리, User auth 링크{:.right-history} 이 문서는 Ubuntu/Debian 계열 정규 배포본에 3.x 버전을 지원하지 않는 플랫폼에 MongoDB Community Edition 3.6 버전을 설치하는 과정을 정리하고 있다. 내용의 기초는 MongoDB Community Edition 3.6 버전을 Amd64, Arm64 지원하는 64bit OS에 설치해 사용하기 위해서 Install MongoDB Community Edition, on-ubuntu를 따라서 진행하고 경험상 필요한 부분을 추가로 정리했다. MongoDB Community Edition 3.6 설치 Mongo Database 구성 Install MongoDB 3.6 Community edition문서에 따르면 리눅스 계열은 Ubuntu, Red Hat, SUSE, Amazon, Debian 과 tarball 설치를 지원한다. 또한 macOS, Windows 플랫폼 설치도 지원한다고 한다. 테스트한 플랫폼은 64bit Ubuntu 16.04: Hardkernel Odroid C2: 64bit, Armbian MongoDB는 다음 패키지를 지원하고 있다: mongodb-org : 다음 패키지를 설치하기 위한 메타 패키지 mongodb-org-server : mongod daemon 과 구성 및 초기 스크립트. mongodb-org-mongos : mongos daemon. mongodb-org-shell : mongo shell. mongodb-org-tools : MongoDB 유틸리티: mongoimport bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop. 사전준비여기서는 Odroid C2 같은 64bit Arm을 지원하는 Armbian 배포본, 그리고 PC Linux/n-Cloud 등의 플랫폼에서 Ubuntu Xeniel 버전에 설치를 했다. Armbian 배포본 Debian Jessie/Stretch 에는 아직 mongodb 64bit 를 제공하지 않고 있다. 레포지토리 등록인증된 .dpkg, .apt 패키지를 설치하기 위해, 아래 처럼 서버의 키를 등록한다. 여러분 시스템이 적용되는 지는 [^1]에 잘 설명되어 있다. 키서버 등록 1$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2930ADAE8CAF5059EE73BB4B58712A2291FA4AD5 MongoDB용 소스 리스트 추가apt의 source list에 mongodb repository를 등록한다. 우분투 계열은 파일 생셩 /etc/apt/sources.list.d/mongodb-org-3.6.list 파일 생성하고 아래 같이 해당 리눅스 버전에 맞는 소스 목록을 추가한다. Ubuntu 16.04 1echo &quot;deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.6 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.6.list Ubuntu 14.04 1$ echo &quot;deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.6 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.6.list remove key &amp; ppa설치 후 필요 없어서 키 서버 저장소 목록을 지우려면, 삭제할 키 해시 8자리 코드를 확인한다. 1234$ sudo apt-key listpub 4096R/A15703C6 2016-01-11 [expires: 2018-01-10]uid MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt; 이 키를 삭제한다. 1$ sudo apt-key del A15703C6 설치그리고 apt 명령으로 소스 캐시를 갱신하고 mongodb-org 커뮤니티 버전의 mongodb를 설치한다. 12$ sudo apt update$ sudo apt install -y mongodb-org mongodb 3.x 버전은 데이터 저장 파일 시스템으로 xfs 를 권장하고 있다. 만약 특정 버전을 설치하려면 다음 같이 버전을 명시한다. 1$ sudo apt-get install -y mongodb-org=3.6.5 mongodb-org-server=3.6.5 mongodb-org-shell=3.6.5 mongodb-org-mongos=3.6.5 mongodb-org-tools=3.6.5 이전 mongod-org 3.4를 Armbian 에서 설치중 systemd unit 설정 파일과 MongoDB 시스템 계정 등이 생성되지 않는 경우가 있었다. 아래를 따라 손으로 생성해 주면 된다. mongodb 사용자mongod-org 설치후 시스템 사용자 mongodb 가 추가되야 한다. 만약 생성되지 않았으면, 새로 만든다. 1$ sudo adduser --disabled-password --gecos &quot;&quot; --no-create-home --disabled-password --disabled-login mongodb systemd service entry만약 mongodb-org 설치후 systemctl 스크립트가 /etc/init.d에 복사되지 않는 경우 여기서는 odroid-c2 armbian 설치 상태, 일반 리눅스 배포본은 잘 된다. systemd 서비스 파일이 /lib/systemd/system/mongod.service에 위치한다. 아래 명령을 실행해 mongodb.service 가 없으면 새로 생성해야 한다. 1$ sudo systemctl list-unit-files --type=service |grep mongodb 만약 mongodb.service 가 없다면, /lib/systemd/system/mongod.service 파일을 다음 같이 활성화 시켜준다. 12$ cd /lib/systemd/system$ sudo systemctl enable mongodb.service mongodb.service 가 등록됐는지 확인한다. 12$ sudo systemctl list-unit-files --type=service |grep mongodbmongodb.service disabled disable 상태면 systemctl 명령으로 enable 시킨다. 1$ sudo systemctl enable mongodb.service ### Run MongoDB Community Edition이 설치되면 요구되는 파일 및 폴더가 다음 위치에 생성됟다. /var/lib/mongodb : 기본 데이터 파일 위치 /var/log/mongodb : 기본 로그 저장 폴더 /etc/mongod.conf : mongod 구성 파일. 로그, 데이터 위치 등을 변경 가능 mongod 데몬은 mongodb user account 계정으로 실행된다. systemctl 명령으로 mongod 를 시작한다. 12$ sudo systemctl start mongod$ sudo systemctl status mongod 실행한 mongod를 확인해 보면 12$ ps -ef |grep mongodmongodb 15385 1 1 12:06 ? 00:00:00 /usr/bin/mongod --config /etc/mongod.conf mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있다. Mongo Database 설정 mongodb 사용자와 디렉토리 퍼미션 확인 mongod.conf 설정 mongo client 접속 테스트 mongodb 인증 퍼미션 확인로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 몽고디비 사용자가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongo.daemon /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata mongod.conf 설정MongoDB의 systemd 서비스는 데이터베이스 구성 파일 /etc/mongod.conf 을 참조한다. 먼저 /etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. 12345678910111213141516storage: dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 127.0.0.1,192.168.0.2 dbPath : 데이터베이스 스토리지 위치 bindIp: 서버 외에서 mongo 클라이언트가 접근하려면 IP 를 입력한다. 현재는 mongo.conf 설정 파일에 접근 제어가 없는 상태에서 mongo 클라이언트로 접속한다 Admin 사용자mongod에 인증이 비활성화 상태에서 mongo` 클라이언트로 접속에 성공하면 &gt; 프롬프트가 나온다. admin 데이터베이스로 전환한다. 12345$mongo&gt;&gt; use adminswitched to db admin&gt; admin 데이터베이스에서 관리자 role을 가진 사용자를 추가하고, 사용할 데이터베이스의 사용자와 접근 제어를 추가해서 사용하기 위해서 작업한다. user administratoruserAdmin role 혹은 userAdminAnyDatabase role을 가진 사용자 만든다. 다음은 admin 데이터베이스에서 사용자를 관리하는 admin 계정을 생성하고 있다. 12345678910&gt;db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() admin 사용자 패스워드 변경은 1&gt; db.changeUserPassword(&quot;accountUser&quot;, &quot;SOh3TbYhx8ypJPxmt1oOfL&quot;) 사용자의 role 을 변경, 12345678910111213141516171819&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}])&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] 혹은 updateUser 를 사용할 수 있다: 1db.updateUser( &quot;appClient01&quot;, ... security.authorizationmongodb.conf 파일에 security.authorization 을 활성화 한다 12security: authorization: enabled 인증모드는 v2.4이전에는 --auth 옵션을 사용하고, v2.6 이후에서 mongod.conf 파일 사용할 때 security.authorization 를 활성화 한다. systemd 로 서비스를 재시작 한다. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 이제 인증 모드에서 데이터베이스에 접속해야 한다. 만약 인증모드로 시작한 후에 다음 같이 인증 정보없이 로그인 하면 데이터베이스 사용시 에러를 만난다. 123456$ mongo&gt; show dbs;Tue Sep 27 23:22:40.683 listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;unauthorized&quot; } at src/mongo/shell/mongo.js:46&gt;&gt; show usersTue Sep 27 23:22:44.667 error: { &quot;$err&quot; : &quot;not authorized for query on test.system.users&quot;, &quot;code&quot; : 16550 } at src/mongo/shell/query.js:128 인증모드로 접속데이터베이스 시스템에 접근제어가 활성화 되면 mongo 클라이언트 접속시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 만약 데이터베이스 인증모드로 실행되는데 비인증 클라이언트 접근은 아래 같이 에러를 낸다: 1234567MongoDB shell version v3.6.5connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.5&gt; use studentsswitched to db students&gt; show users2018-06-25T18:30:38.174+0900 E QUERY [thread1] Error: not authorized on students to execute command { usersInfo: 1.0, $db: &quot;students&quot; } : 원격지에서 접근외부에서 mongodb로 접근시 authentication을 적용한 상태라면 다음과 같은 URL로 접근할 수 있다: “username:password@HOST_NAME/mydb” 그러나 외부접근시 클라이언트 버전과 서버의 Credential 버전이 맞지 않은 경우 다음 같이 실패 메시지를 확인할 수 있다. 2016-05-16T00:53:10.338+0900 I ACCESS [conn2] Failed to authenticate student@student with mechanism MONGODB-CR: AuthenticationFailed: MONGODB-CR credentials missing in the user document2016-05-16T00:53:10.352+0900 I NETWORK [conn2] end connection 220.121.140.59:51634 (0 connections now open) ### 데이터베이스 생성과 인증 새 데이터베이스에 컬렉션을 생성하고 데이터베이스 사용자를 접근제어할 수 있는 내용은 MongoDB User Authentication 에서 다루고 있다. ## MongoDB에 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 ### `mongod` 명령 사용 systemd가 아닌, mongod 명령으로 로 MongoDB를 시작해 설정 파일 등이 제대로 동작하는지 확인할 수 있다. 다만 데이터베이스가 생성하는 데이터와 로그 파일의 접근권한이 실행한 사용자 계정으로 처리되어 퍼미션 문제가 발생할 수 있다. mongoDB v2.4 인증모드로 시작mongod 명령라인으로 시작할 수 있다. 1$ sudo mongod --port 27017 --dbpath /data/mongodata mongoDB v2.4는 다음 같이 인증 모드로 시작한다. mongod 명령라인에서 --auth 옵션을 붙여 DB 인스턴스(mongod)를 시작 혹은 재시작한다. 1$ mongod --auth --port 27017 --dbpath /data/db1 혹은 mongod.conf 설정 파일에서 auth 를 활성화 한다. 1auth = true mongoDB v2.6 이후앞서 시작한 명령행 mongodb를 종료하고 명령라인에서 재시작 --auth 옵션을 붙여 시작한다. 1$ mongod --auth --port 27017 --dbpath /data/mongodata 접근제어 --auth 옵션으로 데이터베이스를 시작하면 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 참조[^1]: Install mongodb on Ubuntu","link":"/2018-06-08-mongodb-3.6-install-be31d0447d18/"},{"title":"[Open API] REST Architecture 요약","text":"REST ArchitectureOracle 에서 발표한 자료에서 설명한 내용을 정리한다. Deview 2017 “그런 REST API로 괜찮은가”Deview 2017 “그런 REST API로 괜찮은가” 발표자료 RESTFull APIRESEFull API는 기술적으로 다음 같이 발전해 왔다. HTTP/1.0 1994-1996Roy T. Fielding, HTTP Object Model “How do i improve HTTP without breaking the Web?” REST 1998Roy T. Fielding, Microsoft Research 발표 “Representational State Transfer:An Architectural Style for Distributed Hypermedia Interaction” REST 2000Roy T. Fielding, 박사 논문으로 발표 “Architectural Styles and the Design of Network-based Software Architectures” 이 기술의 근간은 Web API 이다. SOAPMicsoft에서도 XML-RPC 1998를 통해 Web API를 구현하고자 했다. Microsoft, SOAP Salesforce APISalesforce API, 2000 은 이런 방식을 처음 도입했다.https://web.archive.org/web/20001018092215/http://salesforce.com/ flickr APIflickr의 SOAP https://web.archive.org/web/20040921173223/http://www.flickr.com:80/services/api/response.soap.html flickr의 REST API https://web.archive.org/web/20040821031039/http://www.flickr.com:80/services/api/response.rest.html SOAP과 REST SOAP REST - 복잡하다 - 단순하다 - 규칙 많음 - 규칙 적다 - 어렵다 - 쉽다 Google trends 검색 2006년, AWS가 자사 API의 85%를 REST로 구현2010년, Salesforce.com에서 REST API 추가 CMIS2008년 CMIS 표준 준비 EMC, IBM, Microsoft등이 함께 작업 REST 바인딩 지원 그러나 Roy T. Fielding: “No REST in CMIS” REST API guideline2016년 Microsft 가 제시한 REST API Guideline Roy T. Fielding:“s/REST API/HTTP API/“ http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven 그리고 “REST API를 위한 최고의 버저닝 전략은 버저닝을 안 하는 것” 결국 REST API는 REST 아키텍쳐 스타일을 따르는 API 분산 하이퍼미디어 시스템(예: 웹)을 위한 아키텍쳐 스타일 아키텍쳐 스타일: 제약조건의 집합 REST 를 구성하는 스타일아키텍쳐 스타일 은 다음 같이 구성된다: client-server stateless cache uniform interface layered system code-on-demand (optional) Uniform interfaceUniform Interface는 identification of resources manipulation of resources through representations self-descriptive messages hypermedia as the engine of application state (HATEOAS) Self descriptive messageSelf-descriptive message, 메시지는 스스로를 설명해야한다 1GET / HTTP/1.1 이 HTTP 요청 메시지는 뭔가 빠져있어서 self-descriptive 하지 못하다. 목적지를 추가하면 이제 self-descriptive 12GET / HTTP/1.1Host: www.example.org 결과 메시지도 123HTTP/1.1 200 OK[ { &quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/a/b/c&quot; } ] 1234HTTP/1.1 200 OKContent-Type: application/json-patch+json[ { &quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/a/b/c&quot; } ] HATEOAS애플리케이션의 상태는 Hyperlink를 이용해 전이되어야한다.http://slides.com/eungjun/rest#/37 독립성서버와 클라이언트가 각각 독립적으로 진화한다.서버의 기능이 변경되어도 클라이언트를 업데이트할 필요가 없다.REST를 만들게 된 계기: “How do I improve HTTP without breaking the Web.” 호환성 유지HTML5 첫 초안에서 권고안 나오는데까지 6년 HTML5 드래프트 2008년 1월, 첫 권고안 2014년 10월 HTTP/1.1 명세 개정판 작업하는데 7년 HTTP/1.1 명세 세 번째 개정판인 RFC 7230-7235의 작업기간 2007년 12월 - 2014년 6월 상호운용성에 대한 집착Referer 오타지만 안 고침Referer의 개념을 Tim Berners Lee에게 제안한 것은 Phillip M. Hallam-Baker 이지만, 이름까지 정해서 주지는 않았다고 한다. 따라서 오타를 만든 것은 Tim Berners Lee인 것으로 추정하는듯. See https://lists.w3.org/Archives/Public/ietf-http-wg-old/1995JanApr/0109.htm charset 잘못 지은 이름이지만 안 고침charset은 “character set”이 아님에도 불구하고 그런 오해를 계속해서 불러일으키고 있다. http://w3-org.9356.n7.nabble.com/How-to-pronounce-quot-charset-quot-td254585.html#message254629 HTTP 상태 코드 418 포기함 (I’m a teapot)https://www.facebook.com/eungjun/posts/10213901564392694 HTTP/0.9 아직도 지원함 (크롬, 파이어폭스)구글 크롬에서 HTTP/0.9 지원을 완전히 제거하려다 실패했다. Tenda D301 router와의 호환성이 깨지는 문제가 발견되어서. default port인 경우에만 HTTP/0.9를 지원하도록 하려고 했는데 그마저도 문제가 발견되어 revert했다:https://bugs.chromium.org/p/chromium/issues/detail?id=624462 REST가 웹의 독립적 진화에 도움을 주었나 HTTP에 지속적으로 영향을 줌 Host 헤더 추가 길이 제한을 다루는 방법이 명시 (414 URI Too Long 등) URI에서 리소스의 정의가 추상적으로 변경됨: “식별하고자 하는 무언가” 기타 HTTP와 URI에 많은 영향을 줌 HTTP/1.1 명세 최신판에서 REST에 대한 언급이 들어감 Reminder: Roy T. Fielding이 HTTP와 URI 명세의 저자 중 한명입니다 그럼 REST는 성공했는가 REST는 웹의 독립적 진화를 위해 만들어졌다 웹은 독립적으로 진화하고 있다 성공! 그런데 REST API는?REST API는 REST 아키텍쳐 스타일을 따라야한다.오늘날 스스로 REST API라고 하는 API들의 대부분이 REST 아키텍쳐 스타일을 따르지 않는다. REST 스타일 가이드를 따랴야 한다.링크 An API that provides network-based access to resources via a uniform interface of self-descriptive messages containing hypertext to indicate potential state transitions might be part of an overall system that is a RESTful application– Roy T. Fielding 구현이 쉽지는 않다. 원격 API가 REST API여야 하나?시스템 전체를 통제할 수 있다고 생각하거나, 진화에 관심이 없다면, REST에 대해 따지느라 시간을 낭비하지 마라 링크 REST emphasizes evolvability to sustain an uncontrollable system. If you think you have control over the system or aren’t interested in evolvability, don’t waste your time arguing about REST.– Roy T. Fielding 현재는 (1) REST API를 구현하고 REST API라고 부른다.(2) REST API 구현을 포기하고 HTTP API라고 부른다.(3) REST API가 아니지만 REST API라고 부른다. (현재 상태) 그러므로 제약 조건을 따르던지 다른 단어를 써라!!! I am getting frustrated by the number of people calling any HTTP-based interface a REST API. … Please try to adhere to them or choose some other buzzword for your API.– Roy T. Fielding 일반 Web과 REST API 비교http://slides.com/eungjun/rest#/63 open api spechttps://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md","link":"/restfull-openapi-4fd2d5982df7/"},{"title":"Open API Web Token","text":"Open api keyAPI keys는 사용자 인증, 요청 API 호출을 위해 필요하다. 보통 RESTFull API 호출시 API keys 와 인증 스킴을 사용한다. 주요 차이는: API keys : 앱 혹은 사이트 호출을 식별해서 API 호출을 만다. Auth tokens : 앱 혹은 사이트 사용자를 식별한다. 이런 인증에 두가지 방식을 사용한다. Session-based Authentication Token-based Authentication Token based Authentication토큰 기반 인증은 Stateless Authentication 이 큰 이유이다. 클라이언트 측 로컬 스토리지 (혹은 세션, 쿠키 가능)에 저장된다. 좋은 예는 싱글 페이지 앱, Web ApIs, IoT가 있다 앱이 확장성이 있고 분리되야 한다면, Token 기반이 좋은 사례가 된다. Stateless Authentication: 인증에 대해 서버측이 인증 정보를 보존하지 않는다. JWTJWT(JSON Web Tokens)는 REST API를 사용한 간단하고 보안이 적용된 인증 전략이다. 웹 인증을 위한 표준이고 JSON token 요청을 기반으로 한다. 인증 서버에서 발급한 토큰을 클라이언트가 요청시 마다 헤더에 토큰을 넣어 요구해야 한다. MEAN 스택 앱에 빠르게 인증을 추가하는 것은 JSON Web Token 을 사용할 수 있다. How JWT Works?Node Js JWT Authentication Tutorial From Scratch JSON Web Token is the token; we need to put the header in every request to verify the client. The Architecture of JWT Authentication is pretty darn simple. First user attempt to login with their credentials. After server verifies the credentials, it sends JSON Web Token to the client. A client then saves that token in local storage or any other storage mechanism. Again if a client wants to request a protected route or resource, then it sends JWT in a request header. The server verifies that JWT and if it is correct then return a 200 response with the information, client needs. If the JWT is invalid, then it gives unauthorized access or any other restricted message. Node js JWT Authentication In this tutorial, we are not using any front-end framework. We will use POSTMAN to request the server. We will check the auth using token. So let us get started. Step 1: Install node js dependencies.Create one project folder and go into that folder. Type the following command. 1npm init Now, install the following dependencies. 1npm install express jsonwebtoken mongoose body-parser --save It will install the express web framework, jsonwebtoken package to authenticate the user, mongoose schema model, and body-parser middleware. Also, we need to install the nodemon development server to prevent the stop and restart the server process. So let us do that first. 1npm install nodemon --save-dev Rest dependencies we will install as our project grows. Step 2: Configure the Node Server.In the package.json file, change this object to the following. 123&quot;scripts&quot;: { &quot;start&quot;: &quot;nodemon server&quot;}, So in the terminal when we type npm start command, we bootstrap the server.js file.In the root folder, make one file called server.js. Configure the node server. 1234567891011// server.jsconst express = require(&quot;express&quot;);const app = express();const bodyParser = require(&quot;body-parser&quot;);const PORT = 3000;app.listen(PORT, function () { console.log(&quot;Server is running on Port&quot;, PORT);}); Now, go to terminal and hit the following instruction. 1npm start It will start the server, you can see it on a console. So it is ready to consume any request, either web or API. Step 3: Send a request to node server via Postman.First, we define one route and send the JSON response to the client. 1234567// server.jsapp.get(&quot;/checking&quot;, function (req, res) { res.json({ Tutorial: &quot;Welcome to the Node express JWT Tutorial&quot;, });}); Open the Postman and send the get request to http://localhost:3000/checking. Postman Tutorial Step 4: Configure the MongoDB Database.Write the following code to connect the Node.js application to the MongoDB database. if below mongoose 3.x, 123// server.jsconst mongoose = require(&quot;mongoose&quot;);mongoose.connect(&quot;mongodb://localhost/jwtauth&quot;); Then use above mongoose 4.x, prepare Promise and connect(). 123456// Mongodbmongoose.Promise = global.Promise;mongoose.connect(&quot;mongodb://student:PW@localhost/students&quot;, { useMongoClient: true,}); Also, write the body-parser middleware to the application. 1234// server.jsapp.use(bodyParser.urlencoded({ extended: false }));app.use(bodyParser.json()); Step 5: Create a User model.Create one new folder inside root called models. In that, create one file called user.model.js file. 1234567891011// user.model.js&quot;use strict&quot;;const mongoose = require(&quot;mongoose&quot;);const user = mongoose.Schema({ //_id: mongoose.Schema.Types.ObjectId, email: { type: String, required: true }, password: { type: String, required: true },});module.exports = mongoose.model(&quot;User&quot;, user); We have defined the schema for the User collection. Step 6: Create the routes for users.In the root, make one folder called routes. In that folder, create one file called user.route.js. Now we need to sign the user up for our application. So let us define the post route to signup the user. We also need a bcrypt module to hash the password. We can not store the plain password. So let us install bcrypt module first. 1npm i bcrypt Next, write the following code into the user.route.js file. 123456789101112131415161718192021222324252627282930313233343536373839// user.route.jsconst express = require(&quot;express&quot;);const router = express.Router();const mongoose = require(&quot;mongoose&quot;);const bcrypt = require(&quot;bcrypt&quot;);const User = require(&quot;../models/user.model&quot;);router.post(&quot;/signup&quot;, function (req, res) { bcrypt.hash(req.body.password, 10, function (err, hash) { if (err) { return res.status(500).json({ error: err, }); } else { // const user = new User(req.body); const user = new User({ // _id: new mongoose.Types.ObjectId(), email: req.body.email, password: hash, }); user .save() .then(function (result) { console.log(result); res.status(200).json({ success: &quot;New user has been created&quot;, }); }) .catch((error) =&gt; { res.status(500).json({ error: err, }); }); } });});module.exports = router; What it does is that it tries to hash the incoming request’s password property. If it fails to do so then returns a response with an error in json format. If it successes then it will create a new user and add that to the MongoDB database. Now include this user.route.js file in the server.js file. I am writing the whole file now. 1234567891011121314151617181920212223242526// server.jsconst express = require(&quot;express&quot;);const app = express();const bodyParser = require(&quot;body-parser&quot;);const user = require(&quot;./routes/user.route&quot;);const mongoose = require(&quot;mongoose&quot;);mongoose.connect(&quot;mongodb://localhost/jwtauth&quot;);const PORT = 3000;app.use(bodyParser.urlencoded({ extended: false }));app.use(bodyParser.json());app.get(&quot;/checking&quot;, function (req, res) { res.json({ Tutorial: &quot;Welcome to the Node express JWT Tutorial&quot;, });});app.use(&quot;/user&quot;, user);app.listen(PORT, function () { console.log(&quot;Server is running on Port&quot;, PORT);}); Step 7: Send a post request from the Postman.postman 에서 POST 방식으로 새 사용자를 추가해 보자, POST에서 Body를 Raw 이고 형식은 json(application/json) 를 선택하고 작성한다. 123456{ &quot;firstName&quot;: &quot;&quot;, &quot;lastName&quot;: &quot;&quot;, &quot;email&quot;: &quot;&quot;, &quot;password&quot;: &quot;&quot;} {:width=”500”} [그림. Postman에서 JSON 포스트] You can see here, I have created user successfully. Now, I am using Studio 3T for MongoDB. So here is the newly created user in the database. 이제 실제 암호화된 비밀번호로 생성된 사용자 정보를 확인할 수 있다. {:width=”500”} [그림. 새 사용자 정보] MongoDB Tutorial With An Example Step 8: Sign In the User.사용자가 생성되고 비밀번호로 bcryp로 비밀번호가 생성되면 bcrypt.compare() 를 사용해 사용자 비밀번호를 인증할 수 있다. 12345678910111213141516171819202122232425262728// user.route.jsrouter.post(&quot;/signin&quot;, function (req, res) { User.findOne({ email: req.body.email }) .exec() .then(function (user) { bcrypt.compare(req.body.password, user.password, function (err, result) { if (err) { return res.status(401).json({ failed: &quot;Unauthorized Access&quot;, }); } if (result) { return res.status(200).json({ success: &quot;Welcome to the JWT Auth&quot;, }); } return res.status(401).json({ failed: &quot;Unauthorized Access&quot;, }); }); }) .catch((error) =&gt; { res.status(500).json({ error: error, }); });}); 사용자 이메일로 허가된 사용자인지 인증하는데, 이메일이 존재하지 않으면 401 unauthorized access 에러를 출력한다. {:width=”500”} [그림. Postman에서 Sign 포스트] First, I have checked if the user’s email exists or not. If not then return 401 unauthorized access. If email is there then check the password with bcrypted database password if match found then welcome to the JWT auth else 401 unauthorized access. 이메일로 사용자 검색이 되고 비밀번호 인증이 되면 환영 JWT auth를 반환하고 아니면 401 unauthorized access 를 반환하게 한다. Step 9: Return the JWT, if auth attempt successful.사용자 증명인 이메일과 패스워드가 유효하면 JWT token을 반환하도록 하자, jwt.sign() 함수는 기본으로 HMAC SHA256 해시 코드를 발생한다. 1234jwt.sign({ email: user.email, _id: user._id} 다른 알고리즘이 필요하면 algorighm 속성을 제시해 준다. 12345jwt.sign({ email: user.email, _id: user._id, { algorithm: 'RS256'}} If the user’s credentials email and password are valid then in response, we need to return a JWT token. So let us generate the token and return to the user. 1234567891011121314151617181920// user.route.jsconst jwt = require(&quot;jsonwebtoken&quot;);if (result) { const JWTToken = jwt.sign( { email: user.email, _id: user._id, }, &quot;secret&quot;, { expiresIn: &quot;2h&quot;, } ); return res.status(200).json({ success: &quot;Welcome to the JWT Auth&quot;, token: JWTToken, });} JWT Token의 형식은 HEADER, PAYLOAD, SECRETKEY 조합으로 아래 같다: The format of JWT Token is as following. HEADER: ALGORITHM &amp; TOKEN TYPE 1234{“alg”: “HS256”,“typ”: “JWT”} PAYLOAD:DATA 123456{“email”: “krunallathiya10@gmail.com”,“_id”: “5a7c9bd8fc3e501c94aa6035”,“iat”: 1518120124,“exp”: 1518127324} VERIFY SIGNATURE 12345HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 조합으로 생성한 JWT는 아래 같은 JWT Token을 반환한다. So it is a combination of header, payload, and secretkey, we are providing. Remember, You need to define your secret key in your environment variable file. I have just shown here for the demo purpose. So it will produce the following JWT token. 1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImtydW5hbGxhdGhpeWExMEBnbWFpbC5jb20iLCJfaWQiOiI1YTdjOWJkOGZjM2U1MDFjOTRhYTYwMzUiLCJpYXQiOjE1MTgxMjAxMjQsImV4cCI6MTUxODEyNzMyNH0._6qVGQV_KYlonawnaTHG-OhOJLV4tgD-Eob5iRz89AM 이 토큰을 제한된 자원에 접근하는 앱에 사용할 수 있다. Now use this token to access the protected resources to your application and we are done here. So this is how you can generate the JWT Auth Token. JWT Token verifyingjwt.verify()를 사용해 발급한 토큰이 허용되는지 검증할 수 있다. jwt.verify(token, secretOrPublicKey, [options, callback]) token: 발행된 Json Web Token secretOrPublicKey: 토큰 발행시 제공한 시크릿 키 1234567891011router.post(&quot;/verify&quot;, function (req, res) { const user = User.findOne({ email: req.body.email }); // check expired? jwt.verify(req.body.token, user.secret_key, function (err, decoded) { if (err) { console.log(err); return res.status(200).json(err); } });}); 참조 npm:JSONWebToken Node Js JWT Authentication Tutorial From Scratch Why and When to Use API Keys https://appdividend.com/2018/02/07/node-js-jwt-authentication-tutorial-scratch/ Securing Node.js RESTful APIs with JSON Web Tokens","link":"/2018-06-02-restfull-openapi-jwt_token-13fb94971cf6/"},{"title":"Awk 기본","text":"awk 이용awk란 이름은 이 유틸리티를 작성한 A.V.Aho, P.J. Weinberger, B. Kernigham의 머리글자를 따온 것으로 주로 패턴의 검색과 조작을 주목적으로 만들어진 것이다. 즉 파일의 각 줄에 필드(field)를 인식할 수 있는 패턴 매칭 기능을 가지고 이들 필드를 자유자재로 조작 가능한 유틸리티를 작성하고자 만든 것이다. awk 패턴 매칭 awk pattern {action} filenamesawk -f parttern-action-file filenames filenames: 입력화일 awk실행 action을 가진 프로그램 file 패턴내용| 패턴 | 설명 || —————— | ——————————————————————————————————————————————————————————————– | — | ————————————————————————————————————————— || BEGIN | 입력화일을 읽어들이기 전에 옆에 제시되는 문자을 실행시키도록 한다. || END | awk가 모든 입력을 처리한 후, 옆에 제시되는 문장을 실행시키도록 한다. || expression | 식을 평가한 후 이 식이 참, 즉 non-zero이거나 non-null인 경우 문장을 실행한다. || /re/ | 정규식과 일치하는 문자열을 포함하고 있는 라인에서 문장을 실행한다. || compound-pattern | 복합패턴이라는 것으로 &amp;&amp;(and), | | (or) , !(not) 그리고 괄호에 의해 연결시킨 것이다. expression의 경우와 마찬가지로 복합 패턴도 참인 경우의 문장을 실행시킨다. || pattern1, pattern2 | 이러한 패턴을 범위 패턴이라 한다. 현재 처리되고 있는 라인이 pattern1과 일치되고, 다음에 따라오 는 라인 중 임의의 라인이 pattern2와 일치할 때, 범위 패턴은 두 라인 사이의 각 라인과 일치한다. | awk에서 찾은 내용은 다음 변수에 저장되어 있다. 변수 내 용 FILENAME 현재 처리되고 있는 입력 파일의 이름 FS 입력 필드 분리문자 NR 현재 레코드(행)의 번호 NF 현재 레코드(행)의 필드의 갯수 OFS 출력되는 필드의 분리문자 auth.log 패턴 분석12Apr 16 06:43:04 homepi sshd[20198]: User root from 222.73.37.31 not allowed because not listed in AllowUsersApr 16 06:43:07 homepi sshd[20198]: Failed password for invalid user root from 222.73.37.31 port 41030 ssh2 sshd 접속하는 root 접속 요청을 찾으려면, 1awk '/sshd|root/' /var/log/auth.log # sshd,root 가 있는 줄을 출력 찾은 결과의 특정 컬럼만 출력 가능하다: 1$ awk '/sshd|Failed/ {print $13}' /var/log/auth.log 1$ awk '{print &quot;Number of fields: &quot; NF}' /var/log/auth.log 로그인 실패한 root 사용자가 사용하는 IP만을 추출하고자 한다면, Apr 16 06:43:07 homepi sshd[20198]: Failed password for invalid user root from 222.73.37.31 port 41030 ssh2 12$ awk '/Failed password/ {print $13,&quot;:&quot;,$15 }' /var/log/auth.log222.73.37.31 : 49415 위 결과를 정렬하면, 같은 IP들이 징렬되어 나열된다. 123456awk '/Failed password/ {print $13,&quot;:&quot;,$15 }' /var/log/auth.log | sort ```이 겹치는 결과에서 하나의 IP만 식별하고, 반복된 숫자를 출력하고, 정렬한다.```shawk '/Failed password/ {print $13,&quot;:&quot;,$15 }' /var/log/auth.log | sort | uniq -c | sort -n 123456789101112awk '/^north/' datafile # north로 시작하는 줄 출력awk '/^(no | so)/' datafile : no 또는 so 로 시작하는 줄 출력awk '$5 ~ /\\.[7-9]+/' datafile : 다섯 번째 필드가 마침표 다음엣 7과 9사이 숫자가 하나 이상 나오는 레코드 출력awk '$2 !~ /E/ { print $1, $2 }' datafile : 두 번째 필드에 E 패턴이 없는 레코드의 첫 번째와 두 번째 필드 출력awk '$3 ~ /^Joel/{ print $3 &quot; is a nice guy.&quot;} ' datafile : 세 번째 필드가 Joel로 시작하면 &quot; is a nice guy&quot;와 함께 출력awk '$8 ~ /[0-9][0-9]$/ { print $8 }' datafile : 여덟 번째 필드가 두 개의 숫자이면 그 필드가 출력awk '$4 ~ /Chin$/ { print &quot;The price is $&quot; $8 &quot;.&quot; }' datafile : 네 번째 필드가 Chine으로 끝나면 &quot;The price is $&quot; 8번 필드 및 마침표가 출력awk -F: '{ print $1 } ' datafile : -F 옵션은 입력 필드를 ':'로 구별.awk -F&quot;[ :]&quot; '{ print $1, $2 } ' datafile : 입력 필드로 스페이스와 ':'를 필드 구별자로 사용awk -f awk_script.file datafile : -f 옵션은 awk 스크립트 파일 사용할 때 씀. auth.log 에 있는 잘못된 로그인 정보만 출력 12awk '(/sshd|invalid/){print $(NF-5)}' /var/log/auth.logawk '(/sshd|invalid/){print $13}' /var/log/auth.log 연산자| 연산자 | 설명 || —————– | ———————————— | —- | ———— | — | ———————— || = += -= *= /= %= | 배정(assignment)연산자 || + - * / % ++ – | 산술 연산자 || | | &amp;&amp; ! | 논리 연산자( | | = OR, &amp;&amp; = AND, ! = NOT) || &gt;&gt;= &lt; &lt;= == != | 비교 연산자 || v p | 변수 V가 패턴 P에 부합되면 참 || v !p | 변수 V가 패턴 P에 부합되지 않으면 참 | 123456awk '$7 == 5' datafile : 7번 필드가 5와 같다면 출력awk '$2 == &quot;CT&quot; { print $1, $2 }' datafile : 2번 필드가 &quot;CT&quot; 문자와 같으면 1, 2 번 필드 출력awk '$7 &lt; 5 { print $4, $7}' datafile : 7번 필드가 5보다 작다면 4번, 7번 필드 출력awk '$6 &gt; .9 { print $1, $6}' datafile : 6번 필드가 .9 보다 크다면 1번, 6번 출력awk '$8 &gt; 10 &amp;&amp; $8 &lt; 17 ' datafileawk '$2 == &quot;NW&quot; || $1 ~ /south/ { print $1, $2 }' datafile 액션 awk pattern {action} filenames ① expressions② print expression-list③ printf(format, expression-list)④ if (expression) statement⑤ if (expression) statement else statement⑥ while (expression) statement⑦ for (expression; expression; expression) statement⑧ for (variable in array) statement⑨ do statement while (expression)⑩ break⑪ continue⑫ next⑬ exit⑭ exit expression⑮ {statement} 참조 https://ko.wikibooks.org/wiki/예제로_배우는_AWK/명령행_인자_사용하기 http://www.dreamy.pe.kr/zbxe/CodeClip/6332","link":"/linux-awk-9522dd426160/"},{"title":"Hammerspoon 사용해 데스크탑 자동화","text":"HammerspoonHammerspoon 은 macOS의 데스크탑 자동화를 위해 Lua scipt 를 사용하는 엔진이다. Hammerspoon을 다운받아 설치하고 에 있는 Getting Started 를 보고 바로 시작할 수 있다. 설치최신 릴리즈를 Latest Hammerspoon 에서 다운받아 Application 폴더로 옮긴다. 그리고 Hammerspoon을 실행하면 Status bar에 나타난다. [그림. Hammerspoon] 맥 환경설정 / 보안 및 개인정보 에서 손쉬운 사용에 hammerspoon을 추가해 주고 활성화 한다. [그림. 보안 및 개인정보에서 제어 허용] Open configHammerspoon 메뉴에서 Open Config 를 실행하면 시스템의 .lua 확장자를 열 수 있는 텍스트 에디터가 실행된다. 이곳에 Getting Started 의 샘플 스크립을 복사해서 바로 사용해 볼 수 있다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;Y&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x - 10 f.y = f.y - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;K&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.y = f.y - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;U&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x + 10 f.y = f.y - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;H&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x - 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;L&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x + 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;B&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x - 10 f.y = f.y + 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;J&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.y = f.y + 10 win:setFrame(f)end)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;N&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() f.x = f.x + 10 f.y = f.y + 10 win:setFrame(f)end) init.lua 에 스크립을 작성하고 저장한 후에 Hammerspoon 메뉴에서 Reload config를 실행하고 Console… 메뉴로 스크립 활성화를 확인할 수 있다. Window Resizing*Cmd+Opt+Ctrl+F** 키로 윈도우를 고정된 크기로 변경할 수 있게 사용하고 있다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182--[[ Window Resizing--]]-- Full screenhs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = max.w f.h = max.h win:setFrame(f)end)-- 4:3 ratio: XGA, 1280x960, SXGA+, UGA-- Resizing: XGA 1024-768hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F1&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1024 f.h = 768 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1024x768&quot;}):send()end)-- Resize: 1280x960 (1024)hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F2&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1280 f.h = 960 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1280x960&quot;}):send()end)-- Resize: SXGA+ 1400x1050hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F3&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1400 f.h = 1050 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1400x1050&quot;}):send()end)-- Resize: 1920x1080hs.hotkey.bind({&quot;cmd&quot;, &quot;alt&quot;, &quot;ctrl&quot;}, &quot;F4&quot;, function() local win = hs.window.focusedWindow() local f = win:frame() local screen = win:screen() local max = screen:frame() f.x = max.x f.y = max.y f.w = 1920 f.h = 1080 win:setFrame(f) hs.notify.new({title=&quot;Resizing...&quot;, informativeText=&quot;1920x1080&quot;}):send()end) Aerosnaphttps://blog.jverkamp.com/2016/02/08/duplicating-aerosnap-on-osx-with-hammerspoon/","link":"/mac-hammerspoon-fd545099c24f/"},{"title":"[Open API] Alading Bookstore Open API","text":"Aladin Open API키 인증 방식으로 일반 1일 호출 5000회 가능하다. http://blog.aladin.co.kr/openapi/category/29154404?communitytype=MyPaper TTB 가입 방법여기 http://www.aladdin.co.kr/ttb/wjoinus.aspx 에서 TTB 가입한다. 승인 완료되면 TTB Key값이 발급된다. TTB Key값은 http://www.aladin.co.kr/ttb/wblog_manage.aspx 이 페이지에서 조회하실 수 있습니다. 이 키값은 OPENAPI 키값으로 사용됩니다. 상품 API여기 http://blog.aladin.co.kr/openapi/category/29154402?communitytype=MyPaper 설명되어 있다. 제공 리스트 종류 신간 전체 리스트 주목한 만한 신간 리스트 편집자 추천 리스트(카테고리로만 조회 가능 - 국내도서/음반/외서 만 지원) 베스트셀러 북플 베스트셀러(국내도서 만 조회 가능) 요청 URL : http://www.aladin.co.kr/ttb/api/ItemList.aspx 요청 URL샘플 : 1http://www.aladin.co.kr/ttb/api/ItemList.aspx?ttbkey=TTBKey&amp;QueryType=ItemNewAll&amp;MaxResults=10&amp;start=1&amp;SearchTarget=Book&amp;output=xml&amp;Version=20131101 상품 json 형식item array 밑에 결과 데이터가 있다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101{ &quot;version&quot;: &quot;20131101&quot;, &quot;logo&quot;: &quot;http://image.aladin.co.kr/img/header/2011/aladin_logo_new.gif&quot;, &quot;title&quot;: &quot;알라딘 베스트셀러 리스트 - 소설/시/희곡&quot;, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/common/wbest.aspx?BestType=Bestseller&amp;amp;BranchType=1&amp;amp;CID=1&amp;amp;Year=2013&amp;amp;Month=11&amp;amp;Week=1&amp;amp;partner=openAPI&quot;, &quot;pubDate&quot;: &quot;Tue, 05 Nov 2013 07:48:18 GMT&quot;, &quot;totalResults&quot;: 200, &quot;startIndex&quot;: 1, &quot;itemsPerPage&quot;: 10, &quot;query&quot;: &quot;QueryType=BESTSELLER;CategoryId=1;Year=2013;Month=11;Week=1&quot;, &quot;searchCategoryId&quot;: 1, &quot;searchCategoryName&quot;: &quot;소설/시/희곡&quot;, &quot;item&quot;: [ { &quot;title&quot;: &quot;제3인류 1&quot;, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/wproduct.aspx?ISBN=8932916373&amp;amp;partner=openAPI&quot;, &quot;author&quot;: &quot;베르나르 베르베르 지음, 이세욱 옮김&quot;, &quot;pubDate&quot;: &quot;2013-10-21&quot;, &quot;description&quot;: &quot;베르나르 베르베르 특유의 상상력으로 축조한 장대한 스케일의 과학 소설. 남극. 저명한 고생물학자 샤를 웰즈의 탐사대가 17미터에 달하는 거인의 유골들을 발굴한다. 그러나 인류사를 다시 쓰게 만들 이 중대한 발견은 발굴 현장의 사고와 함께 곧바로 파묻히고 마는데…&quot;, &quot;isbn&quot;: &quot;8932916373&quot;, &quot;isbn13&quot;: &quot;9788932916378&quot;, &quot;itemId&quot;: 32136853, &quot;priceSales&quot;: 12420, &quot;priceStandard&quot;: 13800, &quot;mallType&quot;: &quot;BOOK&quot;, &quot;stockStatus&quot;: &quot;&quot;, &quot;mileage&quot;: 1250, &quot;cover&quot;: &quot;http://image.aladin.co.kr/product/3213/68/coversum/8932916373_2.jpg&quot;, &quot;publisher&quot;: &quot;열린책들&quot;, &quot;salesPoint&quot;: 72420, &quot;fixedPrice&quot;: true, &quot;customerReviewRank&quot;: 9, &quot;bestRank&quot;: 1, &quot;subInfo&quot;: { &quot;ebookList&quot;: [ { &quot;itemId&quot;: 32241318, &quot;isbn&quot;: &quot;E893291637&quot;, &quot;priceSales&quot;: 8100, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/wproduct.aspx?ISBN=E893291637&amp;amp;partner=openAPI&quot; } ], &quot;usedList&quot;: { &quot;aladinUsed&quot;: { &quot;itemCount&quot;: 0, &quot;minPrice&quot;: 0, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/UsedShop/wuseditemall.aspx?ISBN=8932916373&amp;amp;TabType=2&amp;amp;partner=openAPI&quot; }, &quot;userUsed&quot;: { &quot;itemCount&quot;: 9, &quot;minPrice&quot;: 8900, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/UsedShop/wuseditemall.aspx?ISBN=8932916373&amp;amp;TabType=1&amp;amp;partner=openAPI&quot; } } } }, { &quot;title&quot;: &quot;제3인류 2&quot;, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/wproduct.aspx?ISBN=8932916381&amp;amp;partner=openAPI&quot;, &quot;author&quot;: &quot;베르나르 베르베르 지음, 이세욱 옮김&quot;, &quot;pubDate&quot;: &quot;2013-10-21&quot;, &quot;description&quot;: &quot;베르나르 베르베르 특유의 상상력으로 축조한 장대한 스케일의 과학 소설. 남극. 저명한 고생물학자 샤를 웰즈의 탐사대가 17미터에 달하는 거인의 유골들을 발굴한다. 그러나 인류사를 다시 쓰게 만들 이 중대한 발견은 발굴 현장의 사고와 함께 곧바로 파묻히고 마는데…&quot;, &quot;isbn&quot;: &quot;8932916381&quot;, &quot;isbn13&quot;: &quot;9788932916385&quot;, &quot;itemId&quot;: 32136901, &quot;priceSales&quot;: 12420, &quot;priceStandard&quot;: 13800, &quot;mallType&quot;: &quot;BOOK&quot;, &quot;stockStatus&quot;: &quot;&quot;, &quot;mileage&quot;: 1250, &quot;cover&quot;: &quot;http://image.aladin.co.kr/product/3213/69/coversum/8932916381_2.jpg&quot;, &quot;publisher&quot;: &quot;열린책들&quot;, &quot;salesPoint&quot;: 50880, &quot;fixedPrice&quot;: true, &quot;customerReviewRank&quot;: 10, &quot;bestRank&quot;: 2, &quot;subInfo&quot;: { &quot;ebookList&quot;: [ { &quot;itemId&quot;: 32241317, &quot;isbn&quot;: &quot;E893291638&quot;, &quot;priceSales&quot;: 8100, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/wproduct.aspx?ISBN=E893291638&amp;amp;partner=openAPI&quot; } ], &quot;usedList&quot;: { &quot;aladinUsed&quot;: { &quot;itemCount&quot;: 0, &quot;minPrice&quot;: 0, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/UsedShop/wuseditemall.aspx?ISBN=8932916381&amp;amp;TabType=2&amp;amp;partner=openAPI&quot; }, &quot;userUsed&quot;: { &quot;itemCount&quot;: 3, &quot;minPrice&quot;: 10500, &quot;link&quot;: &quot;http://www.aladin.co.kr/shop/UsedShop/wuseditemall.aspx?ISBN=8932916381&amp;amp;TabType=1&amp;amp;partner=openAPI&quot; } } } } ]}","link":"/openapi-aladin-books-416cbdcc5f2d/"},{"title":"NodeJS &#x2F; Process management","text":"nodejs app을 단일 node 명령으로 실행후 백그라운드 혹은 시스템 데몬으로 다룰 수 있도록 해주는 프로세스 관리 유틸리티를 알아보자: nodemon pm2 forever 1. nodemon1nodemon ./server.js localhost 8080 express appnodemon으로 express 의 기본 템플릿을 시작시 bin/www 를 실행애 주어야 한다. app.js 만 실행시 www 에 명시한 포트가 인식 안된다. 1$ nodemon bin/www 혹은 PORT 변수를 입력하고 실행한다. 1$ PORT=3000 DB_USERNAME='mongo' DB_PASSWORD='' DB_SERVER='localhost' DATABASE='student' nodemon server.js 2. pm2 설치pm2는 nodejs app을 실행하고 관리할 수 있는 전문적인 도구이다.node.js 앱을 시스템 서비스로 등록하기 위해서 pm2 를 설치한다. 1npm i -g pm2 예를 들어 express 앱이 있으면 다음 같이 pm2로 시작한다. 12cd www-apppm2 start -n &quot;www-app&quot; bin/www pm2 log formatpm2 이전 버전은 시작시 timestamp를 로그에 저장하고 싶으면 시작시 --log-date-format 옵션을 이용 1pm2 start app.js --log-date-format 'DD-MM HH:mm:ss.SSS' 시작 설정 파일에 log_date_format 옵션을 줄 수 있다. 1&quot;log_date_format&quot; : &quot;DD-MM HH:mm:ss.SSS&quot;, pm2 2.x 이후 부터는 log 의 형식을 --format 옵션을 지정할 수 있다. 1pm2 logs --format pm2 startupstartup 시 pm2 start 로 생성되는 .pm2 디렉토리의 pid 와 app.js 파일을 실행해 준다. pm2 startup systemd 로 스타트를 하면 2개의 프로세스가 만들어 진다. 방법은,,, 먼저 앱을 시작해 둔다. 1pm2 start -n &quot;www-app&quot; bin/www dump를 생성한다. pm2로 현재 실행중인 프로세스 정보를 save로 덤프하게 저장한다. systemd 서비스 스크립을 작성하는데 유용하다. 1pm2 save pm2 startup 명령 pm2 startup 명령은 pm2로 실행중인 프로세스를 systemd 서비스 유니트 파일로 제어 할 수 있다. 명령을 실행하면 sudo 명령으로 실행할 수 있는 스크립을 출력해 준다. 123$ pm2 startup systemd...sudo env PATH=$PATH:/home/foo/.nvm/versions/node/v8.8.1/bin /home/foo/.nvm/versions/node/v8.8.1/lib/node_modules/pm2/bin/pm2 startup systemd -u foo --hp /home/foo 이 스크립을 실행해 주면 pm2-foo.service 서비스 유니 파일이 생성된다. 12Target path/etc/systemd/system/pm2-foo.service 이 서비스 파일을 활성화하고 시작해준다. 1systemctl enable pm2-foo 이제 시스템을 재시작해도 pm2 로 실행중인 프로세스는 자동으로 시작된다. 3. foreverhttps://github.com/foreverjs/forever 백그라운드 로그 출력nodejs app을 백그라운드로 실행하기 위해서 로그 정보를 생성할 수 있다. The forever process will continue to run outputting log messages to the console. 1forever -o out.log -e err.log my-script.js Daemon으로 실행하기forever 프로세스는 대상 프로세스를 백그라운드로 실행할 수 있는 데몬으로 동작이 가능하다. 이것은 nohup 같은 시스템 도구 없이도 가능다. 데몬 실행을 위해 -o -l, &amp; -e 를 사용하도록 권장한다. 12$ forever start -l forever.log -o out.log -e err.log my-daemon.js forever stop my-daemon.js 그리고 -m 옵션으로 재시작 횟수를 지정할 수 있다. here are several examples designed to test the fault tolerance of forever. Here’s a simple usage example: 1$ forever -m 5 examples/error-on-timer.js 설정파일 지원forever에 스크립트 경로와 함께 JSON 설정 파일을 전달해 스크립트의 구성요소를 제공할 수 있다. 예를 들어 아래 같은 앱 디렉토리에 developement.json 설정 파일이 있다고 하자, 1234.├── forever│ └── development.json└── index.js developement.json 설정 파일은 아래 같은 내용으로 구성할 수 있다: 123456789// forever/development.json{ // Comments are supported &quot;uid&quot;: &quot;app&quot;, &quot;append&quot;: true, &quot;watch&quot;: true, &quot;script&quot;: &quot;index.js&quot;, &quot;sourceDir&quot;: &quot;/home/myuser/app&quot;}","link":"/nodejs-processmanaging-90d48834639e/"},{"title":"NodeJS - mongoose middleware","text":"Middleware이 글은 mongoose middleware를 한글로 요약 정리한 것이다. 실제 본문을 요약하여 번역해 정리했으므로 이해가 안되는 부분은 위 링크의 내용을 참조하기 바란다. mongoose middlewarepre, post hook 이라고 불리는 mongoose middleware는 비동기 함수의 실행중 제어권을 다룰 수 있다. 미들웨어는 스키마 수순에서 사용고 plugins 를 작성하는데 유용하다. Mongoose 4.x 은 4종류의 미들웨어를 지원한다: document middleware model middleware aggregate middleware query middleware Document middleware는 아래 도큐멘트 함수를 지원한다. 도큐멘트 미들웨어에서 this 는 도큐멘트를 가르킨다. init validate save remove Query middleware 는 아래 모델과 쿼리 함수를 지원한다. 쿼리 미들웨어 함수에서 this 는 쿼리를 가르킨다. count find findOne findOneAndRemove findOneAndUpdate update Aggregate middleware 는 MyModel.aggregate() 를 위한것이다. Aggregate middleware는 aggregate 객체에서 exec() 를 호출할 때 실행된다.. 여기서 this 는 aggregation object를 가르킨다. aggregate Model middleware 는 아래 모델 함수에 대해 지원한다. 여기서 this는 모델을 가르킨다. insertMany Note: There is no query hook for remove(), only for documents. If you set a ‘remove’ hook, it will be fired when you call myDoc.remove(), not when you call MyModel.remove(). Note: The create() function fires save() hooks. 모든 미들웨어 형식은 pre와 post 훅(hook)을 지원한다. ### Pre middleware Serial과 parallel 이라는 두가지 pre 훅이 있다. #### Serial Serial middleware는 각 미들웨어가 next()를 호출하면 하나 다음 다른 하나를 실행한다. 12345var schema = new Schema(..);schema.pre('save', function(next) { // do stuff next();}); 그렇지만 next() 함수가 미들웨어의 다음 코드 실행을 멈추지 않기 때문에 return 패턴을 사용해서 코드 진행을 멈추면 된다. 123456789var schema = new Schema(..);schema.pre('save', function(next) { if (foo()) { console.log('calling next!'); // `return next();` will make sure the rest of this function doesn't run return next(); } console.log('after next');}); #### Parallel Parallel middleware는 제어를 더욱 정밀하게 할 수 있다. 아래는 Pre 훅에 true 인자를 전달해 parallel 미들웨어를 사용하게 하고, 이것은 save 인 경우 각 미들웨어에서 done 호출 전까지 실행하지 않는다는 의미이다. 12345678var schema = new Schema(..);// `true`: parallel middleware.schema.pre('save', true, function(next, done) { // calling next kicks off the next middleware in parallel next(); setTimeout(done, 100);}); #### Use Cases 미들웨어는 원자화 모델과 비동기 코드의 중첩을 회피하는데 유용한다. 아래 같은 사례: 복합 유효성 확인 의존하는 문서 삭제 (사용자에 관련한 모든 문서를 삭제) asynchronous defaults asynchronous tasks that a certain action triggers triggering custom events notifications #### 에러 처리 미들웨어에서 Error 형식 매개변수로 next(), done() 을 호출할 때 에러로 처리가 가로채지면 콜백 함수에 에러가 전달된다. 아래 같이 에러 발생시 new Error()를 생성해야 다음 next() 가 호출되지 않는다. 123456789schema.pre(&quot;save&quot;, function (next) { var err = new Error(&quot;something went wrong&quot;); next(err);});// later...myDoc.save(function (err) { console.log(err.message); // something went wrong}); ### Post middleware post middleware 는 pre middle 웨어가 완료되어 훅 메서드가 처리된 뒤에 실행된다. post 는 제어를 직접 하지 못한다. 예를 들어 next(), done() callback이 전달되면 post 훅은 이들 메서드를 이벤트 리스너에 등록하는 방법이다. 123456789101112schema.post(&quot;init&quot;, function (doc) { console.log(&quot;%s has been initialized from the db&quot;, doc._id);});schema.post(&quot;validate&quot;, function (doc) { console.log(&quot;%s has been validated (but not saved yet)&quot;, doc._id);});schema.post(&quot;save&quot;, function (doc) { console.log(&quot;%s has been saved&quot;, doc._id);});schema.post(&quot;remove&quot;, function (doc) { console.log(&quot;%s has been removed&quot;, doc._id);}); #### Asynchronous Post Hooks post가 선언된 순서에 따라 post hook이 비동기 적으로 실행되는데, callback function에 두 개의 인자를 전달하면 mongoose는 두번째를 next() 로 가정하고 순서에 따라 next를 트리거 호출한다. 1234567891011121314// Takes 2 parameters: this is an asynchronous post hookschema.post(&quot;save&quot;, function (doc, next) { setTimeout(function () { console.log(&quot;post1&quot;); // Kick off the second post hook next(); }, 10);});// Will not execute until the first middleware calls `next()`schema.post(&quot;save&quot;, function (doc, next) { console.log(&quot;post2&quot;); next();}); #### Save/Validate Hooks The save() 함수는 validate() hook을 유발하는데 이것은 pre('save') hook이 호출되면서 pre('validate') 와 post('validate') hook이 호출된다는 것이다. 123456789101112schema.pre(&quot;validate&quot;, function () { console.log(&quot;this gets printed first&quot;);});schema.post(&quot;validate&quot;, function () { console.log(&quot;this gets printed second&quot;);});schema.pre(&quot;save&quot;, function () { console.log(&quot;this gets printed third&quot;);});schema.post(&quot;save&quot;, function () { console.log(&quot;this gets printed fourth&quot;);}); #### Notes on findAndUpdate() and Query Middleware Pre 와 post save() hook은 update(), findOneAndUpdate() 등에서 호출되지 않는다. Mongoose 4.0 은 이들 함수에 다른 훅을 가지고 있다. 123456789101112schema.pre(&quot;find&quot;, function () { console.log(this instanceof mongoose.Query); // true this.start = Date.now();});schema.post(&quot;find&quot;, function (result) { console.log(this instanceof mongoose.Query); // true // prints returned documents console.log(&quot;find() returned &quot; + JSON.stringify(result)); // prints number of milliseconds the query took console.log(&quot;find() took &quot; + (Date.now() - this.start) + &quot; millis&quot;);}); document middleware에서 this 는 갱신하는 도큐멘트를 가르킨다. 그래서 update() 에 타임스탬프를 추가하고자 하면 아래 pre hook을 사용한다. 123schema.pre(&quot;update&quot;, function () { this.update({}, { $set: { updatedAt: new Date() } });}); Error Handling Middleware New in 4.5.0 일반적으로 next() 호출시 첫번째 error에서 멈추는데 특별한 post middleware로 “error handling middleware” 가 있다.Error handling middleware는 부가적으로 콜백 함수의 매개변수에 error가 전달되는데, 첫번째 인자로 error 를 전달한다. 123456789101112131415161718192021var schema = new Schema({ name: { type: String, // Will trigger a MongoError with code 11000 when // you save a duplicate unique: true, },});// Handler **must** take 3 parameters: the error that occurred, the document// in question, and the `next()` functionschema.post(&quot;save&quot;, function (error, doc, next) { if (error.name === &quot;MongoError&quot; &amp;&amp; error.code === 11000) { next(new Error(&quot;There was a duplicate key error&quot;)); } else { next(error); }});// Will trigger the `post('save')` error handlerPerson.create([{ name: &quot;Axl Rose&quot; }, { name: &quot;Axl Rose&quot; }]); Error handling middleware는 query middleware와도 동작한다. 예를 들어 update() 호출시 키 중철 에러를 처리하는 훅를 고려하면: 12345678910111213141516171819202122// The same E11000 error can occur when you call `update()`// This function **must** take 3 parameters. If you use the// `passRawResult` function, this function **must** take 4// parametersschema.post(&quot;update&quot;, function (error, res, next) { if (error.name === &quot;MongoError&quot; &amp;&amp; error.code === 11000) { next(new Error(&quot;There was a duplicate key error&quot;)); } else { next(error); }});var people = [{ name: &quot;Axl Rose&quot; }, { name: &quot;Slash&quot; }];Person.create(people, function (error) { Person.update( { name: &quot;Slash&quot; }, { $set: { name: &quot;Axl Rose&quot; } }, function (error) { // `error.message` will be &quot;There was a duplicate key error&quot; } );}); ## 참조 mongoose middleware plugins","link":"/2017-12-20-mongodb-mongoose-middleware-871f925b40c0/"},{"title":"openSUSE: Network 관리","text":"Networkyast 명령으로 네트워크 구성을 수정할 수 있다. 실제 네트워크 관련 프레임워크는 wicked 를 사용한다. https://www.suse.com/documentation/sles11/book_sle_admin/data/sec_yast_ncurses_commands.html net-tools기존 ifconfig 가 deprecate 되서 ip 명령을 사용한다. [^2] ip command를 참고한다. 그리고 ip 명령 예제를 참고해 123ip aip addressip link IPGUI에서 YaSt 도구를 사용하면 쉽게 설정할 수 있다. 터미널에서는 wicked 시스템에 따라서 네트워크를 구성한다. https://doc.opensuse.org/documentation/leap/reference/html/book.opensuse.reference/cha.basicnet.html#sec.basicnet.manconf 타 리눅스 배포본에서 사용하는 방법의 구성 설정 파일은 /etc/sysconfig/network/ifcfg-[DEVICE] 이다. *[DEVICE]*는 사용할 인터페이스 이름이다. 1234BOOTPROTO=staticONBOOT=yesIPADDR=192.168.1.10LABEL=&quot;System eth0&quot; Gateway는 /etc/sysconfig/network/routes 파일에 다음 같이 구성해 준다.[^4] 1default gatewayaddr 192.168.1.1 DNS는 /etc/resolv.conf 를 참조하는데 yast 로 변경할 수 있다. 1yast dns edit nameserver1=192.168.1.1 https://doc.opensuse.org Link1sudo ip link set eth0 up","link":"/opensuse-network-8b56243bb38e/"},{"title":"iptables Firewall on Ubuntu&#x2F;Debian","text":"일반적인 리눅스 배포본의 기본 방화벽인 iptables를 쉽게 사용할 수 있는 ufw 를 사용해서 리눅스에 방화벽을 구축하는 방법을 기술하고 있다. iptablesiptables로 당연히 방화벽을 관리할 수 있다. iptables -L 플래그방화벽 룰, 액션에 대해 INPUT, OUTPUT, FORWARD 정보를 볼 수 있다. 1$ sudo iptables -L -S 플래그우리 대신 사용 하 여 각 규칙 및 정책을 사용 하는 데 필요한 명령을 반영 하는 형식으로 출력을 볼 수 있는 1$ sudo iptables -S 규칙을 모두 리플레시 할 수 있다 1sudo iptables -F 방화벽모든 규칙은 DENY -&gt; 일부 허용 순서로 한다. 그래서 TCP 로 1번부터 65526번 포트까지 다 막는 방법이다. 만약 UDP도 막고싶다면, 1sudo iptables -A INPUT -p tcp --dport 1:65526 -j DROP ssh 22 자리는 포트12sudo iptables -I INPUT -p tcp --dport 22 -j ACCEPTsudo iptables -I OUTPUT -p tcp --sport 22 -j ACCEPT 혹은 ip address 를 기반으로 설정할 수 있다. 12iptables -I INPUT -p tcp --dport 22 -s 222.222.222.222 -j ACCEPTiptables -I OUTUT -p tcp --dport 22 -d 222.222.222.222 -j ACCEPT 8080번으로 들어오는 포트를 80 번으로 바꾸기 123sudo iptables -A INPUT -i eth0 -p tcp --dport 80 -j ACCEPTsudo iptables -A INPUT -i eth0 -p tcp --dport 8080 -j ACCEPTsudo iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8080 iptables정보를 저장하고 재부팅 이후에도 동작하도록 설정함. &lt;= vi 로 열어서 맨 마지막에 추가함. 123sudo sh -c &quot;iptables-save &gt; /backup/iptables.rules&quot;sudo vi /etc/network/interfacespre-up iptables-restore &lt; /etc/iptables.rules Web기본 httpd 사용을 위한 80번 포트 개방과, node.js, python 등 실습을 위한 8080번 포트를 열어 주기 위해서 /etc/sysconfig/iptables 에 아래와 같이 입력한다. 12345-A INPUT -p tcp -m tcp --dport 80 -j ACCEPT-A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT-A INPUT -p tcp -m tcp --dport 8080 -j ACCEPT-A OUTPUT -p tcp -m tcp --dport 8080 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited iptables 규칙을 만들 때는 순서가 매우 중요하다.이 때 주의해야 할 것은 위의 4개 코드가 빨간 색의 코드보다 반드시 위에 적혀 있어야 한다. 예를 들어 만일 chain에서 로컬 192.168.100.0/24 서브넷에서 들어오는 모든 패킷을 drop하도록 지정한 후 (drop 하도록 지정된 서브넷에 포함되는) 192.168.100.13에서 들어오는 패킷을 모드 허용하는 chain (-A)을 그 후에 추가하면 뒤에 추가된 추가 규칙이 무시된다.먼저 192.168.100.13를 허용하는 규칙을 설정한 후 서브넷을 drop하는 규칙을 설정해야한다. 이후에 service iptables restart 명령어를 실행해주면 2개의 포트가 열러서 정상적으로 외부접속이 가능해지는 것을 확인할 수 있다. 로그에 있는 IP 목록을 출력 1egrep -o '[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+' | sort -u Check blocked ip addressesiptables 명령으로 막혀있는 ip address를 출력해 보자. [^3] 1$ sudo iptables -L -n --line 12$ sudo iptables -L INPUT -v -n08:43:89:08:00:45:00:00:3c:97:2b:40:00:34:06:4d:8b SRC=90.202.157.25 DST=220.121.141.168 LEN=60 TOS=0x│Chain INPUT (policy DROP 48 packets, 2312 bytes 참조[^3]: Check blocked IP in iptables","link":"/ubuntu-iptables-22b9c2c518b4/"},{"title":"Monitoring fail2ban","text":"Monitoring fail2banInstall로그를 검사해 의심스런 IP 를 찾아 Firewall rule을 관리하기 어렵다 Fail2ban은 정규표현식을 사용해서 로그에서 의심스런 IP를 찾아 Firewall 등록할 수 있도록 해준다. Fail2ban로그를 검사해 의심스런 IP 를 찾아 Firewall rule에 등록해 관리하는 것은 어려운 과정이다. Fail2ban은 정규표현식을 사용해서 로그에서 의심스런 IP를 찾아 Firewall 등록 할 수 있도록 해준다. 설치fail2ban 은 iptables 패키지와 함께 설치한다. 1$ sudo apt install iptables fail2ban 그리고 systemctl 로 재대로 서비스가 시작되는지 확인해 본다. 12$ sudo systemctl restart fail2ban.service # 재시작$ sudo systemctl status fail2ban.service # running 상태 확인 설정을 위해서 fail2ban 설정 파일인 fail2ban.conf, 그리고 jail 파일 jail.conf 파일을 .local 파일로 복사한 사용자 정의 파일에서 사용한다. 123$ cd /etc/fail2ban$ sudo cp fail2ban.conf fail2ban.local # 설정파일$ sudo cp jail.conf jail.local # jail 설정 /etc/fail2ban 디렉토리설치된 후 관련된 설정 파일은 /etc/fail2ban 디렉토리에 저장됩니다. 관련한 로그 기록은 /etc/logratate.d/fail2ban에 정의되어 /var/log/fail2ban.log 로 저장됩니다. 다음은 설정 디렉토리 구조 12345678910111213141516171819$ tree -L 2 fail2ban/fail2ban/├── action.d│ ├── ...│ ├── ufw.conf│ └── xarf-login-attack.conf├── fail2ban.conf├── fail2ban.local├── fail2ban.d├── filter.d│ ├── ...│ ├── sshd.conf│ └── xinetd-fail.conf├── jail.conf├── jail.d│ └── defaults-debian.conf├── jail.local├── paths-common.conf└── paths-debian.conf jail.conf: jail 이라 불리는 모니터링할 대상에 대한 기본 옵션과 행위를 선언한다. action.d/iptables-multiport.conf: fila2ban 이 jail에 맞게 거부(Ban)한 IP를 다루는 기본 액션이다. fail2ban.local : fail2ban 주요 설정 파일 jail.local: jail 설정 파일 jaild.d/defaults-debian.conf: jail enable/disable paths-common.conf: 로그 파일 경로 paths-debian.conf: 로그 파일 경로 설정fail2ban은 jail 을 구성하고 jail의 filter 그리고 action으로 나뉘어 있다. fail2ban.conf 구성fail2ban.conf는 기본 구성 변수로 loggin, socket 그리고 PID 파일 등등이 설정된다. 별도의 파일로 Jail을 구성할 때 fail2ban.local 같은 이름을 사용하고 새로 설정되는 값은 기본 설정 값을 재정의 하게 된다. 단 같은 [default] 섹션이 존재하면 구성된 내용 적용이 잘 안된다. 다음 스크립을 사용하면 모둔 변수를 주석 처리하고 수정할 옵션만 복사해 준다. 1sed 's/\\(^[[:alpha:]]\\)/# \\1/' fail2ban.conf | sudo tee fail2ban.local 1&amp;&gt; /dev/null fail2ban.local 파일은 다음과 같은 내용을 담을 것이다. loglevel: The level of detail that Fail2ban’s logs provide can be set to 1 (error), 2 (warn), 3 (info), or 4 (debug). logtarget: Logs actions into a specific file. The default value of /var/log/fail2ban.log puts all logging into the defined file. Alternately, you can change the value to STDOUT, which will output any data; STDERR, which will output any errors; SYSLOG, which is message-based logging; and FILE, which outputs to a file. socket: The location of the socket file. pidfile: The location of the PID file. jail.conf/etc/fail2ban/jail.conf 는 데몬, 서비스에 대한 jail을 구성한다. jail은 log를 읽어 불필요한 것을 찾아 낸다.다음은 jail.conf에서 주석이 달린 jail.local을 생성해 준다. 1sed 's/\\(^[[:alpha:]]\\)/# \\1/' jail.conf | sudo tee jail.local 1&amp;&gt; /dev/null If using CentOS or Fedora open jail.local and set the backend to systemd. This is not necessary on Debian 8, even though it is a SystemD system. /etc/fail2ban/jail.local 1backend = systemd 화이트리스트 IP먼저 검출된 IP 중에 무시할 영역, 화이트리스트를 선언해 줍니다. 리스트는 ‘,’로 구분하고 서브넷 혹은 IP주소를 입력한다. 12[DEFAULT]ignoreip = 127.0.0.1/8 192.168.0.1/24 차단 시간과 재시도 횟수bantime, findtime, maxretry 은 차단 시간에 대한 구성이다. 123bantime = 2592000findtime = 600maxretry = 3 bantime: 검출된 IP가 접속 차단 시간을 초단위로 선언해 준다. -1 이면 영속적으로 밴 된다. findtime: ban이 설정 전에 로그인 간격 시간 maxretry: 최대 횟수 https://arno0x0x.wordpress.com/2015/12/30/fail2ban-permanent-persistent-bans/ 로컬 시스템의 이메일 주소를 sendmail -t user@email.com, replacing user@email.com with your email address. 이메일fail2ban에 검출되는 jail이 있으면 이메일 설정에 따라 메일로 경고를 받을 수 있다. destemail: The email address where you would like to receive the emails. sendername: The name under which the email shows up. sender: The email address from which Fail2ban will send emails. 그리고 action 설정을 조절할 필요가 있다, 이것은 ban 상황이 기준점에 닿으면 발생한다. 기본 액션 %(action_)s은 사용자만 ban 한다. action_mw 액션은 ban을 실행하고 WhoIS 리포트로 메일을 보내준다. action_mwl은 모든 로그까지 함께 보내준다. You will also need to adjudst the action setting, which defines what actions occur when the threshold for ban is met. The default, %(action_)s, only bans the user. action_mw will ban and send an email with a WhoIs report; while action_mwl will ban and send an email with the WhoIs report and all relevant lines in the log file. This can also be changed on a jail-specific basis. 1action = %(action_)s 1$ sudo service fail2ban restart 각 서버스에 대한 Jail 설정필터를 이용해 Jail을 만들어 의심스런 접근을 막아 보자. 앞서 복사한 jail.local 파일에는 주요 서비스가 모두 선언되어 있고 sshd 만 활성화 되어 있다. Jail은 다음 같이 구성된다. 12345678[ssh]enabled = trueport = sshfilter = sshdlogpath = /var/log/auth.logmaxretry = 6 enabled: Determines whether or not the filter is turned on. port: The port Fail2ban should be referencing in regards to the service. If using the default port, then the service name can be placed here. If using a non-traditional port, this should be the port number. For example, if you moved your SSH port to 3456, you would replace ssh with 3456. filter: The name of the file located in /etc/fail2ban/filter.d that contains the failregex information used to parse log files appropriately. The .conf suffix need not be included. logpath: Gives the location of the service’s logs. maxretry: Will override the global maxretry for the defined service. findtime and bantime can also be added.action: This can be added as an additional setting, if the default action is not suitable for the jail. Additional actions can be found in the action.d folder. 각 서비스에 대한 jail은 jail.d에 설정 파일을 구성해도 된다. (1) sshd Brute-force Attack과 같은 접근을 차단하는 필터로 로그에 아래와 유사한 패턴이 나오면 IP를 검출한다. Jul 22 06:56:50 foo sshd[14984]: Failed password for invalid user a from xxx.xxx.xxx.xxx port 55452 ssh2 jail.config 혹은 jail.local 에서 기본으로 활성화 되어 있다. (2) ssh-ddos sshd-ddos Filter를 사용해 SSH Service를 Scanning하거나 telnet으로 접속할 떄 발생하는 Message를 검사하여 해당 IP의 접근을 차단할 수 있습니다. 이 Filter로 검출되는 /var/log/auth.log의 Message는 다음과 같습니다. Jul 23 13:16:25 foo sshd[21989]: Did not receive identification string from xxx.xxx.xxx.xxx Jail 설정을 위해서 다음과 같이 입력합니다. 12[sshd-ddos]enabled = true 혹은 $ sudo vi /etc/fail2ban/jail.d/sshd-ddos.conf 1$ sudo service fail2ban restart Failregrexs다양한 필터를 사용할 수있다. 의심스런 동작을 Filter로 선언해서 사용하는데 해당 필터를 점검해야할 필요가 있다. 다음 1$ sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf 이 필터를 사용자가 작성할 수 있는데 파이썬의 정규식을 사용해서 사용자 지정 필터를 작성한다. access.log 필터 작성해 보기nginx 로그를 대상으로 200 에러를 검출해 보자 191.134.232.57 - - [28/Nov/2016:07:30:23 +0900] &quot;GET / HTTP/1.1&quot; 200 1125 &quot;http://hundej 123.143.201.75 - - [28/Nov/2016:17:29:18 +0900] “HEAD / HTTP/1.1” 200 0 “-“ “python-requests/2.10.0” fail2ban-regex /var/log/nginx/access.log /etc/fail2ban/filter.d/nginx-test.conf Ban 관리 fail2ban-client set YOURJAILNAMEHERE unbanip IPADDRESSHERE Use iptables -L -n to find the rule name……then use fail2ban-client status to get the actual jail names. 룰 이름이 표시된다 f2b- 으로 시작하는 룰을 찾는다 그리고 fail2ban-status 는 fail2ban-client set YOURJAILNAMEHERE unbanip IPADDRESSHERE HOW to fail2ban http://www.fail2ban.org/wiki/index.php/HOWTOs basic usages12sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf 1sudo iptables -L --line-numbers Nginx기본으로 /etc/fail2ban/jail.conf 에 [nginx-http-auth] jail이 하나 선언되어 있다. [nginx-http-auth] enabled = truefilter = nginx-http-authport = http,httpslogpath = /var/log/nginx/error.log nginx jailnginx-noscript웹 사이트에서 실행되고 침투할 수 있는 코드를 찾아 준다. php 등이 웹 사이트와 연동되지 않았다면 아래 제일을 추가해서 이런 임의의 실행코드 형식 실행을 방지할 수 있다 12345678[nginx-noscript]enabled = trueport = http,httpsfilter = nginx-noscriptlogpath = /var/log/nginx/access.logmaxretry = 6 nginx-badbots웹 요청에 악의적인 봇을 호출하는 것을 방지한다. 1234567[nginx-badbots]enabled = trueport = http,httpsfilter = nginx-badbotslogpath = /var/log/nginx/access.logmaxretry = 2 filter추가한 jail 이 동작할 필터를 작업해 주어야 한다. 필터는 /etc/fail2ban/filter.d 디렉토리에 있다. nginx-http-auth.conf기본으로 제공하는 nginx-http-auth.conf 필터에 하나를 더 추가해 준다. 아래는 사용자가 아이디와 비밀번호를 입력하지 않는 경우에 대해 필터한다. 아래의 no user/password 패턴을 추가한다. 1234567[Definition]failregex = ^ \\[error\\] \\d+#\\d+: \\*\\d+ user &quot;\\S+&quot;:? (password mismatch|was not found in &quot;.*&quot;), client: &lt;HOST&gt;, server: \\S+, request: &quot;\\S+ \\S+ HTTP/\\d+\\.\\d+&quot;, host: &quot;\\S+&quot;\\s*$ ^ \\[error\\] \\d+#\\d+: \\*\\d+ no user/password was provided for basic authentication, client: &lt;HOST&gt;, server: \\S+, request: &quot;\\S+ \\S+ HTTP/\\d+\\.\\d+&quot;, host: &quot;\\S+&quot;\\s*$ignoreregex = nginx-badbots.conf1sudo cp apache-badbots.conf nginx-badbots.conf nginx-noscript[nginx-noscript] jail 은 다음 내용을 입력한다: 12345[Definition]failregex = ^&lt;HOST&gt; -.*GET.*(\\.php|\\.asp|\\.exe|\\.pl|\\.cgi|\\.scgi)ignoreregex = nginx-nohome12345[Definition]failregex = ^&lt;HOST&gt; -.*GET .*/~.*ignoreregex = nginx-noproxy12345[Definition]failregex = ^&lt;HOST&gt; -.*GET http.*ignoreregex = Jail 실행 확인1234$ sudo fail2ban-client statusStatus|- Number of jail: 6`- Jail list: nginx-noproxy, nginx-noscript, nginx-nohome, nginx-badbots, ssh-ddos, ssh 그리고 iptable의 서비스로 방화벽 규칙에 fail2ban 규칙이 동작중인지 확인한다. 123456789101112 $ sudo iptables -S...-A fail2ban-nginx-badbots -j RETURN-A fail2ban-nginx-nohome -j RETURN-A fail2ban-nginx-noproxy -j RETURN-A fail2ban-nginx-noscript -j RETURN-A fail2ban-ssh -j RETURN-A fail2ban-ssh-ddos -j RETURN... 그리고 fail2ban 의 jail 실행 상태를 자세히 보고 싶므면 status 뒤에 jail 이름을 주면 된다. 12345678910$ sudo fail2ban-client status nginx-badbotsStatus for the jail: nginx-badbots|- filter| |- File list: /var/log/nginx/access.log| |- Currently failed: 0| `- Total failed: 0`- action |- Currently banned: 0 | `- IP list: `- Total banned: 0 Testing의심스런 동작을 Filter로 선언해서 사용하는데 해당 필터를 점검해야할 필요가 있다. 다음 1$ sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf Ban 관리nginx 인증 요구시 잘못된 인증을 시도하면 fail2ban 규칙에 따라 접근이 금지당한다. 그리고 jail 규칙이 잘 적용 됐는지 결과를 다음 같이 확인할 수 있다: 1234567891011$ sudo fail2ban-client status nginx-http-authOutputStatus for the jail: nginx-http-auth|- filter| |- File list: /var/log/nginx/error.log| |- Currently failed: 0| \\- Total failed: 12\\- action |- Currently banned: 1 | \\- IP list: 111.111.111.111 \\- Total banned: 1 인증 규칙에 어긋나는 접근을 시도한 IP인 111.111.111.111을 확인 할 수 잇다.금지된 IP는 해당 jail을 이용해 다음 같이 해제할 수 있다. 1$ sudo fail2ban-client set nginx-http-auth unbanip 111.111.111.111 nginx-req-limit http://blog.ricardomacas.com/index.php?controller=post&amp;action=view&amp;id_post=3 fail2squaredhttps://supine.com/posts/2012/08/fail2ban-monitoring-itself-recursively/ TO COMPLETELY FLUSH THE FAIL2BAN LOG FILE AND CLEAR OUR BLACKLIST FILEsudo service fail2ban stopsudo truncate -s 0 /var/log/fail2ban.logsudo truncate -s 0 /etc/fail2ban/ip.blacklistsudo rm /var/lib/fail2ban/fail2ban.sqlite3sudo service fail2ban restart https://ubuntu101.co.za/security/fail2ban/fail2ban-persistent-bans-ubuntu/ sqlite3fail2ban.conf file, I found the following: 1dbfile = /var/lib/fail2ban/fail2ban.sqlite3 So, I did a little research to try to find out how access the database. To open or connect to the database: 1$ sqlite3 /var/lib/fail2ban/fail2ban.sqlite3 To list all the tables in the database: 12sqlite&gt; .tablesbans fail2banDb jails logs To query a table: 1sqlite&gt; SELECT * FROM logs; Another table: sqlite&gt; SELECT * FROM bans; To disconnect from the database: sqlite&gt; .quit 참조 참조: https://www.digitalocean.com/community/tutorials/how-to-protect-ssh-with-fail2ban-on-debian-7 How to protect Nginx Server with fail2ban How to proect ssh with fail2ban on Debian fail2ban 과 iptables Nginx fail2ban jails Fail2ban Wiki","link":"/ubuntu-fail2ban-5ff4cf69c47c/"},{"title":"LED 전구가 Wi-Fi를 교체할 것 인가?","text":"Li-Fi미래 무선 통신은 빛?! 원문: http://www.popsci.com/say-hi-to-lo-fi 밝은 아이디어와이파이를 사용해 팟캐스트를 다운로드 하거나 문자를 보낸다면, 이 데이터는 무선 전파를 타고 전달된다. 이 전파 파동은 전자기 스펙트럼이라는 좁은 경로를 일으키는데, 문제는 이 좁은 폭이 스마트폰과 다른 장치를 위한 대역폭으로 제한되어 있다는 점이다. Edinburgh 대학의 모바일 통신 연구 리더인 Herald Haas는 “이것은 대역폭이 더 많은 스팩트럼을 생성할 수 없다”고 말한다. 무선 전파가 혼잡한 일차선 도로 같다면, 가시 광선은 넓은 폭의 고속도로 같다. 즉 LED전구(벌브)를 통해서 큰 도로의 잇점을 사용해 빠른 다운로드가 가능하다. 벌브를 신호처리 장치로 수정해서 반도체 같은 기능을 포함하고 광선 사이에 디지털 정보를 내장하는 것이다. Light fidelity - Li-Fi는 LED 빛의 형태로 무선 장치들에 데이터 스트림을 제공할 수 있다. 초당 1억회 혹은 1메가 헤르츠 속도의 슈퍼스피드를 낼 수 있다. Haas 교수는 2000년 초에 Li-Fi에 대해 연구를 시작해서 초당 10메가비트 정도에 도달해서 - 인터넷 브라우징이 가능한 정도로 스트리밍에는 미치지 못했다. 그리고 2003년에 주파수를 가로질러 데이터를 분리하는데 주력해서 초당 100메가비트 속도까지 도달했다 - 이것은 빠른 Wi-Fi 보다 15배 빠르다. Li-Fi는 보안에도 뛰어나다. 빛은 벽을 통과할 수 있어서 신호가 건너갈 수 없다. 결점은 인터넷을 하려면 빛이 있어야 한다는 점이다. 인도 스타트업 Velmenni는 Li-Fi가 가능한 LED를 발표했다. 인터넷 기반이 없는 곳에 유망할 것 이다. 거리의 가로등이 인터넷 핫 스팟이 된다면 멋질 것이다. Li-Fi timelineHaas가 운영하는 pureLife.com에서 LiFi제품과 타임라인을 확인해 볼 수 있다 - http://purelifi.com/what_is_li-fi/the-lifi-story/ [Li-Fi Timeline]","link":"/20160621-iot-Li-Fi-86e2fdd7642b/"},{"title":"fail2ban log","text":"fail2ban logfail2ban 로그는 아래 형태로 1234567892016-08-28 12:35:56,163 fail2ban.actions[860]: WARNING [ssh] Ban 103.237.147.192016-08-28 12:36:09,215 fail2ban.actions[860]: WARNING [ssh] Ban 115.248.186.32016-08-28 17:39:47,806 fail2ban.actions[860]: WARNING [ssh] Ban 117.3.120.942016-08-28 23:06:21,291 fail2ban.actions[860]: WARNING [ssh] Ban 155.94.163.642016-08-29 19:50:51,400 fail2ban.actions[860]: WARNING [ssh] Ban 182.75.249.1102016-08-31 14:26:54,093 fail2ban.actions[860]: WARNING [ssh] Ban 103.207.36.362016-09-01 02:23:23,790 fail2ban.actions[860]: WARNING [ssh] Ban 45.32.60.932016-09-01 17:44:35,854 fail2ban.filter [860]: WARNING Determined IP using DNS Lookup: 61-216-182-218.hinet-ip.hinet.net = ['61.216.182.218']2016-09-01 17:47:18,004 fail2ban.actions[860]: WARNING [ssh] Ban 61.216.182.218 awk 이용 ip 주소 추출awk 를 사용해서 로그에서 ip주소를 추출해 보자. 로그 내용에서 ‘Ban’을 포함한 줄을 만나면 $NF 변수에 각 컨럼을 저장한다. 12345$sudo awk '($(NF-1) = /Ban/){print $NF}' /var/log/fail2ban.log103.237.147.19115.248.186.3117.3.120.94 IP주소를 정렬1234$sudo awk '($(NF-1) = /Ban/){print $NF}' /var/log/fail2ban.log | sort | uniq -c | sort -n 1 103.207.36.36 1 103.237.147.19 1 115.248.186.3 각 거부당한 IP 주소는 최대 실패 횟수 이후 ban 하므로 30회 이상의 시도가 있을 모든 백업 로그에서 IP 주소 추출백업된 로그 파일을 모두 사용하려면 zgrep 명령을 사용해도 좋다 1$sudo zgrep -h &quot;Ban &quot; /var/log/fail2ban.log* | awk '{print $NF}' | sort | uniq -c | sort -n 다음은 아주 위험한 서브넷을 출력한다. 1234567891011$sudo zgrep -h &quot;Ban &quot; /var/log/fail2ban.log* | awk '{print $NF}' | awk -F\\. '{print $1&quot;.&quot;$2&quot;.&quot;}' | sort | uniq -c | sort -n | tail 2 222.186. 3 111.74. 3 116.100. 3 182.100. 3 195.154. 3 42.117. 7 115.239. 8 91.224. 14 103.207. 39 221.229. 123456$sudo zgrep -c 221.229 /var/log/fail2ban.log*/var/log/fail2ban.log:0/var/log/fail2ban.log.1:2/var/log/fail2ban.log.2.gz:0/var/log/fail2ban.log.3.gz:2/var/log/fail2ban.log.4.gz:68 전체 로그에 순위 매기기12345zcat /var/log/auth.log* | grep 'Failed password' | grep sshd | awk '{print $1,$2}' | sort -k 1,1M -k 2n | uniq -c 161 Mar 20 202 Mar 21 참조 http://www.the-art-of-web.com/system/fail2ban-log/ Multiple log filehttp://serverfault.com/questions/486301/how-to-set-up-fail2ban-to-read-multi-log-in-a-jail","link":"/ubuntu-fail2ban-log-0aea850b9007/"},{"title":"Yarn","text":"YarnYarn은 Facebook, Google, Exponent, Tilde가 만든 npm을 대체 할 수 있는 새로운 패키지 관리자 이다. npm의 두 가지 큰 문제를 해결하고자 한다,^Yarn vs npm: Everything You Need to Know npm 의 패키지 설치가 만족스럽게 빠르지 않다. 보안 문제가 우려되고 있다. 설치시에 코드가 실행되도록 하고 있다. 다른 듯 같은 점yarn의 버전 표기가 다르기 때문에 같은 패키지를 서로 다른 버전으로 설치하는 잘못이 발생할 수도 있다. npm 5 이후 많은 개선이 이루어 졌다. ^npm 5 vs yarn npm i 는 자동으로 package.json에 의존성을 저장한다. npm-shrinkwrap 가 사라지고 yarn 같이 package-lock.json 파일이 추가되었다. package.json이 파일은 npm과 yarn에서 의존성을 유지하기 위해 사용한다. 그러나 버전 번호가 다를 수 있다. 버전을 major와 minor 로 선택할 수 있고, 표기가 다음 같이 다르다 ^npm-vs-yarn node version: v8.0.0npm verison: 5.0.0yarn verison: 0.24.6 npm, yarn 양쪽 버전이 package.json에 명시되어 설치되는 문제가 생길 수 있다. 이것을 피하기 위해 정확히 yarn으로 설치되는 버전은 yarn.lock 에 관리된다. npm에서도 npm shrinkwrap 명령이 lock 파일을 생성해서 npm install 이 package.json을 읽기 전에 읽어 설치하는 것은 yarn.lock 을 먼저 읽는 것과 같다. 다만 yarn은 기본적으로 yarn.lock을 생성하고 업데이트 한다는 것이다. 병렬 설치npm 이 패키지를 설치하는 작업은 각 패키지를 설치하고 순차적으로 진행한다. yarn은 설치 작업을 별령로 진행한다. express 패키지 42개를 설치할 때 12npm: 9 secondsYarn: 1.37 seconds gulp package 는 의존하는 195개 패키지를 설치한다. 12npm: 11 secondsYarn: 7.81 seconds 출력npm 설치 과정은 장황스럽게 표시된다. yarn은 기본적으로 조금 단순하고 자세한 출력 옵션은 별도로 있다. CLI 의 다른 점yarn global글러벌 설치시 npm은 -g, --global 을 사용하는데, yarn은 global 첨자를 사용한다이다. 그리고 npm과 같이 글로벌 설치시에는 프로젝트 지정 의존성이 글로벌로 설치되지 않는다. global 앞첨자는 yarn add, yarn bin, yarn ls yarn remove 에서만 동작한다. yarn installnpm install 은 package.json 에 명시된 패키지들의 의존성을 설치한다. yarn은 순서데로 yarn.locak 혹은 package.json에 명시된 의존성을 설치한다. yarn add [-dev]npm은 package.json에 의존성을 추가하려면 npm install --save 별도의 플래그를 사용한다. yarn은 yarn add &lt;package&gt; 는 패키지를 설치하고 package.json에 의존성으로 추가한다. 그리고 --dev 플래그를 주면 developer dependency에 추가해 준다. yarn licenses [ls|generate-disclaimer]yarn license ls 는 패키지의 라이센스를 목록을 출력한다. yarn license generate-disclaimer 는 모든 패키지의 라이센스 내역에 대한 면책조항을 생성한다. yarn why의존성 그래프와 그림을 출력해 준다. yarn upgrade npm update와 비슷하게, yarn upgrade 는 package.json에 명시된 패키지를 업그레이드하고 yarn.lock을 재 생성한다. 주목할 점은 패키지를 명시해서 업그레이드 하면 최신 릴리즈로 갱신하고 package.json에 태그를 선언해 둔다. 메이저 릴리즈로 패키지를 업데이트 해준다는 의미이다. yarn generate-lock-entryyarn generate-lock-entry 명령은 package.json을 기초로 yarn.lock 을 생성한다. 이것은 npm shirinkwrap 과 비슷하다. 다만 주의해서 사용해야 하는데 yarn.lock 파일은 yarn add, yarn upgrade 시 생성되거나 업데이트 된다. ### 설치 https://yarnpkg.com/en/docs/install#linux-tab 에 설명되어 있다. macOS1brew install yarn nvm 같은 가상환경을 사용하면 node.js 설치를 제외한다. 1brew install yarn --without-node Ubuntu 16.04이하, 데비안 정식버전 에서12$ curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -$ echo &quot;deb https://dl.yarnpkg.com/debian/ stable main&quot; | sudo tee /etc/apt/sources.list.d/yarn.list 12sudo apt update &amp;&amp; sudo apt install yarnsudo apt-get update &amp;&amp; sudo apt-get install yarn openSUSEOn openSUSE, you can install Yarn via our RPM package repository. 12sudo zypper ar -f https://dl.yarnpkg.com/rpm/ Yarnsudo zypper in yarn 스크립 혹은 npm1curl -o- -L https://yarnpkg.com/install.sh | bash 설치후 경로에 추가한다.export PATH=”$PATH:/opt/yarn-[version]/bin” 사용The following command uses Yarn to install the express package: yarn add express 참조","link":"/nodejs-yarn-npm-3d91ce0df1d0/"},{"title":"Raspberry Pi 3에서 Opensuse LEAP 설치후 10가지 작업","text":"Raspberry Pi 3에서 Opensuse LEAP 설치후 10가지 작업jeos가 아닌 E20, LXQT 같은 데스크탑을 설치후 할 일을 정리했다. Install Gnome Tweak Tool &amp; dconf editorBy default GNOME 3 settings and options are looking good but if you want make your desktop more beautiful. Better you can install Gnome Tweak Tool &amp; dconf editor which will give lots of cool options to make your desktop more beautiful which was not there in GNOME Application. Install Icon themepackman repository라이센스와 특허 문제로 몇몇 중요한 저장소가 빠져서 배포되고 있다. opensuse 커뮤니티에서 이런 패키지를 제공하는 packman 저장소를 운영하고 있다. packman은 4가지 저장소 이루어저 있다. Essensials: 오디오/비디오 앱을 위한 코덱 Multimedia: 멀티미디어 관련 앱 Extra: 멀티미디어 이외의 앱과 네트워크 관련 Games: 게임 패키지 Packman repository 활성화1~&gt; sudo zypper addrepo http://ftp.gwdg.de/pub/linux/misc/packman/suse/openSUSE_Leap_42.3/ Packman-Repository 혹은 1~&gt; sudo zypper ar -f -n packman http://ftp.gwdg.de/pub/linux/misc/packman/suse/openSUSE_Leap_42.3/ packman Tumbleweed [^4] 1~&gt; sudo zypper ar -p 1 -f -n packman http://ftp.gwdg.de/pub/linux/misc/packman/suse/openSUSE_Tumbleweed/ packman 그리고 저장소 정보를 갱신한다. 1~&gt; sudo zypper ref 이 저장소를 지우려면 1sudo zypper lr -d 해당 저장소 번로를 zypper rr [no] 명령으로 삭제한다. 1sudo zypper rr 3 Media applications [^5]vlc 설치 1~&gt; sudo zypper install vlc vlc-codecs Transcode 혹은 비디오 변환작업을 하면 Hanbrake 가 적절한다. 1~&gt;sudo zypper install handbrake-cli handbrake-gtk Install Media CodecsH264/AVC streams support on your PC: [^4] 1~&gt; sudo zypper install x264 libx265-130 libx264-148 k3b-codecs [^5] ffmpeg 와 lame 설치 1~&gt; sudo zypper install ffmpeg lame GStreamer 플러그인 설치 1~&gt; sudo zypper install gstreamer-plugins-bad gstreamer-plugins-ugly gstreamer-plugins-ugly-orig-addon gstreamer-plugins-libav ChromeInstall Chrome [^5] sudo zypper in chromium OpenSUSE comes with Firefox as the default browser. But since Firefox isn’t capable of playing restricted media such as Netflix, I recommend installing Chrome. This takes some extra work. First you need to import the trusted key from Google. Open the terminal app and run the ‘wget’ command to download the key: wget https://dl.google.com/linux/linux_signing_key.pub Then import the key: sudo rpm –import linux_signing_key.pub Now head over to the Google Chrome website and download the 64 bit .rpm file. Once downloaded run the following command to install the browser: sudo zypper install /PATH_OF_GOOGLE_CHROME.rpm yast2 모듈Leap 42.3 에는 yast -l 로 모듈을 확인해 bootloader, checkmediadiskfirewallhostinst_release_noteskeyboardlanlanguageproxyremoterepositoriessecurityservices-managersw_single, timezone, users, view_anymsg 추가적인 yast2 모듈을 설치하기 위해 아래 같이 검색할 수 있다. 1sudo zypper search yast2- 앱VLC is one of the best multimedia players out there. It’s free and open source. You can install it via: sudo zypper in vlcyou are a gamer, then you may probably want to install Steam: sudo zypper in steam Dropbox is probably the most famous solution on Linux desktops. You can install it using: sudo zypper in dropbox 참고[^1]: System Upgrade[^2]: net-tools deprecated[^4]: Things to do after installing opensuse[^5]: 8 things to do after Opensue","link":"/opensuse-todo_10-c402e6008f39/"},{"title":"Rasberry Pi EEG","text":"Raspberry Pi로 구현하는 EEGElectroencepharogram, EEG는 머리에 부착한 적극등에 의해 뇌의 활동 상태를 측정하는 기술이다. 머리의 대뇌피질에 전극을 연결해 뇌파를 측정하면 델타 -δ파(0.2 ~ 3.99 Hz), 쎄타 -θ파(4 ~ 7.99 Hz), 알파 -α파(8 ~ 12.99 Hz), 베타 -β파(13 ~ 29.99 Hz), 감마- g파(30~50 Hz) 파동으로 구분할 수 있다. Raspberry Pi에서 EEG를 시현한 사례도 많이 제공되고 있다. https://www.raspberrypi.org/blog/tag/eeg/ Neosky Mindwave100€ 선에서 Neurosky Mindwave 제품같은 저렴한 EEG 헤드셋을 이용할 수 있다. 그림. Nerosky Mindwave EEG 다음은 유튜브에 공개된 Neurosky Mindwave를 사용한 시연 동영상이다: Mindwave헤드셋과 Bluetooth dongle로 구성되어 있어서, 라즈베리파이에서 USB 장치 연결을 하고 dmesg로 장치 인식을 확인할 수 있다.그리고 Mindwave용 Python라이브러리를 사용해 EEG 신호를 측정할 수 있다. mindwave-python 라이브러리파이썬 Mindwave 라이브러리를 사용할 수 있다. https://github.com/BarkleyUS/mindwave-python DiY EEG circuitEEG 세트를 자작으로 구현해 볼 수 있다. DIY EEG (and ECG) Circuit 참고 Raspberry Pi mindcontrol! Neurosky mindwave as simple EEG interface 뇌파의 개요","link":"/20160621-iot-RPi-EEG-276ce09d576c/"},{"title":"C&#x2F;C++ 표준","text":"C/C++ 표준https://m.blog.naver.com/PostView.nhn?blogId=tipsware&amp;logNo=221032917097&amp;proxyReferer=https%3A%2F%2Fwww.google.com%2Fhttps://junho85.pe.kr/1026 C11 - 2011https://en.wikipedia.org/wiki/C11_(C_standard_revision)) C99 - 1999https://en.wikipedia.org/wiki/C99 1gcc --std=c99 for loop 에 초기화 변수 선언 가능 12for (int i=0; i&lt;9; i++) {} C95 - 1995 wide character. wchar.h, wctype.h digraphs and for &amp;&amp; STDC_VERSION C90 - 1990ISO 표준. ANSI 에서도 받아들임. C89 와 동일한 언어. 약간의 에러 수정 C89 - 1989https://en.wikipedia.org/wiki/ANSI_C#C89 1989년 ANSI 에서 발표한 첫번째 공식 C 표준 gcc 6.3.1 ~ 7.3.1 - gnu11, gnu++145.4.0 - gnu11, gnu++98STDC_VERSION https://sourceforge.net/p/predef/wiki/Standards/ C11 - STDC_VERSION = 201112L","link":"/c_cpp_standard-6e923d6eaada/"},{"title":"Ubuntu&#x2F;시스템 전원관리","text":"Ubuntu - 시스템 전원관리우분투 시스템을 명령으로 잠자기, 깨우기가 가능하다. 컴퓨터의 BIOS에서 Wake On Lan이 활성화 되어야한다. WakeOnLanwakeonlan을 활성화 하려면 이더넷 인터페이스를 화인한다. 123456789$ ifconfigenp5s0 Link encap:Ethernet HWaddr 0f:1a:92:51:70:a9 inet addr:192.168.0.10 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe20::6595:e3fd:ad6:10f1/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:85121 errors:0 dropped:0 overruns:0 frame:0 TX packets:11677 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:25916710 (25.9 MB) TX bytes:1481803 (1.4 MB) 계속 ethtool 로 WakeOnLan이 활성화 되었는지 확인한다. 123456789101112131415161718192021222324252627$ sudo ethtool enp5s0[sudo] password for USERNAME:Settings for enp5s0: Supported ports: [ TP MII ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full Advertised pause frame use: Symmetric Receive-only Advertised auto-negotiation: Yes Link partner advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full Link partner advertised pause frame use: Symmetric Receive-only Link partner advertised auto-negotiation: Yes Speed: 100Mb/s Duplex: Full Port: MII PHYAD: 0 Transceiver: internal Auto-negotiation: on Supports Wake-on: pumbg Wake-on: g Current message level: 0x00000033 (51) drv probe ifdown ifup Link detected: yes 내용중에 Supports Wake-on: 항목이 WakeOnLan 지원을 확인할 수 있다. 문자에 g 가 있으면 Magic Packet™을 지원한다. 그러나 d 가 포함되지 않았으면 아래 명령으로 WoL을 활성화 해야 한다. 1$ sudo ethtool -s enp5s0 wol g 이 명령은 대부분의 시스템에서 재시동이 필요하다. 시스템이 ifupdown 으로 구성되어 있으면 /etc/network/interfaces 에 아래 같이 12345678910auto loiface lo inet loopback# The primary network interfaceauto eth0iface eth0 inet static address 10.0.0.1 netmask 255.255.255.0 gateway 10.0.0.138 up ethtool -s eth0 wol g https://askubuntu.com/questions/764158/how-to-enable-wake-on-lan-wol-in-ubuntu-16-04 Power management우분투 14 버전과 이후 버전의 시스템 전력 관리가 다르다. Ubuntu 14.04 이전1$ sudo apt install powermanagement-interface pmi 명령 혹은 pm-*** 명령을 사용해서 컴퓨터를 재울 수 있다. 12pmi action suspendpmi action hibernate 노트북에서 다음 명령도 실행된다. 12sudo pm-suspendsudo pm-hibernate Ubuntu 15 / 16 이상대상 컴퓨터를 잠자기 모드 ( suspend) 1$ sudo systemctl suspend 최대절전모드인 Hibernation은 pm-hibernate 명령을 사용한다. 1$ sudo pm-hibernate Wake-up 명령네트워크에 연결된 장치를 깨우기 위해서 wakeonlan 명령을 사용할 수 있다. wakeonlan MAC_ADDRESS 12$ wakeonlan 00:1d:92:51:70:d8Sending magic packet to 255.255.255.255:9 with 00:1d:92:51:70:d8 mac에서는 homebrew 로 wakeonlan 명령을 설치해서 사용할 수 있다. 모니터 다루기노트북 화면을 끄거나, 외부 모니터 표시를 잠시 멈출 수 있다. console 에서To turn off monitor in console, the command is the following: 12sudo vbetool dpms off # turn offsudo vbetool dpms on # turn on To regain control of the console on pressing enter key, I suggest sudo sh -c ‘vbetool dpms off; read ans; vbetool dpms on’ X windows 상태에서https://askubuntu.com/questions/253818/manually-turn-off-monitor 데스크탑 윈두우 터미널에서 xrandr 을 실행한다. 12345678910~$ xrandrScreen 0: minimum 8 x 8, current 1280 x 800, maximum 32767 x 32767LVDS1 connected primary 1280x800+0+0 (normal left inverted right x axis y axis) 331mm x 207mm 1280x800 59.9*+ 1024x768 60.0 800x600 60.3 56.2 640x480 59.9 640x400 60.0VGA1 disconnected (normal left inverted right x axis y axis)VIRTUAL1 disconnected (normal left inverted right x axis y axis) in terminal(your laptop screen is something like LVDS1, and your external monitor is some thing like VGA). turn off laptop screen12xrandr --output LVDS1 --off # turn offxrandr --output LVDS1 --on # turn on If you need to turn on the laptop screen:: 노트북 화면 크기를 조정한다. 1xrandr --output LVDS --mode 1280x800 외부 모니터를 끄려면 1xrandr --output VGA --off 참조 WakeOnLan","link":"/2017-11-01-ubuntu-maintain-power-edfaa7d1d4f6/"},{"title":"Angularjs - Karma Unit Testing","text":"angularjs 단위 테스트에 대해 정리한다. angularjs 1.6.x 에서 진행했다. macOS, Linux 환경에 적합하다. node.js 를 nvm 가상환경에서 구축하고 사용하는 방법에 대해서는 Node.js Install with nvm 를 참조하면 된다. angularjs 단위 테스트에 대해 참고한 문서는 아래 참고 섹션에 제공했다. Angularjs Testingangularjs는 unit test와 E2E (end to end) 테스트를 제공하고 있다. Unit testing E2E testing 코드/모듈/함수 레벨 테스트팅 웹 UI 테스팅 서비스, 클래스, 오브젝트 테스트에 적합 웹 서버 필요 샌드박스, 독립 테스트에 적합 통합 테스트에 적합 랜더링 결과와 angularjs 데이터 부합 확인 fast 느리다 Karma자바스크립트 단위 테스트 도구로 테스트 러너 설정시 번거로운 부분을 쉽게 할 수 있다. 시작nodejs가 설치되었으면 새 프로젝트 폴더에서 npm init 로 프로젝트를 초기화 하고 123$ mkdir angularjs-karma-test$ cd angularjs-karma-test$ npm init 글로벌로 karma와 jasmine framework를 설치한다. 12$ npm i –g karma$ npm i -g jasmine jasmine-core 만약 karma를 프로젝트의 로컬 dev 모드로 설치한다면 jasmine도 같이 로컬로 설치하자. 12$ npm i -D jasmine jasmine-core$ npm i -D karma 프로젝트에 angularjs 모듈과 mock 모듈을 설치해 준다. 12$ npm i angular$ npm i -D angular-mocks 그리고 karma.conf.js 파일을 만들기 위해 karma init 명령을 실행하면 선택 입력 항목을 물어 온다. 기본 설정으로 진행한다. 1234567891011121314151617181920212223242526272829Which testing framework do you want to use ?Press tab to list possible options. Enter to move to the next question.&gt; jasmineDo you want to use Require.js ?This will add Require.js plugin.Press tab to list possible options. Enter to move to the next question.&gt; noDo you want to capture any browsers automatically ?Press tab to list possible options. Enter empty string to move to the next question.&gt; Chrome&gt;What is the location of your source and test files ?You can use glob patterns, eg. &quot;js/*.js&quot; or &quot;test/**/*Spec.js&quot;.Enter empty string to move to the next question.&gt;Should any of the files included by the previous patterns be excluded ?You can use glob patterns, eg. &quot;**/*.swp&quot;.Enter empty string to move to the next question.&gt;Do you want Karma to watch all the files and run the tests on change ?Press tab to list possible options.&gt; yesConfig file generated at &quot;/Users/qkboo/www-app/angularjs-karma/karma.conf.js&quot;. 현재 설정을 테스트하기 위해 start 명령으로 시작하면 karma 서버가 시작된다. 12$ karma start20 12 2017 12:41:02.798:INFO [karma]: Karma v1.7.1 server started at http://0.0.0.0:9876/ 데스크탑 환경이면 karma.conf.js 에 지정한 브라우저가 실행되어 보여준다. 테스트 스펙 작성실제 테스트 시나리오를 기술하는 jasmine 테스트 스펙 파일은 아래 같은 구조를 가지고 있다. 123456789101112131415161718192021describe(&quot;테스트 대상 설명&quot;, function () { // 테스트 전처리 before(function () {}); // 테스트 후처리 after(function () {}); // it 마다 매번 실행하는 전처리 beforeEach(function () {}); // it 마다 매번 실행하는 후처리 afterEach(function () {}); it(&quot;테스트 내용 설명&quot;, function () { // 테스트 }); it(&quot;테스트 내용 설명&quot;, function () { // 테스트 });}); 테스트 코드 작성app/src/app.js 1angular.module(&quot;myapp&quot;, [&quot;myapp.service&quot;]); 서비스 모듈을 생성하고 테스트 해보자, test/test.service.js 테스트 스펙을 작성해 보자. app/src/test/test.service.js 123456789describe(&quot;서비스 테스트&quot;, function () { beforeEach(module(&quot;myapp.service&quot;)); //모듈 로드 describe(&quot;서비스 모듈 버전 테스트&quot;, function () { it(&quot;현재 버전 반환&quot;, inject(function (version) { expect(version).toEqual(&quot;0.1&quot;); })); });}); myapp.service.js를 작성한다. app/src/service/myapp.service.js 1angular.module(&quot;myapp.service&quot;, []).value(&quot;version&quot;, &quot;0.1&quot;); //버전 karma를 종료했다 다시 실행한다 – (소스 및 스펙 변경이 바로 적용 안된다면…) 이제 테스트 스크립을 실행해 보기 위해 karma.conf.js에 소스 파일들을 명시하자. files는 karma가 실행될 때 로드되는 파일의 path를 가지고 있는 배열이다. 1234567files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/test/test*.js'], 앞서 실행한 karma 를 종료하지 않아도 된다. 소스를 추가하고 변경하면 테스트가 자동으로 시작된다. 브라우저는 angular-mock으로 테스트하는 프레임워크로 브라우저 내용에는 별다른 정보가 나타나지 않는다, 터미널에 테스트가 실패하면 12Chrome 63.0.3239 (Mac OS X 10.12.6) 서비스 테스트 서비스 모듈 버전 테스트 현재 버전 반환 FAILED Expected '0.1' to equal '1.0'. 버전 정보를 요구되는 값으로 변경하고 저장하면 로그에 다음 같이 테스트 스크립 성공 여부가 표시된다. 1Chrome 63.0.3239 (Mac OS X 10.12.6): Executed 1 of 1 SUCCESS (0.016 secs / 0.012 secs) 컨트롤러 테스트 작성컨트롤러는 Scope을 통해 데이터 바인딩이에 대해 … app/src/test/test.service.js 테스트 스펙을 작성해 보자. 컨트롤러 모듈을 들여오고 필요한 모듈, 여기서 $scope를 주입하고 모듈에 적재되었는지 테스트한다. 1234567891011121314151617181920212223242526describe(&quot;서비스 테스트&quot;, function () { var scope; // 1. 모듈을 들여오고 beforeEach(module(&quot;myapp.controller&quot;)); //모듈 로드 describe(&quot;컨트롤러 모듈 테스트&quot;, function () { //2. 필요한 모듈, 여기서 $scope를 주입하고 it(&quot;컨트롤러 들여오기&quot;, inject([ &quot;$rootScope&quot;, &quot;$controller&quot;, function ($rootScope, $controller) { // 새 스코프 scope = $rootScope.$new(); // 대상 컨트롤러에 의존성을 주입하고 들여온다. userListController = $controller(&quot;userListController&quot;, { $scope: scope, }); }, ])); //3. 모듈에 적재되었는지 테스트한다. it(&quot;userListController 컨트롤러가 정의되어 있다.&quot;, function () { expect(userListController).toBeDefined(); }); });}); 실제 컨트롤러 소스 가 없으므로 아래 같이 에러가 발생한다. 123456Chrome 63.0.3239 (Mac OS X 10.12.6) 서비스 테스트 컨트롤러 모듈 테스트 userListController 컨트롤러가 정의되어 있다. FAILED ReferenceError: userListController is not defined at UserContext.&lt;anonymous&gt; (app/src/test/test.controller.js:18:14)Chrome 63.0.3239 (Mac OS X 10.12.6): Executed 2 of 3 (2 FAILED) (0 secs / 0.013 secChrome 63.0.3239 (Mac OS X 10.12.6): Executed 3 of 3 (2 FAILED) (0 secs / 0.018 secChrome 63.0.3239 (Mac OS X 10.12.6): Executed 3 of 3 (2 FAILED) (0.026 secs / 0.018 secs) 이제 app/src/controller/myapp.controller.js 소스를 작성한다. 123456789angular .module(&quot;myapp.controller&quot;, []) .controller(&quot;userListController&quot;, [ &quot;$scope&quot;, function ($scope) { $scope.test = &quot;Hello Test!&quot;; }, ]); 이제 myapp.controller.js 를 karma.conf.js에 추가해 준다. 123456789files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/controller/myapp.controller.js', 'app/src/test/test*.js'], karma를 종료했다 다시 실행한다 – (소스 및 스펙 변경이 바로 적용 안된다면…) 실제 테스트가 제대로 수행되면 알개 같이 SUCCESS 메시지를 볼 수 있다. 1Chrome 63.0.3239 (Mac OS X 10.12.6): Executed 3 of 3 SUCCESS (0.018 secs / 0.013 secs) 컨트롤로 메서드 단위 테스트myapp.service 에 ‘UserService’ 를 선언한다. 12345678angular .module(&quot;myapp.service&quot;, []) .factory(&quot;UserService&quot;, [ function () { return {}; }, ]); 컨트롤러에 userList 배열을 선언해 주낟. 12345.controller('userListController', ['$scope', function($scope) { $scope.test = &quot;Hello Test!&quot;; $scope.userList = [];}]) test.controller.js 스펙에 12345678910111213141516171819202122232425262728293031323334353637describe(&quot;서비스 테스트&quot;, function () { var userListController, scope, mockService; beforeEach(module(&quot;myapp.controller&quot;)); //모듈 로드 describe(&quot;컨트롤러 모듈 테스트&quot;, function () { it(&quot;컨트롤러 들여오기&quot;, inject([ &quot;$rootScope&quot;, &quot;$controller&quot;, function ($rootScope, $controller) { scope = $rootScope.$new(); //임의 사용자 조회 서비스를 만든다. mockService = { getUserList: function (callback) { callback.call(null, [{ name: &quot;Hello&quot; }]); }, }; // 대상 컨트롤러에 의존성을 주입하고 'UserService' 서비스를 주입한다. userListController = $controller(&quot;userListController&quot;, { $scope: scope, UserService: mockService, }); }, ])); it(&quot;userListController 컨트롤러가 정의되어 있다.&quot;, function () { expect(userListController).toBeDefined(); }); // 사용자 조회 함수를 테스트 한다. it(&quot;사용자를 조회한다.&quot;, function () { scope.searchUsers(); // 1건의 결과가 있다. expect(scope.userList.length).toEqual(1); }); });}); 컨트롤러에 searchUsers() 함수가 없으므로 에러가 발생한다. 1TypeError: scope.searchUsers is not a function 컨트롤러에 UserService를 주입하고, searchusers() 함수를 선언해 준다. 1234567891011.controller('userListController', ['$scope','UserService', function($scope, UserService) { $scope.test = &quot;Hello Test!&quot;; $scope.userList = []; $scope.searchUsers = function() { UserService.getUserList(function(data) { $scope.userList = data; }) }}]) 서비스 단위 테스트앞서 서비스로 UserService 팩토리를 선언했다. 제대로 들여오는지 테스트 스펙에 다음 같이 선언할 수 있다. test.service.js 스펙에 다음을 추가하자. 123it(&quot;UserService가 정의되어 있다&quot;, inject(function (UserService) { expect(UserService).toBeDefined();})); 이제 getUserList() 함수를 테스트해보자 123456789101112131415161718var users;it(&quot;UserService.getUserList 가 사용자를 조회한다&quot;, inject(function ( UserService, $httpBackend) { // http 응답 $httpBackend.when(&quot;GET&quot;, &quot;sample.json&quot;).response([{ name: &quot;test&quot; }]); //서비스를 호출한다. UserService.getUserList(function (data) { users = respond.data; }); $httpBackend.flush(); // http 응답에 1건이 있으므로 expect(d.length).toBe(1);})); 실제 getUserList() 함수가 구현 안되어 있으므로 다음 같이 실패가 나타난다. 12320 12 2017 14:59:44.061:INFO [watcher]: Changed file &quot;/Users/qkboo/www-app/angularjs-karma/app/src/test/test.service.js&quot;.Chrome 63.0.3239 (Mac OS X 10.12.6) 서비스 테스트 UserService.getUserList 가 사용자를 조회한다 FAILED TypeError: UserService.getUserList is not a function 실제 서비스 객체에 함수를 선언해 주자. 12345678.factory('UserService', ['$http', function($http) { return { getUserList: function(callback) { $http.get('sample.json') .then(callback); } };}]) Directive 테스트1234567891011121314151617181920describe(&quot;디렉티브 테스트&quot;, function () { beforeEach(module(&quot;myapp.directives&quot;)); //모듈 로드 describe(&quot;app-version 디렉티브 테스트&quot;, function () { it(&quot;현재 버전 출력&quot;, function () { module(function ($provide) { $provide.value(&quot;version&quot;, &quot;TEST_VER&quot;); }); inject([ &quot;$compile&quot;, &quot;$rootScope&quot;, function ($compile, $rootScope) { var element = $compile(&quot;&lt;span app-version&gt;&lt;/span&gt;&quot;)($rootScope); expect(element.text()).toEqual(&quot;TEST_VER&quot;); }, ]); }); //it });}); 디렉티브 모듈을 선언한다 1234567891011angular .module(&quot;myapp.directives&quot;, []) .directive(&quot;appVersion&quot;, [ &quot;version&quot;, function (version) { return function (scope, elm, attrs) { elm.text(version); }; }, ]); 추가한 소스를 karma.config.js 에 추가해 준다. 12345678910files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/controller/myapp.controller.js', 'app/src/directive/myapp.directive.js', 'app/src/test/test*.js' ], 필터 테스트필터를 테스트 할 때는 필터를 inject 한 후에 호출하면서 진행한다. 먼저 테스트 스펙을 작성해 보자. 12345678910111213141516describe(&quot;필터 테스트&quot;, function () { beforeEach(module(&quot;myapp.filters&quot;)); //모듈 로드 var $filter; describe(&quot;length 필터 테스트&quot;, function () { beforeEach(inject(function (_$filter_) { $filter = _$filter_; })); it(&quot;null 이면 0을 반환&quot;, function () { var length = $filter(&quot;length&quot;); expect(length(null)).toEqual(0); }); });}); length 필터를 선언한 myapp.filters.js 소스 12345angular.module(&quot;myapp.filters&quot;, []).filter(&quot;length&quot;, function () { return function (text) { return (&quot;&quot; + (text || &quot;&quot;)).length; };}); karma.config.js 에 필터 소스를 추가해 준다. 추가한 소스를 karma.config.js 에 추가해 준다. 12345678910files: [ 'node_modules/angular/angular.js', 'node_modules/angular-mocks/angular-mocks.js', 'app/src/app.js', 'app/src/service/myapp.service.js', 'app/src/controller/myapp.controller.js', 'app/src/filter/myapp.filters.js', 'app/src/test/test*.js' ], 새 컨트롤이 추가된 후 karma를 재시작해서 테스트를 진행한다.","link":"/angularjs-test-ac057f41292a/"},{"title":"Python - 과학계산을 위한 Jupyter(pip)","text":"과학계산을 위한 Python3 및 pip를 사용한 scipy, jupyter 설치 및 구성을 요약하고 있다. https://packaging.python.org/guides/installing-scientific-packages/ 과학계산을 위한 Python Jupyter과학계산을 위한 Python 과 Jupyter Notebook 환경을 정리한다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy 등 Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux Setup시스템에 Python2, Python3 가 설치되었는지 확인: Ubuntu/Debian 계열: Python 2.7, Python 3.5 설치되어 있다. openSUSE : Python2.7 Python 3 설치시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. 12sudo apt-get install build-essentialsudo apt-get install python-dev python-distlib python3-dev python3-distlib python-dev, python-distlib, apython-setuptools 은 파이썬 개발과 패키징을 지원한다. apt-get install libfreetype6-devapt-get install pkg-configapt-get install libpng-devapt-get install pkg-config libzmq3-dev은 쥬피터 노트북에서 필요로 한다. 1sudo apt-get install libzmq3-dev python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 Pandas 로 데이터 셋트를 다룰 예정, libgdal-dev 은 geopandas에서 geospatial analysis 에 필요하다. 1sudo apt-get install libgdal-dev For Debian Jessie and Stretch installing the following packages resolves the issue: 1sudo apt-get install libblas3 liblapack3 liblapack-dev libblas-dev Your next issue is very likely going to be a missing Fortran compiler, resolve this by installing it like this: 1sudo apt-get install gfortran pip 설치1apt-get install python3-pip python3 설치후 마지막으로 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 12sudo pip install -U pipsudo pip install -U setuptools pip로 설치하기Python2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. Scientific stack아래 같이 사용자 영역에 python3 기반으로 설치해보자, pip 를 파이썬 버전의 site-package 에 모듈을 설치하기 위해서 파이썬 -m 을 사용한다. 1python3 -m pip install --user numpy sympy nose scipy는 설치 시스템에 따라 시간이 많이 걸린다. 또한 swap 영역을 사용하므로 스왑파일시스템을 활성화 하는 것을 권한다. 1python3 -m pip install --user scipy error스왑 파일시스템을 사용하지 않거나 모자라면 아래 같이 가상메모리 에러 혹은 컴파일 에러가 나는 것 같다. 123 #warning &quot;Using deprecated NumPy API, disable it by &quot; \\ ^~~~~~~virtual memory exhausted: Cannot allocate memory 글쓴이는 OdroidC2, Armbian Stretch 에서 시도했다. pandas 및1python3 -m pip install --user pandas 파이썬이 있고 pip를 사용하여 패키지를 설치하려면 다음 명령을 사용합니다. matplotlib pillow graphviz scikit-learn conda를 사용한 패키지 설치설치된 파이썬이 있다면 conda 패키지 매니저를 사용하여 다음 명령을 실행하면 필요한 패키지를 모두 얻을 수 있습니다. conda install numpy scipy scikit-learn matplotlib pandas pillow graphviz python-graphvizpip를 사용한 패키지 설치 설치 확인설치되고 사용이 가능한지 확인한다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 12python3 -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3 12python3 -c &quot;import scipy;print(scipy.__version__)&quot;0.16.0 1python3 -c &quot;import numpy;print(matplotlib.__version__)&quot; ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 1$ python3 -m pip install --user jupyter 물론 가상환경이 아닌 시스템 패키지로 설치해도 된다.$ sudo pip install jupyter geopandas osmnx jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. Upgrade jupyter여기서는 pip 가상머신을 이용하고 있어서 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1$ python3 -m pip install -U jupyter python3 -m pip freeze —local &gt; requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567$ jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2017-10-30-jupyter-scitific-pip-2350016037a8/"},{"title":"Python - 과학계산을 위한 Jupyter(Armbian)","text":"Odroid C2, Raspberry Pi 계열의 ARM CPU를 위한 Armbian 에서 과학계산을 위한 Jupyter 설치 및 구성까지 요약하고 있다. https://packaging.python.org/guides/installing-scientific-packages/ 과학계산을 위한 Python Jupyter과학계산을 위한 Python 모듈을 시스템 패키지로 설치하고 pip 를 사용해서 Jupyter Notebook 을 설치하고 사용하는 과정을 정리했다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy, pandas Setup시스템에 Python2, Python3 가 설치되었는지 확인: Ubuntu/Debian 계열: Python 2.7, Python 3.5 설치되어 있다. openSUSE : Python2.7 시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. 12sudo apt-get install build-essentialsudo apt-get install python-dev python-distlib python3-dev python3-distlib python-dev, python-distlib, apython-setuptools 은 파이썬 개발과 패키징을 지원한다. pip 설치배포본에 pip가 설치되어 있지 않으면 1apt-get install python3-pip python3 설치후 마지막으로 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 라이브러리 설치Scientific stack - apt시스템 패키지로 과학계산을 지원하는 Python2, Python3 모듈을 설치. 12$ sudo apt-get install python-numpy python-decorator python-scipy python-matplotlib$ sudo apt-get install python3-decorator python3-numpy python3-scipy python3-matplotlib symbolic mathematics 관련 패키지도 설치한다. 12sudo apt-get install python-sympy python-nosesudo apt-get install python3-sympy python3-nose 설치되고 사용이 가능한지 확인한다. 다음 두 모듈 numpy, scipy 의 버전이 출력되면 된다. 12python -c &quot;import numpy;print(numpy.__version__)&quot;1.12.1 12python -c &quot;import scipy;print(scipy.__version__)&quot;0.18.1 여기까지 설치하면 의존성에 관련한 아래 같은 여러 패키지가 함께 설치된다. requests : Python package provides a graceful interface for making HTTP requests, pil : provides Python imaging capabilities, scrapy : is a web scraping framework, geopy provides geocoding and geodesic distance functions, shapely provides 2D geometry manipulation, pyproj: provides cartographic transformations. In the second command, jupyter provides interactive coding notebooks, geopandas spatializes pandas, OSMnx lets you work with OpenStreetMap street networks. 이 패키지들은 별도로 설치를 하고자 하면 pip로 설치하거나 시스템 패키지로 다음 같이 설치 할 수 있다. Python2 1sudo apt-get install python-requests python-pil python-scrapy python-geopy python-shapely python-pyproj Python3 pil -&gt; Pillow 1sudo apt-get install python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj PandasPandas 로 데이터 셋트를 다룰 예정이라면 1sudo apt-get install libgdal-dev libgdal-dev 은 geopandas에서 geospatial analysis 에 필요하다. 1sudo apt-get install python-pandas python3-pandas ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. Jupyter 관련 모듈을 pip로 사용자 환경에 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 1sudo apt-get install libzmq3-dev libzmq3-dev은 쥬피터 노트북에서 필요로 한다. pip먼저 pip를 업그레이드 해준다. 1$ sudo pip install -U pip Python2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. Install Jupyter사용자 환경에서 pip로 Jupyter를 설치한다. Python3 환경에서 설치를 권장하고 있다. 1$ python3 -m pip install --user jupyter 그리고 필요하면 Python2에서 설치할 수 있다. 1$ python2 -m pip install --user jupyter jupyter notebook을 실행해 보자. 서버로 실행jupyter notebook 을 바로 실행하면 로컬 머신의 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 브라우저 없이 시작한다. 1234567$ jupyter notebook --no-browser --ip=* --port=8000[I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e jupyter notebook을 시작하면 콘솔에 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} 사용자 설치 모듈 목록여기까지 pip로 사용자 환경 local에 설치한 모듈 목록을 백업해 둘 수 있다. 1$ pip freeze —-local &gt; requirements.txt Upgrade jupyter여기서는 pip 가상머신을 이용하고 있어서 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1$ python3 -m pip install -U --user jupyter ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일먼저 다음 같이 설정 파일을 생성한다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345#c.NotebookApp.notebook_dir = '/path/to/notebook_directory'c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service 현재 서버의 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 12$ netstat -tlnptcp 0 0 127.0.0.1:8585 0.0.0.0:* LISTEN 11906/python3 virtualenv 이용Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux 참조 Installing the Jupyter Notebook Scipy Install Scientific Python on Raspberry Pi","link":"/2017-10-30-jupyter-scitific-virtuaenv-2a3c1a7a4948/"},{"title":"Python - 과학계산을 위한 Jupyter(Armbian)","text":"Debian 계열의 ARM CPU를 위한 Armbian 에서 과학계산을 위한 Jupyter 설치 및 구성까지 요약하고 있다. https://packaging.python.org/guides/installing-scientific-packages/ 과학계산을 위한 Python Jupyter과학계산을 위한 Python 과 Jupyter Notebook 환경을 정리한다. 개발 프론트 엔드: Jupyter 과학계산 모듈: numpy, scipy 등 Python과 Virtualenv 환경을 더 알고 싶으면 다음 두 링크에 자세한 설명이 있다. Python - Install virtualenv on Linux 공개 사이트 Google Colaboratory nbview Setup시스템에 Python2, Python3 가 설치되었는지 확인: Ubuntu/Debian 계열: Python 2.7, Python 3.5 설치되어 있다. openSUSE : Python2.7 Python 3 설치시스템 개발 패키지 설치컴파일에 필요한 헤더 등이 포함된 개발자 라이브러리를 설치한다. 12sudo apt-get install build-essentialsudo apt-get install python-dev python-distlib python3-dev python3-distlib python-dev, python-distlib, apython-setuptools 은 파이썬 개발과 패키징을 지원한다. pip 설치apt-get install python3-pip python3 설치후 마지막으로 update-alternatives 를 이용해 pip 를 pip3 로 연결해 준다. 다른 배포본에서 필요시 update-alternatives 사용: 1sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 30 라이브러리 설치1sudo apt-get install libzmq3-dev libzmq3-dev은 쥬피터 노트북에서 필요로 한다. python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 Scientific stack - pipPython2.6부터 User scheme 개념이 도입되며서 pip로 설치하는 패키지를 개별 사용자 환경 위치에 설치할 수 있다. install 명령에 --user 옵션을 주고 설치한다.[^2] 기본으로 리눅스는 ~/.local 폴더이고, Mac OS X 는 ~/Library/Python/X.Y 에 위치한다.[^3] 그리고 PATH 에 ~/.local/bin 을 추가한다. xlsx 파일을 위해 xlrd 패키지 설치 pip install -U –user xlrd Scientific stack - apt과학계산을 지원하는 Python2 모듈을 시스템 패키지에 apt 로 설치할 수 있다. 12$ sudo apt-get install python-numpy python-decorator python-scipy$ sudo apt-get install python-matplotlib Python3 패키지도 설치한다. 12$ sudo apt-get install python3-decorator python3-numpy python3-scipy$ sudo apt-get install python3-matplotlib symbolic mathematics 관련 패키지도 설치한다. 12sudo apt-get install python-sympy python-nosesudo apt-get install python3-sympy python3-nose 설치되고 사용이 가능한지 확인한다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 12python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3 12python -c &quot;import numpy;print(numpy.__version__)&quot;0.16.0 여기까지 설치하면 의존성에 관련한 아래 같은 여러 패키지가 함께 설치된다. requests : Python package provides a graceful interface for making HTTP requests, pil : provides Python imaging capabilities, scrapy : is a web scraping framework, geopy provides geocoding and geodesic distance functions, shapely provides 2D geometry manipulation, pyproj: provides cartographic transformations. In the second command, jupyter provides interactive coding notebooks, geopandas spatializes pandas, OSMnx lets you work with OpenStreetMap street networks. 이 패키지들은 별도로 설치를 하고자 하면 pip로 설치하거나 시스템 패키지로 다음 같이 설치 할 수 있다. Python2 1sudo apt-get install python-requests python-pil python-scrapy python-geopy python-shapely python-pyproj Python3 1sudo apt-get install python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj PandasPandas 로 데이터 셋트를 다룰 예정이라면 1sudo apt-get install libgdal-dev libgdal-dev 은 geopandas에서 geospatial analysis 에 필요하다. 1sudo apt-get install python-pandas python3-pandas ### Jupyter Notebook Jupyter는 웹 브라우저를 통해서 IDE 환경을 제공하고, 다양한 언어/문법을 지원하는 Kernel 이라는 해석기를 통해 IDE에서 코딩한 결과를 확인할 수 있다. 여기서는 가상환경을 구성해 Jupyter 관련 패키지를 설치하고 사용하겠다. 시스템에 설치된 Python3 와 pip 모듈 virtualenv 와 virtualenvwrapperpip 를 업그레이드하고, 가상 개발환경에서 쥬피터 관련 모듈을 설치하고 관리하기 위해 pip로 virtualenv, virtualenvwrapper 설치한다. 시스템 pip 모듈을 최신 버전으로 업그레이드한다. 1sudo pip install --upgrade pip 그리고 virtualenv, virtualenvwrapper 설치하는데, 사용자의 .local 폴더에 설치하도록 한다. 1pip install --user virtualenv virtualenvwrapper 자동으로 추가되지 않으면, 다음 스크립을 .bashrc 에 추가해 준다. 123456789# set PATH for pipif [ -d &quot;$HOME/.local/bin&quot; ] ; then PATH=&quot;$HOME/.local/bin:$PATH&quot;fiVIRTUALENVWRAPPER_PYTHON=/usr/bin/python3export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource $HOME/.local/bin/virtualenvwrapper.sh 로그아웃했다 로그인하면 mkvirtualenv, rmvirtualenv 등의 명령어 스크립이 설치된다. Jupyter 가상환경다음은 mkvirtualenv 명령으로 jupyter라는 가상환경을 python3, 시스템 패키지 사용을 위해 –system-site-packages 옵션으로 생성한다. 1234mkvirtualenv -p python3 --system-site-packages jupyter(jupyter) $(jupyter) $ python --versionPython 3.4.6 가상환경 jupyter 에서 필수 모듈이 사용 가능한지 확인한다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 1234(jupyter) $ python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3(jupyter) $ python -c &quot;import numpy;print(numpy.__version__)&quot;0.16.0 그리고 pip로 Jupyter 가상환경에 Jupyter를 설치한다. 1(jupyter)$ pip install jupyter 물론 가상환경이 아닌 시스템 패키지로 설치해도 된다.$ sudo pip install jupyter geopandas osmnx jupyter-notebook을 실행해 보고, 서버 관련 구성 내용을 설정해서 사용해 보자. Upgrade jupyter여기서는 pip 가상머신을 이용하고 있어서 다음 같이 pip install 명령으로 업그레이드 할 수 있다. 1(jupyter)$ pip install -U jupyter virtualenv, virtualenvwrapper는 여기서 사용자 .local 환경에 설치했으므로 1pip install -U --user virtualenv virtualenvwrapper pip3 freeze —local &gt; requirements.txt 서버로 실행jupyter-notebook 은 로컬 머신에서 브라우저를 실행한다. 여기서는 원격 사용을 위해 다음 같이 시작할 수 있다. [DIR] 에 jupyter-notebook에서 작성한 노트북 파일이 저장된다. 1234567$ jupyter-notebook --no-browser --ip=* --port=8000 [DIR][I 02:51:04.797 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 02:51:04.800 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8585/?token=a747472bc9a7c6684829267d2ed0a4cd9a722e 시작후 ?token=a..... 부분의 토큰을 복사해 브라우저에 입력후 쥬피터 노트북 사용을 시작한다. 브라우저로 노트북에 접속해서 복사한 토큰을 입력한 후 로그인한다. {:width=”650”} ### Jupyter 설정 이용 jupyter는 설치된 후에 jupyter 시스템 디렉토리와 사용자 JUPYTER_DATA_DIR에 필요한 내용을 저장한다. 시스템 디렉토리: /usr/local/share/jupyter/ JUPYTER_DATA_DIR 는 보통 ~/.jupyter 설정 파일을 이용해서 사용자 비밀번호를 이용해 노트북을 사용할 수 있다. 먼저 실행중인 쥬피터 노트북에서 passwd() 를 실행해 패스워드 해시 값을 얻는다. 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e043ea597d771089e11eed' 패스워드 해시 값을 데이터 디렉토리의 설정 파일에 입력해야 한다. 데이터 설정 파일다음 같이 설정 파일을 생성해서 사용할 수 있다. 123$ jupyter notebook --generate-configWriting default config to: /home/foo/.jupyter/jupyter_notebook_config.py$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py mynotebook.py에 다음을 설정한다. 12345## The base URL for the notebook server.c.NotebookApp.base_url = 'http://www.yourdomain.com/notebok'c.NotebookApp.password = ''c.NotebookApp.port = 8000c.NotebookApp.port_retries = 50 복사한 패스워드 해시 값을 mynotebook.py 설정 파일 안의 c.NotebookApp.password 항목 주석을 풀고 해시 값을 입력한다. 1c.NotebookApp.password = 'sha1:4ee6bb2da3d7:ed76216b87228540e5f5f20fcfa8069cf82686f0' 설정 파일을 이용해 jupyter-notebook을 실행한다. 1$ jupyter notebook --config .jupyter/mybook_config.py [DIR] 이제 jupyter에 접속하려면 다음 같이 패스워드를 묻고 입력한 후에 사용할 수 있다. {:width=”650”} Background 실행Jupyter-notebook을 백그라운드로 실행하려면 nohup 을 사용할 수 있다. 1$ nohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; nohup은 재시동시 다시 시작해야 하는 불편한 점이 있다. crontab 으로 실행nohup 과 결합해서 사용해도 좋은 방법으로 crontab 을 사용해 재시동 후 자동으로 시작해 줄 수 있다. 사용자 crontab 을 편집해 다음 같이 사용할 수 있다. 1@reboot cd /home/foo; jnohup jupyter notebook --no-browser --ip=* --port=8000 [DIR] &gt; log-jupyter.log &amp; 이 방법도 사용자가 시작/상태확인/종료 같은 직접적인 방법을 사용하기는 좀 불편하다. 그래서 upstart의 init.d 를 사용하거나 systemd 의 unit으로 생성해서 사용하는 것이 좋다. systemd 에서 실행systemd unit으로 새로운 unit 파일을 생성해서 기존 systemctl 명령으로 시작/상태/종료/재시작 등의 작업을 할 수 있다. 물론 재시동 관련해서도 완벽히 동작한다. 우선 jupyter-notebook 명령의 절대 경로를 찾아서 이 위치를 유닛 파일의 Exec 명령에 사용한다. 12$ which jupyter-notebook/home/foo/.local/bin/jupyter-notebook systemd의 unit 위치는 OS 마다 조금 다른 것 같다. 여기서는 /etc/systemd/system 밑에 jupyter.service 라는 유닉 파일로 직접 작업한다. /etc/systemd/system/jupyter.service 가상환경을 사용하고 있으므로 systemd unit의 ExecStart 의 python도 가상환경 위치로 지정해 주어야 한다. 123456789101112131415[Unit]Description=My Jupyter-Notebook[Service]Type=simplePIDFile=/run/jupyter-notebook.pidExecStart=/home/foo/.local/bin/jupyter-notebook --config=/home/foo/.jupyter/mynotebook.pyUser=fooGroup=fooWorkingDirectory=/home/foo/notebooksRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 시스템 유닛을 시작해 준다. 123systemctl enable jupyter.servicesystemctl daemon-reloadsystemctl restart jupyter.service 현재 서버의 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 세번째 컬럼 처럼 127.0.0.1 에 열리면 외부에서 접근이 안된다. 12$ netstat -tlnptcp 0 0 127.0.0.1:8585 0.0.0.0:* LISTEN 11906/python3 12$ netstat -tlnptcp 0 0 0.0.0.0:8585 0.0.0.0:* LISTEN 11906/python3 참조 Pandas Install Scipy Install Scientific Python on Raspberry Pi","link":"/2017-10-30-jupyter-scitific-3cb764047523/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 4개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.2 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x MongoDB Community Edition 설치Opensuse 용 MongoDB가 제공되지만 AMD64, X64 관련한 플랫폼에 지원될 뿐이다. Raspberry Pi 3에 JeOS를 설치하고 네이티브로 빌드해보기로 했다. 준비MongoDB 빌드를 위해서 git, gcc 등, Scons 가 필요하다. 컴파일 환경 준비최신 master branch는, 최신 C++11 compiler: VS2015 Update 2 or newer GCC 5.3.0 Clang 3.4 (or Apple XCode 5.1.1 Clang) or newer Python 2.7 SCons 2.3.5 or newer (for MSVC 2015 support) branch 3.2, 3.0 는 C++11 compiler: VS2013 Update 4 or newer. Note that VS2015 is currently not compatible with the 3.0 and 3.2 branches. You must use VS2013. GCC 4.8.2 or newer. Note that versions of GCC newer than 4.8.2 may produce warnings when building these branches, which are promoted to errors. Please use the –disable-warnings-as-errors build option if necessary to allow the build to succeed despite the warnings. Python 2.7 SCons 2.3.0 or newer 필요한 패키지여기서는 터미널에서 openSUSE yast 사용해 관련 패키지를 설치한다. yast를 시작한다.YaST -&gt; Software -&gt; Software Management 를 선택한다. ![][/images/opensuse/yast-sw2.png] gccgcc 을 선택한다. gcc를 선택하면 gcc-4.8 을 기본으로 설치한다. ![][/images/opensuse/yast-sw-gcc.png] 여러 버전을 설치하면 gcc 를 선택하기 위해 update-alternatives을 사용한다. 링크 update-alternatives 에서 설명을 볼 수 있다. 1234$ sudo update-alternatives --install /usr/bin/gcc gcc \\/usr/bin/gcc-4.8 10 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8$ sudo update-alternatives --install /usr/bin/gcc gcc \\/usr/bin/gcc-6 30 --slave /usr/bin/g++ g++ /usr/bin/g++-6 python검색어에 다음 패키지를 넣고 찾아 하나씩 + 키로 패키지를 선택한다. 1git python python-pip python-devel python3 python3-pip python3-devel Search Phrase에 다음 패키지를 찾아 개발관련 라이브러리를 설치한다. 12build-essential libboost-filesystem-dev libboost-program-options-dev libboost-system-dev libboost-thread-dev -y yast-sw-devel_basis 패키지를 찾아 설치한다. {:width=”640”} Search Phrase 에 gcc 를 넣고 적절한 버전을 선택한다. {:width=”640”} 그리고 Action 탭에서 설치를 실행한다. {:width=”640”} ssl 지원을 위해서 Debian과 Ubuntu systems에서 SSL 지원을 위해서 libssl-dev 가 필요하다. 1sudo zypper install libopenssl-devel 기념사진우분투/데비안 계열에 익숙해 있다가 Raspberry Pi 3 에 openSUSE 를 개발자용 패키지들을 설치하고, 맘 먹고 빌드를 시작해서 9일이 걸렸다. 9일 동안 꿋꿋이 버텨준 Raspberry Pi 3/openSUSE machine!!! {:width=”550”} 참조[^1]: Mongodb on Raspberry pi","link":"/opensuse-jeos-mongodb-72b97d850e23/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Nginx, Node JS, Jupyter","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 5개 글타래로 구성되며, openSUSE 설치, 개발도구 구성 및 서버 구축 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter Build MongoDB 3.4.x Nginx, Node JS, Jupyter Notebook Raspberry Pi 3 openSUSE LEAP 42.2 / JeOS Target services Nginx Nginx Proxy www app : nodejs (PORT 50000) jupyter notebook: PORT 8585 Node.js with nvm Python and virtualenv, jupyter notebook nginxnginx는 1.8 버전으로 당연히 사용하던 데비안 계열과 설정 파일 구성이 조금 다르다. nginx 사용자: nginx /etc/nginx/nginx.conf 가 sites-_ 폴더가 아닌 vhost_ 폴더를 가르킨다. 여기서는 sites-* 폴더를 그대로 사용한다. 기존 데비안 계열 형식 sites-* 폴더를 사용하고 사용자먄 nginx 사용. 설치zypper 로 nginx 배포본을 설치한다. 현재는 1.8.1-10.5.1 버전이다. 1sudo zypper in nginx 설치하면 사용자 nginx:nginx 가 추가된다. nginx.confnginx 설정은 Nginx - Install, WebDAV, Proxy on Ubuntu/Debian 에 설명되어 있다. 이 구성을 기초로 우분투/데비안 계열 같이 site-* 폴더를 구성해서 사용한다. 12cd /etc/nginxmv nginx.conf nginx.orig nginx.conf 에 include 지시자를 사용해 sites-enabled 를 추가한다. 12include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*; 그리고 sites-available, sites-enabled 폴더를 생성하고 사이트 파일을 만든다. 123cd /etc/nginxsudo mkdir sites-available sites-enabledsudo touch sites-available/my-site my-site 가상호스트 파일은 [my-site](/2017/04/03/ubuntu-nginx#my-site) 내용의 파일을 site-available 에 작성하고, 그 링크를 site-enabled에 링크를 걸어 준다. 12cd /etc/nginxsudo -s /etc/nginx/sites-available/my-site /etc/nginx/sites-enabled/my-site ### node.js nvm을 설치한다. 1curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.6/install.sh | bash Node.js 설치와 개발환경 설치에 대해서는 NodeJS / nvm 기반 개발환경 설치 글을 참조할 수 있다. node.js 설치최신 v8 버전을 설치한다. 123&gt; nvm install v8Downloading and installing node v8.8.1...Creating default alias: default -&gt; v8 (-&gt; v8.8.1) 12&gt; which node/home/qkboo/.nvm/versions/node/v8.8.1/bin/node pm2 설치node.js 앱을 시스템 서비스로 등록하기 위해서 pm2 를 설치한다. 1npm i -g pm2 예를 들어 express 앱이 있으면 다음 같이 pm2로 시작한다. 12cd www-apppm2 start -n &quot;www-app&quot; bin/www pm2 startupstartup 시 pm2 start 로 생성되는 .pm2 디렉토리의 pid 와 app.js 파일을 실행해 준다. pm2 startup systemd 로 스타트를 하면 2개의 프로세스가 만들어 진다. 방법은,,, 먼저 앱을 시작해 둔다. 1pm2 start -n &quot;www-app&quot; bin/www dump를 생성한다. pm2로 현재 실행중인 프로세스 정보를 save로 덤프하게 저장한다. systemd 서비스 스크립을 작성하는데 유용하다. 1pm2 save pm2 startup 명령 pm2 startup 명령은 pm2로 실행중인 프로세스를 systemd 서비스 유니트 파일로 제어 할 수 있다. 명령을 실행하면 sudo 명령으로 실행할 수 있는 스크립을 출력해 준다. 123$ pm2 startup systemd...sudo env PATH=$PATH:/home/foo/.nvm/versions/node/v8.8.1/bin /home/foo/.nvm/versions/node/v8.8.1/lib/node_modules/pm2/bin/pm2 startup systemd -u foo --hp /home/foo 이 스크립을 실행해 주면 pm2-foo.service 서비스 유니 파일이 생성된다. 12Target path/etc/systemd/system/pm2-foo.service 이 서비스 파일을 활성화하고 시작해준다. 1systemctl enable pm2-foo 이제 시스템을 재시작해도 pm2 로 실행중인 프로세스는 자동으로 시작된다. ### Python Python 개발 환경을 virtualenv 를 이용해서 구성하고, jupyter 를 설치한다. 그리고 시스템 시작 스크립으로 자동으로 시작하는 jupyter notebook 환경 구성까지 진행한다. python3 설치openSUSE에 python2.7 만 설치되어 있어서, python3 를 설치한다. 다른 버전을 설치하면 openSUSE에서는 자동으로 update-alternatives로 pip를 등록해준다. 123sudo zypper in python3update-alternatives: using /usr/bin/pip3.4 to provide /usr/bin/pip (pip) in auto mode 개발자 패키지 설치jupyter 등 개발, 서버 개발에 필요한 시스템 개발도구를 설치한다. 1sudo zypper in devel_basis 파이썬 개발과 패키지등에서 필요한 파이썬 헤더를 설치한다. 1sudo zypper in python3-devel python-devel jupyter에서 필요한 zmq 라이브러리를 설치한다. 1sudo zypper in python-distutils-extra libczmq3 libgdal20 libzmq3 : jupyter 에서 필요 libgdal : geospatial analysis with geopandas. openSUSE 에서는 curses 관련 파이썬 모듈을 설치해야 한다. 1sudo zypper in python-curses python3-curses python-curses: Python이 (N)Curses Libr에 대한 인터페이스이다 virtualenvpip 로 user scheme 에서 설치했다. 1pip install --user virtualenv virtualenvwrapper Scientific 과 Pandas 개발환경사용하려는 Python 버전에 따라 혹은 모두 아래 과학계산용 모듈을 시스템 패키지로 설치한다. 123sudo zypper in python-decorator python-numpy python-scipy python-matplotlibsudo zypper in python3-decorator python3-numpy python3-scipy python3-matplotlibsudo zypper in python3-sympy python3-nose 라즈베피라이, 오드로이드 등 환경에서 pip로 위 모듈을 설치시 시간이 많이 걸린다. pip install –user pandas decorator numpy scipy matplotlib sympy nose그래서 시스템 패키지로 설치했다. 겨로가적으로 앞선 scipy, matplotlib 설치하며 아래 모듈이 의존성에 따라 함게 설치된다. 1python3-requests python3-pil python3-scrapy python3-geopy python3-shapely python3-pyproj Jupyter NotebookJupyter notebook 으로 파이선, typescript, javascript, c/c++ 등의 IDE 역할을 할 수 있다. 도한 Markdown 을 지원해서 문서화에도 휼륭한 플랫폼이다. jupyter 가상환경 만들기mkvirtualenv 명령으로 jupyter 라는 가상환경을 만드는데, 과학계산용 라이브러리를 시스템 패키지로 설치했으므로 여기서는 가상환경 생성시 시스템 패키지를 함께 참조하도록 생성한다. 12mkvirtualenv -p python3 --system-site-packages jupyter(jupyter) $ 가상환경에서 파이썬 버전을 확인하고 과학계산 개발 등에 필요한 라이브러리가 설치됐는지 확인하자. 12(jupyter) $ python --versionPython 3.4.6 필수 모듈이 설치되고 사용이 가능한지 확인한다. 버전 정보가 출력되면 관련 라이브러리가 제대로 설치되었고 가상환경에서 잘 접근되는 것이다. 다음 두 모듈이 없으면 jupyter 설치가 제대로 안된다. 설치가 안되었으면 앞의 파이썬 개발자 패키지 설치 단락을 확인한다. 12python -c &quot;import numpy;print(numpy.__version__)&quot;1.9.3 12python -c &quot;import numpy;print(numpy.__version__)&quot;0.16.0 그리고 Jupyter 가상환경에서 pip 로 Jupyter를 설치한다. 1(jupyter)$ pip install jupyter 주피커 노트북 파일이 저장되는 위치가 iPython 디렉토리라고 하면 아래 같이 시작할 수 있다. 1(jupyter)$ jupyter-notebook --no-browser --ip=* --port=8000 ./iPython 옵션은 --no-browser : 로컬 브라우저는 시작하지 않는다. --ip : 접속 가능 *는 모든 곳에서 접근 가능 --port: 이런 시작 구성을 설정 파일을 이용해서 저장할 수 있고 이 파일을 이용해서 시작하는 것을 권장한다. Jupyter 설정 파일 이용사용자 JUPYTER_DATA_DIR 인 홈 디렉토리 밑 ~/.jupyter 에 설정 파일을 구성해야 한다. 12(jupyter)$ jupyter notebook --generate-config(jupyter)$ cd .jupyter &amp;&amp; mv jupyter_notebook_config.py mynotebook.py systemdjupyter notebook을 시스템 서비스로 등록해 보자. jupyter.service라는 시스템 서비스 파일을 /etc/systemd/system/jupyter.service 에 생성하고 아래 내용을 입력한다. 123456789101112131415[Unit]Description=HomePi Jupyter-Notebook[Service]Type=simplePIDFile=/run/homepi-jupyter.pidExecStart=/home/foo/.virtualenvs/jupyter/bin/jupyter-notebook --config=/home/foo/.jupyter/mybook_config.pyUser=qkbooGroup=usersWorkingDirectory=/home/foo/iPythonRestart=alwaysRestartSec=10[Install]WantedBy=multi-user.target 그리고 이 시스템 서비스 파이을 활성화하고 시작한다. 123sudo systemctl enable jupyter.servicesudo systemctl daemon-reloadsudo systemctl restart jupyter.service Typescript kerneljupyter notebook에서 Typescript 을 작성하고 컴파일한 결과를 확인할 수 있다. 먼저 Nodejs용 itypescript 모듈을 global로 설치한다. 1npm install -g itypescript its 명령으로 Jupyter kenel로 설치해 준다. 1its --ts-install=local Jupyter-notebook Nginx 설정Jupyter-notebook 을 nginx 뒤에서 실행시 아래 같은 동작이 반복적으로 보이이면 123456[I 19:26:48.843 NotebookApp] Adapting to protocol v5.1 for kernel 97e659cd-0509-4f56-878e-10e2c31803e2[I 19:26:48.853 NotebookApp] Restoring connection for 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1[I 19:26:48.881 NotebookApp] Starting buffering for 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1[I 19:26:51.904 NotebookApp] Adapting to protocol v5.1 for kernel 97e659cd-0509-4f56-878e-10e2c31803e2[W 19:26:51.930 NotebookApp] Replacing stale connection: 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1[W 19:26:51.957 NotebookApp] Replacing stale connection: 97e659cd-0509-4f56-878e-10e2c31803e2:b4d78dff5dff4563b0e5fc7195fefca1 jupyter-notebook-keeps-reconnecting 설명 처럼 nginx proxy 에서 http 버전을 명시해 준다. If you are using jupyter behind a nginx proxy, this post may be effective. Add this line to nginx conf. 1proxy_http_version 1.1; http_proxy_module 에 따르면 keepalive 를 사용하기 위해서 1.1 버전을 꼭 사용해야 할 것 같다. Sets the HTTP protocol version for proxying. By default, version 1.0 is used. Version 1.1 is recommended for use with keepalive connections and NTLM authentication. 참조용 jupyter-notebook conf 123456789101112131415161718192021222324252627282930313233343536373839upstream my-notebook-workhorse { server 127.0.0.1:8888 fail_timeout=0;}map $http_upgrade $connection_upgrade { default upgrade; '' close;}# let my-notebook deal with the redirectionserver { listen 80; server_name my-notebook.wh; server_tokens off; root /dev/null; # Increase this if you want to upload larger attachments client_max_body_size 20m; # individual nginx logs for this vhost access_log /var/log/nginx/my-notebook_access.log; error_log /var/log/nginx/my-notebook_error.log; location / { proxy_pass http://my-notebook-workhorse; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; auth_basic &quot;Restricted Content&quot;; # WebSocket support proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_set_header Origin &quot;&quot;; proxy_read_timeout 86400; }} 참조 How to deploy nodejs app with pm2","link":"/opensuse-jeos-nginxjupyter-de42d79d18f3/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Basic Security","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 3개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.3 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x openSUSE: Basic OS Security for Server이전 글에서 라즈베리파이 3에 설치한 64bit OS openSUSE LEAP / JeOS를 서버 구성을 위해서 보안 설정을 한다. 이 글은 다음 세가지 내용을 포함하고 있다. ssh와 sshd 설정 방화벽 설정: YaST Firewall 대비 ufw 설치 Fail2ban 설치 및 설정 sshd_configssh 사용시 sshd securities 방화벽 설정openSUSE 42.3까지 SuSEfirewall2 가 기본으로 제공되어 서비스를 활성화 하면 사용할 수 있다. UFWSuSEFirewall2 을 우분투/데비안에서 익숙한 ufw 를 사용할 수 있다. 1234567891011121314151617181920Basic Syntax: yast2 firewall interactive yast2 firewall &lt;command&gt; [verbose] [options] yast2 firewall help yast2 firewall longhelp yast2 firewall xmlhelp yast2 firewall &lt;command&gt; helpCommands: broadcast Broadcast packet settings disable Disables firewall enable Enables firewall interfaces Network interfaces configuration logging Logging settings masqredirect Redirect requests to masqueraded IP masquerade Masquerading settings services Allowed services, ports, and protocols startup Start-up settings summary Firewall configuration summary zones Known firewall zones 먼저 SuSEfirewall2 를 멈추고 비활성화 한다. 1sudo yast firewall disable 12systemctl stop SuSEfirewall2systemctl disable SuSEfirewall2 그리고 ufw를 설치하고 1zypper in ufw 1234ufw default denyufw enablesystemctl enable ufwsystemctl start ufw Fail2banrsyslog 를 설치한다. https://en.opensuse.org/SDB:SSH_systematic_attack_protection https://www.howtoforge.com/fail2ban_opensuse10.3 zypper in fail2ban 참조OpenSSH Public Key Authentication https://doc.opensuse.org/documentation/leap/security/html/book.security/cha.security.firewall.html","link":"/opensuse-jeos-securities-a4b6a62d3848/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Service 관리","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 3개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.3 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x openSUSE: Basic OS Security for ServeropenSUSE는 systemd 를 사용한 서비스/데몬 시작/종료/활성화/비활성화 작업을 할 수 있다. 서비스에 대한 작업은 systemctl CLI 혹은 YaST에서 가능하다. yastopenSUSE는 yast 로 서비스 데몬도 설치/실행/멈춤 을 할 수 있다. {:width=”640”} 서비스는{:width=”640”} systemdhttps://doc.opensuse.org/documentation/leap/reference/html/book.opensuse.reference/cha.systemd.html https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal 1systemctl list-unit-files --type=service #현재 사용 가능한 모든 서비스 이 작업은 1234567systemctl stop SuSEfirewall2systemctl disable SuSEfirewall2zypper in ufwufw default denyufw enablesystemctl enable ufwsystemctl start ufw ssmtpsSMTP is a simple MTA to deliver mail from a computer to a mail hub (SMTP server). sSMTP is simple and lightweight, there are no daemons or anything hogging up CPU; Just sSMTP. Unlike Exim4, sSMTP does not receive mail, expand aliases, or manage a queue. https://wiki.debian.org/sSMTP 42.3, 15.0 에 ssmtp가 포함되지 않았다. https://build.opensuse.org/package/binaries/home:jloehel/ssmtp/openSUSE_Factory_ARM mail utitlity1$ sudo zypper install mail Then try to send email from command line with: 1$ echo &quot;Message Body&quot; | mail -s &quot;Message Subject&quot; receiver@example.com 참조[^1]: systemd: Enable/Disable Services","link":"/opensuse-services-0c2bccdb369b/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Basic Security","text":"Raspberry Pi 3 64bit OS openSUSE 는 이글은 3개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.3 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 Install 64bit openSUSE Leap 42.3 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS Build MongoDB 3.4.x openSUSE: Basic OS Security for Server이전 글에서 라즈베리파이 3에 설치한 64bit OS openSUSE LEAP / JeOS를 서버 구성을 위해서 보안 설정을 한다. 이 글은 다음 세가지 내용을 포함하고 있다. ssh와 sshd 설정 방화벽 설정: YaST Firewall 대비 ufw 설치 Fail2ban 설치 및 설정 sshd_configssh 사용시 sshd securities 방화벽 설정openSUSE는 SuSEfirewall2 가 기본으로 제공되어 서비스를 활성화 하면 사용할 수 있다. 아직 익숙치 않아서 SuSEFirewall2 을 우분투/데비안에서 익숙한 ufw 를 설치해 사용하겠다. 1234567891011121314151617181920Basic Syntax: yast2 firewall interactive yast2 firewall &lt;command&gt; [verbose] [options] yast2 firewall help yast2 firewall longhelp yast2 firewall xmlhelp yast2 firewall &lt;command&gt; helpCommands: broadcast Broadcast packet settings disable Disables firewall enable Enables firewall interfaces Network interfaces configuration logging Logging settings masqredirect Redirect requests to masqueraded IP masquerade Masquerading settings services Allowed services, ports, and protocols startup Start-up settings summary Firewall configuration summary zones Known firewall zones 먼저 SuSEfirewall2 를 멈추고 비활성화 한다. 1sudo yast firewall disable 12systemctl stop SuSEfirewall2systemctl disable SuSEfirewall2 그리고 ufw를 설치하고 1zypper in ufw 1234ufw default denyufw enablesystemctl enable ufwsystemctl start ufw Fail2banrsyslog 를 설치한다. https://en.opensuse.org/SDB:SSH_systematic_attack_protection https://www.howtoforge.com/fail2ban_opensuse10.3 sshufwfail2banzypper in fail2ban 참조OpenSSH Public Key Authentication https://doc.opensuse.org/documentation/leap/security/html/book.security/cha.security.firewall.html","link":"/opensuse-ufw-2407f166b539/"},{"title":"Raspberry Pi 3 64bit OS openSUSE: Install","text":"2017-10-30: swap 추가, timezone 수정{:.right-history} Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 이글은 5개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Install 64bit openSUSE Leap 42.2 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter openSUSE: Build MongoDB 3.4.x Install 64bit openSUSE Leap 42.2 / JeOSopenSUSE는 Raspberry Pi 3를 위한 Opensuse community edition은 정식 버전 Leap 42.2 image, 개발버전 Tumbleweed image, 커뮤니티버전 non-upstream openSUSE Tumbleweed image* 으로 구성되어 있다. 이들 버전은 용도에 따라 JeOS, E20, LXQT X11 이미지로 다운받을 수 있다. Just Enought Operating System (JeOS) jeOS 이미지는 기본 오에스만을 포함하고 있다. https://www.suse.com/products/server/jeos/ E20 데스크탑 환경으로 Enlightenment 을 사용하 GUI 이미지 LXQt LXDE-Qt 와 RazorQt 병합한 데스크탑 환경 https://en.opensuse.org/LXQt ### Download and Install Download Page 의 두번째 Installing the 64-bit openSUSE Leap image 단락에 있는 JeOS image 를 다운로드 한다. Writing image to SD CardEtcher 등을 이용해서 다운받은 이미지 파일을 SD Card에 쓴다. {:width=”640”} dd 를 사용한다면,다운받은 .xz 파일을 dd 를 이용해서 SD Card에 쓴다. 1xzcat openSUSE-Leap42.2-ARM-JeOS-raspberrypi3.aarch64.raw.xz | sudo dd of=/dev/rdisk1 bs=4m; sync #### Serial console 여기서는 Serial console에서 네트워크 확인 및 초기 설정을 하고 ssh 로 서버에 로그인해서 시스템 구성을 진행한다. SD Card를 라즈베리파이에 꽃고 HDMI, Keyboard 및 Mouse 가 별도로 준비되어 있으면 직접 모니터를 보고 작업을 진행하면 좋다. USB to Serial 케이블을 사용해서 Raspberry Pi의 Serial Console에 연결한다. {:width=”640”} 그리고 시리얼 포트를 통해 tty 연결을 위해 터미널 프로그램에서 baud rate 115200 으로 연결한다. 아래는 macOS의 screen CLI 명령으로 usb serial 포트에 연결하고 있다. 1$ screen /dev/cu.usbserial 115200 이제 SD Card를 넣고 부팅을 하면, 터미널에 부트 단계가 진행되고 처음 5분 정도 소요된다. {:width=”640”} Raspberry Pi를 위한 이미지는 처음 계정은 root/linux 이다. 터미널에서 uname 은 aarch64 임을 확인 할 수 있다. 12root# uname -aLinux homepi 4.4.90-18.32-default #1 SMP Fri Oct 6 13:30:08 UTC 2017 (465b410) aarch64 aarch64 aarch64 GNU/Linux 처음으로 라즈베리파이에서 64bit 환경으로 운영해 볼 수 있게 됐다. ### 설치 후 서버 구성을 위해 할 일 JeOS를 서버로 구성하기 위해서 다음 같은 작업을 수행해 준다. root 패스워드 변경 sudoer 사용자 생성 DHCP를 고정 IP로 변경 root 패스워드root 사용자의 패스워드를 변경한다. {:width=”640”} UpdateUbuntu/Debian 계열의 패키지 명령 apt,apt-get 과 비슷한 openSUSE 명령라인 패키지 관리자는 zypper 가 있다. 123456789zypper help search # to print help for the search commandzypper refresh, ref # Refresh all repositories.zypper update, up # to update all installed packageszypper lp # to see what patch updates are neededzypper patch # to apply the needed patcheszypper se sqlite # to search for sqlitezypper rm sqlite2 # to remove sqlite2zypper in sqlite3 # to install sqlite3zypper in yast* # to install all packages matching 'yast*' zypper usages 에서 사용방법을 자세히 알 수 있다. 머저 최신 소프트웨어 목록으로 업데이트 한다. 12zypper refreshzypper ref 그리고 최근 업그레이드된 필요한 패키지를 다운로드하고 설치한다.[^1] 12zypper updatezypper up 지원중단된 패키지, 나뉘어진 패키지 등의 의존성을 고려한 업그레이드를 하려면 dup 명령을 사용한다.&gt; 12zypper dup # distribution upgradezypper dist-upgrade upgrade 후에실행중인 데몬을 재시작해줄 필요가 있는데 zypper ps -s 를 실행하면 목록을 표시해 준다. 1234567891011121314151617181920212223242526272829303132333435pi64:/home/ # zypper ps -sThe following running processes use deleted files:PID | PPID | UID | User | Command | Service------+-------+------+------------+----------------------------+-------------------307 | 1 | 0 | root | systemd-journald (deleted) | systemd-journald484 | 1 | 0 | root | auditd | auditd502 | 1 | 1000 | qkboo | python3 | jupyter513 | 1 | 499 | messagebus | dbus-daemon (deleted) | dbus525 | 1 | 0 | root | systemd-logind (deleted) | systemd-logind529 | 1 | 0 | root | agetty (deleted) | getty@tty1996 | 1 | 0 | root | cupsd | cups1018 | 1 | 0 | root | cron | cron1043 | 1 | 74 | ntp | ntpd | ntpd1047 | 1043 | 74 | ntp | ntpd | ntpd1145 | 1 | 0 | root | python2.7 | fail2ban1146 | 1 | 1000 | qkboo | node | pm2-qkboo2131 | 1 | 0 | root | agetty (deleted) | serial-getty@ttyS05716 | 1146 | 1000 | qkboo | node | pm2-qkboo5749 | 1146 | 1000 | qkboo | node | pm2-qkboo12400 | 1 | 0 | root | sshd (deleted) |12402 | 1 | 1000 | qkboo | systemd (deleted) |12405 | 0 | 1000 | qkboo | systemd (deleted) |12411 | 12400 | 1000 | qkboo | sshd (deleted) |12412 | 12411 | 1000 | qkboo | bash |12783 | 12412 | 0 | root | sudo |12784 | 12783 | 0 | root | bash |12876 | 1 | 0 | root | nginx | nginx12879 | 12876 | 494 | nginx | nginx | nginx12880 | 12876 | 494 | nginx | nginx | nginx12881 | 12876 | 494 | nginx | nginx | nginx12882 | 12876 | 494 | nginx | nginx | nginx15908 | 502 | 1000 | qkboo | node | jupyter15916 | 15908 | 1000 | qkboo | node | jupyter26929 | 502 | 1000 | qkboo | node | jupyter ip 주소 확인ifconfig 명령으로 현재 IP Address를 확인하고 이 IP Address에 ssh 를 사용해 접속한다. 1234567891011linux:~ # ifconfigeth0 Link encap:Ethernet HWaddr B9:40:EB:BA:10:02 inet addr:192.168.1.104 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe90::ba37:ebff:feba:1012/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:83136 errors:0 dropped:0 overruns:0 frame:0 TX packets:27300 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:120797947 (115.2 Mb) TX bytes:2369690 (2.2 Mb)linux:~ #linux:~ # shutdown now 좀더 편리한 사용을 위해 ifconfig 명령으로 찾은 IP address에 ssh 로그인을 해서 작업을 진행한다. 1$ ssh root@192.168.1.104 ### 시스템 설정 이제 sudoer 사용자로 시스템을 서버에 적합하게 구성해 보자. sudoer 추가 yast 소개 timezone Network 구성: 호스트 이름, IP 주소 swap 개선 yast로 사용자 추가 sudoerroot 사용자가 아닌 일반사용자를 sudoer로 등록해 관리자 기능을 대행 할 수 있다. 그러기 위해서 먼저 사용자를 추가한다. openSUSE yast라는 시스템 도구로 할 수 있지만 여기선 useradd 명령을 사용해서 사용자 추가한다. useradd에 대해서는 useradd 명령을 참조한다. useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. 추가한 사용자를 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 추가 그리고 -m 옵션으로 으로 사용자 홈 디렉토리 까지 생성한다. 1root# useradd -m foo 그리고 패스워드를 등록한다. 1234root# passwd fooNew password:Retype new password:passwd: password updated successfully sudoer 등록visudo 명령으로 /etc/sudoers 파일을 편집한다. 1$ sudo visudo sudoer 파일에 있는 User privilege 항목 아래에 새로운 사용자 foo를 아래 같이 등록한다. 123# User privilege specificationroot ALL=(ALL) ALLfoo ALL=(ALL) ALL 이제 root에서 로그아웃하고 새로 추가한 사용자로 로그인한다. 1234$ ssh foo@192.168.1.104Password:Have a lot of fun...foo@linux:~&gt; openSUSE는 관리자용 명령을 직접 내리면 찾지 못한다고 한다. 12foo@linux:~&gt; yast2 timezone-bash: yast2: command not found 그리고 처음으로 sudoer 사용자가 관리자 권한이 필요한 명령을 사용하기 위해 sudu 로 명령을 내리면 아래 같은 경고가 나온다. 12345678foo@linux:~&gt; sudo /sbin/yast2 timezoneWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. openSUSE는 시스템 관리 도구로 yast 를 사용해서 소프트웨어 설치, 네트워크 구성, 시간 관리, 보안 및 사용자 등을 다루는 소프트웨어로 GUI와 CLI 모두 사용할 수 있다. 시스템 네트워크를 구성하기 위해서 yast 명령을 사용해보자, yastyast는 GUI 혹은 ClI에서 사용이 가능하다 . 다음은 sudo yast 를 실행하면 Ncurse 로 표시되는 yast 화면이다. {:width=”640”} TAB 키로 각 항목을 이동할 수 있고, Enter로 실행한다. 전체 화면에서 F9는 Cancel, F10은 OK 기능을 수행한다. Timezone처음 설치후 CET 시간대로 되어 있어서 Asia/Seoul로 변경하고자 한다. 12linux:~ # dateSun Oct 29 09:19:31 CET 2017 시스템 시간대를 설정하려면 yast 를 시작해 System -&gt; Date and Time 을 실행해 시간대를 지정한다. 혹은 yast timezone 모듈 명령을 주면 해당 Date and Time 화면으로 이동할 수 있다. {:width=”640”} 시간대를 변경후 확인해 보면, 12linux:~ # dateSun Oct 29 17:22:11 KST 2017 ntp로 동기화하려면 Other Settings… 항목을 선택해 ntp server 를 설치하고 활성화 한다. {:width=”640”}{:width=”640”}","link":"/opensuse-jeos-install-4313818eeceb/"},{"title":"Rasberry Pi Camera 개발환경 구성","text":"piCamera 구성현재 시스템 정보 12$ uname -aLinux camerapi 4.9.35-v7+ #1014 SMP Fri Jun 30 14:47:43 BST 2017 armv7l GNU/Linux Science modules123sudo apt-get install build-essential python-dev python-distlib python3-dev python3-distlibsudo apt-get install libzmq3-devsudo apt-get install libgdal-dev 12345$ sudo apt-get install python-numpy python-decorator python-scipy$ sudo apt-get install python-matplotlib$ sudo apt-get install python3-decorator python3-numpy python3-scipy$ sudo apt-get install python3-matplotlib Jupyter-notebook123456$ mkvirtualenv -p python3 --system-site-packages cv3python3$(cv3python3) $ pip install jupyter(cv3python3) $ jupyter-notebook --no-browser --ip=* --port=8585 jupyterCamera/ Camera카메라 파이썬 모듈은 pip에서 설치하는 것으로 하자. 패키로 설치시 1$ sudo apt-get install python-picamera python-numpy python-rpi.gpio python-opencv ffmpeg cv3","link":"/run-pi-camerapi-5ee71f3fd8e4/"},{"title":"synergy build","text":"2017-09-17: 최초 작성{:.right-history} SynergySynergy는 키보드와 마우스 자원을 공유할 수 있는 클라이언트 서버 프로그램이다. 홈페이지: https://symless.com/synergy Github: https://github.com/symless/synergy-core {:width=”600”} [그림. Synergy 통한 결합 (symless.com)] https://symless.com/synergy 에서 유료 가입도 가능하고, 소스 기반의 배포본을 직접 빌드해서 사용할 수 있다. 사용하는 Mac과 Arm 기반의 Orangepiplus, Raspberry Pi 사이의 키보드/마우스 공유를 위해서 Synergy를 사용하는데, Arm 기반의 바이너리가 없어서 빌드를 하는 과정을 기록했다. Build여기서는 다음 저장소의 버전을 사용. https://github.com/brahma-dev/synergy-stable-builds 위 페이지의 releases 페이지에 MacOS 버전은 dmg 로 제공받을 수 있다. 다만 Arm 기반 머신의 바이너리는 없어서 소스 빌드를 해야 한다. 다운로드한 소스에서 README 파일을 참고해서 빌드를 한다. 사전 준비소스 빌드를 위해서 개발용 패키지가 필요하다. 여기서 Ubuntu, Debian 계열에서 필요한 패키지만 나열했다. [^1] Ubuntu 10.04 to 15.10 1sudo apt-get install cmake make g++ xorg-dev libqt4-dev libcurl4-openssl-dev libavahi-compat-libdnssd-dev libssl-dev libx11-dev Debian 7/8 1sudo apt-get install build-essential cmake libavahi-compat-libdnssd-dev libcurl4-openssl-dev libssl-dev lintian python qt4-dev-tools xorg-dev fakeroot Orangepi Plus현재 Orangepiplus 머신에 Armbian 릴리즈를 설치해서 사용중이다. 그런데 빌드중 gtest, qmake 관련한 에러가 발생해서 libgtest와 qt4-qmake 를 설치했다. 12sudo apt install libgtest-devsudo apt install qt4-qmake libqt4-dev build소스를 git으로 다운로드한다. 123git clone https://github.com/brahma-dev/synergy-stable-builds.git synergycd synergycat README README에서 “hm conf” 와 “hm build” 로 빌드한다고 한다. 쉘 유틸리티 hm.sh 를 사용한다. 1./hm.sh 먼저 빌드환경을 설정 - hm.sh genlist 결과 중에서 선택한다. 123$ ./hm.sh genlist1: Unix Makefiles2: Eclipse CDT4 - Unix Makefiles 해당 빌드환경으로 선택해 설정을 시작한다. 12345$ ./hm.sh conf -g 1Mapping command: conf -&gt; configureRunning setup...Setup complete.cmake version 3.5.1 빌드를 진행한다 - 거의 1시간 이상 소요 허…ㄱ 허…ㄱ 1$ ./hm.sh build 빌드중 다음같은 qmake 에러가 발생하면 12Going back to: /home/qkboo/Hdd/synergy-stable-buildsError: Could not test for cmake: qmake: could not exec '/usr/lib/arm-linux-gnueabihf/qt4/bin/qmake': No such file or directory qt4-qmake를 설치해 준다. 1sudo apt install qt4-qmake libqt4-dev 빌드가 완료되면 build/bin 디렉토리 밑의 실행 파일을 적당한 곳에 옮겨 놓고 synergy 를 실행하면 된다. synergy 사용보통 서버는 마우스/키보드를 공유할 컴퓨터이고, 클라이언트는 공유 마우스/키보드를 사용할 컴퓨터이다.그러므로 같은 네트워크에 있는 컴퓨터여야 한다. ( 같은 허브, 라우터 등) 아래 같이 해주면 기본적으로 마우스/키보드를 서버-클라이언트에서 사용할 수 있다. (1) 먼저 클라이언트에서 synergy를 실행해서 클라이언트 screen name을 정한다. 보통 호스트 이름이 그대로 사용된다.이 screen name으로 서버에서 접속을 허용되므로 주의해야 한다. (2) 서버에서 synergy를 실행해 클라이언트를 추가하고 클라이언트의 screen name을 입력해준다. {:width=”600”} ## 참조 [^1]: 실제 공식 컴파일 위키","link":"/2017-09-17-synergy-build-030fd717b4d4/"},{"title":"webpack 기반 angularjs 프로젝트 빌드","text":"Webpack 과 angularjsangular.js 프로젝트를 webpack 기반으로 시도해 보자. 새 프로젝트프로젝트 구조를 준비한다. 123$ mkdir myproject &amp;&amp; cd myproject$ git init$ npm init --yes 프로젝트 초기 구조를 시작했음을 커밋으로 기록하자. 12$ git add package.json$ git commit -m 'Initialize git and npm' 아래는 여기 소스느 https://github.com/zamarrowski/pokemon-poc 를 참조. angularjs 실행에 필요한 패키지를 설치하기 위해서 다음 명령을 실행한다. 1npm i angular angular-ui-router 1npm i -D webpack webpack-dev-server","link":"/build-webpack-angular-d956768c7e55/"},{"title":"npm과 webpack 기반 빌드","text":"Build tools for Frontend: webpack, gulp 설치webpack, gulp 설치typescript, gulp는 global 로 설치하자, 자주 쓰일 수 있다. gulp-cli, 를 글로벌로 설치하고 프로젝트에서 webpack 등 모듈을 설치한다. 1npm i -g -D gulp-cli typescript gulp-typescript 를 설치하고 dev 의존성으로 저장한다. 1npm i -D gulp-typescript 개발용 Http server를 설치한다. 많이 사용되는 서버로 http-server, lite-server가 있다. npm 으로 HTTP 서버를 띄워서 작업을 쉽게 할 수 있도록 http-server을 글로벌로 설치한다. 1npm i -g -D http-server lite-server를 사용해도 되는데, 서버 개발시 실시간 리로딩과 browser-sync (lite-server의 하부 모델)를 이용해 HTML, CSS, JS 를 테스트한다. 1$ npm i -g -D lite-server 결과를 브라우저에서 확인해 보자. 1http-server -p 3000 -c-1 ./src&quot; 12$ git add package.json$ git commit -m 'add http-server' webpack12npm i -D webpacknpm i -D webpack@&lt;version&gt; 로컬 설치시 node_modules/.bin/webpack 으로 실행할 수 있다. package.json 에 webpack을 시작 명령으로 해준다. 123&quot;scripts&quot;: { &quot;start&quot;: &quot;webpack --config webpack.config.js&quot;} 소스 디렉토리src 폴더를 html, js 소스를 모두 포함하게 구성하자. 1234$ cd src$ mkdir js$ mv index.js js$ mv ../index.html . 프로젝트 폴더는 아래 같이 구성된다. 123456webpack-demo |- package.json |- /src |- /js |- index.js |- index.html 12$ git add index.html src/$ git commit -m 'all source at src' 외부 라이브러리lodash 를 예로 들어 보자, lodash를 설치한다. 1npm i lodash ES2015의 import 구문을 이용해 외부 라이브러리를 들여온 후 webpack으로 빌드하면 하나의 최적화된 자바스크립 소스에 내장할 수 있다. 예를 들어 src/js/index.js 에 lodash 를 들여온다. 123456789101112import _ from &quot;lodash&quot;;function component() { var element = document.createElement(&quot;div&quot;); // Lodash, now imported by this script element.innerHTML = _.join([&quot;Hello&quot;, &quot;webpack&quot;], &quot; &quot;); return element;}document.body.appendChild(component()); 역시 src/index.html 도 &lt;script&gt;로 들여온 lodash를 빌드 결과물 bundle.js 로 스크립트를 변경한다. 123&lt;body&gt; &lt;script src=&quot;js/bundle.js&quot;&gt;&lt;/script&gt;&lt;/body&gt; 커밋한다. 12$ git add package.json package-lock.json src/git commit -m 'add lodash and commit to source' bundle.jsnode_modules/.bin/webpack 로 실행할 수 있으므로 src/js/index.js 를 진입점으로 해서 결과를 src/js/bundle.js 로 저장할 수 있다. 12345678910$ ./node_modules/.bin/webpack src/js/index.js src/js/bundle.jsHash: ee3bf1d517f9a2f682ceVersion: webpack 3.8.1Time: 2511ms Asset Size Chunks Chunk Namesbundle.js 544 kB 0 [emitted] [big] main [0] ./src/js/index.js 255 bytes {0} [built] [2] (webpack)/buildin/global.js 488 bytes {0} [built] [3] (webpack)/buildin/module.js 495 bytes {0} [built] + 1 hidden module Webpack configurationES2015 표준의 import, export 구문은 기존 브라우저들이 지원되지 않는 경우가 많다. 그래서 ECMA6 를 ECMA5 로 전환 컴파일 하려면 Babel 같은 패키지를 사용한다. 이들 패키지지는 webpack 적재시스템을 통해 사용한다. 또 복잡한 프로젝트 요구를 위해서 설정 파일을 이용해 구성 가능하다. 이런 시나리오를 고려해 보자 webpack.config.js 에 소스 및 빌드 디렉토리가 명시되고 src/js/index.js 를 dist/assets/js/app.min.js 로 복사된다. src/[html,js,css] 를 build/[html,assets/[js,css,images,ext]] 로 복사한다. webpack configuration 파일은 webpack.config.js에 설정을 구성한다. 설정 구성 내용은 아래 같다. 1234567const path = require(&quot;path&quot;);module.exports = { entry: &quot;./src/*&quot;, output: { filename: &quot;&quot;, path: path.resolve(__dirname, &quot;&quot;) }, plugins: [],}; 소스와 라이브러리 빌드 구성하기,CopyWebpack plugin 은 파일 혹은 디렉토리를 빌드 디렉토리로 복사해 준다. 1npm i -D copy-webpack-plugin CopyWebpackPlugin은 객체를 생성해 사용한다. new CopyWebpackPlugin([patterns], options) pattern: { from: ‘source’, to: ‘dest’ } webpack.config.js 을 프로젝트 루트에 저장하고 아래 같은 내용을 갖는다. webpack.config.js 파일에 플러그인을 구성한다. 1234567891011const path = require(&quot;path&quot;);var CopyWebpackPlugin = require(&quot;copy-webpack-plugin&quot;);module.exports = { entry: &quot;./src/js/index.js&quot;, output: { filename: &quot;js/bundle.js&quot;, path: path.resolve(__dirname, &quot;build/&quot;), }, plugins: [new CopyWebpackPlugin([{ from: &quot;src/index.html&quot; }])],}; webpack 으로 빌드가 이루어지고 복사가 되는지 확인해 보자. webpack 을 시작하고 build 디렉토리를 확인해 보자. 1$ ./node_modules/.bin/webpack --config webpack.config.js 웹 서버로 build 디렉토리를 시작해서 브라우저에서 확인해 보자. npm 스크립트npm으로 빌드와 테스트 서버 시작을 할 수 있도록 다음 같이 수정한다. 12345&quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;start&quot;: &quot;http-server -p 3000 -c-1 ./build&quot;, &quot;build&quot;: &quot;NODE_ENV=developement node node_modules/.bin/webpack --config webpack.config.js&quot;}, 이제 npm으로 build 스크립을 지시할 수 있다.command and your parameters, e.g. npm run build – –colors. 1npm run build 그리고 서버를 시작해 브라우저로 결과를 확인해 보자. 커밋한다. 1$ git add package* webpack.config.js &quot;start&quot;: &quot;node node_modules/.bin/webpack-dev-server --content-base app&quot;, &quot;test&quot;: &quot;NODE_ENV=test karma start&quot;, &quot;build&quot;: &quot;NODE_ENV=production node node_modules/.bin/webpack --config webpack.config.js &amp;&amp; cp src/index.html dist/index.html&quot;, file-loader pluginfile-loader 는 npm i -D webpack-stream Babel12npm i -D babel-core babel-loader babel-preset-latestnpm install babel-core babel-loader babel-preset-es2015 루트에 .babelrc 파일을 만들고 1{ &quot;presets&quot;: [ &quot;es2015&quot; ] } ### 프로젝트 태스크 관련 1npm i -D bower-main gulp-load-plugins gulp-rename gulp-uglify gulp-autoprefixer gulp-uglifycss gulp-watch del gulp-clean-dest 설치한 후 package.json 에 다음 같이 추가된다. 1234567891011121314&quot;devDependencies&quot;: { &quot;bower&quot;: &quot;^1.7.9&quot;, &quot;bower-main&quot;: &quot;^0.2.14&quot;, &quot;gulp&quot;: &quot;^3.9.1&quot;,}devDependencies { &quot;gulp-autoprefixer&quot;: &quot;^3.1.0&quot;, &quot;gulp-load-plugins&quot;: &quot;^1.2.4&quot;, &quot;gulp-rename&quot;: &quot;^1.2.2&quot;, &quot;gulp-uglify&quot;: &quot;^1.5.4&quot;, &quot;gulp-uglifycss&quot;: &quot;^1.0.6&quot;, &quot;gulp-watch&quot;: &quot;^4.3.8&quot;} gulfile.js 관련앞서 설치한 태스크를 사용한 프로젝트 태스크를 gulpfile.js 에 선언한다. gulp 모듈을 들여오고, 작업을 진행할 source 디렉터리와 결과물을 보관할 build 디렉터리를 지정한다. 1234567891011121314var gulp = require(&quot;gulp&quot;);const webpack = require(&quot;webpack&quot;);const webpackStream = require(&quot;webpack-stream&quot;);const webpackConfig = require(&quot;./webpack.config.js&quot;);var src = &quot;./src/&quot;;var dest = &quot;./build/&quot;;gulp.task(&quot;js&quot;, () =&gt; { gulp .src(src + &quot;/js/index.js&quot;) .pipe(webpackStream(webpackConfig), webpack) .pipe(gulp.dest(&quot;./dist/js&quot;));}); run그리고 package.json의 scripts 부분에 아래와 같은 내용을 추가하고, npm install 명령을 이용해서 최초 구성을 할 때 bower install 명령이 함께 실행되도록 한다. 위 두 가지 내용을 scripts 의 postinstall 과 start 속성으로 추가합니다. 1234567... &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;postinstall&quot;: &quot;bower install&quot;, &quot;start&quot;: &quot;http-server -a localhost -p 8000 -c-1 ./build&quot; },... 최종적으로, 필요 패키지가 설치됐는지 확인하고, 1npm install 이제 gulp 빌드를 시작하면 src 디렉터리를 만들고, sample 디렉토리에 디렉토리 js, css, html 를 src 디렉터리에 복사한다. 1gulp gulp로 빌드 태스크를 시작하고 Ctrl+C로 종료한다. 그리고 build 밑에 소스가 생성되었는지 확인다. 1234$ ll build/assets/index.htmlview/ http-server를 실행한다. 1npm start angular-seedangularjs 기본 프로젝트 구성을 가진 저장소로 bower, gulp 기반으로 제공된다. 1git clone https://github.com/angular/angular-seed.git 참조https://pawelgrzybek.com/using-webpack-with-gulpjs/http://webpack.github.io/docs/motivation.html https://andy-carter.com/blog/a-beginners-guide-to-package-manager-bower-and-using-gulp-to-manage-components","link":"/build-webpack-gulp-49ad6c6a10b3/"},{"title":"npm과 webpack 기반 빌드","text":"Build tools for Frontend기존 npm + bower + gulp 혹은 npm + ? + gulp 같이 쓰이다, yarn의 등장으로 npm 개선이 활발하고 해서 npm + gulp, npm + webpack 및 gulp 같은 쓰임이 대세인듯하다. npm 란Node.js 모듈의 의존성 관리. Webpackhttps://github.com/gaw508/bootstrap-starter-projectgit hub의 webpack-demo 저장소에 있다. WebpackWebPack은 ES6 코드로 핵심 모듈을 작성해 프론트 엔드 시스템을 빌드할 수 있다. 다음 핵심 개념을 이해할 필요가 있다. Entry내부 의존성 그래프를 결과 빌드 시작에 사용하는 모듈을 가르킨다. Output Loaders Plugins entry설정 파일에 하나 또는 그 이상의 entry 속성을 선언할 수 있다. entry points 문서를 참조. 123module.exports = { entry: &quot;./path/to/my/entry/file.js&quot;,}; Outoutoutput 속성은 번들을 생성하고 이름을 붙이는 것을 말한다. 123456789const path = require(&quot;path&quot;);module.exports = { entry: &quot;./path/to/my/entry/file.js&quot;, output: { path: path.resolve(__dirname, &quot;dist&quot;), filename: &quot;my-first-webpack.bundle.js&quot;, },}; 이곳 output 속성에 대해 자세히 알 수 있다. Loadersloaders는 webpack은 자바스크립을 이해하지마 다른 처리를 할 수 있게 해준다. 기본적으로 로더는가 처리하는 파일은 모듈로 다뤄질 수 있다. 크게 로더는 설정에서 두 가지 목적을 갖는다. 어떤 파일이 이런 로더로 변형되는지 식별한다 (test 속성 사용) 의존성 그래프에 추가할 수 있게 파일을 변형한다 - 모듈이 된다 (use 속성 사용) 다음은 import, resolve에 .txt 파일이 있으면 모듈로 추가하기 전에 raw-loader 를 사용하라는 설정이다. 12345678910111213const path = require(&quot;path&quot;);const config = { entry: &quot;./path/to/my/entry/file.js&quot;, output: { path: path.resolve(__dirname, &quot;dist&quot;), filename: &quot;my-first-webpack.bundle.js&quot;, }, module: { rules: [{ test: /\\.txt$/, use: &quot;raw-loader&quot; }], },};module.exports = config; rules 속성은 test와 use 속성을 필요로 한다. 로더에 대해 더 자세히 알고 싶으면 Loaders를 참고하라. Plugins플러그인은 최적화, 최소화, 환경변수 등의 넓은 범위의 일을 할 수 있다. plugin interface는 강력한 힘을 줄 수 있다. 플러그인은 require() 구뭉을 사용한다. 그리고 new 연산자로 객체롤 plugins 배열에 추가해 준다. 12345678910111213141516171819const HtmlWebpackPlugin = require(&quot;html-webpack-plugin&quot;); //installed via npmconst webpack = require(&quot;webpack&quot;); //to access built-in pluginsconst path = require(&quot;path&quot;);const config = { entry: &quot;./path/to/my/entry/file.js&quot;, output: { path: path.resolve(__dirname, &quot;dist&quot;), filename: &quot;my-first-webpack.bundle.js&quot;, }, module: { rules: [{ test: /\\.txt$/, use: &quot;raw-loader&quot; }], }, plugins: [ new webpack.optimize.UglifyJsPlugin(), new HtmlWebpackPlugin({ template: &quot;./src/index.html&quot; }), ],};module.exports = config; 첫번째 프로젝트여기 샘플 프로젝트 webpack-demo 폴더 구조는 보통 다음과 같다. 12345webpack-demo |- package.json+ |- index.html+ |- /src+ |- index.js 프로젝트 폴더에서 package.json 파일을 만들기 위해 초기화 한다. 123mkdir webpack-democd webpack-demogit init .gitignore 12node_modules/**build/** 12git add .gitignoregit commit -m 'add gitignore' src 파일webpack getting started 샘플 src/index.js 123456789function component() { var element = document.createElement(&quot;div&quot;); // Lodash, currently included via a script, is required for this line to work element.innerHTML = _.join([&quot;Hello&quot;, &quot;webpack&quot;], &quot; &quot;); return element;}document.body.appendChild(component()); index.html 123456789&lt;html&gt; &lt;head&gt; &lt;title&gt;Getting Started&lt;/title&gt; &lt;script src=&quot;https://unpkg.com/lodash@4.16.6&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=&quot;./src/index.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 소스 추가 12$ git add index.html src/$ git commit -m 'add sample source' npm init1npm init --yes 이렇게 생성된 package.json 은, 1234567891011{ &quot;name&quot;: &quot;webpack-demo&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;} 12$ git add package.json$ git commit -m 'initialize npm' webpack 설치typescript, 는 global 로 설치하자, 자주 쓰일 수 있다. 1npm i -g -D typescript 개발용 Http server를 설치한다. 많이 사용되는 서버로 http-server, lite-server가 있다. npm 으로 HTTP 서버를 띄워서 작업을 쉽게 할 수 있도록 http-server을 글로벌로 설치한다. 1npm i -g -D http-server 결과를 브라우저에서 확인해 보자. 1http-server -p 3000 -c-1 ./src&quot; webpack-dev-server”: “2.2.0” 를 설치하자 12$ git add package.json$ git commit -m 'add http-server' ### webpack webpack은 12npm i -D webpacknpm i -D webpack@&lt;version&gt; 로컬 설치시 node_modules/.bin/webpack 으로 실행할 수 있다. package.json 에 webpack을 시작 명령으로 해준다. 123&quot;scripts&quot;: { &quot;start&quot;: &quot;webpack --config webpack.config.js&quot;} 소스 디렉토리src 폴더를 html, js 소스를 모두 포함하게 구성하자. 1234$ cd src$ mkdir js$ mv index.js js$ mv ../index.html . 프로젝트 폴더는 아래 같이 구성된다. 123456webpack-demo |- package.json |- /src |- /js |- index.js |- index.html 12$ git add index.html src/$ git commit -m 'all source at src' 외부 라이브러리lodash 를 예로 들어 보자, lodash를 설치한다. 1npm i lodash ES2015의 import 구문을 이용해 외부 라이브러리를 들여온 후 webpack으로 빌드하면 하나의 최적화된 자바스크립 소스에 내장할 수 있다. 예를 들어 src/js/index.js 에 lodash 를 들여온다. 123456789101112import _ from &quot;lodash&quot;;function component() { var element = document.createElement(&quot;div&quot;); // Lodash, now imported by this script element.innerHTML = _.join([&quot;Hello&quot;, &quot;webpack&quot;], &quot; &quot;); return element;}document.body.appendChild(component()); 역시 src/index.html 도 &lt;script&gt;로 들여온 lodash를 빌드 결과물 bundle.js 로 스크립트를 변경한다. 123&lt;body&gt; &lt;script src=&quot;js/bundle.js&quot;&gt;&lt;/script&gt;&lt;/body&gt; 커밋한다. 12$ git add package.json package-lock.json src/git commit -m 'add lodash and commit to source' bundle.jsnode_modules/.bin/webpack 로 실행할 수 있으므로 src/js/index.js 를 진입점으로 해서 결과를 src/js/bundle.js 로 저장할 수 있다. 12345678910$ ./node_modules/.bin/webpack src/js/index.js src/js/bundle.jsHash: ee3bf1d517f9a2f682ceVersion: webpack 3.8.1Time: 2511ms Asset Size Chunks Chunk Namesbundle.js 544 kB 0 [emitted] [big] main [0] ./src/js/index.js 255 bytes {0} [built] [2] (webpack)/buildin/global.js 488 bytes {0} [built] [3] (webpack)/buildin/module.js 495 bytes {0} [built] + 1 hidden module Webpack configurationES2015 표준의 import, export 구문은 기존 브라우저들이 지원되지 않는 경우가 많다. 그래서 ECMA6 를 ECMA5 로 전환 컴파일 하려면 Babel 같은 패키지를 사용한다. 이들 패키지지는 webpack 적재시스템을 통해 사용한다. 또 복잡한 프로젝트 요구를 위해서 설정 파일을 이용해 구성 가능하다. 이런 시나리오를 고려해 보자 webpack.config.js 에 소스 및 빌드 디렉토리가 명시되고 src/js/index.js 를 dist/assets/js/app.min.js 로 복사된다. src/[html,js,css] 를 build/[html,assets/[js,css,images,ext]] 로 복사한다. webpack configuration 파일은 webpack.config.js에 설정을 구성한다. 설정 구성 내용은 아래 같다. 1234567const path = require(&quot;path&quot;);module.exports = { entry: &quot;./src/*&quot;, output: { filename: &quot;&quot;, path: path.resolve(__dirname, &quot;&quot;) }, plugins: [],}; 소스와 라이브러리 빌드 구성하기,CopyWebpack plugin 은 파일 혹은 디렉토리를 빌드 디렉토리로 복사해 준다. 1npm i -D copy-webpack-plugin CopyWebpackPlugin은 객체를 생성해 사용한다. new CopyWebpackPlugin([patterns], options) pattern: { from: ‘source’, to: ‘dest’ } webpack.config.js 을 프로젝트 루트에 저장하고 아래 같은 내용을 갖는다. webpack.config.js 파일에 플러그인을 구성한다. 1234567891011const path = require(&quot;path&quot;);var CopyWebpackPlugin = require(&quot;copy-webpack-plugin&quot;);module.exports = { entry: &quot;./src/js/index.js&quot;, output: { filename: &quot;js/bundle.js&quot;, path: path.resolve(__dirname, &quot;build/&quot;), }, plugins: [new CopyWebpackPlugin([{ from: &quot;src/index.html&quot; }])],}; webpack 으로 빌드가 이루어지고 복사가 되는지 확인해 보자. webpack 을 시작하고 build 디렉토리를 확인해 보자. 1$ ./node_modules/.bin/webpack --config webpack.config.js 웹 서버로 build 디렉토리를 시작해서 브라우저에서 확인해 보자. npm 스크립트npm으로 빌드와 테스트 서버 시작을 할 수 있도록 다음 같이 수정한다. 12345&quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;start&quot;: &quot;http-server -p 3000 -c-1 ./build&quot;, &quot;build&quot;: &quot;NODE_ENV=developement node node_modules/.bin/webpack --config webpack.config.js&quot;}, 이제 npm으로 build 스크립을 지시할 수 있다.command and your parameters, e.g. npm run build – –colors. 1npm run build 그리고 서버를 시작해 브라우저로 결과를 확인해 보자. 커밋한다. 1$ git add package* webpack.config.js &quot;start&quot;: &quot;node node_modules/.bin/webpack-dev-server --content-base app&quot;, &quot;test&quot;: &quot;NODE_ENV=test karma start&quot;, &quot;build&quot;: &quot;NODE_ENV=production node node_modules/.bin/webpack --config webpack.config.js &amp;&amp; cp src/index.html dist/index.html&quot;, file-loader pluginfile-loader 는 npm i -D webpack-stream Babel12npm i -D babel-core babel-loader babel-preset-latestnpm install babel-core babel-loader babel-preset-es2015 참조https://pawelgrzybek.com/using-webpack-with-gulpjs/","link":"/build-npm-webpack-6722046a724b/"},{"title":"Gulp와 Bower","text":"Gulp와 Boweryarn이 bower 지원을 중단하고 yarn이 bower_components를 node_modules 로 이동함에 따라 bower 대신 npm (yarn), webpack 으로 전환이 되고 있다. [^Using Bower with Yarn], [^Migrate from Bower to npm and Webpack] Bower 란 자바스크립 모듈의 의존성 관리. 예) angularjs, angular-material 등 의존성 관리 트위터에서 만든 프론트 엔드의 패키지를 관리해주는 도구이다. https://bower.io Gulp 빌더 Bowerjavascript라이브러리 뿐만 아니라 css도 포함되는 ui 컴퍼넌트들은 해당 라이브러리들의 경로 문제도 있어 다양한 라이브러리 사용시의존성 문제가 더더욱 발생된다. 이러한 점을 쉽게 bower를 이용해 해결이 가능하며, 사용하는 라이브러리들의 업데이트 사항도 체크가 가능하니 매우 편하다. bower 은 gulp, npm 에서 스크립트로 실행해서 프로젝트의 로컬로 설치해도 무방하다. 1npm i bower Bower 명령어bower를 이용하여 패키지를 설치를 하고 싶은경우 bower install이라는 명령어를 이용하면 패키지가 설치가 가능하다. 1bower install &lt;패키지명&gt; 만약 jquery를 설치하고 싶은 경우는 아래와 같이 입력하면된다. 1bower install jquery 특정 버전을 설치하고 싶은 경우는 뒤에 #버전을 입력하면 가능하다. 1bower install jquery#1.11.1 패키지를 삭제하고 싶은경우는 install 대신 uninstall로 입력한다. 1bower uninstall &lt;패키지명&gt; Bower.jsonbower의 경우도 npm과 마찬가지로 패키지 명시를 파일로 관리하게된다. npm은 package.json을 이용하여 관리하였지만 bower는 bower.json 파일로 관리하게되며 마찬가지로 bower init 명령어를 통하여 쉽게 생성이 가능하다. 세부 내역은 bower.json 에서 확인할 수 있다. 12345{ &quot;name&quot;: &quot;packageName&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;ignore&quot;: [&quot;**/.*&quot;, &quot;node_modules&quot;, &quot;components&quot;]} Name필수값이며, 패키지 명칭이다 npm과 마찬가지고 패키지의 명칭을 이용하여 install이 가능하다. version패키지 버전정보 사실 bower로 배포하는게 아니라면 크게 의미없는 항목이다. ignorebower가 설치할때 무시할 항목이다. dependencies/devDependencies의존성 관리 항목이다. dev가 붙은건 개발시에만 필요한 의존성 라이브러리로 bower에 배포할게 아니라면 크게 구분할 의미가 없다. .bowerrc.bowerrc 파일은 bower 가 실행될 때 항상 먼저 실행이 되는 기본적이 내용을 정의하게 된다. bower config 에 세부 내역을 확인할 수 있다. Gulpgulp-cli, 를 글로벌로 설치하고 프로젝트에서 gulp, bower 모듈을 설치한다. gulp-cli 를 글로벌로 설치한다. 1npm i -g gulp-cli gulpfile.js를 만들고 필요한 task 들을 정의 proj 폴더 루트에 gulpfile.js 를 작성한다. 1234567var gulp = require(&quot;gulp&quot;);var ts = require(&quot;gulp-typescript&quot;);var tsProject = ts.createProject(&quot;tsconfig.json&quot;);gulp.task(&quot;default&quot;, function () { return tsProject.src().pipe(tsProject()).js.pipe(gulp.dest(&quot;dist&quot;));}); 첫번째 프로젝트이 bower, gulp 이용한 프로젝트 폴더 구조는 보통 다음과 같다. 12345678./myproject/ |______bower_components/ |______build/ |______node_modules/ |______src/ |______bower.json |______gulpfile.js |______.bowerrc 프로젝트 폴더에서 package.json 파일을 만들기 위해 초기화 한다. 123mkdir myprojectcd myprojectgit init .gitignore 파일 123bower_components/**node_modules/**build/** gitignore 파일을 추가하고 커밋 12git add .gitignoregit commit -m 'add gitignore' npm init1npm init 이렇게 생성된 package.json 은, 1234567891011{ &quot;name&quot;: &quot;myproject&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;} 이어서 typescript, gulp, gulp-typescript, bower 를 설치하고 dev 의존성으로 저장한다. 12npm install --save-dev typescript gulp gulp-typescriptnpm install --save-dev bower package.json에 의존성 패키지가 명시되면 패키지 버전이 명시되는데 이 방법을 Semantic Versioning(Semver)라고 한다. started/semantic-versioning 참고한다. bower 스크립트bower init 를 실행해서 1bower init 기본값으로 bower.json 파일을 생성하면, 1234567891011121314151617{ name: 'bower_gulp_exam', description: '', main: 'index.js', authors: [ 'gangtai &lt;gangtai.goh@gmail.com&gt;' ], license: 'ISC', homepage: '', ignore: [ '**/.*', 'node_modules', 'bower_components', 'test', 'tests' ]} 그리고 .bowerrc 파일에 의존성 파일들을 다운로드 할 디렉터리만 설정한다. 123{ &quot;directory&quot;: &quot;bower_components&quot;} bower 명령어를 통해서 angular-material, angular-loader, angular-route 패키지를 추가한다. 1bower install --save angular-material angular-loader angular-route 패키지가 추가된 bower.json 은 다음 같다. 12345678910111213141516171819202122{ &quot;name&quot;: &quot;blog-npm&quot;, &quot;description&quot;: &quot;Npm + Bower + Gulp for client web development&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;authors&quot;: [ &quot;road &lt;roadkh@gmail.com&gt;&quot; ], &quot;license&quot;: &quot;ISC&quot;, &quot;homepage&quot;: &quot;&quot;, &quot;ignore&quot;: [ &quot;**/.*&quot;, &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;test&quot;, &quot;tests&quot; ], &quot;dependencies&quot;: { &quot;angular-material&quot;: &quot;^1.0.9&quot;, &quot;angular-loader&quot;: &quot;^1.5.7&quot;, &quot;angular-route&quot;: &quot;^1.5.7&quot; }} 프로젝트 태스크 관련gulp는 빌드를 위한 task를 정의하므로 여기서 myproject에서 처리할 태스크는 다음 같다: (1) bower_components 하위에 있는 모듈들을 디렉터리 구조를 유지하면서 그 안에 있는 js와 css를 build/assets/ext 디렉터리로 복사합니다. 이때 해당 모듈의 minify 된 js와 css가 있으면 해당 js와 css를 복사하고 없으면 일반 js와 css를 복사합니다. (2) src/js 하위에 있는 자바스크립트 파일을 minify하고 파일명을 .min.js 형식으로 변경한 후에 build/assets/js 에 디렉터리구조를 유지하면서 복사합니다. (3) src/css 하위에 있는 css 파일을 읽어서 지정된 브라우저 설정에 맞는 처리를 진행하고 minify 한 후에 파일명을 .min.css 형식으로 변경하여 build/assets/css 에 디렉터리 구조를 유지하면서 복사합니다. (4) src/html 에 있는 html 파일을 디렉터리 구조를 유지하면서 build/ 폴더로 복사합니다.목업 작업 중 위에 지정한 작업이 계속해서 이루어져서 일일이 명령어를 치지 않도록 합니다. 마지막으로 build 디렉터리를 지우는 명령도 있었으면 합니다. 이 태스크를 다루기 위한 모듈을 추가로 설치한다. 추가 할 모듈은 아래와 같습니다: gulp-load-plugins : 지금부터 설치할 모든 npm 중 gulp 관련 모듈 패키지들을 쉽게 사용. bower-main : bower_components 폴더의 파일에 대한 처리를 위해 추가. gulp-rename : 파일명을 바꾸기 위해 추가. gulp-uglify : 자바스크립트의 minify 처리를 위해 추가. gulp-autoprefixer : 지원하고자 하는 브라우저의 정보를 설정해서 적절한 처리를 자동으로 진행하게 하는 모듈 패키지. https://www.npmjs.com/package/gulp-autoprefixer 의 내용을 참고. gulp-uglifycss : CSS 파일의 minify 처리를 위해 추가. gulp-watch : 작업중에 작업된 내용을 실시간으로 gulp 에 설정한 내용이 실행되도록 하기 위해 추가. del : build 디렉터리를 지우는 clean task 를 만들기 위해 추가. 태스크에 사용할 패키지를 설치한다. 1npm i -D bower-main gulp-load-plugins gulp-rename gulp-uglify gulp-autoprefixer gulp-uglifycss gulp-watch del gulp-clean-dest 설치한 후 package.json 에 다음 같이 추가된다. 1234567891011121314&quot;devDependencies&quot;: { &quot;bower&quot;: &quot;^1.7.9&quot;, &quot;bower-main&quot;: &quot;^0.2.14&quot;, &quot;gulp&quot;: &quot;^3.9.1&quot;,}devDependencies { &quot;gulp-autoprefixer&quot;: &quot;^3.1.0&quot;, &quot;gulp-load-plugins&quot;: &quot;^1.2.4&quot;, &quot;gulp-rename&quot;: &quot;^1.2.2&quot;, &quot;gulp-uglify&quot;: &quot;^1.5.4&quot;, &quot;gulp-uglifycss&quot;: &quot;^1.0.6&quot;, &quot;gulp-watch&quot;: &quot;^4.3.8&quot;} Http serverhttp-server, lite-server npm 으로 HTTP 서버를 띄워서 작업을 쉽게 할 수 있도록 npm 에 http-server 의존성 추가 1npm i -g http-server lite-server는 Node 서버 개발시 실시간 리로딩과 browser-sync (lite-server의 하부 모델)를 이용해 HTML, CSS, JS 를 테스트한다. https://www.npmjs.com/package/lite-server 1$ npm i -D lite-server lite-server 이용We need a server and live-reload so we need to install lite-server: npm install —save-dev lite-serverEdit package.json file and add this script: “scripts”: {“start”: “lite-server”} npm install –save-dev concurrently Edit package.json scripts: “scripts”: {“start”: “concurrently ‘lite-server’ ‘webpack — watch’”} gulfile.js 관련앞서 설치한 태스크를 사용한 프로젝트 태스크를 gulpfile.js 에 선언한다. gulp 모듈을 들여오고, 작업을 진행할 source 디렉터리와 결과물을 보관할 build 디렉터리를 지정한다. 1234var gulp = require(&quot;gulp&quot;);var src = &quot;./src/&quot;;var dest = &quot;./build/&quot;; npm 에 추가한 모듈들을 일일이 require하지 않고 사용하기 위한 처리입니다.예를 들어 bower-main의 경우는 plugins.bowerMain() 식으로 사용이 가능합니다.gulp-로 시작하는 모듈들의 경우는 gulp-를 뺀 나머지로 사용가능합니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110var plugins = require(&quot;gulp-load-plugins&quot;)({ pattern: [&quot;gulp-*&quot;, &quot;gulp.*&quot;, &quot;bower-main&quot;], replaceString: /\\bgulp[\\-.]/,});// Minify &amp; copy JS/* 자바스크립트에 대한 처리를 진행합니다. {base: ''} 옵션을 넣은 이유는 이렇게 해야 디렉터리 구조를 유지한 상태로 복사합니다. 그렇지 않을 경우에는 build 디렉터리에 그대로 파일을 복사합니다. 혹시 concat모듈을 이용해서 하나의 거대 파일로 합칠 경우에는 위 옵션은 필요없습니다. 처리의 내용은 src/js/ 하위의 모든 js 파일을 읽어서 이름을 .min.js 로 변경하고 minify를 진행한 후에 build/assets/js 로 복사하라는 내용입니다.*/function processJS() { return gulp .src(src + &quot;js/**/*.js&quot;, { base: src + &quot;js/&quot; }) .pipe(plugins.rename({ suffix: &quot;.min&quot; })) .pipe(plugins.uglify()) .pipe(gulp.dest(dest + &quot;assets/js&quot;));}// gulp에 scripts라는 task로 지정합니다.gulp.task(&quot;scripts&quot;, processJS);// Minify &amp; copy CSS/* CSS 파일에 대한 처리를 진행합니다. 자바스크립트와 거의 동일한데 autoprefixer 부분만 특징적입니다. 아래 설정은 모든 브라우저의 최근 2개버전을 처리하기 위한 css 처리를 하라는 내용입니다.*/function processCss() { return gulp .src(src + &quot;css/**/*.css&quot;, { base: src + &quot;css/&quot; }) .pipe( plugins.autoprefixer({ // browsers: ['last 2 Chrome versions', 'last 2 Firefox versions', 'last 2 Android versions', 'last 2 ChromeAndroid versions'], browsers: [&quot;last 2 versions&quot;], cascade: true, }) ) .pipe(plugins.rename({ suffix: &quot;.min&quot; })) .pipe(plugins.uglifycss()) .pipe(gulp.dest(dest + &quot;assets/css&quot;));}// gulp에 css라는 task로 지정합니다.gulp.task(&quot;css&quot;, processCss);// Copy HTML/* HTML 파일들을 복사합니다.*/function processHtml() { return gulp .src(src + &quot;html/**/*.html&quot;, { base: src + &quot;html/&quot; }) .pipe(gulp.dest(dest));}gulp.task(&quot;html&quot;, processHtml);// Copy Vendor JSS &amp; CSS from bower_components/* bower_components 디렉터리에 있는 js와 css 들을 복사합니다. bower_main 모듈의 처리 결과는 minified, minifiedNotFound, normal 있는데 내용은 minified : minify 처리된 파일 normal : 일반 파일 minifiedNotFound : minify 처리된 파일이 없는 파일들의 일반 파일 입니다. 각 파일들의 파일명 리스트를 모두 합쳐서 디렉터리 구조를 유지시키면서 assets/ext 로 복사합니다.*/function processExternal() { var scriptBowerMain = plugins.bowerMain(&quot;js&quot;, &quot;min.js&quot;); var cssBowerMain = plugins.bowerMain(&quot;css&quot;, &quot;min.css&quot;); var mapBowerMain = plugins.bowerMain(&quot;js&quot;, &quot;min.js.map&quot;); return gulp .src( scriptBowerMain.minified .concat(scriptBowerMain.minifiedNotFound) .concat(cssBowerMain.minified) .concat(cssBowerMain.minifiedNotFound) .concat(mapBowerMain.minified), { base: &quot;./bower_components&quot; } ) .pipe(gulp.dest(dest + &quot;assets/ext&quot;));}// gulp 에 external 이라는 task 로 지정합니다.gulp.task(&quot;external&quot;, processExternal);// Watch for changes in files/* 실시간 감시를 위한 task 등록입니다. 지정한 디렉터리를 감시하고 있다가 추가/삭제/변경 등이 발생할 경우에는 지정한 함수를 호출합니다. 원래 gulp.watch 가 있는데 이 경우는 변경사항은 감지가 되지만 추가/삭제는 감지가 되지 않습니다. 그래서 gulp-watch 모듈을 이용했습니다.*/gulp.task(&quot;watch&quot;, function () { plugins.watch(src + &quot;js/**/*.js&quot;, processJS); plugins.watch(src + &quot;css/**/*.css&quot;, processCss); plugins.watch(src + &quot;html/**/*&quot;, processHtml); plugins.watch(&quot;./bower_components/**/*&quot;, processExternal);});// Default Task 입니다.gulp.task(&quot;default&quot;, [&quot;scripts&quot;, &quot;css&quot;, &quot;html&quot;, &quot;external&quot;, &quot;watch&quot;]);/** * clean build. * 원래는 default task에 넣어서 gulp가 시작될 때 깨끗하게 build 디렉터리를 비우게 만들고 싶었는데, * 오류가 발생해서 잘 안됩니다. 뭔가 방법이 있을텐데 쉽게 찾아지지는 않네요. */gulp.task(&quot;clean&quot;, function (cb) { plugins.del([&quot;build/**&quot;], cb);}); run그리고 package.json의 scripts 부분에 아래와 같은 내용을 추가하고, npm install 명령을 이용해서 최초 구성을 할 때 bower install 명령이 함께 실행되도록 한다. 위 두 가지 내용을 scripts 의 postinstall 과 start 속성으로 추가합니다. 1234567... &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;postinstall&quot;: &quot;bower install&quot;, &quot;start&quot;: &quot;http-server -a localhost -p 8000 -c-1 ./build&quot; },... 최종적으로, 필요 패키지가 설치됐는지 확인하고, 1npm install 이제 gulp 빌드를 시작하면 src 디렉터리를 만들고, sample 디렉토리에 디렉토리 js, css, html 를 src 디렉터리에 복사한다. 1gulp gulp로 빌드 태스크를 시작하고 Ctrl+C로 종료한다. 그리고 build 밑에 소스가 생성되었는지 확인다. 1234$ ll build/assets/index.htmlview/ http-server를 실행한다. 1npm start angular-seedangularjs 기본 프로젝트 구성을 가진 저장소로 bower, gulp 기반으로 제공된다. 1git clone https://github.com/angular/angular-seed.git 참조 https://roadmichi.blogspot.kr/2016/06/npm-bower-gulp.html https://github.com/angular/angular-seed https://andy-carter.com/blog/a-beginners-guide-to-package-manager-bower-and-using-gulp-to-manage-components","link":"/build-gulp-bower-64de4de270db/"},{"title":"NPM 으로 빌드 수행하기","text":"build with npm프론트엔드 개발 결과를 빌드할 때 gulp 와 npm 을 이용해 수행한다. grunt, gulp 로 빌드할 때 불편한 점 grunt, gulp는 wrapper로 실제 툴을 npm과 혼용하는게 좋다 gulp-sass는 node-sass 의 wrapper이다. 실제 사용하는 하부 모듈의 버전을 확인해야 한다. 이런 빌드 툴은 새로운 태스크를 추가하려면 많은 의존성을 해결해야 한다. npm으로 &amp;&amp; 연결로 해결 Grunftfile.js 스크립트 대신 package.json 만 있으면 된다. package.json에 명령을 추가할 수 있다. npm 기본–version or -v–global as -g–save as -S–save-dev as -D Outdated module현재 package.json 에 설치된 버전과 명시된 버전 그리고 최신 버전과 차이를 알 수 있다. 1234npm outdatedPackage Current Wanted Latest Locationbody-parser 1.15.2 1.15.2 1.18.2 application-namedebug 0.7.4 0.7.4 3.1.0 application-name 최신 버전으로 설치를 하려면 package.json을 버전코드로 변경하고 업데이트를 진행한다. 모든 패키지를 업데이트할 수 있다. 123npm update+ mongoose@4.13.1added 1 package, removed 4 packages and updated 2 packages in 32.975s 특정 모듈만 업데이트하려면 패키지를 명시하면 된다. 1npm update debug 프로젝트 시작프로젝트를 위해 폴더를 만들고 npm init 으로 초기화 한다. package.json 파일 생성 부터 묻는데, 응답이 귀잖고 즉시 초기화를 할 것이면 –yes 옵션을 사용한다. 12$ mkdir hellonpm &amp;&amp; cd hellonpm$ npm init --yes 현재 폴더에 package.json 의 골격이 생성된다: 123456789101112{ &quot;name&quot;: &quot;hellonpm&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;keywords&quot;: [], &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;} test 스크립트가 생성되어 있는데 실행해 본다: 1234$ npm test&gt; hellonpm@1.0.0 test /home/qkboo/Lectures/lecture_node/npm/hellonpm&gt; echo &quot;Error: no test specified&quot; &amp;&amp; exit 1... node_modules 가 없다고 나오는데, 빌드를 위해 dev-dependencies 를 먼저 설치한다. 1$ npm i -D jshint lite-server mocha concurrently node-sass uglify-js -D : Package will appear in your devDependencies 패키지 디렉토리package.json에 의존성 패키지가 명시되면 패키지 버전이 명시되는데 이 방법을 Semantic Versioning(Semver)라고 한다. started/semantic-versioning 참고한다. npm install 명령으로 모듈이 설치되면 아래 같은 구조를 갖는다. 1234567891011121314├── photo-gallery/└───── node_modules/ └───── modaal/ ├───── demo/ │ ├───── css/ │ ├───── img/ │ └───── js/ ├───── dist/ │ ├───── css/ │ └───── js/ └───── source/ ├───── css/ └───── js/ └───── lib/ 스크립트package.json 의 scripts 에 태스크를 추가한다. 필요한 테스트 모듈은 … lite-serverNode 서버 개발시 실시간 리로딩과 browser-sync (lite-server의 하부 모델)를 이용해 HTML, CSS, JS 를 테스트한다. https://www.npmjs.com/package/lite-server 123$ npm install lite-server --save-dev# or yarn$ yarn add lite-server --dev package.json에 lite-server 스크립트를 추가하자 1234&quot;scripts&quot;: { ... &quot;dev&quot;: &quot;lite-server&quot;} 그리고 npm run dev 로 테스트를 시작한다. browser-sync는 cross-browser checking도 지원한다. 자세한 것은 https://www.npmjs.com/package/light-server 참조 json-serverjson-server는 Fake REST API로 여기를 참조: https://scotch.io/tutorials/json-server-as-a-fake-rest-api-in-frontend-development 설치 1$ npm install -D json-server 스크립트는, 1234&quot;scripts&quot;: { ... &quot;db&quot;: &quot;json-server --watch db.json --port 3005&quot; } 테스트 실행은 12$ npm run db concurrently여러 명령을 쉽게 실행하게 해준다. https://www.npmjs.com/package/concurrently 테스트 스크립트에 다른 테스크를 동시에 실행하도록 해준다. 1234&quot;scripts&quot;: { ... &quot;start&quot;: &quot;concurrently -k \\&quot;npm run dev\\&quot; \\&quot;npm run db\\&quot;&quot; } concurrently 를 쓰기 싫다면 &amp;&amp; 로 묶어서 실행해도 된다. uglifyjavascript 파일을 minify 해서 저장하도록 해준다. 1234&quot;scripts&quot;: { ... &quot;uglify&quot;: &quot;mkdir -p dist/js &amp;&amp; uglifyjs src/js/*.js -m -o dist/js/app.js&quot;} lint1234&quot;scripts&quot;: { ... &quot;lint&quot;: &quot;jshint src/**.js&quot;} sass1234&quot;scripts&quot;: { ... &quot;sass&quot;: &quot;node-sass --include-path scss scss/main.scss assets/main.css&quot;} mochamocha는 javascript 테스트 프레임워크로 npm test shorthand for npm run test. 1234&quot;scripts&quot;: { ... &quot;test&quot;: &quot;mocha test&quot;} bash쉘 스크립트로 만든 명령을 실행해 준다. 1234&quot;scripts&quot;: { ... &quot;bash&quot;: &quot;Location of the Bash/Shell script file&quot;} rimraf여러 계층의 파일/디렉토리를 지울 수 있는 모듈. https://www.npmjs.com/package/rimraf Boilerplate12345678910111213141516171819202122&quot;scripts&quot;: {&quot;start&quot;: &quot;concurrently -k \\&quot;npm run dev\\&quot; \\&quot;npm run watch-css\\&quot;&quot;,&quot;dev&quot;: &quot;lite-server&quot;,&quot;db&quot;: &quot;json-server --watch db.json --port 3005&quot;,&quot;build-js&quot;: &quot;mkdir -p dist/js &amp;&amp; uglifyjs src/js/\\*.js -m -o dist/js/app.js&quot;,&quot;lint&quot;: &quot;lint jshint src/**/**.js&quot;,&quot;build-css&quot;: &quot;node-sass --include-path scss scss/main.scss assets/main.css&quot;,&quot;watch-css&quot;: &quot;nodemon -e scss -x \\&quot;npm run build-css\\&quot;&quot;,&quot;test&quot;: &quot;mocha test&quot;,&quot;pretest&quot;: &quot;npm run lint&quot;,&quot;posttest&quot;: &quot;echo the test has been run!&quot;,&quot;bash&quot;: &quot;Location of the bash/shell script file&quot;&quot;clean&quot;: &quot;rimraf ./dist/\\*&quot;} 참조 http://george.webb.uno/posts/gulp-and-npm-for-front-end-web-development Using npm as a Build Tool npm for beginners a guide for front end developers","link":"/build-npm-47baca25fd06/"},{"title":"Angular4 Tutorial for Beginner -- (1)","text":"Angular 이용에 대한 튜토리얼은 Angular Tutorial for beginners to Professionals 를 요약하고 있다. Angular App여기서는 angular cli를 사용해서 angular project를 생성하고 다루는데, 링크 Angular Cli Usages 에서 새 프로젝트 실행에 대해 살펴볼 수 있다. Anguar 의 개발 환경은 Create Angular2 를 참조한다. 프로젝트 생성ng new 명령으로 프로젝트를 생성한다. 1ng new myproducts 새로 생성한 프로젝트 디렉토리로 이동해서 서비스를 실행한다. ng serve 명령은 서버를 실행 12cd myproductsng serve 브라우저로 localhost:4200 으로 접속 디렉토리 구성ng new 생성하는 템플릿은 이렇게 구성되 있다. Root 폴더 Angular-cli.json: Angular CLI를 위한 구성 파일..editorconfig: 에디터 설정 파일. http://editorconfig.org 참고..gitignore: git 소스 제어를 하지 않는 설정 파일. karma.conf.js: karma test runner 설정 파일. package.json: npm 패키지 목록 설정 파일 protractor.conf.js: The Configuration file for protractor end to end test runner. README.md tsconfig.json: TypeScript compiler configuration for your IDE to pick up and give you helpful tooling. tslint.json: tslint is a static code analysis tool used in software development for checking Typescript code quality. To check if TypeScript source code complies with coding rules. TSLint checks your TypeScript code for readability, maintainability, and functionality errors typings.d.ts: Typescript type definition file e2e 폴더 protractor 가 엔드투엔드 테스트하는데 필요한 파일을 포함한다. Protractor는 실제 브라우저에 대비해 앱을 테스트할 수 있게 한다. 여기서 자세한 것은 배울 수 있다. 콤포넌트 분석Angular CLI로 생성한 프로젝트는 여러 콤포넌트로 구성되어 있다. src/app/ 밑에 콤포넌트 소스가 있다. app.component.ts앱의 뷰를 표현하고, 뷰는 화면의 한 부분이다. 3개로 구성되어 있다. class, class decorator, import statement 12345678910import { Component } from &quot;@angular/core&quot;;@Component({ selector: &quot;app-root&quot;, templateUrl: &quot;./app.component.html&quot;, styleUrls: [&quot;./app.component.css&quot;],})export class AppComponent { title = &quot;app&quot;;} export 키워드로 AppComponent class는 다른 콤포넌트에서 사용할 수 있다. 이런 콤포넌트 클래스는 속성과 메서드를 가질 수 있다. @Component decorator는 클래스 데코레이터로 이 콤포넌트에 대한 메타데이터를 제공한다. 이 메타데이터를 사용해서 Angular가 뷰를 생성한다. templateUrl: styleUrl: selector: angular에게 템플릿을 표시할 곳을 말한다. 이 콤포넌트에서 app-root 셀렉터는 index.html에서 사용한다. import 구문 외부 라이브러리를 콤포넌트에서 사용하고자 할 때 사용. 여기서 @angular/core 라이브러리에서 Component 데코레이터를 가져왔다. Root 모듈angular 앱은 모듈로 구성된다. app.module.ts 소스를 루트 모듈(root module)로 부른다. 123456789101112import { BrowserModule } from &quot;@angular/platform-browser&quot;;import { NgModule } from &quot;@angular/core&quot;;import { AppComponent } from &quot;./app.component&quot;;@NgModule({ declarations: [AppComponent], imports: [BrowserModule], providers: [], bootstrap: [AppComponent],})export class AppModule {} Angular 모듈의 구조는 콤포넌트 클래스와 비슷하다. class, class decorator, import Module class 는 콤포넌트와 비슷하게 export로 외부 모듈에서 사용할 수 있다. 1export class AppModule {} Angular 모듈은 @NgModule 데코레이터를 필요로 한다. 이 데코레이터로 모듈에 관련한 메타데이터를 전달한다. 소스에서 @NgModule은 declarations, imports, providers, bootstrap 네 가지 필드를 선언하고 있다. imports: 이 모듈에서 사용하는 모듈을 선언한다. Declarations: 이 모듈에 관련한 콤포넌트, 디렉티브, 파이프를 선언한다. Providers: 서비스를 선언하면 다른 콤포넌트가 사용할 수 있다. Bootstrap: 메타 데이터는 루트 콤포넌트를 식별한다. Import 구문AppModuel 에서 요구하는 외부 라이브러리를 들여오는데 사용한다. 또한 원하는 AppComponent를 들여오기 위해서 AppComponent가 필요하다. 부트스트래핑루트 모듈을 부트스트랩 해보자. 먼저 화면에 보이기 위해서 템플릿 파일인 app.component.html 이 있다. 이것은 AppComponent에 바인딩 된다. 결국 AppComponent 가 AppModule이 로드될 때 부트스트랩된다고 알 수 있다. 그래서 앱이 올라올 때 Angular에게 AppModule을 적재하자고 묻는데 이것은 src/main.ts 파일에서 완성된다. 12345678910111213import { enableProdMode } from &quot;@angular/core&quot;;import { platformBrowserDynamic } from &quot;@angular/platform-browser-dynamic&quot;;import { AppModule } from &quot;./app/app.module&quot;;import { environment } from &quot;./environments/environment&quot;;if (environment.production) { enableProdMode();}platformBrowserDynamic() .bootstrapModule(AppModule) .catch((err) =&gt; console.log(err)); platformBrowserDynamic 콤포넌트: angular 앱에서 부트스트랩을 위해 필요한 모든 함수들. enableProdMode: 기본적으로 개발자 모드로 실행하게 한다. environment: environment.ts 는 개발자 모드 환경이 있다. 개발자 환경에서 environments.ts 파일을 사용한다. 실제 상업 모드에서는 environments.prod.ts 가 사용된다. env 맵의 목록에서 어떤 파일이 사용되는지 확인할 수 있는데 angular-cli.json 파일에 있다. index.html앱의 메인 페이지이다. 셀렉터가 콤포넌트를 태그 처럼 사용하게 한다. app.component.ts에 선언한데로 이 셀렉터에 템플릿이 표시된다. 다른 파일app 폴더 밑에 다른 파일을 살펴보자. Assets 폴더이미지 혹은 앱을 빌드하는데 필요한 자원을 넣어 두는 곳. polyfills.ts웹 표준을 다르게 구현/지원하는 여러 브라우저를 위해 일반화를 해준다. 브라우저 지원 가이드에 따라서 core-js, zone.js 로 관리한다. styles.css전역에 지원하는 스타일을 선언한다. test.ts단위 테스트를 위한 관문. tsconfig.{applspec}.json타입스크립 컴파일러 구성 과 테스트 구성파일. ng 명령ng new, init, ng new 명령1ng new &lt;project-name&gt; [Options] –dry-run, -d: 시험 실행, 실제 프로젝트 파일은 만들지 않고 출력 파일만 생성한다. –verbose, -v: –skip : 프로젝트 생성 후에 npm 명령 실행 못한다. –skip-git: 이 프로젝트에는 git repository 생성 못한다. – : 새 프로젝트를 생성할 부모 디렉토리. 참조 https://www.tektutorialshub.com/create-first-angular-2-application/","link":"/2017-09-05-angular-tour-1-5d6d41c714d0/"},{"title":"Angular 개발환경","text":"Angular4 CLI2017년 3월에 기존 2.x 버전에 호환하는 Angular 4.0.0이 출시되었다. [^1] ### CLI Quick Start Angular CLI는 명령행 인터페이스로 프로젝트를 생성, 파일 추가 그리고 개발 태스크 - 테스트, 번들, 개발에 대한 기능을 제공하고 있다.여기서 Angular CLI로 TypeScript 에서 앱을 개발하는 과정을 Style Guide가 권장하는데 맞게 진행해 보자 예제 다운로드 개발환경 설정node.js와 npm에 대해 사용이 가능해야 하고 구성해야 한다. Angular CLI를 전역환경에 설치한다. 시간이 소요된다. 1npm install -g @angular/cli ng 명령을 사용할 수 있다. 1ng -v CLI에서 새 프로젝트 생성ng new 명령으로 프로젝트를 생성한다 - 생성으로 관련 npm 패키지를 설치하는 과정이 길다. [^2] 1ng new my-app 새로 생성한 프로젝트 디렉토리로 이동해서 서비스를 실행한다. ng serve 명령은 서버를 실행하고, 파일을 12cd my-appng serve --open #### Angular QuickStart Source Angular Quickstart Source 를 사용해서 CLI 없이 Angular 4를 시작할 수 있다. – 여러 의존성 문제가 발생한다. node v4.x.x 와 npm 3.x.x 이상을 필요로한다. To use the Angular 2 Quickstart, you run: 12$ git clone https://github.com/angular/quickstart.git my-proj$ cd my-proj Quickstart source 에 푸시하지 않으려면 .git 폴더를 삭제해도 무방하다. 12rm -rf .git # OS/X (bash)rd .git /S/Q # windows 또한 테스트와 저장소 유지를 위해 사용하는 non-essential을 삭제해도 된다. Linux (bash) 123xargs rm -rf &lt; non-essential-files.txtrm src/app/*.spec*.tsrm non-essential-files.txt OS/X (bash) 123xargs rm -rf &lt; non-essential-files.osx.txtrm src/app/*.spec*.tsrm non-essential-files.osx.txt Windows 123for /f %i in (non-essential-files.txt) do del %i /F /S /Qrd .git /s /qrd e2e /s /q 패키지를 설치한다. 1npm install 이제 최신 angular4 패키지를 설치하고 package.json 에 저장한다. To upgrade, paste (Mac only): 1npm install @angular/{common,compiler,compiler-cli,core,forms,http,platform-browser,platform-browser-dynamic,platform-server,router,animations}@next --save 1npm install @angular/common@next @angular/compiler@next @angular/compiler-cli@next @angular/core@next @angular/forms@next @angular/http@next @angular/platform-browser@next @angular/platform-browser-dynamic@next @angular/platform-server@next @angular/router@next @angular/animations@next --save npm install @angular/core @angular/http –save Typescript 이 설치되어 있지 않다면 역시 설치해 준다. 1npm install typescript@2.3 --save 시작 1npm start 앱 프로젝트 살펴보기Angular component 수정app-root 로 불리는 _ ./src/app/app.component.ts._ 콤포넌트를 수정해 보자. 에디터에서 열고 title 속성을 수정해 보자. 12345678910import { Component } from &quot;@angular/core&quot;;@Component({ selector: &quot;app-root&quot;, templateUrl: &quot;./app.component.html&quot;, styleUrls: [&quot;./app.component.css&quot;],})export class AppComponent { title = &quot;안녕하세요. Angular App&quot;;} ./app.component.css 스타일시트 파일을 수정해 보자. css 수정src/app/app.component.css 에서 스타일을 수정해 보자. 12345h1 { color: #369; font-family: Arial, Helvetica, sans-serif; font-size: 250%;} 프로젝트 구성src 폴더는 Angular components, templates, styles, images 등을 포함하고 있다. 파일 설명 app/app.component.{ts,html,css,spec.ts} AppComponent를 HTML 템플릿, CSS 스타일, 단위 테스트와 함게 선언한다. 이것은 앱에 관련한 계층적인 콤포넌트 트리가 되는 root 콤로넌트다. ng 기본 명령ng serve 로 서버를 제공한다. 기본 http://localhost:4200/ 에서 확인한다. 그리고 변경된 내용은 자동으로 서버에 적용된다. 서비스 포트와 호스트는 기본 포트는 4200번으로 .angular-cli.json 파일에 defaults 섹션에 선언할 수 있다. 12345678910{ &quot;defaults&quot;: { &quot;styleExt&quot;: &quot;css&quot;, &quot;component&quot;: {}, &quot;serve&quot;: { &quot;port&quot;: 4201, &quot;host&quot;: 127.0.0.1 } }} Code 발판새로운 콤포넌트를 추가하려면 ng generate component component-name 명령을 실행하면 새로운 모듈이 추가된다. ng generate 명령 1ng generate directive|pipe|service|class|guard|interface|enum|module BuildRun ng build 명령은 프로젝트를 빌드한다. 빌드 결과물은 dist/ 디렉토리에 저장된다. -prod 옵션을 사용하면 완성본을 구성할 수 있다. Running unit tests단위 테스트를 수행할 수 있는데, ng test 는 Karma를 통해서 단위테스트를 수행한다. Running end-to-end testsRun ng e2e to execute the end-to-end tests via Protractor.Before running the tests make sure you are serving the app via ng serve. 참조CLI 없이 Angular 4를 시작 [^1]: Angular 4.0.0 Now Available[^2]: Angular 4 Quick Start","link":"/2017-09-02-angular-cli-38f4248e4289/"},{"title":"Angular 개발환경","text":"Angular모바일, 데스크탑 웹 앱 구축을 지원하는 UI Framework 이다. Version History Angular 2: Initial Release 14.09.2016 Angular 4: Release on 23.03.2017 2017년 3월에 기존 2.x 버전에 호환하는 Angular 4.0.0이 출시되었다. [^1] Angular 5: Currently in beta 4 release 16.08.2017 Angular Changelog 에서 최신 정보를 얻을 수 있다. Angular4 특징기존 Angular 2에 비해 새로운게 많이 추가되었다. 작고 빠르게Angular 4 앱은 이전 버전에 비해 더 작은 공간이 소모되고 빠른 실행이 된다. View engine개선된 *nglf 와 *ngFor템플릿 바인딩이 변겨오디었는데 if/else 문법을 사용하고 관찰할 대상에 대해 변수를 대입할 수 있다. 123456789&lt;div *ngIf=&quot;userList | async as users; else loading&quot;&gt; &lt;user-profile *ngFor=&quot;let user of users; count as count; index as i&quot; [user]=&quot;user&quot; &gt; User {{i}} of {{count}} &lt;/user-profile&gt;&lt;/div&gt;&lt;ng-template #loading&gt;Loading...&lt;/ng-template&gt; Angular Universal커뮤니티 안에서 개발되던 것을 angular team에서 받아들여, Universal 은 서버에서 Angular를 실행할 수 있게 해준다. @angular/platform-server 에 포함되어 있다. Angular Universal 를 배우려면 먼저 @angular/platform-server 안의 renderModuleFactory 메서드를 살펴보고, Rob Wormald’s Demo Repository 를 살펴보라. TypeScript 2.1, 2.2 호환최신 버전의 TypeScript 를 적용했다. 그러므로 ngc 스피드를 향샹 시켰고, 앱에서 형 점검을 더 좋게 했다. 템플릿을 위한 소스 맵템플릿에서 어떤 에러가 발생하면 소스 맵을 생성해서 원래 템플릿에서 의미있는 내용을 보여준다. Flat ESM / FESM펼친 모듈을 배보한다. 예제 파일 참조. ES2015 빌드우리 패키지를 the ES2015 Flat ESM format 형식으로 배포하고 있다. 이것은 실험적인 선택사항이다. 이 패키지와 합친 경우 7% 번들 크기가 줄어드는 것으로 복되고 있다. 4.0으로 업그레이드Angular 의존성을 4.0.0으로 업그레이드는 쉽다. Linux/Mac1npm install @angular/{common,compiler,compiler-cli,core,forms,http,platform-browser,platform-browser-dynamic,platform-server,router,animations}@latest typescript@latest --save Windows1npm install @angular/common@latest @angular/compiler@latest @angular/compiler-cli@latest @angular/core@latest @angular/forms@latest @angular/http@latest @angular/platform-browser@latest @angular/platform-browser-dynamic@latest @angular/platform-server@latest @angular/router@latest @angular/animations@latest typescript@latest --save Angular Update guide 참조.","link":"/2017-09-02-angular-0start-d8aa4b77199b/"},{"title":"Typescript &#x2F; 5min in Typescript","text":"자바스크립트 개발자 또는 경험자를 위한 typescriptlang.org 의 Tutorials 를 정리했다. 5분에 끝내는 TypeScript Gulp Migrating from Javascript React &amp; Webpack 5분에 끝내는 TypeScript자바스크립트 개발자 또는 경험자가 알아야할 내용을 정리한 TypeScript in 5min을 정리했다. 설치TypeScript는 Node.js를 사용하며, npm으로 typescript 지원 도구를 설치한다. 1npm install -g typescript 개발자용 nightly build도 설치 할 수 있다. 1npm install -g typescript@next tsc 컴파일러TypeScript 소스를 tsc 컴파일러로 컴파일하고, 결과는 Javascript로 생성된다. 12$ tsc -VVersion 2.5.2 최신버전 갱신은 Typscript blog 를 참조한다. 첫번째 TypeScript 파일보통 Typescript 소스 확장자는 .ts 로 저장하고 tsc 컴파일러로 컴파일한다. .ts 파일을 컴파일 하면 .js 자바스크립트 소스파일이 생성된다. 예를 들어 아래 자바스크립트로 구성된 코드를 greeter.ts 파일에 입력한다. 1234567function greeter(person) { return &quot;Hello, &quot; + person;}var user = &quot;Jone James&quot;;document.body.innerHTML = greeter(user); 그리고 컴파일 하면 자바스크립트 소스 greeter.js 가 생성된다. 1$ tsc greeter.ts greeter.ts 소스와 컴파일 결과 greeter.js 소스는 일치한다. Type annotationsTypeScript에서 형(Types) 표기는 함수 혹은 변수에 의미를 부여하기 위한 방법으로, 아래 코드의 greeter 함수에 전달하는 인자가 string 형 이라고 의도하기 위해서, 변수 다음 :으로 오른쪽에 형을 지정(annotation)해 선언한다 - 즉, 문자열로 전달할 거야 하는 의도를 선언한다고 이해하면 된다. 123456function greeter(person: string) { return &quot;Hello, &quot; + person;}var user = [&quot;My&quot;, 1, 2, 3];greeter(user); 이제 tsc 로 컴파일을 실행하면 아래 같이 형 지정 에러를 표시한다. 비슷하게 greeter() 함수의 매개변수를 모두 지우고 컴파일해도 비슷한 결과를 보여준다. 12$ tsc greeter.tsgreeter_2.ts(7,9): error TS2345: Argument of type '(string | number)[]' is not assignable to parameter of type 'string'. Typescript의 형 지정은 코드와 주어진 형 지정자를 기반으로 정적 분석을 제공한다. 이렇게 컴파일 에러는 발생하지만 .js 자바스크립트는 생성되는 것을 확인 할 수 있다. 코드에 에러가 있어도 TypeScript을 사용할 수 있다, 다만 원래 의도데로 실행되지는 않는다는 것을 경고해 준다. Interfaces추상화를 위해 interface 를 사용해서 속성을 가진 개체를 선언 할 수 있다. 아래 Person 인터페이스는 firstName, lastName 속성으로 선언하고 있다. TypeScript에서는 내부 구조가 호환하면 두 객체는 호횐 된다고 한다. 이것은 명시적으로 implements 절을 사용하지 않고도 인터페이스가 요구하는 형태를 가지면 인터페이스에 동일하게 구현이 가능하다고 한다. 이제 greeter 함수를 인터페이스 Person 형으로 다음 같이 선언할 수 있다. 123456789101112interface Person { firstName: string; lastName: string;}function greeter(person: Person) { return &quot;Hello, &quot; + person.firstName + &quot; &quot; + person.lastName;}var user = { firstName: &quot;Jane&quot;, lastName: &quot;User&quot; };document.body.innerHTML = greeter(user); 이 소스를 tsc 로 컴파일 해도 형이 일치한다고 판단해서 경고가 없고 결과 자바스크립트를 HTML로 코딩해서 결과를 확인해 보자, 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;TypeScript Greeter&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=&quot;greeter_3interface.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; Classes자바스크립에는 없는 클래스 기반의 객체지향 프로그래밍을 지원한다. class 키워드로 선언하고 속성과 메서드를 가진다. 또한 생성자 constructor() 에 public 접근제한자를 지정해서 추상화 단계를 결정하게 하고, 생성자의 public 지정자는 해당 이름으로 자동으로 속성을 생성하게 해준다. 이것은 클래스가 인터페이스와 잘 결합되게 해준다. 1234567891011121314151617181920212223class Student { fullName: string; constructor( public firstName: string, public middleInitial: string, public lastName: string ) { this.fullName = firstName + &quot; &quot; + middleInitial + &quot; &quot; + lastName; }}interface Person { firstName: string; lastName: string;}function greeter(person: Person) { return &quot;Hello, &quot; + person.firstName + &quot; &quot; + person.lastName;}var user = new Student(&quot;Jane&quot;, &quot;M.&quot;, &quot;User&quot;);document.body.innerHTML = greeter(user); Person 인터페이스를 요구받는 greeter()에 Student class의 생성자에 호혼한다. 그래서 tsc로 컴파일해도 아무 문제 없다. 다만, 클래스의 생성자 매개변수가 인자 수, 형 같이 다르면 다음 같이 에러를 발생한다. 1greeter_4classes.ts(18,12): error TS2554: Expected 3 arguments, but got 2. 컴파일한 자바스크립은 HTML에서 실행할 수 있다. 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;TypeScript Greeter&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=&quot;greeter.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 실제 실행하면 Person 객체는 세번째 매개변수가 없기 때문에 undefined 로 나타난다. Hello, Jane undefined TypeScript에서 클래스 기반의 코드를 컴파일해서 자바스크립트 생성된 결과를 보면, 클래스는 자바스크립트의 프로토타입 기반의 객체지향 방법의 축약형이다. 123456789var Student = /** @class */ (function () { function Student(firstName, middleInitial, lastName) { this.firstName = firstName; this.middleInitial = middleInitial; this.lastName = lastName; this.fullName = firstName + &quot; &quot; + middleInitial + &quot; &quot; + lastName; } return Student;})(); 참조Typescript in 5 min","link":"/2017-09-01-typescript-1quickstart-ab08ed3c3df5/"},{"title":"Typescript &#x2F; Gulp","text":"자바스크립트 개발자 또는 경험자를 위한 typescriptlang.org 의 Tutorials 를 정리했다. 5분에 끝내는 TypeScript Gulp Migrating from Javascript React &amp; Webpack GulpGulp 와 함께 TypeScript 를 빌드할 수 있고 Gulp pipeline에 Browserify, uglify, or Watchify 를 추가할 수 있다. 여기서 Babelify를 사용한 Babel 함수화에 대한 함수화를 추가할 것이다. Node.js와 npm을 다룰 수 있다고 가정한다. 프로젝트새로운 프로젝트 디렉토리 proj 를 만들고, 1234mkdir projcd projmkdir srcmkdir dist 이 프로젝트 아래 src,dist 를 추가한다. 123proj/ ├─ src/ └─ dist/ 그리고 package.json 파일을 만들기 위해 초기화 한다. 1npm init 여러가지를 묻는데 그 중 시작점을 ./dist/main.js로 지정한다. 의존성 설치gulp-cli 를 글로벌로 설치한다. 1npm install -g gulp-cli 이어서 typescript, gulp, gulp-typescript 를 설치하고 dev 의존성으로 저장한다. 1npm install --save-dev typescript gulp gulp-typescript 간단한 예제src 폴더에 main.ts 를 작성하자. 1234function hello(compiler: string) { console.log(`Hello from ${compiler}`);}hello(&quot;TypeScript&quot;); proj 폴더의 루트에 tsconfig.json을 작성한다. 1234567{ &quot;files&quot;: [&quot;src/main.ts&quot;], &quot;compilerOptions&quot;: { &quot;noImplicitAny&quot;: true, &quot;target&quot;: &quot;es5&quot; }} proj 폴더 루트에 gulpfile.js 를 작성한다. 1234567var gulp = require(&quot;gulp&quot;);var ts = require(&quot;gulp-typescript&quot;);var tsProject = ts.createProject(&quot;tsconfig.json&quot;);gulp.task(&quot;default&quot;, function () { return tsProject.src().pipe(tsProject()).js.pipe(gulp.dest(&quot;dist&quot;));}); 빌드하고 node로 실행한다. 12gulpnode dist/main.js 모듈을 추가한다모듈을 추가해 보자, src/greet.ts 소스를 작성한다. 123export function sayHello(name: string) { return `Hello from ${name}`;} export 는 함숭름 sayHello를 외부에서 사용할 수 있게 해준다. 이 모듈을 src/main.tx 에서 import 로 들여와서 사용한다. ES2015 모듈 문법을 사용하는데 Typescript은 CommonJS 모듈을 이어받아 사용한다. 123import { sayHello } from &quot;./greet&quot;;console.log(sayHello(&quot;TypeScript&quot;)); 모듈은 tsconfig.json 에 등록해주어야 한다. 1234567{ &quot;files&quot;: [ &quot;src/main.ts&quot;, &quot;src/greet.ts&quot; ], ...} 빌드하고 node로 실행한다. 12gulpnode dist/main.js Browserify이제 Node 앱을 브라우저로 이전해 보자. 우리 모든 번들을 자바스크립으로 무꺼어야 한다. 이것은 Browserify가 수행해 준다. 이 모듈도 또한 CommonJS 모듈시스템을 사용한다. 그러므로 TypeScript과 Node.js 설정을 쉽고 변경없이 이전이 가능하다. 먼저 tsify와 vinyl-source-stream 을 설치한다. tsify 는 Browserify 플러그인으로 타입스크립트 컴파일러에 접근하게 해준다. vinyl-source-stream은 browserify의 결과 파일을 gulp가 이해하는 vinyl 형식으로 호환해준다. 1npm install --save-dev browserify tsify vinyl-source-stream 페이지 생성src에 index.html 파일을 만든다. 1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p id=&quot;greeting&quot;&gt;Loading ...&lt;/p&gt; &lt;script src=&quot;bundle.js&quot;&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; main.ts 를 페이지에 접근할 수 있게 갱신한다. 12345678import { sayHello } from &quot;./greet&quot;;function showHello(divName: string, name: string) { const elt = document.getElementById(divName); elt.innerText = sayHello(name);}showHello(&quot;greeting&quot;, &quot;TypeScript&quot;); 그리고 gulfile.js 를 변경한다. 12345678910111213141516171819202122232425var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var tsify = require(&quot;tsify&quot;);var paths = { pages: [&quot;src/*.html&quot;],};gulp.task(&quot;copy-html&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});gulp.task(&quot;default&quot;, [&quot;copy-html&quot;], function () { return browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }) .plugin(tsify) .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}); 기본 의존성으로 copy-html 태스크를 추가한다: 가장먼저 copy=html 이 실행된다. Browserify를 호출해서 gulp-typescript 대신 tsify 플러그인을 사용한다. bundle()이 호출되고 vinyl-source-stream을 사용해 bundle.js 로 소스를 모은다. Notice that we specified debug: true to Browserify. This causes tsify to emit source maps inside the bundled JavaScript file. Source maps let you debug your original TypeScript code in the browser instead of the bundled JavaScript. You can test that source maps are working by opening the debugger for your browser and putting a breakpoint inside main.ts. When you refresh the page the breakpoint should pause the page and let you debug greet.ts. 마지막으로 gulp 로 빌드하고 dist/index.html을 브라우저에서 실행해 보자. Watchify, Babel, UglifyBrowserify로 코드를 묶었다. 다음 Browserify 플러그인으로 더 확장된 빌드를 구현할 수 있다. Watchify: gulp 를 시작하고 증분 컴파일을 할 수 있다. 수정-저장-갱신 사이클을 브라우저에서 유지할 수 있다. Babel: ES2015 와 ES5, ES3 으로 변환할 수 있는 컴파일러 이다. Typescript 이 지우너하지 않는 사용자화 변경과 확장을 추가할 수 있다. Uglify: 다운로드 시간을 줄일 수 있도록 코드를 압축한다. Watchify다음 같이 설치한다. 1npm install --save-dev watchify gulp-util gulpfile.js 를 watchify 와 gulp-util 을 사용하게 변경한다. 12345678910111213141516171819202122232425262728293031323334var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var watchify = require(&quot;watchify&quot;);var tsify = require(&quot;tsify&quot;);var gutil = require(&quot;gulp-util&quot;);var paths = { pages: [&quot;src/*.html&quot;],};var watchedBrowserify = watchify( browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }).plugin(tsify));gulp.task(&quot;copy-html&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});function bundle() { return watchedBrowserify .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}gulp.task(&quot;default&quot;, [&quot;copy-html&quot;], bundle);watchedBrowserify.on(&quot;update&quot;, bundle);watchedBrowserify.on(&quot;log&quot;, gutil.log); We wrapped our browserify instance in a call to watchify, and then held on to the result. We called watchedBrowserify.on(“update”, bundle); so that Browserify will run the bundle function every time one of your TypeScript files changes. We called watchedBrowserify.on(“log”, gutil.log); to log to the console. 이제 gulp 를 실행하며 watchify에 의해 소스 변경을 점검하고 변경시 컴파일을 한다. 1234567$ gulp[04:39:43] Using gulpfile ~/Works/typescript/proj/gulpfile.js[04:39:43] Starting 'copy-html'...[04:39:43] Finished 'copy-html' after 105 ms[04:39:43] Starting 'default'...[04:39:52] 3199 bytes written (0.38 seconds)[04:39:52] Finished 'default' after 8.66 s Uglifyuglify 는 코드를 난독화 시키고, 용량을 줄여 준다. 1npm install --save-dev gulp-uglify vinyl-buffer gulp-sourcemaps gulpfile.js에 추가한다. 1234567891011121314151617181920212223242526272829303132var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var tsify = require(&quot;tsify&quot;);var uglify = require(&quot;gulp-uglify&quot;);var sourcemaps = require(&quot;gulp-sourcemaps&quot;);var buffer = require(&quot;vinyl-buffer&quot;);var paths = { pages: [&quot;src/*.html&quot;],};gulp.task(&quot;copy-html&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});gulp.task(&quot;default&quot;, [&quot;copy-html&quot;], function () { return browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }) .plugin(tsify) .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(buffer()) .pipe(sourcemaps.init({ loadMaps: true })) .pipe(uglify()) .pipe(sourcemaps.write(&quot;./&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}); uglify 는 한번 호출하는데 - sourcemaps를 유지하기 위해 버퍼링하고 소스맵을 하기 위해 호출한다. 이것으로 분리된 소스맵 파일을 생성한다. gulp를 실행해 bundle.js 를 통해 최소화된 파일로 출력되는지 점검할 수 있다. 12gulpcat dist/bundle.js BabelBabel과 Bebel preset ES2015를 설치한다. 기본 설정으로 Uglify 같이 코드를 난독화 한다. 역시 vinyl-buffer, gulp-sourcemaps 가 필요하다. 파일 확장자 .js, .es, .es6 and .jsx 에 대해서만 다룬다. 그러므로 .ts 확장자도 추가할 필요가 있다. 1npm install --save-dev babelify babel-preset-es2015 vinyl-buffer gulp-sourcemaps gulpfile.js 를 12345678910111213141516171819202122232425262728293031323334var gulp = require(&quot;gulp&quot;);var browserify = require(&quot;browserify&quot;);var source = require(&quot;vinyl-source-stream&quot;);var tsify = require(&quot;tsify&quot;);var sourcemaps = require(&quot;gulp-sourcemaps&quot;);var buffer = require(&quot;vinyl-buffer&quot;);var paths = { pages: [&quot;src/*.html&quot;],};gulp.task(&quot;copyHtml&quot;, function () { return gulp.src(paths.pages).pipe(gulp.dest(&quot;dist&quot;));});gulp.task(&quot;default&quot;, [&quot;copyHtml&quot;], function () { return browserify({ basedir: &quot;.&quot;, debug: true, entries: [&quot;src/main.ts&quot;], cache: {}, packageCache: {}, }) .plugin(tsify) .transform(&quot;babelify&quot;, { presets: [&quot;es2015&quot;], extensions: [&quot;.ts&quot;], }) .bundle() .pipe(source(&quot;bundle.js&quot;)) .pipe(buffer()) .pipe(sourcemaps.init({ loadMaps: true })) .pipe(sourcemaps.write(&quot;./&quot;)) .pipe(gulp.dest(&quot;dist&quot;));}); 그리고 tsconfig.js에 typescript 의 대상을 *”target”: “es5”*에서 ES2015로 명시해 준다.Babel’s ES5 output should be very similar to TypeScript’s output for such a simple script.","link":"/2017-09-01-typescript-2gulp-f348c88366dd/"},{"title":"Raspberry Pi 3 64bit OS openSUSE LEAP 15: Install","text":"2017-10-30: swap 추가, timezone 수정{:.right-history} Opensuse 에서 Raspberry Pi 3를 위한 64bit OS openSESE Leap 42.2 을 제공하고 있다. https://en.opensuse.org/HCL:Raspberry_Pi3 이글은 5개 글타래로 구성되며, openSUSE 설치 및 사용에 대해 작성한다. Install 64bit openSUSE Leap 42.2 / JeOS openSUSE: Managing Service daemon openSUSE: Basic OS Security for Server Install &amp; Configuration - Nginx, Node JS, Jupyter openSUSE: Build MongoDB 3.4.x Install 64bit openSUSE Leap 42.2 / JeOSopenSUSE는 Raspberry Pi 3를 위한 Opensuse community edition은 정식 버전 Leap 42.2 image, 개발버전 Tumbleweed image, 커뮤니티버전 non-upstream openSUSE Tumbleweed image* 으로 구성되어 있다. 이들 버전은 용도에 따라 JeOS, E20, LXQT X11 이미지로 다운받을 수 있다. Just Enought Operating System (JeOS) jeOS 이미지는 기본 오에스만을 포함하고 있다. https://www.suse.com/products/server/jeos/ E20 데스크탑 환경으로 Enlightenment 을 사용하 GUI 이미지 LXQt LXDE-Qt 와 RazorQt 병합한 데스크탑 환경 https://en.opensuse.org/LXQt ### Download and Install Download Page 의 두번째 Installing the 64-bit openSUSE Leap image 단락에 있는 JeOS image 를 다운로드 한다. Writing image to SD CardEtcher 등을 이용해서 다운받은 이미지 파일을 SD Card에 쓴다. {:width=”640”} dd 를 사용한다면,다운받은 .xz 파일을 dd 를 이용해서 SD Card에 쓴다. 1xzcat openSUSE-Leap42.2-ARM-JeOS-raspberrypi3.aarch64.raw.xz | sudo dd of=/dev/rdisk1 bs=4m; sync #### Serial console 여기서는 Serial console에서 네트워크 확인 및 초기 설정을 하고 ssh 로 서버에 로그인해서 시스템 구성을 진행한다. SD Card를 라즈베리파이에 꽃고 HDMI, Keyboard 및 Mouse 가 별도로 준비되어 있으면 직접 모니터를 보고 작업을 진행하면 좋다. USB to Serial 케이블을 사용해서 Raspberry Pi의 Serial Console에 연결한다. {:width=”640”} 그리고 시리얼 포트를 통해 tty 연결을 위해 터미널 프로그램에서 baud rate 115200 으로 연결한다. 아래는 macOS의 screen CLI 명령으로 usb serial 포트에 연결하고 있다. 1$ screen /dev/cu.usbserial 115200 이제 SD Card를 넣고 부팅을 하면, 터미널에 부트 단계가 진행되고 처음 5분 정도 소요된다. {:width=”640”} Raspberry Pi를 위한 이미지는 처음 계정은 root/linux 이다. 터미널에서 uname 은 aarch64 임을 확인 할 수 있다. 12root# uname -aLinux homepi 4.4.90-18.32-default #1 SMP Fri Oct 6 13:30:08 UTC 2017 (465b410) aarch64 aarch64 aarch64 GNU/Linux 처음으로 라즈베리파이에서 64bit 환경으로 운영해 볼 수 있게 됐다. ### 설치 후 서버 구성을 위해 할 일 JeOS를 서버로 구성하기 위해서 다음 같은 작업을 수행해 준다. root 패스워드 변경 sudoer 사용자 생성 DHCP를 고정 IP로 변경 root 패스워드root 사용자의 패스워드를 변경한다. {:width=”640”} UpdateUbuntu/Debian 계열의 패키지 명령 apt,apt-get 과 비슷한 openSUSE 명령라인 패키지 관리자는 zypper 가 있다. 123456789zypper help search # to print help for the search commandzypper refresh, ref # Refresh all repositories.zypper update, up # to update all installed packageszypper lp # to see what patch updates are neededzypper patch # to apply the needed patcheszypper se sqlite # to search for sqlitezypper rm sqlite2 # to remove sqlite2zypper in sqlite3 # to install sqlite3zypper in yast* # to install all packages matching 'yast*' zypper usages 에서 사용방법을 자세히 알 수 있다. 머저 최신 소프트웨어 목록으로 업데이트 한다. 12zypper refreshzypper ref 그리고 최근 업그레이드된 필요한 패키지를 다운로드하고 설치한다.[^1] 12zypper updatezypper up 지원중단된 패키지, 나뉘어진 패키지 등의 의존성을 고려한 업그레이드를 하려면 dup 명령을 사용한다.&gt; 12zypper dup # distribution upgradezypper dist-upgrade upgrade 후에실행중인 데몬을 재시작해줄 필요가 있는데 zypper ps -s 를 실행하면 목록을 표시해 준다. 1234567891011121314151617181920212223242526272829303132333435pi64:/home/ # zypper ps -sThe following running processes use deleted files:PID | PPID | UID | User | Command | Service------+-------+------+------------+----------------------------+-------------------307 | 1 | 0 | root | systemd-journald (deleted) | systemd-journald484 | 1 | 0 | root | auditd | auditd502 | 1 | 1000 | qkboo | python3 | jupyter513 | 1 | 499 | messagebus | dbus-daemon (deleted) | dbus525 | 1 | 0 | root | systemd-logind (deleted) | systemd-logind529 | 1 | 0 | root | agetty (deleted) | getty@tty1996 | 1 | 0 | root | cupsd | cups1018 | 1 | 0 | root | cron | cron1043 | 1 | 74 | ntp | ntpd | ntpd1047 | 1043 | 74 | ntp | ntpd | ntpd1145 | 1 | 0 | root | python2.7 | fail2ban1146 | 1 | 1000 | qkboo | node | pm2-qkboo2131 | 1 | 0 | root | agetty (deleted) | serial-getty@ttyS05716 | 1146 | 1000 | qkboo | node | pm2-qkboo5749 | 1146 | 1000 | qkboo | node | pm2-qkboo12400 | 1 | 0 | root | sshd (deleted) |12402 | 1 | 1000 | qkboo | systemd (deleted) |12405 | 0 | 1000 | qkboo | systemd (deleted) |12411 | 12400 | 1000 | qkboo | sshd (deleted) |12412 | 12411 | 1000 | qkboo | bash |12783 | 12412 | 0 | root | sudo |12784 | 12783 | 0 | root | bash |12876 | 1 | 0 | root | nginx | nginx12879 | 12876 | 494 | nginx | nginx | nginx12880 | 12876 | 494 | nginx | nginx | nginx12881 | 12876 | 494 | nginx | nginx | nginx12882 | 12876 | 494 | nginx | nginx | nginx15908 | 502 | 1000 | qkboo | node | jupyter15916 | 15908 | 1000 | qkboo | node | jupyter26929 | 502 | 1000 | qkboo | node | jupyter ip 주소 확인ifconfig 명령으로 현재 IP Address를 확인하고 이 IP Address에 ssh 를 사용해 접속한다. 1234567891011linux:~ # ifconfigeth0 Link encap:Ethernet HWaddr B9:40:EB:BA:10:02 inet addr:192.168.1.104 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe90::ba37:ebff:feba:1012/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:83136 errors:0 dropped:0 overruns:0 frame:0 TX packets:27300 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:120797947 (115.2 Mb) TX bytes:2369690 (2.2 Mb)linux:~ #linux:~ # shutdown now 좀더 편리한 사용을 위해 ifconfig 명령으로 찾은 IP address에 ssh 로그인을 해서 작업을 진행한다. 1$ ssh root@192.168.1.104 ### 시스템 설정 이제 sudoer 사용자로 시스템을 서버에 적합하게 구성해 보자. sudoer 추가 yast 소개 timezone Network 구성: 호스트 이름, IP 주소 swap 개선 yast로 사용자 추가 sudoerroot 사용자가 아닌 일반사용자를 sudoer로 등록해 관리자 기능을 대행 할 수 있다. 그러기 위해서 먼저 사용자를 추가한다. openSUSE yast라는 시스템 도구로 할 수 있지만 여기선 useradd 명령을 사용해서 사용자 추가한다. useradd에 대해서는 useradd 명령을 참조한다. useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. 추가한 사용자를 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 추가 그리고 -m 옵션으로 으로 사용자 홈 디렉토리 까지 생성한다. 1root# useradd -m foo 그리고 패스워드를 등록한다. 1234root# passwd fooNew password:Retype new password:passwd: password updated successfully sudoer 등록visudo 명령으로 /etc/sudoers 파일을 편집한다. 1$ sudo visudo sudoer 파일에 있는 User privilege 항목 아래에 새로운 사용자 foo를 아래 같이 등록한다. 123# User privilege specificationroot ALL=(ALL) ALLfoo ALL=(ALL) ALL 이제 root에서 로그아웃하고 새로 추가한 사용자로 로그인한다. 1234$ ssh foo@192.168.1.104Password:Have a lot of fun...foo@linux:~&gt; openSUSE는 관리자용 명령을 직접 내리면 찾지 못한다고 한다. 12foo@linux:~&gt; yast2 timezone-bash: yast2: command not found 그리고 처음으로 sudoer 사용자가 관리자 권한이 필요한 명령을 사용하기 위해 sudu 로 명령을 내리면 아래 같은 경고가 나온다. 12345678foo@linux:~&gt; sudo /sbin/yast2 timezoneWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. openSUSE는 시스템 관리 도구로 yast 를 사용해서 소프트웨어 설치, 네트워크 구성, 시간 관리, 보안 및 사용자 등을 다루는 소프트웨어로 GUI와 CLI 모두 사용할 수 있다. 시스템 네트워크를 구성하기 위해서 yast 명령을 사용해보자, yastyast는 GUI 혹은 ClI에서 사용이 가능하다 . 다음은 sudo yast 를 실행하면 Ncurse 로 표시되는 yast 화면이다. {:width=”640”} TAB 키로 각 항목을 이동할 수 있고, Enter로 실행한다. 전체 화면에서 F9는 Cancel, F10은 OK 기능을 수행한다. Timezone처음 설치후 CET 시간대로 되어 있어서 Asia/Seoul로 변경하고자 한다. 12linux:~ # dateSun Oct 29 09:19:31 CET 2017 시스템 시간대를 설정하려면 yast 를 시작해 System -&gt; Date and Time 을 실행해 시간대를 지정한다. 혹은 yast timezone 모듈 명령을 주면 해당 Date and Time 화면으로 이동할 수 있다. {:width=”640”} 시간대를 변경후 확인해 보면, 12linux:~ # dateSun Oct 29 17:22:11 KST 2017 ntp로 동기화하려면 Other Settings… 항목을 선택해 ntp server 를 설치하고 활성화 한다. {:width=”640”}{:width=”640”}","link":"/opensuse-leap15-install-1a26ec000ca5/"},{"title":"NodeJS - mongoose","text":"이 글은 mongoose doc 에서 필요한 부분만 요약 정리했다. MongoDB와 MongooseNode.js에서 Mongodb에 연결하기 위해서 Driver가 필요 mongooseMongoDb를 위한 Node.js 커넥터로 Object Data Mapping (ODM)을 통해 MVC를 구현해 준다. using-mongodb-and-mongoose 설치프로젝트 폴더에서 npm으로 mongoose 모듈를 설치한다. 1$ npm i mongoose npm &lt; 5 이하 버전은 -S 혹은 --save 옵션으로 모듈 의존성을 package.json 에 추가한다. 12345678910&quot;dependencies&quot;: { &quot;body-parser&quot;: &quot;~1.13.2&quot;, &quot;cookie-parser&quot;: &quot;~1.3.5&quot;, &quot;debug&quot;: &quot;~2.2.0&quot;, &quot;express&quot;: &quot;~4.13.1&quot;, &quot;jade&quot;: &quot;~1.11.0&quot;, &quot;mongoose&quot;: &quot;^4.4.16&quot;, &quot;morgan&quot;: &quot;~1.6.1&quot;, &quot;serve-favicon&quot;: &quot;~2.3.0&quot;} Scheme 사용Scheme 는 Model 로 변환해야 한다. ^modelsmongoose.model() 메서드는 모델 이름과 스키마를 받아 변환한다. mongoose.model(modelName, schema); 12var schema = new mongoose.Schema({ name: &quot;string&quot;, size: &quot;string&quot; });var Tank = mongoose.model(&quot;Tank&quot;, schema); model()에 전달한 modelName은 mongoose가 자동으로 컬렉션에서 복수형으로 찾는다. 예를 들어 위의 Tank는 tanks 컬렉션을 참조한다. connect()mongoose 에서 mongodb 드라이버에 연결할 때 mongodb 버전에 따라 달리 접근한다. 또한 mongoose 4.x와 5.x 의 몇몇 옵션도 주의해서 사용해야 한다. mongodb 3.x 연결mongoose 4.x 버전 부터는 Promise를 선언하고 connect()를 연결한다. 123456789101112var mongoose = require(&quot;mongoose&quot;);mongoose.Promise = global.Promise;mongoose .connect(&quot;mongodb://localhost/somecollection&quot;) .then(() =&gt; console.log(&quot;connection succesful&quot;)) .catch((err) =&gt; console.error(err));//or mongo client optionmongoose.connect(&quot;mongodb://localhost/somecollection&quot;, { useMongoClient: true,}); mongoose 5.x 버전 부터는 Promise connect()를 연결한다. mongodb 2.x 연결mongodb 2.x 버전에서 createConnection(), connect() 메서드를 사용해 연결한다. 123456789101112var mongoose = require(&quot;mongoose&quot;);var connection = mongoose.createConnection(&quot;mongodb://localhost/sensors&quot;);//Schemasvar BookScheme = new mongoose.Schema({ title: String, author: String, year: String,});// Modelsvar BookModel = mongoose.model(&quot;Book&quot;, BookScheme); 여러 연결1234567891011var conn = mongoose.connect(&quot;mongodb://localhost/testA&quot;);var conn2 = mongoose.connect(&quot;mongodb://localhost/testB&quot;);var SensorModel = conn.model(&quot;qkboo_sensor&quot;, Sensorcheme);var ModelB = conn2.model( &quot;Model&quot;, new mongoose.Schema({ title: { type: String, default: &quot;model in testB database&quot; }, })); APIsave()Model#save()는 주어진 도큐멘트를 저장한다. return: Promise create()Model.create() 는 하나 혹은 그 이상의 도큐멘트를 저장할 수 있다. MyModel.create(docs) 는 주어지는 도큐멘트 마다 new MyModel(doc).save() 를 수행한다. methodsModel의 인스턴스는 documents 로 내장 메서드가 제공되지만, 사용자가 새로운 메서드를 추가할 수 있다. 12345var animalSchema = new Schema({ name: String, type: String });animalSchema.methods.findSimilarTypes = function (cb) { return this.model(&quot;Animal&quot;).find({ type: this.type }, cb);}; 이제 animalSchema 의 인스턴스는 새 메서드 findSimilarTypes 사용이 가능하다. 123456var Animal = mongoose.model(&quot;Animal&quot;, animalSchema);var dog = new Animal({ type: &quot;dog&quot; });dog.findSimilarTypes(function (err, dogs) { console.log(dogs); // woof}); Staticsstatic method도 추가할 수 있다. 123456789// assign a function to the &quot;statics&quot; object of our animalSchemaanimalSchema.statics.findByName = function (name, cb) { return this.find({ name: new RegExp(name, &quot;i&quot;) }, cb);};var Animal = mongoose.model(&quot;Animal&quot;, animalSchema);Animal.findByName(&quot;fido&quot;, function (err, animals) { console.log(animals);}); Db.prototype.authenticatemongodb 3.6 이후는 인증시 Socket을 통한 인증을 거부한다. 그래서 Db.prototype.authenticate 을 사용하지 않고 .MongoClient.connect 에서 인증 서명서와 함께 사용해야 한다. Promise1(node:24499) DeprecationWarning: Mongoose: mpromise (mongoose's default promise library) is deprecated, plug in your own promise library instead: http://mongoosejs.com/docs/promises.html 이것은 .save(), query 결과가 Promises/A+ conformant promises 를 반환한다는 것이다. 반환된 결과로 MyModel.findOne({}).then() and yield MyModel.findOne({}).exec() 같은 작업을 할 수 있다는 의미가 된다. Mongoose 4 는 기본으로 mpromise를 약속한다. 1234567891011var gnr = new Band({ name: &quot;Guns N' Roses&quot;, members: [&quot;Axl&quot;, &quot;Slash&quot;],});var promise = gnr.save();assert.ok(promise instanceof require(&quot;mpromise&quot;));promise.then(function (doc) { assert.equal(doc.name, &quot;Guns N' Roses&quot;);}); Queries are not promisesMongoose queries are not promises. 그러나 대신 양보와 비동기/대기를 위해 .then() 함수를 가지고 있다. fully-fledged promise 가 필요하다면 .exec() 함수를 사용하라. 123456789101112131415var query = Band.findOne({ name: &quot;Guns N' Roses&quot; });assert.ok(!(query instanceof require(&quot;mpromise&quot;)));// A query is not a fully-fledged promise, but it does have a `.then()`.query.then(function (doc) { // use doc});// `.exec()` gives you a fully-fledged promisevar promise = query.exec();assert.ok(promise instanceof require(&quot;mpromise&quot;));promise.then(function (doc) { // use doc}); Plugging in your own Promises Library New in Mongoose 4.1.0 기본 사용에서 mpromise가 만족스러웠지만, 고급 사용자는 ES6-style promises 같은 bluebird 라이브러리를 플러그인으로 넣거나 혹은 네이티브 ES6 를 사용하기를 바랬다. mongoose.Promise 로 좋아하는 ES6 스타일 프로마이즈를 사용할 수 있다. Mongoose ES6 native promises, bluebird, and q를 테스트했다. 어떤 라이브러리도 이론적으로Any promise library that exports an ES6-style promise constructor should work in theory, but theory often differs from practice. If you find a bug, open an issue on GitHub 12345678910111213var query = Band.findOne({ name: &quot;Guns N' Roses&quot; });// Use native promisesmongoose.Promise = global.Promise;assert.equal(query.exec().constructor, global.Promise);// Use bluebirdmongoose.Promise = require(&quot;bluebird&quot;);assert.equal(query.exec().constructor, require(&quot;bluebird&quot;));// Use q. Note that you **must** use `require('q').Promise`.mongoose.Promise = require(&quot;q&quot;).Promise;assert.ok(query.exec() instanceof require(&quot;q&quot;).makePromise); 참고 mongoose doc mongoose api doc mpromise bluebird](https://www.npmjs.com/package/bluebird) ES6-style promises [^1]: Promise 란","link":"/2017-07-13-mongodb-mongoose-cbe8a2ffda9c/"},{"title":"NodeJS: 콤포넌트 만들기","text":"모듈 방식의 express 콤포넌트 만들기 코드 기반 모듈화 하기Modular nodejs express 를 정리했다. 모듈식 구조는 콤포넌트 사이를 완전히 분리되지 않는 것으로 이해할 수 있다. 모듈화 구조는: 작은 콤포넌트로 나뉜다 콤포넌트 자체의 의존성 (테스트)를 갖고 타 콤포넌트에 영향을 최소화해 갱신할 수 있다. 프로젝트 전반 의존성은 개별 콤포넌트낄 공유 (혹은 덮어씀)할 수 있다 콤퍼넌트 우선-클래스(first-class)를 만들어야 한다. 즉 상대적인 경로롤 require를 구문을 사용 않는다. 다시 구성할 필요 없이앱 확장 (혹은 축소)에 전념한다 최소 모듈식 구조아래 같은 최소 구조를 기반으로 하자: 1234bin/lib/package.jsonindex.js bin: npm 스크립에 내장하지 않는 모든것 (ex. hooks, ci 등등 ) lib: 앱 콤포넌트 콤포넌트를 추가콤포넌트는 단독으로 사용할 수 있는 프로젝트의 모든 측면이다. 예를 들어, 한 구성 요소는 cron 작업 스케줄링, 전자 메일 보내기, 내보내기 도구에 다른 구성 작업을 할 수 있다. 데이터 측면에서 모든 모델에 전용 인 하나의 구성 요소 또는 각 모델에 대해 별도의 구성 요소를 가질 수 있다 lib 디렉토리에 콤포넌트를 추가한다: 12345678910bin/lib/ |- app/ | |- index.js | └─ package.json |- logger/ |- config/ └─ models/package.jsonindex.js 콤포넌트의 진입점은 index.js 이고 package.json에 관련 의존성을 담는다. package.json은 npm init -y 으로 초기화한다. 먼저 express 모듈을 설치한다. ( 여기선 npm version 5 이상 사용) 1npm i express logger 디렉토리에 로깅 모듈을 설치하고, config 디렉토리에 콤포넌트를 위한 구성 파일을 둔다. 콤포넌트 우선 클래스 만들기콤포넌트는 앱에서 우선 클래스 이라서 프로젝트 어느 곳에서든 바로 접근할 수 있어야 해서, 아래 같이 상대적 경로를 사용하지 말아야 한다. 1var logger = require('../../../logger') 콤포넌트에서 모든 모듈은 /lib 폴더를 참조하게 하므로 아래 같이 트릭을 사용해 node_modules 밑에 _ 로 링크를 만들어 주면In UNIX, this is: 12cd {project_root}/node_modulesln -s ../lib _ In Windows, it is: 12cd {project_root}/node_modulesmklink /D _ ..\\lib require('_/looger) 같이 참조할 수 있다. 1var log = require('_/logger') 의존성 공유이제 프로젝트 루트에서 콤포넌트를 설치하면 의존성을 사용할 수 있다. 설정콤포넌트의 분리는 휼륭하다 preinstall1234567891011121314151617var fs = require(&quot;fs&quot;);var resolve = require(&quot;path&quot;).resolve;var join = require(&quot;path&quot;).join;var cp = require(&quot;child_process&quot;);// get library pathvar lib = resolve(__dirname, &quot;../lib/&quot;);fs.readdirSync(lib).forEach(function (mod) { var modPath = join(lib, mod); // ensure path has package.json if (!fs.existsSync(join(modPath, &quot;package.json&quot;))) return; // install folder cp.spawn(&quot;npm&quot;, [&quot;i&quot;], { env: process.env, cwd: modPath, stdio: &quot;inherit&quot; });}); 참조 Modular nodejs express package.json","link":"/module-components-4af1ce94562f/"},{"title":"AI &#x2F; Start Google TensorFlow","text":"Getting Started with TensorFlow 글을 요약 번역한다. tensorflow를 사용하기 위해서는 Python 프로그래밍 배열에 대한 이해 머신러닝에 대한 이해. TensorFlow는 여러 API를 제공하고 있다. TensorFlow Core: 가장 저수준 API 고수준 API는 TensorFlow Core 위에 구성되 있다. 고수준 API 에서 contrib- 를 포함한 메서드 이름은 개발중으로 향후 변경 가능성이 크다. TensorsTensorFlow 에서 주요 데이터 단위가 tensor 이다. tensor는 어떤 차원의 배열로 구성된 기초적인 값의 집합이다. tensor의 rank는 차원의 수이다. 여러 rank를 가진 tensors의 예: 12343 # 하나의 rank 0 tensor; 모양 [] 인 스칼라 값이다.[1. ,2., 3.] # rank 1 tensor; 모양 [3] 인 벡터이다.[[1., 2., 3.], [4., 5., 6.]] # rank 2 tensor; 모양 [2,3]인 행렬이다.[[[1., 2., 3.]], [[7., 8., 9.]]] # 모양 [2, 1, 3] 인 rank 3 tensor ### TensorFlow Core tutorial 먼저 import로 tensorflow 패키지를 가져온다. 1import tensorflow as tf 연산 그래프 Computational GraphTensorFlow Core 프로그램은 두 개의 불연속 구획으로 구성되었다고 생각할 수 있다. 연산 그래프 구성하기 그래프를 조립하는 단계 연산 그래프 실행하기 Session에서 graph 실행 예를 들어 뉴럴 네트워크를 표현하고 학습시키기 위해 구성 단계에는 graph를 만들고 실행 단계에는 graph의 훈련용 작업들(set of training ops)을 반복해서 실행합니다.[^1] 연산 그래프는 그래프 노드에 배열된 TensorFlow 작업의 급수이다. 간단한 연산 그래프를 구성해 보면, 각 노드는 0 혹은 다수의 tensor를 입력으로 가지고 tensor 하나를 출력으로 생성하게 하자. 노드 형식 중 하나는 상수인데, 모든 TensorFlow 상수 값은 입력으로 받지 않고, 초기화한 값을 사용한다. 아래 처럼 부동소수 tensor의 node1, node2 두 개를 생성해 보자 1234node1 = tf.constant(3.0, dtype = tf.float32)node2 = tf.constant(4.0) # 명시적으로 tf.float32 를 인자로 사용해도 된다.node3 = tf.add(node1, node2)print(node1, node2) 아래 같이 출력된다. 1Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32) 실제 값이 연산되려면 Session 을 생성하고 실행해야 한다. 다음 같이 세션을 만들고 node를 실행한다. 12sess = tf.Session()print(sess.run([node1, node2])) #[3.0, 4.0] Tensor 노드를 묶어 복합적인 계산을 구성할 수 있다. 노드를 더해서 새로운 노드로 만들 수 있다. 123node3 = tf.add( node1, node2)print(&quot;node3:&quot;, node3)print(&quot;sess.run(node3):&quot;, sess.run(node3)) 노드를 더하는 결과는 아래 같다. 12node3: Tensor(&quot;Add:0&quot;, shape=(), dtype=float32)sess.run(node3): 7.0 TensorFlow 는 TensorBoard 를 지원해 계산 그래프를 그림으로 표시할 수 있다. 아래는 TensorBoard로 출력한 스크립샷이다. 상수가 아닌 매개변수 형식으로 외부 입력을 받을 수 있는 placeholders{:.keyword} 를 사용하면 값을 나중에 입력받을 수 있다. 1234567a = tf.placeholder(tf.float32)b = tf.placeholder(tf.float32)adder_node = a + b # + provides a shortcut for tf.add(a, b)# 노드를 실행한다.print(sess.run(adder_node, {a: 3, b:4.5}))print(sess.run(adder_node, {a: [1,3], b: [2, 4]})) 결과는 127.5[ 3. 7.] TensorBoard 로 그려본 그래프는 다음 같다. 연산 그래프에 다른 연산을 더해 줄 수 있다. 12add_and_triple = adder_node * 3.print(sess.run(add_and_triple, {a: 3, b:4.5})) # 22.5 앞의 연산에 대한 TensorBoard에서 그래프는, 머신러닝에서 모델에 위와 같은 유효한 입력을 가지게 한다. 그리고 모델을 훈련시키기 위해서 새로운 출력을 갖도록 수정할 수 있다. Variables 는 그래프에 훈련시킬 매개변수를 더하게 해준다. 아래 같은 초기화 값이 있고, 1234W = tf.Variable([.3], dtype=tf.float32)b = tf.Variable([-.3], dtype=tf.float32)x = tf.placeholder(tf.float32)linear_model = W * x + b 상수는 tf.constant{:.keyword} 를 호출할 때 초기화 되지만 이후 값을 변경 할 수 없다. 반면 Variable은 tf.Variable{:.keyword}가 호출될 때 초기화 되지 않는다. 초기화 하려면 아래같은 암묵적인 연산을 해주어야 한다. 12init = tf.global_variables_initializer()sess.run(init) 그런데 init 의 실체는 모든 전역 변수를 초기화하는 TensorFlow sub-graph 핸들 이라는 것이다. 또한 sess.run 이 실행 될 때까지 초기화 되지 않는다.이제 x 가 placeholder{:.keyword} 이기 때문에 다음 같이 lenear_model 의 수치를 구하게 한다. 123print(sess.run(linear_model, {x:[1,2,3,4]}))# [ 0. 0.30000001 0.60000002 0.90000004] 이제 훈련 데이터로 linear_model을 평가하기 위해서 y placeholder를 준비하자. 그리고 loss 함수를 작성한다.loss 함수는 제공한 데이터와 현재 모델 사이가 얼마나 떨어져 있는지를 측정한다. 이것은 선형회귀(Linear Regression)에 대한 표준 loss model로 현제 모델과 제공한 데이터 사이의 델타의 제곱근의 합이다. linear_model - y 는 예제의 에러 델타에 대응하는 요소로 이루어진 벡터를 생성한다. tf.sqaure{:.keyword} 를 호출해서 에러에 대한 제곱근을 구한다. 12345y = tf.placeholder(tf.float32)squared_deltas = tf.square(linear_model - y)loss = tf.reduce_sum(squared_deltas)print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))# 23.66 여기서 W, b 에 최적화된 값 -1, 1을 재지정 할 수 있는데, tf.assign{:.keyword} 같은 연산으로 바꿔 줄 수 있다. 12345fixW = tf.assign(W, [-1.])fixb = tf.assign(b, [1.])sess.run([fixW, fixb])print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))# 0.0 결과 0.0 으로 W, b의 완벽한 값으 추축해 볼 수 있다. 머신러닝의 중요한 점은 자동으로 정확한 매개변수를 찾는 것이다. 다음 섹션에서 이것을 살펴볼 것이다. tf.train APITensorFlow 는 optimizers를 제공해서 loss 함수의 매개변수 순서에 따라 값을 변경할 수 있다. 간단한 최적화는 gradient optimizer 이다. 함수의 전달하는 자릿수에 따라 각 값을 바꿀 수 있다. 코드여기까지 코드는 아래와 같다: 참조 텐서플로우 문서 한글 번역본 Getting Started TensorFlow [^1]: 텐서플로우 한글 번역본-기본적인 사용법","link":"/2017-07-12-ai-platform-tensorflow-start-ccaee5982340/"},{"title":"AI &#x2F; Google TensorFlow Install","text":"2015년 인공지능 개발용 오픈소스 TensorFlow 를 공개했다. TensorFlowTensorFlow는 머신러닝을 위한 Research cloud로 1000 Cloud TPU로 가동하고 있다. 1000 TPU는 180Petaflops를 제공하고 있다. {: width=”650”} Ubuntu Linux, macOS X, Windows 머신에 설치할 수 있다. Ubuntu 14.04 이상에서 설치 가능하다. Install on Ubuntu Install먼저 TensorFlow 종류를 결정한다. TensorFlow CPU only support : 시스템에 NVIDI&amp;reg; GPU가 없으면 CPU 버전을 설치한다. 5~10분 정도 소요되고 쉽다. GPU가 있더라도 이 버전을 먼저 시도해 볼 것을 권한다. TensorFlow GPU only support : CPU보다 현저하게 빠르다. NVIDIA&amp;reg; GPU가 있고, 요구사항에 부합하며 성능 문제를 고려하면 이 버전을 설치한다. NVIDIA GPU에서 TensorFlow 실행시 요구조건GPU 지원 TensorFlow를 설치하려면 아래 NVIDIA 소프트웨어가 설치되야 한다: CUDA® Toolkit 8.0 : NVIDIA’s documentation. LD_LIBRARY_PATH 환경변수에 Cuda 경로 추가해준다. CUDA Toolkit 8.0 관련 The NVIDIA drivers 설치. cuDNN v5.1: NVIDIA’s documentation 참고, 설치후 CUDA_HOME 환경변수 설정. GPU card with CUDA Compute Capability 3.0 or higher. 지원하는 종류는 VIDIA documentation를 참조. libcupti-dev library: 아래 명령으로 NVIDIA CUDA Profile Tools Interface를 설치한다. 1$ sudo apt-get install libcupti-dev 시스템에 설치된 소프트웨어가 위에 명시하 패키지 보다 이전 버전이면 업그레이드가 필요하다. 아닌 경우 TensorFlow가 실행되지만 아래 작업을 해주어야 한다: TensorFlow 를 소스에서 설치한다 Installing TensorFlow from Sources. 최소 아래 NVIDIA versions으로 설치한다: CUDA toolkit 7.0 or greater cuDNN v3 or greater GPU card with CUDA Compute Capability 3.0 or higher. ### TensorFlow 설치 방법 TensorFlow는 virtualenv, “native” pip, Docker, Anaconda 에서 설치할 수 있다.virtualenv 환경을 권장한다. virtualenv 환경에서 설치여기서는 macOS에서 Python 가상 개발환경 설치 Linux에서 Python 가상 개발환경 설치 를 참조해서 virtualenv, virtualenvwrapper 를 구성해서 사용한다고 가정한다. 12$ mkvirtualenv --system-site-packages -p python3 tensorflow(tensorflow)$ 그리고 tensorflow 패키지를 설치한다 - GPU 버전을 선택적으로 설치한다. 12(tensorflow)$ pip install --upgrade tensorflow # CPU(tensorflow)$ pip install --upgrade tensorflow-gpu # GPU 위 명령으로 설치가 실패시 pip 버전이 8.1 이하일 수 있다. 업그레이드 후 재 시도한다. 혹은 다음 명령으로 TensorFlow Python package를 직접 설치한다. 1(tensorflow)$ pip install --upgrade tfBinaryURL tfBinaryURL 은 여기서 찾아서 직접 지정한다. Uninstall Tensorflow가상환경 디렉토리를 삭제하거나 12(tensorflow)$ deactivate$ rm -rf .virtualenv/tensorflow 혹은 가상환경에서 tensorflow 를 pip로 지운다. 12(tensorflow)$ pip uninstall tensorflow # CPU(tensorflow)$ pip uninstall tensorflow-gpu # GPU ### Run a short TensorFlow program python 을 실행해 REPL 환경 혹은 스크립트로 아래 코드를 입력한다: 1234import tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello)) 결과로 b'Hello, TensorFlow!' 같이 출력되면 성공적으로 실행된 것이다. 이어서 Getting Started with TensorFlow 를 따라간다. 참조[^1]: Intruducing TensorFlow Research Cloud","link":"/2017-07-12-ai-platform-tensorflow-efc7afc3e35c/"},{"title":"AI - Platform","text":"AI인공지능은 사람이 정보를 분석하고 특성을 모델링하는 머신러닝이 지지부진 하다 2012년 부터 딥러닝 기반은 기계가 스스로 수 많은 정보에서 지식을 구성해 가는 시스템이 실제 구현되며 전환기를 맞고 있다. 과거 IBM의 Deep Blue는 체스를 목적으로 한 체스 전용 소프트웨어와 하드웨어를 인공지능으로 구현되었다. 최근 딥러닝을 기반으로하는 알파고 같은 기술은 하드웨어와 소프트웨어가 범용적 특성을 가지고 있다.[^3] AI platformAI 플랫폼은[^1] 플랫폼이 갖는 주요기능에 따라 음성지능, 언어지능, 시각지능, 공간지능, 감성 지능 플랫폼으로 구분한다. 적용 대상에 따라서 일반 소비자를 대상으로 다양한 서비스 제공이 가능한 범용 AI 플랫폼과 의료, 금융, 법률 등 특정 산업영역에 특화된 전문 AI 플랫폼으로 구분 할 수 있다. 인공지능 플랫폼의 활용주요 IT기업이 “artificial intelligence as a service.” [^2] 으로 3rd party 기업/개발사 들이 앱/서비스를 만들어 가는 형태로 발전하고 있다. 개인/개발사들이 인공지능을 구현하는데 비해서 전문 플랫폼 사이의 성능 격차가 크다. 첫째로 기계학습에 제공하는 양질의 데이터는 큰 격차가 존재한다. 둘째로 비용, 시간 측면에서 기술과 경험이 부족해서 고도화된 서비스를 이용하는 면이 시간적 경제적으로 잇점이다. 범용 인공지능 플랫폼으로,Google Machine Learning Platform2016년 3월 음성인식, 이미지 분석, 번역 기능을 수행하는 인공지능 플랫폼 공개. 구글 머신러닝 플랫폼을 이용해 영상 처리를 한 결과를 이용한 서비스를 만들어 사용할 수 있다.[^3] 2015년 인공지능 개발용 오픈소스 TensorFlow 를 공개했다. Facebook 으로 정교화된 맞춤형 인공지능 플랫폼페이스북은 2013년 딥러닝 분야의 핵심 연구자인 얀 레쿤(Yann LeCun) 교수를 영입하고 뉴욕, 파리 등에 인공지능 전용 연구소를 설립해 인 공지능 핵심 기술 개발에 집중해 오고 있다. 2월에 게시물에 감정 표현 종류를 “좋아요”,”기쁨”,”슬픔” 등 6가지로 확대 세분화, 인공지능 플랫폼 ‘챗봇’은 개인 사용자 선호도를 분석해 서비스를 제공할 가능성, Amazon 실생활 플랫폼2015년 Alexa라는 대화형 인공지능 에이전트로 정보검색, 쇼핑몰 상품 주문, 결제 등의 다양한 기능 수행. 최근 가전, 전등, 스위치 등 스마트 디바이스와 연동되고 있다. 산업별 특화 인공지능 플랫폼 Vertical A.I PlatformIBM 의료 전문 인공지능 플랫폼, IBM 의료 전문 인공지능 플랫폼방대한 정보를 조합해 지식을 만들어 내는 Watson의 핵심 기술을 활용해 IBM은 의료, 금융 분야에 특화된 인공지능으로 발전시켜 가고 있다. 의료 전문 인공지능 플랫폼인 ‘Waston Health’를 운영중인 IBM은 다수의 헬스케어 서비스 기업들을 참여시키며 생태계를 만들어 가고 있다. 또한 약 4조원이 넘는 규모의 집중적인 M&amp;A를 통해 의료 분야의 역량을 빠르게 확보하고 있다. 의학 분야의 경우 IBM은 2012년 캐더링 암 센터와의 제휴를 통해 약 200만 페 이지 의료 전문 서적, 60만건 진단서, 150만건 환자 기록을 확보했다. 지난 2월 약 3조원을 들여 인수한 Truven Health Analytics 는 미 연방 정부 및 주정부 등 약 8500개 고객사에 헬스케어 서비스 제공하는 기업 으로서 막대한 양의 의료 정보를 보유한 기업이다. IBM은 데이터 확보를 위해 엄청 난 금액으로 기업들을 인수하면서 인공지능의 전문성을 높여 가고 있다. Medtronic이라는 헬스케어 디 바이스 제조 기업은 Watson을 활용해 사용자들의 디바이스에서 수집된 생체 정보를 의학적으로 분 석한다. 예를 들어 인슐린 수치를 모니터링 하는 경우 사용자의 수치를 주기적으로 측정해 Watson 에 전달하고 Watson은 이를 분석해 이상 징후가 예견되면 사용자에게 미리 경고를 하거나 당 섭취 절제 등을 권고해 위험을 사전에 방지한다. Arch Health Partners는 전문 의 료 기관임에도 불구하고 고혈압 환자 관리에 Watson을 활용한다. 전문의가 있지만 모든 환자를 상시적으로 관리할 수 없기 때문에 Watson이 그 기능을 대신한다. GE의 산업 인공지능 플랫폼항공, 에너지, 헬스케어, 제조 등 다양한 산업 분야에서 오랜 사업 경험을 갖고 있는 GE는 산업 현장에 인공지능을 적용하고 있다.2015년 Jeff Immelt(CEO)는 “GE는 지금까지는 제조 기반의 회사였지만 앞으로 글로벌 Top 10 소프트웨어 회사로 탈바 꿈 하겠다”고 선언했다. 약 1200명의 소프트웨어 개발자를 확보하고 실리콘 밸리에 소프트웨어 연구소(GE Digital)를 설립한 GE는 산업용 클라우드 플랫폼인 Predix Platform을 발표하며 산업 현장에 인공지능 플랫폼 적용을 확산시키며 4차 산업 혁 명 시대를 주도하려 한다. Predix가 기본적으로는 센서, 기계 간 통신, 데이터 분석과 같은 IoT 기술을 지원하는 클라우드 플랫폼이지만 결국 이를 넘어 인공지능이 접목될 수밖에 없음을 의미하기도 한다. 실제 Predix는 이제 단순한 기계 간 연결, 정보 수집의 단 계를 넘어서 기계들이 정보를 분석하고 상황에 따라 능동적으로 작업을 수행하는 방향으로 발전하고 있다. 국내 AI 플랫폼 [^20] 기업 플랫폼 특징 삼성 빅스비 LG 구글 어시스턴트 SKT 누구 KT 기가지니 네이버 쇼핑톡톡(아미카) SK 플래닛 바로 카카오톡 카카오톡 플러스 친구 주요 분야2016년 주요 기업의 인공지능 분야 M&amp;A [^3] 년도 인수 기업 피인수 기업 기술/사업 요약 2013 Google DNNresearch 딥러닝 및 Neutral Network 기반 이미지 검색 기술 Intel Indisys 자연어 처리 및 대화형 인공지능 서비스 기술 Yahoo IQ Engines 이미지 인식 기술 (이미지 내 객체 인식) Yahoo LookFlow 이미지 인식 및 사물의 종류 분류 기술 Yahoo SkyPhrase 자연어 인식 및 처리 기술 Google DeepMind 딥러닝 및 자가/강화 학습 기술 2014 IBM Cogenea 인공지능 기반의 가상형 비서 서비스 Twitter Madbits 딥러닝 기반의 인공지능 플랫폼 구현 Google Jetpac SNS내 사진 분석을 통한 지능형 여행 가이드 서비스 Google Deepmind Dark Blue Labs 딥러닝 기반의 자연어 처리 기술 Google Deepmind Vision Factory 딥러닝 기반의 텍스트 인식 기술 2015 Facebook Wit.ai 자연어를 통한 스마트홈 및 로봇 분야의 서비스 제어 기술 IBM AlchemyAPI 클라우드 기반의 자연어 처리 기술 (핵심 키워드 추출 및 주제 분류) Twitter Whetlab 머신러닝 최적화 기술 (속도, 성능) Apple Vocal IQ 음성 인식 처리 기술 (인간과 대화형 서비스) Amazon 영상 처리를 통한 사물 인식 기술 Intel 인지 컴퓨팅 기술 Apple 인간의 감정 변화 분석 기술 ~2016/4 NICe Systems Nexidia 비정형화 된 오디오, 비디오, 텍스트 데이터 검색 기술 Salesforce PredictionIO 오픈소스 기반의 머신러닝 서버 구축 Salesforce MetaMind 인공지능 기반의 개인 맞춤화 고객 관리 서비스 참고[^1]: 이코노믹 리뷰, “빠지는데 없는 감초 아마존 인공지능 알렉사”, 2017-1-8[^2]: IBM Watson 임원 David Jenny가 AI as a Service 시대를 예견[^3]: “인공지능 플랫폼 경쟁이 시작되고 있다.”, 이승훈, LGERI, 2016. 5. 11.[^20]: 인공지능 플랫폼 동향과 정책적 시사점, 2017-05-12","link":"/2017-07-12-ai-platform-72f34eae0cdf/"},{"title":"Nodejs middleware: Express","text":"ExpressExpress는 NodeJS Webapplication framework이다. Install expressExpress는 크게 express 모듈과 CLI 모듈로 구성되어 있다. express-generator: Express 프로젝트 및 템플릿 생성 exporess module: Node.js module expres 명령을 이용해서 프로젝트를 생성하는 모듈로서 글로벌로 설치합니다. 12$ mkdir myapp$ cd myapp npm의 package.json 를 초기화하자. 1$ npm init entry point: 에 app.js 혹은 index.js 시작점을 선언한다. 그리고 현재 프로젝트에 express 모듈을 설치하고 package.json에 의존성을 추가해 준다. npm 5.0+ 이상은 npm install 시 모듈을 의존성 목록에 자동으로 추가한다. 1$ npm install express 이전 버전은 아래같인 --save 를 명시해야 한다. 1$ npm install express --save Express Generatorexpress-generator 모듈은 손쉽게 프로젝트를 구성할 수 있게 해준다. CLI 명령으로 글로벌로 설치해 준다. 1$ npm i -g express-generator pug 뷰 엔진을 가진 myapp 이란 프로젝트를 생성하려면 1$ express --view=pug myapp 프로젝트로 이동해 모듈을 설치하고 시작한다. 1$ cd myapp &amp;&amp; npm install MacOS or Linux 에서 디버그 모드로 시작한다. 1$ DEBUG=myapp:* npm start Windows 에서 1&gt; set DEBUG=myapp:* &amp; npm start debug modulehttps://developer.ibm.com/node/2016/10/12/the-node-js-debug-module-advanced-usage/ https://expressjs.com/en/guide/writing-middleware.html ExpressJS Middlewares morgan:logger body-parser:parse the body so you can access parameters in requests in req.body. e.g. req.body.name. cookie-parser:parse the cookies so you can access parameters in cookies req.cookies. e.g. req.cookies.name. serve-favicon:exactly that, serve favicon from route /favicon.ico. Should be call on the top before any other routing/middleware takes place to avoids unnecessary parsing. 주요 미들웨어The following middlewares are not added by default, but it’s nice to know they exist at least: compression:compress all request. e.g. app.use(compression()) session:create sessions. e.g. app.use(session({secret: 'Secr3t'})) method-override:app.use(methodOverride('_method')) Override methods to the one specified on the _method param. e.g. GET /resource/1?_method=DELETE will become DELETE /resource/1. response-time: app.use(responseTime()) adds X-Response-Time header to responses. errorhandler:Aid development, by sending full error stack traces to the client when an error occurs. app.use(errorhandler()). It is good practice to surround it with an if statement to check process.env.NODE_ENV === ‘development’. vhost:Allows you to use different stack of middlewares depending on the request hostname. e.g. app.use(vhost(‘.user.local’, userapp)) and app.use(vhost(‘assets-.example.com’, staticapp)) where userapp and staticapp are different express instances with different middlewares. csurf:Adds a Cross-site request forgery (CSRF) protection by adding a token to responds either via session or cookie-parser middleware. app.use(csrf()); timeout:halt execution if it takes more that a given time. e.g. app.use(timeout(‘5s’));. However you need to check by yourself under every request with a middleware that checks if (!req.timedout) next();.","link":"/express-775b55f39462/"},{"title":"Jekyll - Bootstrap 4","text":"jekyll에서 Bootstrap 4 사용하기bootstrap4 는 2017-6월 현재 alpha 버전으로 jekyll 과 github page에 적용하기 위해서 몇가지 구성과 설정을 해주어야 한다. bootstrap 4 gem 추가bootstrap4는 sass를 지원하고, 실제 sass 파일을 추가하거나 gem으로 설치하는 두 가지 방법으로 설치한다. (1) sass 소스 파일 추가 (2) Gem 으로 설치 만약 bootstrap 3를 사용한다면 Bootstrap 3은 Less로 작성되었고, Jekyll은 Sass를 지원한다.[^3] 여기서는 Bootstrap Ruby gem 으로 설치한다 bootstrap gem을 설치하고 설정을 한 후에 github page에서 사용하기 위해 마지막 섹션에 설명한 것 처럼 bootstrap scss 파일을 복사하는 과정을 거친다. GemfilesGemfile 파일을 열고 bootstrap, autoprefixer-rails, jekyll-assets gem을 추가한다. [^2]. 또한 Gemfile 에서 minima 테마 gem을 막는다. 1234567# gem &quot;minima&quot;, &quot;~&gt; 2.0&quot;group :jekyll_plugins do gem &quot;jekyll-feed&quot;, &quot;~&gt; 0.6&quot; gem 'bootstrap', '~&gt; 4.0.0.alpha4' gem 'autoprefixer-rails' gem 'jekyll-assets' autoprefixer-rails: Autoprefixer for Ruby and Ruby on Rails jekyll-assets: Jekyll을 위한 Sprockets 3 사용한 Asset pipelines. _config.yml_config.yml 을 열고, minima 사용을 막는다. 123456#theme: minimagems: - jekyll-feed - bootstrap - autoprefixer-rails - jekyll-assets 새로 추가한 bootstrap gem을 bundle 명령으로 설치한다. 1$ bundle install assets/main.scssassets/main.scss 파일에 minima를 사용하지 않고, bootstrap에서 사용할 scss 파일을_sass/ 폴더에 작성한다. 12345//@import &quot;minima&quot;;@import &quot;bootstrap&quot;;@import &quot;_custom&quot;; // before 'main', variables for bootstrap@import &quot;main&quot;;@import &quot;blog&quot;; @import “bootstrap” 은 bootstrap gem을 통해 scss 소스를 읽어 온다. 여기서는 _custom.scss 파일은 bootstraps 변수, blog.scss 파일은 블로그 테마를 구성하도록 추가해서 구성했다. _sass/custom.sass 파일이 파일은 bootstrap4 scss _variables 에 있는 변수를 다시 정의한다. 다음 같다 [^2] 12345678910111213141516171819202122232425262728// Bootstrap overrides// Options$enable-flex: true;$enable-rounded: false;$enable-shadows: false;$enable-gradients: false;$enable-transitions: true;// Typography@font-face { font-family: &quot;NotoSansCJKkr-Regular&quot;; src: url( '../assets/fonts/NotoSansCJKkr-Regular.otf') format( 'opentype');}@font-face { font-family: &quot;NotoSansCJKkr-Bold&quot;; src: url( '../assets/fonts/NotoSansCJKkr-Bold.otf') format( 'opentype'); font-style: bold;}@font-face { font-family: &quot;NotoSansCJKkr-Light&quot;; src: url( '../assets/fonts/NotoSansCJKkr-Light.otf') format( 'opentype');}$base-font-family: &quot;NotoSansCJKkr-Regular&quot;, &quot;Helvetica Neue&quot;, Arial, sans-serif !default;$font-family-sans-serif: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, &quot;Helvetica Neue&quot;, Arial, sans-serif;$font-family-base: $font-family-sans-serif; _sass/main.scss 파일여기서 main.scss 에서는 TAG에 대한 전체적인 구성을 했다. minima 에서 가져온 코드등이 혼재한다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/* * Globals */@media (min-width: 48em) { html { font-size: 18px; }}@mixin media-query($device) { @media screen and (max-width: $device) { @content; }}@mixin relative-font-size($ratio) { font-size: $font-size-base * $ratio;}// Width of the content area$on-palm: 600px !default;$on-laptop: 800px !default;$background-color: #fdfdfd !default;$spacing-unit: 30px !default;$footer-height: 4.5rem;$small-font-size: $font-size-base * 0.875 !default;$base-line-height: 1.5 !default;$my-body-font: &quot;NotoSansCJKkr-Regular&quot;, &quot;Helvetica Neue&quot;, Arial, sans-serif !default;/* * TAG */html { position: relative; min-height: 100%;}body { font: $font-weight-base #{$font-size-base}/#{$base-line-height} $my-body-font; color: #111; background-color: $background-color;}h1, .h1,h2, .h2,h3, .h3,h4, .h4,h5, .h5,h6, .h6 { font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-weight: normal; color: #333;}table, td, th { border: 1px solid #003300;}table { border-collapse: collapse; border-spacing: 0;}th { border: 2px solid black;}td { padding: 1px 2px;}/* * Syntaxhighliting from minima */%vertical-rhythm { margin-bottom: $spacing-unit / 2;}// Import partials from minima@import &quot;minima/syntax-highlighting&quot;; 마지막엔 아직 다른 syntaxhighter를 설치 안하고 기존 minima에서 사용하던 syntaxhighliter 를 사용하게 했다. layout 파일 the post page layouts _include/head.html 파일12345&lt;link rel=&quot;stylesheet&quot; href=&quot;{{ &quot;/assets/main.css&quot; | relative_url }}&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css&quot;/&gt; _layout/default.html 파일footer.html 구문 밑에 bootstrap 관련 스크립을 추가한다. 1234567891011121314151617181920{% include header.html %}&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt;{{ content }}&lt;/div&gt;&lt;/div&gt;{% include footer.html %}&lt;!-- JavaScript --&gt;&lt;script src=&quot;https://code.jquery.com/jquery-3.1.1.slim.min.js&quot; integrity=&quot;sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js&quot; integrity=&quot;sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; header.htmlheader.html 을 bootstrap navbar 형태로 다음 같이 변경한다. 123456789101112131415161718192021222324252627&lt;nav class=&quot;navbar navbar-toggleable-sm navbar-inverse bg-inverse bg-faded fixed-top&quot;&gt; {% assign default_paths = site.pages | map: &quot;path&quot; %} {% assign page_paths = site.header_pages | default: default_paths %} &lt;button class=&quot;navbar-toggler navbar-toggler-right&quot; type=&quot;button&quot; data-toggle=&quot;collapse&quot; data-target=&quot;#nav-content&quot; aria-controls=&quot;nav-content&quot; aria-expanded=&quot;false&quot; aria-label=&quot;Toggle navigation&quot;&gt; &lt;span class=&quot;navbar-toggler-icon&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;{{ &quot;/&quot; | relative_url }}&quot;&gt;{{ site.title | escape }}&lt;/a&gt; {% if page_paths %} &lt;div class=&quot;collapse navbar-collapse justify-content-end&quot; id=&quot;nav-content&quot;&gt; &lt;ul class=&quot;navbar-nav&quot;&gt; {% for my_page in site.pages %} {% if my_page.title %} &lt;li class=&quot;nav-item&quot;&gt; &lt;a class=&quot;nav-link&quot; href=&quot;{{ my_page.url | prepend: full_base_url }}&quot;&gt;{{ my_page.title | escape }}&lt;/a&gt; &lt;/li&gt; {% endif %} {% endfor %} &lt;/ul&gt; &lt;/div&gt; {% endif %}&lt;/nav&gt; navbar에서 참조한 구현 사례는 여기 샘플을 참조한다. footer.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;footer class=&quot;footer&quot;&gt; &lt;h3&gt;{{ site.title | escape }}&lt;/h3&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-3 footer-col&quot;&gt; &lt;ul class=&quot;contact-list&quot;&gt; &lt;li&gt; {% if site.author %} {{ site.author | escape }} {% else %} {{ site.title | escape }} {% endif %} &lt;/li&gt; {% if site.email %} {% comment %}&lt;li&gt;&lt;a href=&quot;mailto:{{ site.email }}&quot;&gt;{{ // site.email }}&lt;/a&gt;&lt;/li&gt;{% endcomment %} {% endif %} &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;col-md-3 footer-col&quot;&gt; &lt;ul class=&quot;social-media-list&quot;&gt; {% if site.github_username %} &lt;li&gt; {% include icon-github.html username=site.github_username %} &lt;/li&gt; {% endif %} {% if site.twitter_username %} &lt;li&gt; {% include icon-twitter.html username=site.twitter_username %} &lt;/li&gt; {% endif %} &lt;/ul&gt; &lt;/div&gt; &lt;div class=&quot;col-md-5 footer-col&quot;&gt; &lt;p&gt;{{ site.description | escape }}&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/footer&gt;{% if page.comments %} &lt;!-- Disqus comment count --&gt; &lt;script id=&quot;dsq-count-scr&quot; src=&quot;//{{ site.disqus.shortname }}.disqus.com/count.js&quot; async&gt;&lt;/script&gt;{% endif %} {% raw %} ### \\_layouts 파일 bootstrap 클래스로 감싼다. 12&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt; home.html 파일, {% raw %} 123456789101112131415161718192021222324&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;h1 class=&quot;page-heading&quot;&gt;Posts&lt;/h1&gt; {{ content }} &lt;ul class=&quot;post-list&quot;&gt; {% for post in site.posts %} &lt;li&gt; {% assign date_format = site.minima.date_format | default: &quot;%b %-d, %Y&quot; %} &lt;span class=&quot;post-meta&quot;&gt;{{ post.date | date: date_format }}&lt;/span&gt; &lt;h2&gt; &lt;a class=&quot;post-link&quot; href=&quot;{{ post.url | relative_url }}&quot;&gt;{{ post.title | escape }}&lt;/a&gt; &lt;/h2&gt; &lt;/li&gt; {% endfor %} &lt;/ul&gt; &lt;p class=&quot;rss-subscribe&quot;&gt;subscribe &lt;a href=&quot;{{ &quot;/feed.xml&quot; | relative_url }}&quot;&gt;via RSS&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt; {% endraw %} bootstrap gem과 github pagesgithub page에 올리기 위해서 gem 설치한 bootstrap themem 파일이 필요하다. 로컬에서는 bootstrap gem 으로 bootstrap의 scss 소스를 사용하지만 github page에서는 실제 scss 파일이 함께 저장소에 있어야 한다. 먼저 다음 같이 bootstrap gem 위치로 이동한다. 12$ cd `bundle show bootstrap`/usr/local/lib/ruby/gems/2.4.0/gems/bootstrap-4.0.0.alpha6 $ 스타일 시트 파일을 로컬 _scss 폴더 밑으로 복사한다. 12$ cd assets/stylesheets$ cp -r * ~/work-blog/qkboo-github-work/_sass/ Gemfile, _config.ymlbootstrap gem 사용을 막는다. mamima 테마 삭제minima 테마를 사용하지 않으므로 관련 파일이 있으면 삭제한다. deleted: _sass/minima.scss deleted: _sass/minima/_base.scss deleted: _sass/minima/_layout.scss 단, _sass/minima/_syntax-highlighting.scss 는 일단 유지하자. github page update 문제jekyll 등에서 작업한 내용을 push 했지만 github page 내용이 변경되지 않는 경우, scss 파일 등에 에러가 있을 수 있다. 해당 페이지 프로젝트의 Settings -&gt; Github pages 섹션에 에러가 표시된다. {: width=”500”} 참조[^1]: Bootstrap for Sass[^2]: Bootstrap 4 + Jekyll[^3]: Using Bootstrap CSS with Jekyll","link":"/2017-06-28-jekyll-bootstrap4-10bf3c1bdee2/"},{"title":"Raspbian Wheezy : Python 설치","text":"Raspbian과 Pythonraspbian-wheezy에는 Python 2.7과 Python 3.2가 설치되어 있습니다. Python tools파이썬으로 개발하며 필요한 도구를 설치해서 사용하면 좋습니다. 파이썬 패키지 관리 도고, 가상 개발 환경 등의 설치를 통해서 APT로 설치라즈비안에서 사용하는 파이썬 패키지들은 apt를 이용해서 라즈비안 저장소의 다양한 패키지를 사용할 수 있습니다. apt로 파이썬 패키지를 설치해 사용할 수 있는데 Python 2.x와 Python 3.x의 호환을 위해서 Python 2.x는 ‘python-‘ 접두어를 사용하고 Python 3.x 패키지들은 ‘python3-‘ 를 사용합니다.예를 들어 picamera 패키지는 python-picamera와 Python 3.x 버전을 위해서 python3-picamera가 있습니다. 사전 준비기본 개발자 모듈이 설치 안되어 있다면 설치한다. 1$ sudo apt install build-essential Python 개발을 위해서는 리눅스에 파이썬 헤더가 필요하다. 그래서 python-dev 패키지를 설치해 준다.Jessie에서 Python3.4 헤더는 설치가 되어 있다. 12$ sudo apt-get install python3-devpython3-dev is already the newest version. python2 개발환경을 위해서 헤더를 설치하려면 1234$ sudo apt install python-devThe following extra packages will be installed: libexpat1-dev libssl-dev libssl-doc python2.7-dev pip전통적인 파이썬 패키지 도구인 PIP(Python Package Index, PyPI)를 이용하면 폭넓게 범위를 넓힐 수 있습니다. Raspbian Jessie : 기본으로 제공apt를 이용해 저장소에 있는 외부 패키지를 설치해 사용할 수 있습니다. 그렇지만 개발에 필요한 모든 패키지가 라즈비안 저장소에 있지 않거나 오래된 버전일 수 있습니다. Python2.x용 pip는 python-pip를 설치하고 Python3.x pip는 python-pip3 를 설치합니다. 12$ sudo apt-get install -y python-pip$ sudo apt-get install -y python3-pip Pip 소스로 설치혹은 pip를 최신 소스로 부터 직접 설치하려면 다음같이 실행합니다. 1$ wget https://bootstrap.pypa.io/get-pip.py 시스템에 설치된 python 버전 마다 sudo로 pip를 설치애야 합니다. Python3 을 위한 pip를 설치한다. 12$ sudo python3 get-pip.pySuccessfully installed pip-8.1.2 setuptools-24.0.3 wheel-0.29.0 다음은 Python2를 위한 pip를 설치합니다. 1$ sudo python2.7 get-pip.py Raspbian에서 사용자 계정에서 pip 설치하면 퍼미션 에러가 발생한다.OSError: [Errno 13] Permission denied: ‘/usr/local/lib/python2.7/dist-packages/pip-7.1.2.dist-info’sudo 명령으로 설치해야 한다. pip 설치 참조https://pip.pypa.io/en/latest/installing.htmlhttp://stackoverflow.com/questions/6587507/how-to-install-pip-with-python-3 슈퍼사용자로 pip 설치시 사용자 계정에서 사용하기 불편한 점이 많다. 그래서 가상 개발환경을 구성해 사용자 계정에서 제약없이 사용하도록 한다. pip 사용pyhthon2, python3 버전이 설치되어서 pip도 역시 해당 버전이 별도로 설치되어 있습니다. 다음 버전 저보를 출력하면 어떤 버전인지 확인이 가능합니다. 1234$ pip3 --versionpip 8.1.2 from /usr/local/lib/python3.5/dist-packages (python 3.5)$ pip2 --versionpip 8.1.2 from /usr/local/lib/python2.7/dist-packages (python 2.7) 특정 파이썬 버전의 패키지 모듈을 설치한다면 해당 pip 버전을 호촐하는게 정확합니다. upgrade pippip 는 다음 같이 업그레이드 해야 합니다. 1$pip install -U pip On Windows [5]: 1$python -m pip install -U pip Python 버전 관리자다양한 파이썬 버전을 위해 환경 구성을 해주는 유틸리티. pyenv : “Simple Python Version Management”, 로컬에 다양한 파이썬 버전을 설치하고 사용할 수 있도록 한다. pyenv를 사용함으로써 파이썬 버전에 대한 의존성을 해결할 수 있다. virtualenv : “Virtual Python Environment builder”, 로컬에 다양한 파이썬 환경을 구축하고 사용할 수 있도록 한다. 일반적으로 Python Packages라고 부르는 ( pip install을 통해서 설치하는 ) 패키지들에 대한 의존성을 해결할 수 있다. virtualenv와 virtualenvwrapper를 사용할 것이다. autoenv : 만약 pyenv와 virtualenv를 통해서 의존성을 해결한다고 하더라도 작업할때마다 설정해주는 것은 귀찮은 작업이다. 특정 프로젝트 폴더로 들어가면 자동으로 개발 환경을 설정해주는 autoenv라는 스크립트를 활용하자. 여기서는 virtualenv를 설치하고 virtualenvwrapper를 사용해서 모듈을 설치하고 관리한다. 그러기 위해서 먼저 시스템의 기본 /usr/bin/python 버전을 확인하고 해당 버전의 pip 모듈을 사용해서 virtualenv 와 virtualenvwrapper 를 설치한다. virtualenvvirtualenv는 가상의 파이썬 작업환경을 만들어 준다. 작업환경을 따로따로 만들어주면 해당 환경 내의 파이썬으로 무슨 짓을 해도 시스템 파이썬이나 다른 가상의 작업환경에게 영향을 주지 않는다.pip로 설치할 수 있습니다. pip는 시스템의 site-packages 폴더에, /usr/lib/python2.7/site-packages에 모듈을 설치한다. virtualenv를 이용하면 분리할 수 있다. 단, 현재 python2.7과 python3.4가 공존하는 상태에서 virtualenv는 python2.x를 기반으로 만들어 져서 /usr/bin/python을 찾는데 그래서 다음 같이 pip2 버전으로 virtualenv를 설치해 준다. 1$ pip install virtualenv virtualenv는 python 버전에 관계 없이 하나만을 설치해 두면 된다. virtualenvwrappervirtualenvwrapper는 virtualenv 통합 환경을 좀 더 쉽게 접근할 수 있도록 도와줍니다. ‘virtualenv’ 가 설치된 글로벌 사이트 패키지 위치에 설치되야 합니다. 아마 관리자 권한이 필요할 것입니다. 라즈비안에서는 sudo로 설치해 주어야 한다. 다름 같이 pip로 설치합니다. 1$ sudo pip install virtualenvwrapper 이제 일반 사용자 환경에서 python 개발환경을 구축해 보자. 셀 환경 구성하기쉘 (.bashrc, .profile, 등)에 다음 라인을 추가합니다. 123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh 그리고 쉘 환경을 로딩하기 위해서 다시 로그인 하거나 다음 같이 source 명령을 이용해도 좋습니다. 12345678910111213141516$ source .profileebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extentpermitted by applicable law.Last login: Fri Oct 23 18:17:41 2015 from 192.168.219.103virtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/get_env_details 다음 에러가 발생하면 쉘에 VIRTUALENVWRAPPER_PYTHON 를 추가해 준다. /usr/bin/python: No module named virtualenvwrappervirtualenvwrapper.sh: There was a problem running the initialization hooks. If Python could not import the module virtualenvwrapper.hook_loader,check that virtualenvwrapper has been installed forVIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is Quick-Start다음 같이 virtualenvwrapper 를 사용할 수 있습니다. workon 명령으로 실행 가상 환경 목록 혹은 변경한다. 1$workon 실행 가상 환경 ‘raspberrypi2’ 생성 1234567891011$ mkvirtualenv -p python2 raspberrypi2New python executable in raspberrypi2/bin/python2.7Also creating executable in raspberrypi2/bin/pythonInstalling setuptools, pip, wheel...done.virtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/raspberrypi2/bin/get_env_details(raspberrypi2)pi@raspberrypi ~ $ # 실행 가상 환경 쉘 프로젝트 환경을 빠져 나오려면 ‘deactivate’를 실행한다. 1(raspberrypi2):~$ deactivate rpi.gpio1(raspberrypi2)$pip install rpi.gpio 이제 이 디렉토리 밑에서 코드 작업을 하고 사용하면 됩니다. 다른 Python 버전 환경 만들기123456$ mkvirtualenv -p python3 rpi_py3Running virtualenv with interpreter /usr/bin/python3New python executable in rpi_py3/bin/python3Also creating executable in rpi_py3/bin/pythonInstalling setuptools, pip...done.... virtualenv 사용위의 설명과 같이 고립된 작업환경을 만들려면 디렉토리 구조를 잘 구성해야 합니다. 다음 같이 라즈베리파이 프로그램을 작업할 ‘Blinke’ 디렉토리를 만듭니다. Blinken은 LED를 깜박이는 작업을 수행할 것입니다. 1234567$mkdir blinken$cd blinken$virtualenv envNew python executable in env/bin/pythonInstalling setuptools, pip...done.$. env/bin/activate(env)$ 마지막 명령으로 가상환경을 활성화시키면 프롬프트 앞에 (env)가 표시됩니다. 가상환경을 바탕으로 환경 설정이 동작한다는 것을 의미합니다. 이제 필요한 파이썬 패키지 및 프로그램을 설치하고 개발을 할 수 있습니다. 독립된 DJango 환경 이용하기12345$ mkdir django_tests$ cd django_tests$ virtualenv --no-site-packages env$ source env/bin/activate(env)$ 다시 시스템 파이썬으로 복귀하고 싶으면 deactivate를 실행합니다. 1(env)$ deactivate 다른 버전의 Python 환경 만들기1$ sudo python3 get-pip.py python3의 virtualenvwrapper를 설치한다. 123$ sudo pip3 install virtualenvwrapperCollecting virtualenvwrapper Using cached virtualenvwrapper-4.7.1-py2.py3-none-any.whl mkvirtualenv에서 python3의 환경을 하나 설치한.다. 123456$ mkvirtualenv -p python3 rpi_py3Running virtualenv with interpreter /usr/bin/python3New python executable in rpi_py3/bin/python3Also creating executable in rpi_py3/bin/pythonInstalling setuptools, pip...done.... 가상환경 복사하기cpvirtualenv oldenv newenvrmvirtualenv oldenv pyvenv3.3에서부터 pyvenv에 기본으로 설치되어 있다. 다만 3.3에서는 pip를 가상 환경을 만들 때마다 설치해주어야 한다. 3.4에서는 pip까지 기본으로 설치되어 있다. 12345$ mkdir django_tests$ cd django_tests$ pyvenv-3.4 env$ source env/bin/activate # env의 파이썬 활성화(env)$ deactivate # 시스템 파이썬으로 복귀 라즈비안 시스템과 파이썬파이썬을 이용하면 시스템 관련 정보를 활용할 수 있습니다. 라즈페리파이 모델 확인하기cpuinfo를 살펴보면 현재 라즈베리파이 모델을 확인할 수 있습니다. 1234$cat /proc/cpuinfo... Hardware : BCM2708 Revision : 0003 출력 결과에서 Revision을 살펴보면 라즈페리파이 모델을 확인할 수 있습니다. 이 리비전 번호를 다음 링크의 테이블에서 찾아 보면 확인이 가능합니다. http://elinux.org/RPi_HardwareHistory#Board_Revision_History Python으로 오에스 확인하기123456789101112131415$ pythonPython 2.7.3 (default, Mar 18 2014, 05:13:23)&gt;&gt;&gt; import os&gt;&gt;&gt; print os.nameposix&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.platformlinux2&gt;&gt;&gt; import platform&gt;&gt;&gt; platform.system()'Linux'&gt;&gt;&gt; platform.release()'3.18.7+'&gt;&gt;&gt; platform.machine()'armv6l' 참조 RPi HW History Python Library pyenv + virtualenv + autoenv 를 통한 Python 개발 환경 구축하기 Raspberry Pi에서 Python 3.4와 Django 1.7로 프로젝트 셋업하기 Python과 한글 Short Tutorial : Raspbian + Python3.4 + RPi.GPIO","link":"/rasbian_wheezy-python-setup-535e1a9972e9/"},{"title":"Photoshop Clipping Mask","text":"클리핑 마스크는 원본 이미지에 다른 이미지를 합성할 때 유용하다. 클리핑 마스크 Clipping MaskClipping-Mask는 원본의 특정 영역에, 클리핑 마스크로 다독거린 이미지로 매스킹해서 깔끔하게 합성한 이미지를 표현한다. 그래서 클리핑 마스크는 원본 이미지에 다른 이미지를 합성할 때 유용하다. 원본 이미지에서 일분 영역만을 Clipping-Mask 이미지로 대입해서 표현할 수 있다. 노트북 사진의 배경 변경하기여기서 사용한 방법은 이곳 블로그([^1]) 를 참조해서 연습했다 - 링크에 있는 스마트폰 배경을 클리핑하는 과정은 자세히 설명되어 있다. 아래 그림 같이 왼쪽 맥북 화면에 F1 배경 이미지를 Clipping Mask를 넣어 보자. {:width=”800”} [그림. 노트북에 배경을 클리핑한 예제] 이미지 준비: 1. 배경 이미지를 하나. 2. 노트북 이미지 하나. 노트북 배경 만들기: 배경 이미지를 합성할 노트북 이미지를 가져와서 노트북 이란 레이어로 만든다. 이미지에서 배경을 대입할 영역을 Lasso 같은 툴로 선택한다. 선택된 상태에서 *레이어복제 (Ctrl+J, Cmd+J)*를 실행하면, 선택한 부분만 새 레이어로 만들어 지는데, 이 이름을 타겟 이라고 하겠다. 타겟에 넣을 이미지를 가져와서, 레이어 혹은 스마트 오브젝트 등으로 추가해 레이어를 배경 으로 하자 레이어 패널에서 배경 레이어와 타겟 레이어 사이를 Alt+클릭 혹은 Ctrl+Alt+g키를 누르면 Clipping Mask가 생성되서 배경이 클리핑 마스크한 타겟에만 보이게 된다. {:width=”800”} [그림. 레이어 패널 상태와 배경을 클리핑한 상태] 노트북 이미지 누운 경사와 배경을 맞추려면 배경 레이어에서 Transform 으로 조절하면 된다. Edit -&gt; Transform -&gt; Skew 로 조절할 수 있다. 클리핑 마스크 이미지가 타겟에 보여지지만 노트북 이미지를 가리는 부분이 생길 수 있다 - 여기서는 맥북의 Dock이 가려져 보인다.이때는 노트북 레이어에서 배경 마스크에 보이게 하려면, 노트북 레이어를 Lasso, Maque, Eraser 등으로 지워주면 원하는 모습에 가까와 진다. 사진에서 원하는 부분 지우기이미지나 사진에서 원하는 부분만 남기고 나머지를 지우는 작업을 많이 하게 되는데 이때도 Clipping-Mask를 사용하면 깔끔하게 된다. {:width=”600”} 작업할 사진/이미지를 가져온다. 여기서 앞의 F1 배경 사진에서 레드불 RB16 차를 뒤 배경 아스팔트와 잔디로 채우는 작업을 클리핑마스크와 스탬프 도구를 함께 사용하면 두드러지지 않게 차를 지울 수 있다. 가져온 이미지를 *레이어복제(Ctrl+J, Cmd+J)*한다. 복제한 레이어 이름을 work으로 하겠다. work 이미지에서 Pen, Maque, Lasso 같은 도구로 사라지게 할 영역을 둘러싸고 선택영역으로 만든다. 선택영역 상태에서 레이어 패널에서 레이어복제(Ctrl+J, Cmd+J) 해서 레이어 이름을 대상으로 하겠다. 이 대상 레이어 위헤 빈 레이어를 하나 만들고 레이어 이름을 클리핑 이라고 하자, 대상과 클리핑 레이어 사이를 Alt+클릭 하면 클리핑레이어가 클리핑 마스크로 전환된다. work 레이어에서 Stamp 툴을 선택하고, 교체할 영역을 Alt+클릭으로 지정해 준다. 그리고 클리핑 레이어를 선택하고 바꿀 이미지 영역을 클릭해주면 원본 손상없이 클리핑마스크 영역만 원하는 이미지 영역으로 스탬프로 복제하게 된다. {:width=”400”} 참조[^1]: 클리핑마스크 활용한 이미지 틀안에 쉽게 넣기","link":"/2017-05-20-photoshop-clipping-mask-9b68a51beee5/"},{"title":"R 시작하기","text":"R 소개R은 벨 연구소 Becker 등에 의해 개발됐던 S language를 기반으로 통계 계산, 시각화를 위한 프로그래밍 언어를 포함한 개발환경이다. S language를 이용한 Insightful사의 S+는 S 언어를 이용한 상업용 소프트웨어이고, R은 공개소프트웨어 기반의 소프트웨어 이다. 예) Excel, SPSS, SAS, HLM, MPlus 등 통계 프로그램 소개http://revolution-computing.typepad.com/.a/6a010534b1db25970b01676908ecaf970b-pi 설치R 의 GUI 도구로 R Studio를 사용할 수 있다. http://r-project.org 의 CRAN mirror에서 R을 다운받아 설치한다. http://r-project.org RStudio 설치 http://www.RStudio.com Download R 시작하기R 은 console을 통해 프로그래밍을 하거나 외부 에디터에서 작성한 소스를 컴파일해서 실행 할 수 있다. macOS에서 R 시작시 다음 같은 경고를 보이면 macOS FAQ를 참고해 설정을 해주어야 한다. [그림. ] promptR을 실행하면 명령 입력 프롬프트 ‘&gt;’을 볼 수 있다. 프롬프트에서 한 줄에 하나 혹은 한문장의 명령이 입력되고 실행된다. 1234567print(“Hello World”)Factorial(10) # 계산 기능Rep(x=”hello”, times=5)Rep(times=5) : Error…Plot(10,10)Plot(c(5,7), c(20, 30))Plot(runif(100), runif(100)) # runif()는 랜덤 넘버 생성 함수 에서 명령을 입력하고 엔터로 실행이 되지만 괄호((),{},[])가 닫히지 않으면 ‘+’ 프로프트에서 계속 입력할 수 있다. help() 사용R에서 도움말을 통해 함수, 형식, 등의 정보를 얻을 수 있다. 1&gt; help(“함수명”) 패키지를 로드하지 않은 함수의 도움말 보기 1&gt; help.search(“함수명”) 내가 얻은 패키지는 어떤 것인가? 1&gt; help(package=”알고싶은 패키지명”) 주요 도움말 명령 사용 1234567891011121314151617181920&gt; help() # 도움말 창&gt; help(ls) # 함수 ls()에 대한 도움말&gt; ?ls # 도움말 단축키 ?로 help(ls) 호출&gt; help(&quot;&gt;&quot;) # R의 예약어, 연산자 등은 &quot;&quot;로&gt; help(&quot;for&quot;) # 묶는다.&gt; #특정 패키지에 대한 도움말 요청&gt; help(package=&quot;datasets&quot;)&gt; # 일반 검색어를 이용해 도움말 검색&gt; help.search(&quot;Latex&quot;)&gt; ??&quot;Latex&quot;&gt;&gt; # 사용 예제 검색&gt; example(mean)mean&gt; x &lt;- c(0:10, 50)mean&gt; xm &lt;- mean(x)mean&gt; c(xm, mean(x, trim = 0.10))[1] 8.75 5.50&gt; object다음 같이 hello 변수와 값을 대입하고 hello 변수를 살펴본다. 123456789101112&gt; hello &lt;- “안녕하세요&quot; #유니코드 문자열&gt; hello[1] “안녕하세요&quot;&gt; hello2 &lt;- “R&quot;[] “R&quot;&gt; Object1 &lt;- 1 # 숫자&gt; Obect2 &lt;- 2&gt; Object1 + Object2[] 3&gt; Object1 &lt;- TRUE # 논리형&gt; Object2 &lt;- FALSE WorkspaceR에서 작업공간(workspace)에 사용자가 R을 이용하여 수행하는 자료와 분석 프로시져 등을 포함하게 된다. setwd( … ): 명령으로 워크스페이스 변경 getwd(): 현재 워크스페이스 경로 list.files(PATH): 경로의 파일 목록을 반환 R의 종료를 위해서는 명령문 프롬프트에서 **q()**를 실행하던가 메뉴로부터 “종료”를 선택한다.종료시 워크스페이스에 작업된 자료를 저장할 수 있다. R 객체 이용하기R의 최소 단위는 벡터 정수(1), 실수(5.8271), 문자(‘A’) 문자열(“hello”)는 스칼라이다.벡터는 {1,2,3,4,5,6}과 같이 스칼라가 여러 개 모인 것이이다. 한 개의 스칼라 값을 가진 벡터를 선언한다. 1&gt; a &lt;- 5 객체에 다른 객체 넣기 1234567&gt; object1 &lt;- 1&gt; object2 &lt;- 2&gt; object1[1] 1&gt; object1 &lt;- object2&gt; object1[1] 2 객체에 다른 객체 넣기 123456&gt; object1 &lt;- 1&gt; object1 &lt;- 2&gt; object1 &lt;- object2&gt; object2 &lt;- 100&gt; object1[1] 2 함수 계산 결과를 객체에 넣기 12345678910111213141516&gt; Excel1 &lt;- read.csv(“example_student.csv”)&gt; Object1 &lt;- sum(1,8,4,5,9)Object1 : 27&gt; A &lt;- c(1,3,5,6,9) # 벡터에 대해A : 1,3,5,6,9&gt; A &lt;- 1Is.vector(a): TrueA &lt;- c(1,2,5)Is.vector(a): True&gt; A &lt;- c(“첫번째”, “두번째”, “세번째”)A : ??? Package 관리외부에서 제공하는 모듈을 Install, Update, Library 명령으로 관리할 수 있다. 패키지 설치는 Install 그리고 사용할 때는 Library 명령을 사용하고 패키지 갱신에 Update 명령을 사용한다. 패키지 관리패키지 설치과 업데이트 1234&gt; install.packages(&quot;패키지명&quot;) # 패키지 설치&gt; library(&quot;패키지명&quot;) # 패키지 불러들이기 (사용)&gt; require(&quot;패키지명&quot;) #&gt; update.packges('패키지명') # 패키지 갱신 설치된 패키지 목록 보기123&gt; Library()&gt; installed.packages()&gt; Install.packages()[, c(“Packages”, “version”, “License”)] 필수 패키지1234567891011Install.packages(“rgl”) # 3D 그래프 보여주는 패키지Install.packages(“ggplot2”)Install.packages(“ggthemes”)Install.packages(“data.table”)Install.packages(“devtools”)Install.packages(“KoNLP”)Install.packages(“dplyr”)Install.packages(“plyr”)Install.packages(“reshape2”)Install.packages(“scales”)Install.packages(“stringr”) Github로 패키지 설치하기개발자가 베타 버전을 github에 공개하는 경우Knitr 패키지는 R에서 html, pdf, MS-Word 문서를 만들 수 있음고 https://github.com/yihui/knitr 에서 배포한다. 1234&gt; Install.packages(“devtools”)Library(“devtools”)&gt; install_github(“yihui/knitr”) RStudio UTF8 지원 참조 http://dev.epiloum.net/1546 http://xmlarchive.org/hrc/wp-content/uploads/2012/12/r_book_mac_v3.pdf","link":"/2017-05-15-bigdata-r-install-3a63fe765e9f/"},{"title":"Jekyll Usages","text":"jekyll 기본 사용 지킬 사이트의 테마 이용 전역 설정 글쓰기 사이트 변환 New sitenew 명령을 jekyll의 gem-based themes 를 사용하게 구성해 준다.혹은 빈 폴더에서 새롭게 구성할 수 있다. jekyll newjekyll new로 생성되는 사이트는 gem-based theme를 사용한 jekyll project bootstrapped 로 생성된다. jekyll new SITE_NAME 으로 생성 1$ jekyll new myblog 아래 같은 템플릿 파일로 구성되다. 1234567GemfileGemfile.lock_config.yml_posts/_site/about.mdindex.md 중요한 구성 파일은, 파일 설명 _config.yml 설정 파일 _drafts 발행하지 않은 준비중인 포스트. _includes 재사용 가능한 조각 파일로, _post, _layouts에서 사용 _layouts 포스팅 글의 배치를 할 수 있다. 빈 사이트 만들기1$ jekyll new myblog --blank 디렉토리 구조만 생성된다. 1234_draft/_layout/_posts/index.html _config.yml jekyll configuration 참조 jekyll 설정 참조 1234markdown: kramdownhighlighter: pygmentspermalink: prettyrelative_permalinks: false Jekyll 실행 환경을 지정할 수 있다. 예를 들어 디버깅, 개발, 운영 환경으로 구분한다면 코드에 다음 같이 넣을 수 있다: 123{% if jekyll.environment == &quot;production&quot; %} {% include disqus_comments.html %}{% endif %} jekyll을 실행시 JEKYLL_ENV에 값을 지정해 줄 수 있다. 기본 값은 development 이다. 12$ JEKYLL_ENV=production bundle exec jekyll build$ JEKYLL_ENV=production jekyll build 지킬의 포스트 등에서 사용하는 변수는 https://jekyllrb.com/docs/variables/ 에서 확인할 수 있다. github 지원 config items아래는 GitHub에서 기본으로 제공하는 설정으로 사용자가 원하는 대로 변경이 가능한 설정. 123456789101112131415github: [metadata]kramdown: input: GFM hard_wrap: falsegems: - jekyll-coffeescript - jekyll-paginatelsi: falsesafe: truesource: [your repo's top level directory]incremental: falsehighlighter: rougegist: noscript: false lsi : 관련 포스트글에 대한 인덱스를 생성. safe : 사용자 플러그인을 비활성화 하고, 심볼릭 링크(symbolic links)를 무시. source : Jekyll이 읽을 파일의 위치를 변경. incremental : 수정 변경한 포스트만 다시 빌드하는 옵션. highlighter : rough highlighter 지정 gist : GitHub gist 사용 설정. post포스트는 _posts 폴더에 저장한다. yyyy-mm-dd-파일명.markup( md 또는 markdown 또는 textile) 형식으로 포스트 파일명을 만들어야 한다. 파일 내용은 다음 같이 구성된다. Front matterBODY Front matter 는 다음 같이 구성되고, Front Matter, **머리말**를 참조한다. YAML 머리말 블록을 가진 모든 파일을 특별한 파일로 인식하여 처리하고, 머리말은 반드시 올바른 YAML 형식으로 작성되어야 하며, 대시문자 3개(—)로 감싸서 파일의 맨 첫 부분과 끝 부분에 위치한다. BODY 내용은 마크다운, 기타 문법 형식으로 작성하면 된다. []다른 포맷 지원](http://jekyllrb-ko.github.io/docs/plugins/#converters-1) Front Matter 머릿말세 개의 대쉬 라인(—) 사이에 메타 정보를 넣는다. 123456---layout: posttitle: &quot;Welcome to Jekyll!&quot;date: 2017-05-03 18:53:47 +0900categories: jekyll update--- 빈 메타 정보는 빈 두개의 — 로 둔다. Front matter 에 사용할 수 있는 내장된 변수는 다음 같다: 변수 설명 layout 사용할 레이아웃 파일을 지정한다. 레이아웃 파일명에서 확장자를 제외한 나머지 부분만 입력한다. 레이아웃 파일은 반드시 _layouts 디렉토리에 존재해야 한다. permalink 생성된 블로그 포스트 URL 을 사이트 전역 스타일 (디폴트 설정: /year/month/day/title.html)이 아닌 다른 스타일로 만드려면, 이 변수를 사용하여 최종 URL 을 설정하면 된다. published 사이트가 생성되었을 때 특정 포스트가 나타나지 않게 하려면 false 로 설정하라. category,categories 포스트를 특정 폴더에 넣지 않고, 포스트가 속해야 하는 카테고리를 하나 또는 그 이상 지정할 수 있다. 사이트가 생성될 때, 포스트는 그냥 평범하게 이 카테고리들에 속한 것처럼 동작한다. 두 개 이상의 카테고리들을 지정할 때에는 YAML 리스트 또는 쉼표로 구분된 문자열을 사용한다. tags 카테고리와 유사하게, 하나 이상의 태그를 포스트에 추가할 수 있다. 또 카테고리와 동일하게, YAML 리스트 또는 쉼표로 구분된 문자열로 지정할 수도 있다. 외부 자원이미지, 다운로드 파일 등을 사용할 때는 루트 디렉토리의 images, assets, downloads 라는 디렉토리를 만들고 그곳에 둔다. 그리고 해당 자원의 참조를 / 경로를 기준으로 삼으면 된다. 1![친절한 스크린샷](/screenshot.jpg) site.url 변수 1![친절한 스크린샷]({{ site.url }}/assets/screenshot.jpg) 1… PDF 를 직접 [다운로드]({{ site.url }}/assets/mydoc.pdf)할 수 있습니다. Build실제 웹 사이트에는 html 파일로 제공되야 한다. 그러기 위해서 serve 혹은 build 명령으로 마크다운 파일을 변환해야 한다. jekyll serve 명령은 지킬 사이트 디렉터리 안으로 접근하여 실행해야 한다. serve 명령으로 빌드한 html과 파일은 _site 폴더에 생성된다. ### Theme Jekyll은 기본 테마로 Minima라 불리는 gem-based theme를 사용한다. 이 테마를 구성하는 파일은 jekyll new 명령으로 위치에 다음 같이 구성된다. Minima 테마는 assets, _layouts, _includes, and _sass 디렉토리를 실제 Minima theme gem 디렉토리에 위치하고 있고 아래 같은 구성으로 사이트가 생성된다. 1234567├── Gemfile├── Gemfile.lock├── _config.yml├── _posts│ └── 2016-12-04-welcome-to-jekyll.markdown├── about.md└── index.md 다른 Theme gem을 사용하려면 bundle update를 실행하거나 bundle update &lt;THEME&gt; 로 사용할 를 지정한다. jekyll은 사이트 접근시 처음에 컨텐츠를 아래 폴더 안에서 찾는다. /assets /_layouts /_includes /_sass 예를 들어 post 레이아웃을 사용하고 있다면 _layouts 폴더에 _layouts/page.html 테마 파일을 생성해 변경할 수 있다. 처음부터 생성하는 것 보다 기본 테마 파일을 이용하는 것이 빠르다. #### 기본테마 Manima Minima 테마의 기본 폴더는 bundle show minima 명령으로 확인이 가능하다. 기본테마 디렉토리는 아래 같이 구성되어 있다. 테마 정의에 필요한 _includes/, _layouts/, _sass/, assets/ 폴더이다. 1234567891011121314151617181920212223├── _includes│ ├── disqus_comments.html│ ├── footer.html│ ├── google-analytics.html│ ├── head.html│ ├── header.html│ ├── icon-github.html│ ├── icon-github.svg│ ├── icon-twitter.html│ └── icon-twitter.svg├── _layouts│ ├── default.html│ ├── home.html│ ├── page.html│ └── post.html├── _sass│ ├── minima│ │ ├── _base.scss│ │ ├── _layout.scss│ │ └── _syntax-highlighting.scss│ └── minima.scss└── assets└── main.scss 기본 테마 재정의 하기Jekyll theme는 기본 layouts, includes, stylesheets를 지정하는데, 이것을 사이트 콘텐트에 맞게 재정의할 수 있다. Minima 테마의 기본 폴더는 bundle show minima 명령으로 확인이 가능하다. 그리고 아래 같이 찾아서 열어 볼 수 있다. 먼저 macOS 는 1open $(bundle show minima) Windows 에서는 1explorer /usr/local/lib/ruby/gems/2.3.0/gems/minima-2.1.0 기본 테마 디렉토리 구조를 복사해 와서 작업하겠다. 12$ cd `bundle show minima`~minima-2.1.1$ cp -r _includes _layouts _sass assets ~/mysite/ 각각의 테마 요소를 알아보자. Layout컨텐츠의 구성은 _layouts 폴더에 넣는다. 이렇게 구성해 보자 123default.html| ├&lt;-- post.html ├&lt;-- page.html ### sass _sass 디렉토리에 .sass 파일을 두면 sass 컴파일러가 컴파일 한다. fonts외부 폰트, ttf, otf 등의 폰트를 _assets/fonts 같은 폴더에 다운로드하고 css로 불러와 사용한다. 그리고 _sass/main.scss 등의 css 파일에 다음 같이 폰트를 선언한다. 123456789@font-face { font-family: &quot;NotoSansCJKkr-Regular&quot;; src: url(&quot;../_assets/fonts/NotoSansCJKkr-Regular.otf&quot;) format(&quot;opentype&quot;);}@font-face { font-family: &quot;NotoSansCJKkr-Bold&quot;; src: url(&quot;../_assets/fonts/NotoSansCJKkr-Bold.otf&quot;) format(&quot;opentype&quot;); font-style: bold;} 그리고 html 혹은 css 에서 font-family 이름을 사용하면 된다. 1234h1,h2 { font-family: &quot;NotoSansCJKkr-Bold&quot;;} ### Disqus disqus.com 에서 새 사이트를 구성하고, Jekyll 을 선택하면 Universal code 를 얻을 수 있다. #### Disqus Universal Code 설치 comments 변수 comments 변수를 YAML Front Matter에 추가하기 위해, Jekyll의 manima 테마에서 _layouts/post.html 에 변수를 추가해 준다. 1234---layout: defaultcomments: true--- Universal code `{% if page.comments %}` 와 `{% endif %}` 태그 사이에 Universal Embeded Code를 추가해 준다. manima 테마의 \\_includes/disqus_comments.html 파일에 구성되어 있다. 코드에서production을 developement로 바꿔서 테스트 해보자. 댓글 수 표시 태그 전에 아래 스크립트를 원하는 위치에 둔다. 12345{% if page.comments %} &lt;!-- Disqus comment count --&gt; &lt;script id=&quot;dsq-count-scr&quot; src=&quot;//{{ site.disqus.shortname }}.disqus.com/count.js&quot; async&gt;&lt;/script&gt;{% endif %} href 속성에 #disqus_thread 를 추가하기 위해서, _layouts/post.html 템플릿에 다음을 추가한다. 123456{% if page.author %}• &lt;span itemprop=&quot;author&quot; itemscope itemtype=&quot;http://schema.org/Person&quot;&gt;&lt;span itemprop=&quot;name&quot;&gt;{{ page.author }}&lt;/span&gt;&lt;/span&gt;{% endif %}{% if page.comments %} • &lt;a href=&quot;{{ site.url }}{{ page.url }}#disqus_thread&quot;&gt;Comments&lt;/a&gt;{% endif %} 이제 제목 밑에 disqus 링크가 표시된다. {:width=”400”} 조건에 page.conmments 를 참조하면 post 에 comments: true 가 정의되면 되고, layout 전체를 담당하려면 아래 같은 layout.comments 를 비교한다: 123{% if layout.comments %} • &lt;a href=&quot;{{ site.url }}{{ page.url }}#disqus_thread&quot;&gt;Comments&lt;/a&gt;{% endif %} ### Google Analytics jekyll new 로 새 사이트를 설치하면 __includes/google-analytics.html 이 포함되어 있다. Google Analytics에서 Tracking ID를 발급받아 사용하면 된다. #### Tracking ID Google account가 있으면 손쉽게 만들수 있다.여기 에서 로그인해서 Admin &gt; Property &gt; Tracking Info &gt; Tracking Code 에서 찾을 수 있다. {:width=”400”} #### 설정 파일 __includes/google-analytics.html 안의 {{ site.google_analytics }}에 Tracking ID가 치환 되는데, 이것은 _config.yml 파일 google_analytics: 항목에 본인의 Tracking ID를 입력한다. 12# Google servicesgoogle_analytics: UA—XXXXXXXX-X #### default.html 이 파일을 _includes/head.html 파일에는 production 모드에서 analytics가 적용이 된다. 123{% if jekyll.environment == 'production' and site.google_analytics %}{% include google-analytics.html %}{% endif %} 운영모드인 production 은 github 에 업로드시 자동으로 적용된다. 만약 다른 사이트에 업로드하려면 빌드를 한다.$ JEKYLL_ENV=production bundle exec jekyll build Pagenation지킬에서 jekyll-paginate gem 을 추가하면 페이지 구분을 추가할 수 있다. https://jekyllrb.com/docs/pagination/ Gemfile과 _config.ymlGemfile에 추가. 123group :jekyll_plugins do gem &quot;jekyll-feed&quot;, &quot;~&gt; 0.6&quot; gem &quot;jekyll-paginate&quot; config.yml에서 활성화: 12345678gems: - jekyll-feed - jekyll-paginate#페이지 활성화paginate: 6 Custom Domaingithub page를 github.io 서브도메인 대신 본인의 도메인에 등록하려면 두 가지를 한다: 깃헙 페이지의 설정에서 custom domain 을 추가한다. DNS에 CNAME을 등록한다. Custom domain 추가github 에서 github page 저장소의 Settings 에서 Custom Domain에 사용할 도메인 이름을 저장한다. CNAME 등록DNS에 CNAME 을 github의 USER_NAME.github.io 에 연결해 준다.제대로 등록됐는지 dig 명령으로 확인한다. 12345$ dig docs.example.com +nostats +nocomments +nocmd;docs.example.com. IN Adocs.example.com. 3592 IN CNAME YOUR-USERNAME.github.io.YOUR-USERNAME.github.io. 43192 IN CNAME &lt; GITHUB-PAGES-SERVER &gt;. &lt; GITHUB-PAGES-SERVER &gt;. 22 IN A 199.27.XX.XXX 참조: https://help.github.com/articles/setting-up-a-custom-subdomain/","link":"/2017-05-07-jekyll-usages-f728e688351b/"},{"title":"Jekyll Install","text":"이 글은 github pages 를 통해서 블로그를 할 수 있도록 다음 작업을 한다: 로컬에 ruby를 기반으로한 jekyll 을 설치한다. markdown 으로 작성한 문서를 github pages 에 올린다. jekylljekyllrb.com 의 가이드에 따라 github page에서 블로그로 사용하고자 한다. 설치Ruby 개발 도구가 반드시 필요한데 macOS는 Ruby 최신 버전이 제공되고 있다. Linux/Windows에서 rvm 이라는 가상 개발 환경으로 설치하는게 깔끔하다. GNU/Linux, Unix, or macOS Ruby version 2.0 or above, including all development headers RubyGems GCC and Make (in case your system doesn’t have them installed, which you can check by running gcc -v and make -v in your system’s command line interface) Only required for Jekyll 2 and earlierPermalink NodeJS, or another JavaScript runtime (for CoffeeScript support). Python 2.7 Ruby 개발 도구가 반드시 필요한데 다음 같이 rvm 이라는 가상 개발 환경으로 설치하는게 깔끔하다. Ruby 가상개발환경을 설치한다. Linux/Ubuntu먼저 필요 패키지 12$ sudo apt-get install gnupg2$ sudo apt-get install curl rvm을 설치한다. 1234$ gpg --keyserver hkp://keys.gnupg.net --recv-keys D39DC0E3$ \\curl -sSL https://get.rvm.io | bash -s stable$ source /home/vjinn/.rvm/scripts/rvm$ rvm install ruby-2.2.0 macOS12$ \\curl -sSL https://get.rvm.io | bash -s stable$ rvm requirements #rvm 필수요소를 설치합니다 $HOME/.rvm 이 bashrc 에 추가된다. 로그아웃 하거나 쉘을 열어 rvm 을 샐행해 본다. $HOME/.rvm/scripts/rvm 명령이 실행되야 한다. Install Ruby on rvmruby 를 설치한다. macOS는 기본으로 ruby가 설치되어 있다.단, armhf 인 경우는 binary가 제공되지 않아서 소스를 다운해서 빌드과정을 거친다. 12$ rvm install ruby-2 #ruby-2 최신 버전을 설치$ ruby -v rvm 명령에 대한 사용은 이 블로그를 참조한다. ### jekyll 설치 gem 으로 설치한다. 12$ gem install jekyll bundler... bundler gem은 다른 Ruby gem을 관리하는 gem으로 gem과 gem 버전, 의존성을 지키게 해준다. 12$ jekyll -vjekyll 3.4.3 다음은 jekyll 개발자 버전을 설치한다면 사용한다. #### jekyll 개발버전 git에서 다운로드 최신 개발 버전 사용하고자 한다면 github 에서 다운로드해서 사용한다. 12345$ git clone git://github.com/jekyll/jekyll.git$ cd jekyll$ script/bootstrap$ bundle exec rake build$ ls pkg/*.gem | head -n 1 | xargs gem install -l ### jekyll 사용 jekyll 명령으로 블로그 사이트를 생성, 갱신, 삭제 등이 가능하다. 12$ jekyll new my-awesome-siteRunning bundle install in /home/qkboo/Hdd/Blogs/qkboo.github... 이렇게 생성된 사이트는 아래 같은 구조를 갖는다: 1234567├── Gemfile├── Gemfile.lock├── _config.yml├── _posts│ └── 2016-12-04-welcome-to-jekyll.markdown├── about.md└── index.md 그리고 다음 같이 서버를 실행해서 config.yml 파일을 생성하게 하자. 1234567$ cd my-awesome-site$ bundle exec jekyll serveServer address: http://127.0.0.1:8080/ Server running... press ctrl-c to stop.Ctrl+C Ctrl+C 종료 시키고 my-site/_config.yml 파일에 다음 같이 외부에서 접속 가능하게 해준다. 123# deploymenthost: 0.0.0.0port: 5000 이렇게 해주어야 외부에서 브라우저로 접근할 수 있다. gem-based themes에서는 assets, _layouts, _includes, _sass 디렉토리가 테마의 gem에 있다. #### jekyll 실행 확인 서버가 4000 포트에서 대기중인지 확인 1sudo lsof -i :4000 ##### **bunlde** 명령 bundle 명령을 사용해 jekyll 을 실행할 수 있다. 또한 URL Root 위치를 –baseurl 로 변경 1$ bundle exec jekyll serve -w --baseurl '/' Port 변경 1$ bundle exec jekyll serve -w --baseurl '/' --port 4000 디버그 메시지 출력 –trace: 1$ bundle exec jekyll serve -w --trace ### RubyGem으로 jekyll 관리 RubyGem 을 사용하기 위해 gem 명령으로 사용한다: 1$ jekyll --version 설치한 지킬 또는 gem 패키지 목록은 다음의 명령으로 확인할 수 있다. 123$ gem listor$ gem list jekyll # jekyll 목록 RubyGems 으로 gem 버전을 찾을 수 있다. 1$ gem search jekyll --remote 지킬 특정 버전을 사용하고 싶다면 아래와 같은 옵션을 주면 된다. (예, 1.5.1) 1$ gem install jekyll -v 1.5.1 지킬 삭제는 아래와 같다. 1$ sudo gem uninstall jekyll 특정 버전 삭제는 아래와 같다. (예, 1.5.1) 1$ gem uninstall jekyll -v 1.5.1 다양한 지킬 버전이 설치되어 있을 때 최신 버전 제외 모두 삭제는 아래와 같다. 1$ sudo gem cleanup jekyll 지킬 버전 업데이트는 아래와 같다. gem update를 사용하는 것이 좋다. 123$ sudo gem updateor$ sudo gem update jekyll 위의 내용들은 아래의 명령을 통해 도움을 얻을 수 있다. 1$ gem help ### MathJax LaTex 같은 수학 수식을 지원하려면 _include/head.html 같은 위치에 MathJax 를 포함한다. 1234&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; ## 참조 Jekyll Installation 리눅스에서 지킬 설치] Jekyll extras","link":"/2017-05-06-jekyll-install-2920c3911dec/"},{"title":"Tmux cheatsheet","text":"2017-07-14: 윈도우에서 session 관리 2017-07-10: tmux copy &amp; paste{:.right-history} 터미널 명령은 $ tmux 로 표현하고, Tmux window 에서 Prefix key 키 조합은 는 C{:.keyword} 표기하고, Meta key인 Alt는 M{:.keyword}으로 표기한다 - Tmux Start 참조. 여기서는 .tmux.conf 에서 기능키/메타키 연결해서 기본 Prefix key인 Ctrl+b 를 Ctrl+a로 묶었다. 123set -g prefix C-abind C-a send-prefixunbind C-b Tmux 명령tmux는 세션을 만들고, 세션에서 window를 구성하고, window 안에 pane을 사용한다. 새로운 세션 시작하기12$ tmux #새로운 새션$ tmux new -s session_name #session_name으로 새로운 세션 세션을 dettach하면 세션은 저장된다. 사용하지 않으면 kill로 종료한다. 세션 이용하기123$ tmux ls$ tmux list-session$ tmux list-windows # Window 목록 열린 세션에 붙기. 세션 번호중 낮은 번호에 우선해서 접속한다. 123$ tmux attach$ tmux at$ tmux a 특정 세션에 접속하기 세션 번호 혹은 이름으로 접속한다. 1$ tmux a -t session_name 세션 마감하기1$ tmux kill-session session_name Tmux로 접속한 session은 처음 한개의 Window를 갖는다. window 안에서 session, window, pane을 관리한다. 각 윈도우는 한 개 이상의 Pane 구획으로 나누어 사용할 수 있다. Tmux Window현재 세션 이용 12C-s #Session 목록C-$ #Session 이름 변경 window 사용하기세션에서 여러 윈도우를 추가 해서 사용할 수 있다. 1C-c #새로운 윈도우 생성 여러 윈도우는 윈도우 순서에 따라 현재 윈도우 화면을 교환 할 수 있다. 1234567C-w #윈도우 목록C-1 ... #지정 윈도우 번호로 전환: 0,1,...C-p #이전 윈도우로 이동C-n #다음 윈도우로 이동C-l #가장 마지막 윈도우로 이동C-, #현재 윈도우 이름 변경C-&amp; #현재 윈도우 제거 현재 세션에서 나온다. 세션은 백그라운드에서 실행된다. 12C-d #현재 세션을 빠져 나온다 (detach)C-D #빠져나올 세션을 선택할 수 있다. Tmux paneTmux window를 여러 분할면 pane으로 나눠 사용한다. 1234567891011C-% #수직으로 나누기C-&quot; #수평으로 나누기C-z #현재 pane 확대 및 돌아오기C-{ #현재 pane을 이전 pane 위치로 이동C-} #현재 pane을 다음 pane 위치로 이동C-Arrow #앞,뒤 pane을 방향키로 이동C-M+Arrow #pane 크기를 방향키에 따라 변경C-spacebar #pane 방향 전환 (수직&lt;-&gt;수평)C-! #현재 pane을 새 window로 분리C-x #pane 종료C-[ #pane에서 스크롤 기능을 활성화 Session transitionTmux window 상태에서 여러 세션 사이의 전환 단축키; 12345C-$ # 현재 세션 이름 바꾸기C-( # 이전 세션으로 전환C-) # 다음 세션으로 전환C-L # 사용한 세션중 마지막 세션으로 전환C-s # 사용 가능한 세션 목록 Tmux copy &amp; pastetmux 는 자체 버퍼에 터미널에서 선택한 영역의 텍스트를 복사해서 사용할 수 있다. 1234C-[ # copy modeCtrl+space # 복사할 영역을 선택한다. 터미널에 영역이 선택되어 보인다.Ctrl+w # 선택한 영역을 복사한다.C-] # 붙여 넣는다. 단, 시스템 버퍼는 별도의 플러그인을 사용한다. Copy with mouse dragmouse mode를 활성화 하면 터미널에서 마우스 드래그로 텍스트를 선택하면 tmux buffer에 복사되게 한다. .tmux.conf 파일에 다음 구성을 추가한다: 1set -g mouse on","link":"/2017-05-05-tmux-cheatsheet-38c090793298/"},{"title":"Tmux Start","text":"2017-07-10: tmux-continum 추가{:.right-history} Tmux는 terminal multiplexer로 서버에 여러 프로그램을 세션에 저장하고, 다른 작업 혹은 연결을 끊었다 다시 접속해서 세션을 열어 작업을 이어갈 수 있다. {: width=”600”} [그림. Tmux 실행 모습 (tmux.github.io)] 설치여기서는 tmux 2.x 이상을 사용한다. Ubuntu 14.04, Raspbian Jessie, Armbian 등에서 tmux가 1.8, 1.9 버전이 제공 Ubuntu 15, 16 Xenivior 버전은 Tmux 2.1 macOS는 brew 를 사용한다. Tmux 2.3 설치이전 Ubuntu 14.04, Raspbian 등에서 tmux가 1.8, 1.9 버전이 제공되는데 package manager 같은 기능을 사용할 수 없다. 소스로 빌드해서 사용할 수 있다. Ubuntu 14.04 desktop, orangepi plus, raspberry pi jessie 초기 버전에서 빌드 소스 설치혹시 모르니 기존 낮은 버전의 tmux를 삭제하고 시작해 보자. 1$ sudo apt remove --purge tmux 소스를 https://github.com/tmux/tmux/releases/ 에서 최신 버전으로 다운로드 하고 빌드한다. 1234567sudo apt updatesudo apt install -y libevent-dev libncurses-devwget https://github.com/tmux/tmux/releases/download/2.3/tmux-2.3.tar.gztar xvzf tmux-2.3.tar.gzcd tmux-2.3/./configure &amp;&amp; makesudo make install deb 바이너리 설치 단, libtinfo5 6.x 설치시 의존성 라이브러리 문제로 패키지 삭제 문제 발생!!! https://launchpad.net/ubuntu/yakkety/amd64/tmux/2.2-3 에 빌드되어 있는 바이너리를 Ubuntu 14.04 설치하기 위해서 다음 패키지 버전이 필요하다. Depends on: libc6 (&gt;= 2.14) libevent-2.0-5 (&gt;= 2.0.10-stable) libtinfo5 (&gt;= 6) libutempter0 (&gt;= 1.1.5) 기본 설치후 업그레이드를 했다면 libc6 버전은 문제가 없는듯. 12$ sudo apt-cache show libc6$ sudo apt-cache show libtinfo5 Ubuntu14.04.4 LTS 버전의 libtinfo5는 5.9로 다음 같이 설치해 준다. 1$ wget http://launchpadlibrarian.net/271601076/libtinfo5_6.0+20160625-1ubuntu1_amd64.deb 그리고 tmux 2.2 버전의 deb 를 다운로드한다. 1$ wget http://launchpadlibrarian.net/263289132/tmux_2.2-3_amd64.deb 설치 12$ sudo dpkb -i libtinfo5_6.0+20160625-1ubuntu1_amd64.deb$ sudo dpkb -i tmux_2.2-3_amd64.deb 이제 tmux 명령으로 다중 터미널 명령을 사용할 수 있다. macOS에서 tmux 설치homebrew를 사용해서 tmux를 설치한다. 2017년 현재 2.4 버전이 설치된다. 1$ brew install tmux 이제 tmux 명령으로 시작할 수 있다. 시작tmux 를 시작하면 하나의 세션에 하나의 윈도우가 만들어 진다. 12$ tmux # 세션을 시작하고 참가한다.$ tmux new -s foo # 세션 foo를 시작하고 참가한다 세션에 참가하면 하나 혹은 그 이상의 윈도우에서 Pane을 배치해 사용할 수 있다. {: width=”600”}[그림. Tmux window layout] Control와 Meta keyTmux 세션 참가후 Window에서는 Prefix key로 Session, Window, Pane 관련 명령을 키로 조합해 사용한다. 기본 Prefix key는 Control+b key고 옵션으로 사용하는 Meta key는 Alt 키 이다. 여기서 Prefix key는 C와 조합으로 표기하고, Meta key인 Alt는 M으로 표기한다. 윈도우 명령 control, meta 키 조합과 병행해 윈도우에서 명령모드를 사용할 수 있다. 명령모드는 C-: 키로 시작하고, 명령모드에서 명령 자동 완성을 지원한다. {: width=”600”}[그림. Window command mode] Pane 다루기윈도우는 수직/수평으로 구획을 나눌수 있다. C-“ 키로 현재 Pane 아래에 수평으로 새 Pane을 나눈다. 그리고 **C-%**키로 수직으로 새 Pane을 나눌 수 있다. {: width=”600”}[그림. Tmux Window Pane] C-q : pane 번호를 표시하고 번호를 눌러서 이동 C-o : pane을 순서대로 이동 C-방향키 : 해당 방향으로 이동 C-M-방향키 : 해당 방향으로 크기 조절 C-M-1~5 : 몇 가지 미리 설정된 레이아웃을 고를 수 있고, prefix space로 이 레이아웃을 순서대로 - 돌아가며 선택 가능 C-z : 특정화면만 확대하기 다시 예전 Panes상태로 돌아오기 Pane을 지우려면 터미널 exit 명령 혹은 C-x 키로 빠져 나올 수 있다. Window 다루기윈도우는 명령모드에서 new-window 혹은 C-c 키로 새 윈도우를 추가할 수 있다. {: width=”600”}[그림. new Window ] 윈도우 사이의 이동은 윈도우 번호에 따라 단축키 C-0,1,2…9를 사용하거나 C-w로 윈도우 목록에서 선택해 이동할 수 있다. C-n, C-p : 다음 윈도우, 이전 윈도우로 이동 C-l : 직전 사용하던 윈도우로 이동 C-w : 윈도우 리스트를 띄우고 선택 C-, : 윈도우 이름 바꾸기 세션 사용중에 세션을 빠져 나오려면 C-d 로 detach 하거나, 명령모드 C-:에서 detach 명령을 준다. 복사와 스크롤Tmux 화면 버퍼는 한 화면분 밖에 안되서, 이전 화면 내용을 보려면 스크롤 기능을 켜야 한다. C+[ 키는 스크롤 키고, 우측상단에 페이지 표시가 나타난다. 키보드 방향키나 Page Up/Down키로 스크롤이 가능하다. 세션 연결세션은 하나 혹은 그 이상 만들고 attach 명령으로 세션에 참가할 수 있다. 1234$ tmux new -s foo -d # 세션 foo를 시작하고 빠져나온다.$ tmux ls # 세션 목록을 출력한다.0: 1 windows (created Fri May 12 10:26:00 2017) [80x24] (attached)foo: 1 windows (created Fri May 12 10:34:18 2017) [80x24] 터미널에서 세션에 참가하려면 attach 명령과 대상 세션을 지정해 준다. 대상 세션은 tmux ls 명령에 표시되는 세션번호 혹은 세션이름을 지정한다. 123$ tmux attach$ tmux attach -t 0 # 세션 0번에 참여한다$ tmux attach -t foo # 세션 foo에 참여한다. 세션을 완전히 종료 시키려면, tmux 세션에서 명령모드 C-: 에서 kill-session 명령을 실행한다.혹은 다른 터미널에서 세션번호 혹은 세션 이름으로 종료한다. 1$ tmux kill-session -t 3 # 세션번호 3을 종료한다. 설정파일 .tmux.conf사용자 홈디렉토리에 .tmux.conf 파일에 tmux에 대한 설정을 명시할 수 있다. Control + a 사용하기Capslock키를 Control 키로 대체해 사용하면, Control+a 키 조합이 편하다. .tmux.conf 에 키 조합을 변경한다. 12345#Control+a에 'prefix' 연결set -g prefix C-a#send-prefix를 Control+a에 전달bind C-a send-prefixunbind C-b 위에서 prefix는 C-a 로 재배치된다. Mouse On/Off123456789# Toggle mouse on with META mbind m \\ set-option -g mouse on \\;\\ display 'Mouse: ON'# Toggle mouse off with META Mbind M \\ set-option -g mouse off \\;\\ display 'Mouse: OFF' Plugin managerTmux Pluin Manager 를 설치하고, tmux 기능을 확장할 수 있다. tpm 설치먼저 사용자 홈 디렉토리에 저장한다. 1$ git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm 다음 설정을 tmux.conf 에 저장한다. 1234567# List of pluginsset -g @plugin 'tmux-plugins/tpm'set -g @plugin 'tmux-plugins/tmux-sensible'set -g @plugin 'tmux-plugins/tmux-resurrect'# Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)run '~/.tmux/plugins/tpm/tpm' plugin 관리플러그인 설치를 위해서 C-I (대문자) 를 실행플러그인 업그레이드를 위해서 C-U 를 실행 플러그인 목록에서 플러그인을 선택하고 C-M-u (소문자) Tmux-Resurrectiontmux-resurrect{:.keyword}는 tmux 세션을 백업/복구 할 수 있는 플러그인이다. tmux.conf에 다음을 추가 1set -g @plugin 'tmux-plugins/tmux-resurrect' 플러그인 설치를 위해서 C-I 를 실행하면 설치를 시작한다. Resurrection 플러그인으로 백업/복구하는 키는 다음 같이 지정되어 있다: C-s : save C-r : restore Tmux-continuumtmux-resurrect{:.keyword} 에서 저장한 환경을 자동으로 저장/복구할 수 있는 플러그인이다. tmux-continuum tmux-continuum{:.keyword} 의 주요 기능은: tmux{:.keyword} 환경을 15분 마다 자동 저장 컴퓨터/서버 시작시 tmux{:.keyword} 자동 시작 tmux{:.keyword} 시작시 자동 복구 tmux 1.9 이상, bash, tmux-resurrect plugin 설치.tmux.conf 파일에 아래 플러그인을 추가: 12set -g @plugin 'tmux-plugins/tmux-resurrect'set -g @plugin 'tmux-plugins/tmux-continuum' tmux 에서 플러그인 설치를 위해서 C-I (대문자) 를 실행 그리고 .tmux.conf 파일에 continuum-restore 을 on으로 해준다. 1set -g @continuum-restore 'on' tmux 세션을 모두 나와서 tmux 서버를 모두 kill-session 같은 명령으로 종료시킨후 tmux를 다시 시작하면 .tmux/resurrect 에 저장된 마지막 세션이 복구되는 것을 확인할 수 있다. 이제부터 15분 마다 자동 저장하고 서버를 재시작한 후에 tmux를 다시 시작하면 저장한 환경을 자동으로 복구해 준다. tmux status 표시tmux-continuum 의 상태를 tmux status line에 표시할 수 있다. 1set -g status-right 'Continuum status: #{continuum_status}' Linux에서 tmux 자동 시작tmux-continuum 은 Linux systemd, macOS 에서 자동 시작을 지원한다. Linux는 .tmux.conf 파일에 다음 부트 옵션을 추가한다. 1set -g @continuum-boot 'on' 그리고 현재 실행중인 세션에 변경한 설정을 적용하려면 1$ tmux source-file ~/.tmux.conf macOS에서 tmux 자동 시작.tmux.conf 파일에 다음 부트 옵션을 추가한다. 1set -g @continuum-boot 'on' 그리고 현재 실행중인 세션에 변경한 설정을 적용한다. 1$ tmux source-file ~/.tmux.conf 맥이 재시작 하면 자동으로 Terminal.app 이 실행된다. 터미널 크기는 다음 옵션으로 지정한다: 1234set -g @continuum-boot-options 'fullscreen' # terminal window will go fullscreenset -g @continuum-boot-options 'iterm' # start iTerm instead of Terminal.appset -g @continuum-boot-options 'iterm,fullscreen' # start iTerm in fullscreen 다중 tmux 서버는 지원하지 않는다.tmux 로 서버를 하나 시작하고, tmux -S /tmp/foo 같이 다른 소켓을 사용했다고 자동 저장/복구가 별도로 진행되지 않는다. [^10] 여기까지 설정한 내용은 qkboo/tmux.conf gist 에서 확인 가능. ### 설정 저장 tmux 설정을 위힌 default 파일이 존재하지 않는다는 점이다. 그래서 tmux 기본 설정을 어딘가 추출해서 보관해두면 다시 돌아오는데 편리하다. 현재 tmux에 설정된 값은 다음 명령어로 추출할 수 있다. 1$ tmux show -g | sed 's/^/set-option -g /' &gt; ~/.tmux.current.conf tmux.conf를 적용하는 명령은 source-file이다. 1$ tmux source-file ~/.tmux.current.conf 참고 Tmux-Part1 Tmux-Part2 Tmux 소개 tmux 사용에 도움되는 설정과 플러그인 정리 스크롤에 대한 의견 tmux-한글-파일명-출력-문제-해결하기 [^10]: Behaviro when running multiple tmux servers","link":"/2017-05-04-tmux-start-8a8283fda5a3/"},{"title":"mongodb - Collection","text":"CollectionmongoDB는mongoDB는 Collection 이 데이터베이스 테이블과 같은 개념이다. 아래 테이블은 관계형 데이터베이스 MySQL과 MongoDB의 개념을 비교해 주고 있다. [^1] MySQL MongoDB Table Collection Row Document Column Field Joins Embedded documents, linking 늦은 데이터베이스 생성 Lazy Creationuse 명령은 데이터베이스가 존재하지 않으면 새로운 데이터베이스를 생성하고, 그리고 해당 데이터베이스로 전환한다. 12&gt; use mydbswitched to db mydb 그러나 mongodb는 lazy creation 방식을 채용해서 실제 데이터가 CRUD로 조작 될 때 컬렉션이 데이터베이스에 생성된다. use DATABASE 명령 만으로는 실제 데이터 저장공간이 만들어 지지 않는다. 아래같이 show dbs 를 실행해도 데이터베이스가 검색되지 않는다. 123456&gt; use first;switched to db first&gt; show dbs;local (empty)test 0.203125GB 아래와 같이 collection.save() 함수로 새로운 컬렉션에 도큐멘트을 생성하면 데이터베이스 저장 공간에 컬렉션 안에 도큐멘트가 생성되면서 실제 데이터가 저장된다. 12345&gt; db.first.save({ hello: &quot;Hello, Mongodb&quot;});&gt; show dbs;first 0.203125GBlocal (empty)test 0.203125GB 현재 use 로 사용 중인 데이터베이스는 dropDatabase() 함수로 데이터베이스를 삭제할 수 있다. 12345&gt; use firstswitched to db first&gt; db.dropDatabase(){ &quot;dropped&quot; : &quot;first&quot;, &quot;ok&quot; : 1 }&gt; show dbs Collection과 DocumentsmongoDB에 저장되는 도큐멘트는 JSON ojbect 와 유사하게 속성:값 형태로 구성된다. 123var a = { age: 25 };var n = { name: &quot;Ed&quot;, languages: [&quot;c&quot;, &quot;ruby&quot;, &quot;js&quot;] };var student = { name: &quot;Jim&quot;, scores: [75, 99, 87.2] }; mongoDB는 document를 컬렉션에 저장한다. collection.save()아래는 collection.save() 함수로 {a: 99} 도큐멘트를 scores 렉션에 저장하라는 명령이다. 1db.scores.save({ a: 99 }); 실제 데이터베이스의 컬렉션에 도큐멘트가 저장될 때는 바이너리 직렬 구조인 Binary JSON이라는 BSON 으로 저장된다.[^5] 그리고 해당 콜렉션의 담긴 도큐멘트를 find() 함수로 출력한다. 1db.scores.find(); 반복문을 이용해서 여러개의 documents를 저장할 수 있다. 1for(i=0; i&lt;100; i++) { db.scores.save( {a: i, exam: 5 } ) }; 컬렉션 내용을 find()를 실행하면 10개의 결과가 출력됩니다. 123456&gt; for(i=0;i&lt;100;i++){db.scores.save({a:i,b:'bbb'})};&gt; db.scores.find();{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 } 이렇게 데이터베이스에 저장된 컬렉션을 관계형 데이터베이스 처럼 CRUD 명령 셋트를 이용해 질의를 해서 사용한다. Basic Queries관계형데이터 베이스와 NoSQL 데이터베이스는 Query Language가 다르다. SQL과 NoSQL의 CRUDSQL의 INSERT 1INSERT INTO users (user_id, age, status) VALUES ('bcd001', 45, 'A') mongoDB의 INSERT 12345db.users.insert({ user_id: &quot;bcd001&quot;, age: 45, status: &quot;A&quot;,}); SQL의 SELECT 1SELECT * FROM users mongoDB의 find() 1db.users.find(); SQL의 UPDATE 1UPDATE users SET status = 'C' WHERE age &gt; 25 mongoDB의 update() 12345db.users.update( { age: { $gt: 25 } }, { $set: { status: &quot;C&quot; } }, { multi: true }); SQL의 DELETE 1DELETE FROM users WHERE user_id='bcd001' mongoDB의 remove() 123db.users.remove({ user_id: &quot;bcd0001&quot;,}); collection의 주요 CRUD 함수컬렉션에 대한 query는 Collection Method 에 설명되어 있다. 아래 테이블은 주요 CRUD 함수. Name db.collection.find() 컬렉션에서 쿼리를 행하고 결과를 cursor 객체로 반환 db.collection.findOne() 쿼리를 실행하고 도큐멘트 하나를 반환한다. db.collection.findAndModify() 자동으로 수정하고 도큐멘트 하나를 반환한다. db.collection.save() 새 도큐멘트를 삽입하기 위해 insert() 와 update()를 묶어 놓은 함수 db.collection.insert() 컬렉션 안에 새 문서를 생성한다. db.collection.insertOne() 컬렉션 안에 새 문서 하나를 생성한다. db.collection.insertMany() 컬렉션 안에 새 문서 여러개를 생성한다. db.collection.update() 컬렉션 안의 문서를 수정한다 db.collection.updateOne() 컬렉션 안에 문서 하나를 수정한다 db.collection.updateMany() 컬렉션 안에 여러 문서를 수정한다 db.collection.remove() 컬렉션에서 문서(들)을 삭제한다 db.collection.renameCollection() 컬렉션 이름을 바꾼다 컬렉션 보기show collections 명령은 콜렉션의 목록을 볼 수 있다. 12345&gt; show collectionsfooscoressystem.indexesusers collection.renameCollection()로 콜렉션명을 수정 할 수 있다. 1db.[collectionName].renameCollection(&quot;newCollectionName&quot;); 콜렉션의 삭제는 아래와 같다. 1&gt; db.[collectionName].drop() document 조회 – find()find()는 컬렉션 안의 도큐멘트 전체 혹은 지정한 도큐멘트의 속성에 해당하는 도큐멘트를 반환한다. 1db.[collectionName].find([Document]); 데이터베이스 컬렉션 students 안의 도큐멘트를 find() 함수로 보여준다. 12&gt; db.students.find(){ &quot;_id&quot; : ObjectId(&quot;513b38ad81dc4b8f06062146&quot;), &quot;name&quot; : &quot;james&quot;, &quot;age&quot; : 24, &quot;grade&quot; : &quot;A&quot; } find()로 콜렉션에 지정한 속성 값만 검색할 수 있다. 1234&gt; db.students.save({name:'jessi', age:20, grade:'A'});&gt; db.students.find({name:'james'}){ &quot;_id&quot; : ObjectId(&quot;513b38ad81dc4b8f06062146&quot;), &quot;name&quot; : &quot;james&quot;, &quot;age&quot; : 24, &quot;grade&quot; : &quot;A&quot; }&gt; 컬렉션 scores 에서 a가 0인 데이터를 출력해 보자. 1234&gt; db.scores.find({a:0});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; } 컬렉션 scores 에서 a:1, b:bbb인 데이터를 출력해 보자. 12&gt; db.scores.find({a:1, b:'bbb'});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592b&quot;), &quot;a&quot; : 1, &quot;b&quot; : &quot;bbb&quot; } 컬렉션 scores 안의 모든 도큐멘트를 a:1을 기준으로 정렬해서 반환한다. 12345&gt; db.scores.find().sort({a:1});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592b&quot;), &quot;a&quot; : 1, &quot;b&quot; : &quot;bbb&quot; } 컬렉션 scores 안의 도큐멘트 숫자를 반환한다. 12&gt; db.scores.count();110 findOne()find()와 동일한 매개변수를 이용할 수 있습니다. 다른점은 find()는 커서를 리턴하지만, findOne()은 데이터베이스에서 첫번째 document나 null을 리턴합니다. 1234567&gt; db.scores.findOne({a:0});&gt; ```결국 이 쿼리는```js&gt; find({a:&quot;0&quot;}).limit(1). 와 동일한 결과를 얻습니다. limit();쿼리의 결과의 수를 제한된 수의 결과로 제한하게 해서 처리할 수 있습니다. MongoDB cursors are not snapshots - operations performed by you or other users on the collection being queried between the first and last call to next() of your cursor may or may not be returned by the cursor. Use explicit locking to perform a snapshotted query. mongo 쉘 에서 고급 기법에 대해서는 아래 링크를 참조하세요. http://www.mongodb.org/display/DOCS/mongo+-+The+Interactive+Shell Cursor 객체find()는 cursor 객체를 리턴합니다. cursor 객체는 쿼리의 결과 집합에 대한 포인터라고 한다.[^3]cursor는 여러 데이터의 집합이므로 아래 같이 이용 할 수 있다. 1234&gt; var cursor = db.scores.find();&gt; while(cursor.hasNext()) printjson(cursor.next());{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 } printjson() 은 내장 함수로 데이터를 json 형식으로 출력해 준다. mongo 쉘로 사용시 아래 처럼 foreach 콜백 함수를 이용할 수 있다. 123&gt; db.scores.find().forEach(printjson);{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }… 또한 cursor를 배열 처럼 이용 할 수 있다. 123&gt; var cursor = db.scores.find();&gt; printjson(cursor[10]);{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; } 이 시점에 결과가 메모리에 적재되기 때문에 아주 큰 데이터를 다루면 out of memory를 만나게 될 수 있다. 배열 스타일의 접근을 위해 cursor 를 배열로 변경할 수 있다. 123&gt; var arr = db.scores.find().toArray();&gt; arr[10];{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400592a&quot;), &quot;a&quot; : 0, &quot;b&quot; : &quot;bbb&quot; } 도큐멘트 - updatemongoDB에서 도큐멘트 갱신은 update methods를 참고한다. update() 메서드는 다음 형식으로 되어 있다: 1db.collection.update(query, update, options) 아래와 같은 두 개의 document가 있다. 12&gt; db.books.save({name:'James',language:['Java','C++']});&gt; db.users.save({name:'Jenny',language:['HTML5','Actionscript']}); update() 업데이트를 하면 전체 문서에 대해서 갱신이 된다. 아래 쿼리는 Jenny 라는 name 속성을 가진 도큐멘트를 모두 주어진 도큐멘트 속서으로 변경한다. 1234&gt; db.users.update( {name:'Jenny'}, {name:'James',language:['Korea','English']});&gt; db.users.find();{ &quot;_id&quot; : ObjectId(&quot;4fc05ff01708cc4a3eadd3c8&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Java&quot;, &quot;C++&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc0601d1708cc4a3eadd3c9&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Korea&quot;, &quot;English&quot; ] } 데이터의 일정부분만 갱신하려면 $set 연산자 및 배열을 위한 $push, $pull 연산자를 함께 사용할 수 있다. 12345678910&gt; db.users.update( {name:'James'}, {'$set': {age:'30'}} );&gt; db.users.find();{ &quot;_id&quot; : ObjectId(&quot;4fc0601d1708cc4a3eadd3c9&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Korea&quot;, &quot;English&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc060fa1708cc4a3eadd3ca&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Java&quot;, &quot;C++&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc060fe1708cc4a3eadd3cb&quot;), &quot;name&quot; : &quot;James&quot;, &quot;language&quot; : [ &quot;Korea&quot;, &quot;English&quot; ] }{ &quot;_id&quot; : ObjectId(&quot;4fc05ff01708cc4a3eadd3c8&quot;), &quot;age&quot; : &quot;30&quot;, &quot;language&quot; : [ &quot;Java&quot;, &quot;C++&quot; ], &quot;name&quot; : &quot;James&quot; }&gt; db.users.update({name: 'Sue'}, {'$pull': {'languages': 'scala'} });&gt; db.users.update({name: 'Sue'}, {'$push': {'languages': 'ruby'} }); collection.remove()도큐멘트의 항목을 삭제할 수 있다. 12&gt; db.users.remove({name:'James'});&gt; db.users.find(); 모든 데이터를 제거하려면 remove()만 호출합니다. 1&gt; db.users.remove(); index 생성 123db.scores.encureIndex( {a:1, b:’bbb’});group(), min(), max(), $where Query와 Projection 연산자쿼리에 제약 혹은 확장을 할 수 있는 쿼리 선택자 (Query selector)는 비교, 논리, 요소, 배열 등에 대한 연산자로 지원된다. Projection 연산자는 쿼리의 특정 부분만을 투영할 수 있는 연산자를 지원하고 있다. [^4] 자세하고 더 많은 내용은 Query and Projection operators를 참조하라. $gt 연산자입력된 데이터에서 20보다 큰 데이터를 찾아 보겠습니다. 12345&gt; db.scores.find({a:{'$gt':30}});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005949&quot;), &quot;a&quot; : 31, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400594a&quot;), &quot;a&quot; : 32, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400594b&quot;), &quot;a&quot; : 33, &quot;b&quot; : &quot;bbb&quot; }… $gte 연산자$gte는 Greater Than or Equal로 크거나 같은 값을 비교하는 연산자 123&gt; db.scores.find({a:{'$gte':22}});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005940&quot;), &quot;a&quot; : 22, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005941&quot;), &quot;a&quot; : 23, &quot;b&quot; : &quot;bbb&quot; } $lt, $lte 연산자$lte 연산자는 작거나 같은 값을 비교하는 연산자 1234&gt; db.scores.find( {a:{'$lte':5}} );{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 } $ne 연산자$ne 연산자는 같지 않은 값을 비교하는 연산자 1234&gt; db.scores.find({b:{'$ne':'bbb'}});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 } $gte 와 $lte를 동시에 쓰기도 한다 1234&gt; db.scores.find({a: {'$gte':5,'$lte':8}});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e32&quot;), &quot;a&quot; : 5, &quot;b&quot; : 6 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e33&quot;), &quot;a&quot; : 6, &quot;b&quot; : 7 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e34&quot;), &quot;a&quot; : 7, &quot;b&quot; : 8 } $in in Array$in 연산자는 주어진 컬렉션 값이 포함되었는지 비교한다. 12345&gt; db.scores.find({a:{'$in':[10,20,30,40]}});{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005934&quot;), &quot;a&quot; : 10, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f371664400593e&quot;), &quot;a&quot; : 20, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005948&quot;), &quot;a&quot; : 30, &quot;b&quot; : &quot;bbb&quot; }{ &quot;_id&quot; : ObjectId(&quot;4fc0549c58f3716644005952&quot;), &quot;a&quot; : 40, &quot;b&quot; : &quot;bbb&quot; } 반대로 $nin 연산자는 주어진 컬렉션에 포함 안된 값을 비교한다. 1234567&gt; db.scores.find({a:{'$nin':[10,20,30]}});{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2d&quot;), &quot;a&quot; : 0, &quot;b&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2e&quot;), &quot;a&quot; : 1, &quot;b&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;4fbe149b206a4e5abfad0e2f&quot;), &quot;a&quot; : 2, &quot;b&quot; : 3 }…has more","link":"/2017-04-21-mongodb-collections-c0cb4b185312/"},{"title":"MongoDB - Database와 User Authentication","text":"2018-06-21 설치 링크로 대체{:.right-history} MongoDB 설치후 데이터베이스 위치, 로그, 인증 등에 관련한 서버 구성과 설정을 정리한다. MongoDB 2.6 과 MongoDB Community Edition 3.x 버전을 사용했다. mongoDB 접근제어mongoDB 는 설치과정 중에 인증과 관련해 설정하는 부분이 없어서 설치 후 누구나 DB에 접속 할 수 있다. 인증을 추가해 데이터베이스 관리자와 데이터베이스 사용자로 구분해서 이용하고, 각 데이터베이스의 사용자는 허가된 역할(Role)을 가지고 데이터베이스에 접근 가능하도록 구성한다. 여기서는 다음 두 가지를 다루고 있다. (1) 데이터베이스 관리자 추가 (2) 데이터베이스 사용자 추가 Ubuntu/Debian 리눅스 배포본에 MongoDB 3.x 버전이 지원되지 않으면, MongoDB Community Edition 를 패키지 혹은 소스로 설치할 수 있다. MongoDB Community Edition 3.4 on Armv8 MongoDB Community Edition 3.6 데이터베이스 관리자mongod가 비인증 모드로 실행중인 상태에서, mongo 클라이언트로 데이터베이스에 접속한다.접속에 성공하면 &gt; 프롬프트가 표시된다. 그리고 접속한 후에 admin 데이터베이스로 전환한다. 123&gt; use adminswitched to db admin&gt; mongo 클라이언트로 접속해 mongoDB 데이터베이스 관리자 admin 추가해서, 사용자 롤로 userAdminAnyDatabase 롤을 추가해준다. mongoDB 2.6 이후 관리자 계정 추가mongoDB 2.6 이후는 db.createUser() 로 사용자를 추가한다. [^2]다음은 admin 데이터베이스에서 사용자를 관리하는 admin 계정을 생성하고 있다. 123456789101112131415161718192021&gt;&gt; db.createUser({ user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() // 데이터베이스 사용자 확인[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] [^2]: Enable Authentication after Creating the User Administrator(v2.6) mongoDB 2.4 이전 관리자 계정 추가mongoDB 2.4 까지는 새로운 사용자는 db.addUser() 로 추가한다.[^1] 123456$ mongo // mongo client 로 접속&gt;use admin // admin DB 사용&gt;db.addUser( { user: &quot;&lt;username&gt;&quot;, // admin name pwd: &quot;&lt;password&gt;&quot;, roles: [ &quot;userAdminAnyDatabase&quot; ] // Database role } ) mongoDB 2.6까지 32bit 버전을 지원하고 있다. [^1]: Add User Administrator(v2.4 ) 관리자 계정을 만든후 MongoDB에 mongo 클라이언트로 인증 로그인을 한 후에 데이터베이스를 생성하고 해당 데이터베이스 사용자에 접근 권한을 추가해 준다. security.authorizationmongodb.conf 파일에 security.authorization 을 활성화 한다 12security: authorization: enabled 데이터 베이스 생성과 롤 기반 인증관리자 로그인이제 데이터베이스 관리자 계정으로 로그인해서 사용하려는 데이터베이스를 use로 선택하고 해당 데이터베이스 사용자를 추가해준다. mongo 클라이언트 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 1234$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0 혹은 인증없이 mongo 클라이언트로 데이터베이스에 접속한 후에 db.auth() 명령을 사용할 수 있다. 123456789101112&gt; use adminswitched to db admin&gt; db.auth(&quot;admin&quot;, &quot;****&quot;)1&gt; show users{ &quot;_id&quot; : ObjectId(&quot;5733676238ac1ddf4cf745c2&quot;), &quot;user&quot; : &quot;admin&quot;, &quot;readOnly&quot; : false, &quot;pwd&quot; : &quot;24413999168dccff96dcc735720c85ce&quot;}&gt; 이제 각 데이터베이스에 사용자를 생성해서 사용해서 인증한 사용자만 데이터베이스를 사용하게 할 수 있다. Database 사용자 추가mongoDB v3.x 사용자 관리mongoDB v2.6 히우는 대부분 mongoDB v3.4와 호환되는 사용자 관리 명령을 사용한다. 여기서는 User Management Methods (v3.4)를 참고하고 있다. Name Description db.auth() 데이터베이스에 사용자 인증 db.createUser() Creates a new user. db.updateUser() Updates user data. db.changeUserPassword() 사용자 패스워드 변경 db.dropAllUsers() 데이터베이스에 관련된 모든 사용자를 삭제한다. db.dropUser() 한 사용자를 삭제한다 db.grantRolesToUser() 롤과 권한을 사용자에 허용한다 db.revokeRolesFromUser() 사용자에 부여한 롤을 삭제한다 db.getUser() 지정한 사용자의 정보를 반환한다 db.getUsers() 데이터베이스에 관련된 모든 사용자의 정보를 반환한다 createUser()db.createUser() 는 두 개의 도큐멘트를 인자로 사용한다: db.createUser(user, writeConcern) 여기서 user 도큐멘트는 아래 같은 형식을 갖는다: 12345678{ user: &quot;&lt;name&gt;&quot;, pwd: &quot;&lt;cleartext password&gt;&quot;, customData: { &lt;any information&gt; }, roles: [ { role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; } | &quot;&lt;role&gt;&quot;, ... ]} customData: 선택적으로 추가할 정보를 담은 도큐멘트. 다음은 product 데이터베이스로 전환해서 product 데이터베이스 사용자를 추가하고 있다. customeData 를 주목하자. 12345678&gt; use productsdb.createUser( { user: &quot;user1&quot;, pwd: &quot;changeMe&quot;, customData: { employeeId: 12345 }, // prducts roles: [ { role: &quot;clusterAdmin&quot;, db: &quot;admin&quot; }, { role: &quot;readAnyDatabase&quot;, db: &quot;admin&quot; }, &quot;readWrite&quot;] }, { w: &quot;majority&quot; , wtimeout: 5000 } ) 다양한 사례는 createUser() Exmaple 를 참고하자. mongoDB v2.4는 사용자 추가 방법이 조금 다르다. mongoDB v2.4 사용자 추가사용하려는 데이터베이스의 계정으로 접근제어를 추가해 주어야 한다. mongoDB 2.4 까지는 새로운 사용자는 db.addUser() 로 추가한다.[^3] [^3]: Add User To Database(v2.4) 아래는 데이터베이스 관리자 계정 admin으로 로그인해서, 필요하면 students 데이터베이스를 생성합니다. 그리고 students 데이터베이스 사용자 student 계정을 추가하고 있다. 123456789101112131415&gt; use studentsswitched to db students&gt; db.addUser('student', '****'){ &quot;user&quot; : &quot;student&quot;, &quot;readOnly&quot; : false, &quot;pwd&quot; : &quot;7a70591507db46bdd3df47a213d8922f&quot;, &quot;_id&quot; : ObjectId(&quot;57336a71c1ef2bed6688d296&quot;)}&gt; db.auth('student', '012345')1&gt; db.student.save({name:'qkboo', class:'Database', grade:'A'})&gt; db.student.find(){ &quot;_id&quot; : ObjectId(&quot;57336b7d1be9091521cbeb36&quot;), &quot;name&quot; : &quot;qkboo&quot;, &quot;class&quot; : &quot;IoT&quot;, &quot;grade&quot; : &quot;A&quot; }&gt; 이제 mongo 클라이언트로 생성한 students 에 데이터베이스 사용자 student로 로그인한다. 123$ mongo student -u student -p ****MongoDB shell version: 2.4.10connecting to: student 만약 해당 데이터베이스 사용자가 아닌 계정에서 데이터베이스 접근시 다음 같이 인증되지 않은 접근으로 에러를 발생한다. 12345678$ mongoMongoDB shell version: 2.4.10connecting to: test&gt; use studentswitched to db student&gt; show dbsTue Sep 27 23:45:38.269 listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;unauthorized&quot; } at src/mongo/shell/mongo.js:46&gt; MongoDB에 관련 글MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4","link":"/2017-04-20-mongodb-user-auth-0ca5aa6aeae6/"},{"title":"mongodb 3.4 on Armbian","text":"2018-06-22 내용 정리, User auth 링크{:.right-history} 이 문서는 MongoDB Community Edition 3.4 버전을 64bit OS인 Amd64, Arm64 지원 OS에 설치해 사용하기 위해서 Install MongoDB Community Edition, on-ubuntu를 따라서 진행했다. 여기서는 Arm을 사용하는 SBC[^2] 컴퓨터에 mongodb 3.4 버전을, Hardkernel Odroid C2를 사용해서 설치를 진행했다. Odroid C2 for 64bit Armbian Ubuntu Xeniel MongoDB Community edition테스트한 Arm64 기반의 Odroic C2 에서는 MongoDB Community Edition을 설치한 후에 systemd 관련 스크립트와 설정 파일등이 적절히 설치되지 않아서, 이 부분에 대한 언급을 추가했다. 사전준비여기서는 Odroid C2 를 사용하고 Armbian 배포본에서 Ubuntu Xeniel 버전을 사용했다. Armbian 배포본 Debian Jessie 에는 아직 mongodb 64bit 를 제공하지 않고 있다. 레포지토리 등록아래 같이 키 서버를 등록하고 apt source list에 mongodb 를 등록한다. 여러분 시스템이 적용되는 지는 [^1]에 잘 설명되어 있다. 키서버 등록 1$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6 Mongodb 3.4 는 /etc/apt/sources.list.d/mongodb-org-3.4.list 파일 생성하고 아래 같이 해당 리눅스 버전에 맞는 소스 목록을 추가한다. Ubuntu 16.04 1echo &quot;deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list Ubuntu 14.04 1echo &quot;deb [ arch=amd64 ] http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list remove key &amp; ppa설치 후 필요 없어서 키 서버, 저장소 목록을 지우려면, 삭제할 키 해시 코드 확인: 다음 같이 8자리 코드로 나오거나 1234sudo apt-key listpub 4096R/A15703C6 2016-01-11 [expires: 2018-01-10]uid MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt; 다음 같이 긴 해시 코드로 나온다. 123456--------------------pub rsa4096 2016-01-11 [SC] [expires: 2018-01-10] 0C49 F373 0359 A145 1858 5931 BC71 1F9B A157 03C6uid [ unknown] MongoDB 3.4 Release Signing Key &lt;packaging@mongodb.com&gt;/etc/apt/trusted.gpg.d/debian-archive-jessie-automatic.gpg``` 이 키를 1sudo apt-key del A15703C6 설치그리고 apt 명령으로 소스 캐시를 갱신하고 mongodb-org 커뮤니티 버전의 mongodb를 설치한다. 12sudo apt updatesudo apt install mongodb-org 설치전 mongodb 3.x 버전은 데이터 저장 파일 시스템으로 xfs 를 권장하고 있다. create systemd / service entrymongodb-org 설치후 systemctl 스크립트가 /etc/init.d에 복사되지 않았다. 여기서는 odroid-c2 armbian 설치 상태, 일반 리눅스 배포본은 잘 된다. 아래 명령을 실행해 mongodb.service 가 없으면 새로 생성해야 한다. 1$ sudo systemctl list-unit-files --type=service |grep mongodb 만약 mongodb.service 가 없다면, /lib/systemd/system/mongod.service 파일을 다음 같이 활성화 시켜준다. 12$ cd /lib/systemd/system$ sudo systemctl enable mongodb.service mongodb.service 가 있고, 12$ sudo systemctl list-unit-files --type=service |grep mongodbmongodb.service disabled disable 상태면 systemctl 명령으로 enable 시킨다. 1$ sudo systemctl enable mongodb.service 그리고 서비스를 시작한다. 1234567891011$ sudo systemctl start mongod.service$ sudo systemctl status mongod.service● mongod.service - High-performance, schema-free document-oriented database Loaded: loaded (/lib/systemd/system/mongod.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2017-07-18 09:17:53 UTC; 1s ago Docs: https://docs.mongodb.org/manual Main PID: 7234 (mongod) CGroup: /system.slice/mongod.service └─7234 /usr/bin/mongod --config /etc/mongod.confJul 18 09:17:53 odroidc2 systemd[1]: Started High-performance, schema-free document-oriented database. mongod 서비스가 제대로 실행됐으면 mongo 클라이언트로 테스트해 볼 수 있으면 접속해 볼 수 있다. Mongo Database 설정 mongodb 사용자와 디렉토리 퍼미션 확인 mongod.conf 설정 mongo client 접속 테스트 mongodb 인증 mongodb 사용자 확인mongodb-org 설치하면 사용자 mongodb가 만들어 지지만, 혹시 생성되지 않았으면 시스템에 사용자 mongodb 가 없으면 새로 만든다. 1$ sudo adduser --disabled-password --gecos &quot;&quot; --no-create-home --disabled-password --disabled-login mongodb 로그 디렉토리 /var/log/mongo 그리고 데이터 디렉토리 /data/mongodata 라면 해당 디렉토리에 몽고디비 사용자가 쓸 수 있는 퍼미션을 준다. 12$ sudo chown mongo.daemon /var/log/mongodb$ sudo chown mongodb.mongodb /data/mongodata mongod.conf 설정MongoDB의 systemd 서비스는 데이터베이스 구성 파일 /etc/mongod.conf 을 참조한다. /etc/mongod.conf 파일에 인증을 제외한 데이터 디렉토리, bindIp, 로그 부분만 설정한다. 12345678910111213141516storage: dbPath: /data/mongodata/ journal: enabled: truesystemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.logprocessManagement: fork: truenet: port: 27017 bindIp: 127.0.0.1,192.168.0.2 dbPath : 데이터베이스 스토리지 위치 bindIp: 서버 외에서 mongo 클라이언트가 접근하려면 IP 를 입력한다. 현재는 mongo.conf 설정 파일에 접근 제어가 없는 상태에서 mongo 클라이언트로 접속한다 Admin 사용자mongo 클라이언트로 접속에 성공하면 &gt; 프롬프트가 나온다. admin 데이터베이스로 전환한다. 12345$mongo&gt;&gt; use adminswitched to db admin&gt; admin 데이터베이스에서 관리자 role을 가진 사용자를 추가하고, 사용할 데이터베이스의 사용자와 접근 제어를 추가해서 사용하기 위해서 작업한다. user administratoruserAdmin role 혹은 userAdminAnyDatabase role을 가진 사용자 만든다. 다음은 admin 데이터베이스에서 사용자를 관리하는 admin 계정을 생성하고 있다. 12345678910&gt;db.createUser( { user:'admin', pwd:'****', roles:['userAdminAnyDatabase'] })Successfully added user: { &quot;user&quot; : &quot;admin&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] }&gt;&gt; db.getUsers() admin 사용자 패스워드 변경은 1&gt; db.changeUserPassword(&quot;accountUser&quot;, &quot;SOh3TbYhx8ypJPxmt1oOfL&quot;) 사용자의 role 을 변경, 12345678910111213141516171819&gt; db.grantRolesToUser( 'admin', [{role: 'userAdmin', db:'admin'}])&gt; db.getUsers()[ { &quot;_id&quot; : &quot;admin.admin&quot;, &quot;user&quot; : &quot;admin&quot;, &quot;db&quot; : &quot;admin&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;userAdmin&quot;, &quot;db&quot; : &quot;admin&quot; }, { &quot;role&quot; : &quot;userAdminAnyDatabase&quot;, &quot;db&quot; : &quot;admin&quot; } ] }] 혹은 updateUser 를 사용할 수 있다: 1db.updateUser( &quot;appClient01&quot;, ... security.authorizationmongodb.conf 파일에 security.authorization 을 활성화 한다 12security: authorization: enabled systemd 로 서비스를 재시작 한다. 12$ sudo systemctl restart mongod.service$ sudo systemctl status mongod.service 이제 인증 모드에서 데이터베이스에 접속해야 한다. 인증모드로 접속데이터베이스 시스템에 접근제어가 활성화 되면 mongo 클라이언트 접속시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; ### `mongod` 명령 사용 명령 mongod 로 MongoDB를 시작해 설정 파일 등이 제대로 동작하는지 확인할 수 있다. 비인증 모드 시작다음 같이 mongod 를 시작해 동작을 확인한다. 123$ sudo mongod --port 27017 --dbpath /data/mongodata...&gt; 인증 모드 시작앞서 시작한 명령행 mongodb를 종료하고 명령라인에서 재시작 --auth 옵션을 붙여 시작한다. 1$ mongod --auth --port 27017 --dbpath /data/mongodata 접근제어 --auth 옵션으로 데이터베이스를 시작하면 로그인시 -u &lt;username&gt;, -p &lt;password&gt; 와 --authenticationDatabase &lt;database&gt; 를 지정해 주어야 한다. 12345$ mongo --port 27017 -u &quot;admin&quot; -p &quot;****&quot; --authenticationDatabase &quot;admin&quot;MongoDB shell version v3.4.0connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.0&gt; 명령행으로 시작한 mongod 는 종료하고 설정 파일에 인증을 넣자. 데이터베이스 생성과 인증새 데이터베이스에 컬렉션을 생성하고 데이터베이스 사용자를 접근제어할 수 있는 내용은 MongoDB User Authentication 에서 다루고 있다. ### 기타 WiredTiger library panicext4 파일시스템에서 wiredTiger engine으로 실행중 아래 같은 에러가 발생, 여기[^10] 에서 --repair 로 재구성한 후 사용하도록 권장한다. 123452017-07-21T23:26:57.991+0900 E STORAGE [conn31] WiredTiger error (-31804) [1500647217:991504][803:0x7f5794fc20], file:collection-0--8962566541221692692.wt, WT_CURSOR.next: the process must exit and restart: WT_PANIC: WiredTiger library panic2017-07-21T23:26:57.992+0900 I - [conn31] Fatal Assertion 28558 at src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp 361 --repair 로 재구성 1$ sudo mongod --storageEngine wiredTiger --repair --dbpath /data/dbdata/ repaire를 sudo로 진행해서 /data/dbdata 안의 index 파일들이 root 소유권으로 바뀐다. 그래서 /data/dbdata 저장소를 chown으로 mongodb 사용자로 다시 설정 1$ sudo chown -R mongodb.mongodb /data/dbdata 이제 재시작 하면 된다. XFS warning1I STORAGE [initandlisten] ** WARNING: Using the XFS filesystem is strong$y recommended with the WiredTiger storage engine USB Memory 디스크 사용시Odroid C2에 64GB USB Memory를 외부 저장장치로 구성할 때 아래 같이 에러를 발생하며 diagnostic.data 폴더 에러, mongodb 가 다운된다. 아마 ext3 파일 시스템을 사용해서 그런 것 같다. 123456FTDC [ftdc] Uncaught exception in 'FileNotOpen: Failed to open interim file /data/mongodata/diagnostic.data/metrics.interim.temp' in full-time diagnostic data capture subsystem. Shutting down the full-time diagnostic data capture subsystem.2017-04-03T15:00:01.659+0900 E STORAGE [WTJournalFlusher] WiredTiger error (30) [1491199201:659123][877:0x7f7ccfec90], WT_SESSION.log_flush: /data/mongodata/journal/WiredTigerLog.0000000048: handle-write: pwrite: failed to write 128 bytes at offset 19456: Read-only file system2017-04-03T15:00:01.662+0900 E STORAGE [WTJournalFlusher] WiredTiger error (30) [1491199201:662709][877:0x7f7ccfec90], WT_SESSION.log_flush: journal/WiredTigerLog.0000000048: fatal log failure: Read-only file system stackoverflow 에 diagnostic-data 폴더를 지우고 다시 시작하도록 제시되고 있다: 1$ sudo rm -f /var/lib/mongo/diagnostic.data/* 그리고 /etc/mongod.conf에 full time diagnostic을 비활성화 했다. 12setParameter: diagnosticDataCollectionEnabled: false ## MongoDB 관련 글 MongoDB Community Edition Installations 시리즈:ㅇ MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB 구성 설정 과 사용자 인증 사용 MongoDB Tutorials 시리즈: MongoDB Tutorials: collections MongoDB Tutorial MongoDB와 Middleware Platform: NodeJS Mongoose Mongodb mongoose-middleware 이전 버전과 기타 자료: MongoDB User Authentication MongoDB Community Edition 3.6 on Ubuntu(ARM64) Mongodb 3.4 install on Armv8 Raspberry Pi 3 64bit OS openSUSE: Build MongoDB 3.4 참고 MongoDB Tutorial 왜 Guardian은 MongoDB를 선택했나? 포스퀘어가 MongoDB를 선택한 이유 [^1]: Install mongodb on Ubuntu[^2]: SBC Sigle Board Computer. Raspberry Pi, Odroid 등등…[^3]: mongodb installation on Debian[^10]: UnsupportedFormat fatal assertion in wiredTiger following","link":"/2017-04-11-mongodb-3.4-install-armv8-f692faebaa20/"},{"title":"Ubuntu&#x2F;Debian ARM Cross compile 환경","text":"이 글은 우분투, 리눅스 박스에서 GNU ARM Cross compiler 를 설치하고 관리하는 방법을 다루고 있다. 2018-05-17: sidebar.nav/linux 사용{: .right-history} ARM Cross compiler 설치우분투/데비안 리눅스에서 제공하는 ARM Toolchain 환경은 Linaro 툴체인을 바탕으로 만들어져 있어서 두가지 버전으로 제공된다. Hard Float을 지원하는 버전과 그렇지 않은 버전이다.[^1] (1) gcc-arm-linux-gnueabi 이 툴체인은 EABI가 gcc의 -mfloat-abi=soft 혹은 -mfloat-abi=softfp 옵션으로 생성한다는 의미이다. (2) gcc-arm-linux-gnueabihf 이 툴체인은 EABI가 gcc -mfloat-abi=hard 옵션으로 생성한다는 의미이다. 이 의미는 Function Calling Convention이 double, float 사용시 FPU 레지스터에 올려서 전달하고 반환도 FPU 레지스터를 사용하게 된다는 것이다. update-alternatives플랫폼에 따른 gcc 환경을 변경하는 것은 update-alternatives을 사용한다. 링크 update-alternatives에서 설명을 볼 수 있다. ARM toolchain 설치Ubuntu 14.04 에서 테스트했다. 그 이상 버전도 충분히 가능하다. 아래 도구를 설치하면 각 플랫폼에 대한 binutils–arm-linux-, gcc-arm-linux-, g++-arm-linux-, cpp-arm-linux- 도구가 설치된다. Ubuntu14.04 에서 arm toolchain 설치Coretex ARM 12sudo apt-get install gcc-arm-linux-gnueabihfsudo apt-get install g++-arm-linux-gnueabihf ARM 12$ sudo apt-get install gcc-arm-linux-gnueabi$ sudo apt-get install g++-arm-linux-gnueabi Bare metal ARM 12$ sudo apt-get install gcc-arm-none-eabi$ sudo apt-get install g++-arm-none-eabi 필요하면 gfortran-arm-linux-, gobjc++-arm-linux- 등의 도구를 설치한다. 툴 체인 등록여러 개발 보드의 cross compiler를 사용하기 위해서 해당 버전의 접두어를 사용해 보자. arm 을 사용하는 보드는 arm-linux-gnueabi[hf] 명칭을 사용한다. 1$ update-alternatives --list arm-linux-gnueabihf 새로운 arm-linux-gnueabihf- 를 등록하자. arm-linux-gnueabihf 등록하기arm-linux-gnueabihf-gcc-4.8 관련 도구를 gcc 그룹에 등록하기 12sudo update-alternatives --install /usr/bin/arm-linux-gnueabihf-gcc arm-linux-gnueabihf /usr/bin/arm-linux-gnueabihf-gcc-4.8 50 \\--slave /usr/bin/arm-linux-gnueabihf-g++ arm-linux-gnueabihf-g++ /usr/bin/arm-linux-gnueabihf-g++-4.8 arm-linux-gnueabihf-gcc-4.7 관련 도구를 gcc 그룹에 등록하기 12sudo update-alternatives --install /usr/bin/arm-linux-gnueabihf-gcc arm-linux-gnueabihf /usr/bin/arm-linux-gnueabihf-gcc-4.7 40 \\--slave /usr/bin/arm-linux-gnueabihf-g++ arm-linux-gnueabihf-g++ /usr/bin/arm-linux-gnueabihf-g++-4.7 Raspberry pi Toolchain 등록하기Raspberry pi 배포본에서 제공하는 arm gcc compile를 arm-linux-gnueabihf 그룹에 등록해 보자 [^2]. git으로 툴체인을 다운받아 ~/raspberrypi/tools 에 설치한다고 가정한다. [^3] 1git clone https://github.com/raspberrypi/tools ~/raspberrypi/tools 다운로드한 tools 밑에 32bit, 64bit 버전의 컴파일러가 있다. 32bit 버전은 tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian/bin64bit 버전: tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin 다운로드 한 후에 적절한 위치에 놓고, 해당 경로를 확인한다. 123456$ cd ~/rpi-arm/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin/$ arm-linux-gnueabihf-gcc --versionarm-linux-gnueabihf-gcc (crosstool-NG linaro-1.13.1+bzr2650 - Linaro GCC 2014.03) 4.8.3 20140303 (prerelease)Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 64bit Raspberry Pi arm-linux-gnueabihf-gcc- 관련 도구를 gcc 그룹에 등록하기 12sudo update-alternatives --install /usr/bin/arm-linux-gnueabihf-gcc arm-linux-gnueabihf ~/raspberrypi/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin/arm-linux-gnueabihf-gcc-4.8.3 30 \\--slave /usr/bin/arm-linux-gnueabihf-g++ arm-linux-gnueabihf-g++ ~/raspberrypi/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64/bin/arm-linux-gnueabihf-g++","link":"/2017-04-05-crosscompile-arm-32ee69e7ba91/"},{"title":"find 명령 usages","text":"find 명령에서 자주 사용하는 쓰임새를 요약했다. 2018-05: rm, i-node 내용 추가{:.right-history} find 명령find 명령 요약주어진 이름으로 찾아 화면에 출력한다. -name 은 대소문자 구분한 이름을 준다. 1find ./ -name '*.xml' -print 주어지는 이름의 패턴은 *? 를 사용할 수 있다. 찾은 결과를 받아 명령의 입력으로 실행할 수 있다. 다음은 현재 디렉토리 밑에서 .c 파일을 찾아 md5sum 으로 해시 값을 출력한다. -iname은 대소문자 구분을 하지 않는다. 12find -iname &quot;*.c&quot; -exec md5sum {} \\;d41d8cd98f00b204e9800998ecf8427e ./mycprogram.c 검색시 탐색 깊이는 -maxdepth 혹은 -mindepth를 사용할 수 있다. 1find -maxdepth 2 -iname &quot;*.c&quot; -exec md5sum {} \\; 어떤 파일을 제외한 것만 찾을 수 있다: 1find -maxdepth 1 -not -iname &quot;mycprogram.c&quot; 파일의 퍼미션으로 찾을 수 있다. 123find . -perm -g=r -type f -exec ls -l {} \\;find . -perm g=r -type f -exec ls -l {} \\;find . -perm 040 -type f -exec ls -l {} \\; 찾은 후 삭제하기: 1find ./ -name 'Debug' -exec rm -rf {} \\; find 명령으로 i-node를 통해서 지우기: 아래 처럼 특수문자로 “~” or “a b c” 등의 이상한 파일이 있을 경우 inode를 확인해 삭제에 유용하다. 1234$ ls -i$ 32471 a b c$ find . -inum 32471 -exec rm -rf {} ';'$ find . -inum 32471 -exec rm -rf {} \\; 회피문자 파일 이름 삭제하기???? 같이 지워지지 안는 파일 같은 경우도 i-node로 삭제할 수 있다. 1234567891011~$ ls -ali~$ ls -alitotal 206842467329 drwxr-xr-x 11 qkboo qkboo 4096 Jun 20 22:54 . 2 drwxr-xr-x 10 qkboo qkboo 4096 Jun 1 12:56 ..42467482 drwxr-xr-x 2 qkboo qkboo 12288 Jul 2 2016 .Picasa3Temp42598444 drwxrwxrwx 3 qkboo qkboo 4096 Mar 29 23:45 ??????42475521 drwxr-xr-x 4 qkboo qkboo 4096 Jun 20 22:52 Design_Assets42467936 drwxr-xr-x 14 qkboo qkboo 4096 Mar 4 16:39 Incoming~$ find . -inum 42598444 -exec rm {} \\; 파일 형식으로 검색옵션 -type 은 파일 형식으로 찾을 수 있다. 파일 형식은: b block specialc character speciald directoryf regular filel symbolic linkp FIFOs socket 일반 파일 1find . -type f 소켓 형식의 파일 1find . -type s 디렉토리 형식 1find . -type d 숨겨진 파일만 검색도 가능하다. 1find . -type f -name &quot;.*&quot; 역시 숨겨진 디렉토리만 찾을 수 도 있다. 1find -type d -name &quot;.*&quot; 파일 크기로 검색옵션 -size 를 사용해서 파일의 크기로 찾을 수 있다. 아래는 어떤 크기 보다 크거나, 작은 파일을 찾아 준다. 123find -size +100M # 보다 큰 파일find -size -100M # 보다 작은 파일find -size 100M # 같은 크기의 파일 다음 같이 응용해 볼 수 있다. 100MB 보다 큰 파일을 찾아 삭제한다: 1find / -type f -name *.zip -size +100M -exec rm -i {} \\; 파일의 수정된 시간을 기준모든 파일의 수정된 시간 정보를 알 수 있다. test_1.txt의 시간을 기준으로 검색해 보자. 12ls -lrt test_1.txt-rw-r--r-- 1 gtko gtko 0 2011-02-01 02:26 test_1.txt 옵션 -newer 에 대상 파일을 주면 해당 파일을 생성한 날짜 이후의 결과만을 표시하게 된다. 12345find -newer test_1.txt../dir2./dir2/file2./dir2/file3 자주 사용할 만한 find 명령유용한 find 명령들 alias로 만들어 사용하기도 한다. a.out 인 파일 지우기 1alias rmao=&quot;find . -iname a.out -exec rm {} \\;&quot; c프로그램의 core 파일 1alias rmc=&quot;find . -iname core -exec rm {} \\;&quot; 큰 파일 삭제… 1234alias rm100m=&quot;find / -type f -name *.tar -size +100M -exec rm -i {} \\;&quot;alias rm1g=&quot;find / -type f -name *.tar -size +1G -exec rm -i {} \\;&quot;alias rm2g=&quot;find / -type f -name *.tar -size +2G -exec rm -i {} \\;&quot;alias rm5g=&quot;find / -type f -name *.tar -size +5G -exec rm -i {} \\;&quot; iconv 와 결합iconv로 파일 인코딩을 변환할 수 있는데, 많은 파일을 한번에 처리하기 위해서 find와 결합해 찾은 모든 파일의 파일 인코딩을 변환할 수 있다. 다음은 .c 파일을 찾아 인코딩을 euc-kr에서 utf-8로 변환하는 명령이다. 1find ./ -name '*.c' -exec iconv -feuc-kr -tutf-8 {} -o {} \\; find 를 사용하지 않는다면, 디렉토리 안에 있는 모든 파일의 인코딩을 변환하고자 할 때는 shell 조건문과 섞어서 사용할 수 있다. 1$ for F in './*.sql'; do iconv -c -feuc-kr -tutf-8 $F -o $F; done 참조Linux find command examples","link":"/linux-find-368164662e46/"},{"title":"update-alternatives 명령 사용","text":"이 글은 우분투, 리눅스 박스에서 여러버전의 도구를 관리할 수 있는 update-alternatives 를 다루고 있다. update-alternativeupdate-alternative 유틸리티로 리눅스 기본 제공 개발 환경의 gcc, cross compiler용 gcc 등 여러 버전의 gcc를 사용할 수 있게 구성할 수 있다.이들 버전의 환경을 교체해서 사용하기를 원한다. update-alternative 도구를 사용할 수 있다. update-alternative 사용여러 버전의 gcc를 update-alternative를 사용해서 선택적으로 사용할 수 있다. gcc 로 등록된 현재 버전 목록을 질의 한다. 1$ update-alternatives --query gcc 등록여기서 사용하는 여러 gcc 버전들을 설치한 후에 다음과 같은 명령어로 등록을 할 수 있다. 1update-alternatives --install &lt;link&gt; &lt;name&gt; &lt;path&gt; &lt;priority&gt; 실행파일 이름으로 /etc/alternatives/ 을 가리킨다. (예: /usr/bin/pager) 해당 링크 그룹의 대표 이름으로, 여러 가지 버전의 패키지들을 대표하는 이름으로 보면 될 것 같다.(예: pager) alternatives 로 실제 연결할 실행파일 이름으로, 시스템에 설치한 패키지의 실행파일 이름이다.(예: /usr/bin/less) automatic 모드에서 어떤 것을 자동으로 선택해서 사용할지 결정할 때 사용되는 우선순위로, 높은 수가 더 높은 우선순위이다. gcc 등록Ubuntu 14.04 최신 버전에 gcc4.7, 4.8 를 사용하려고 설치했다고 가정한다. 123sudo apt-get updatesudo apt-get install gcc-4.7 g++-4.7sudo apt-get install gcc-4.8 g++-4.8 그리고 gcc 그룹에 4.8를 우선도가 높게 50으로 준다. 1sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 50 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8 여기서 gcc를 master로 g++을 slave로 준비했다. --slave 옵션은 --install 로 지정한 master에 종속해서 여러개의 슬레이브를 마스터에 추가할 수 있고, 마스터의 링크가 바뀌면 슬레이브도 함께 바뀐다. 두번째 버전은 gcc-4.7 버전을 우선도가 40 정도로 하자. 1sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.7 50 --slave /usr/bin/g++ g++ /usr/bin/g++-4.7","link":"/linux-update-alternatives-4efbfa82e5f2/"},{"title":"Python - Build python source","text":"2015년 쯤 작성한 것으로 Raspberry Pi, Orange Pi, Odroid SBC 보드에서 3.4를 빌드했다. 2017년 현재 배포본, Debian Jessie, Ubuntu Xeniel 등은 3.4, 3.5가 내장되어 배포되고 있다.Python 3.6 이상 최신 소스를 빌드하는데 참고할 수 있다. Build Python 3.4Raspbian Wheezy에는 3.2가 설치되어 있다. Jessie 가 출시된 이후에 3.2에 대한 모듈 의존성 관리가 되지 않고 있어서 3.4 이상이 설치가 필요하다. SSL/TLS 지원을 하기 위해 libssl, openssl 라이브러리를 설치한다. 12$ sudo apt update$ sudo apt install libssl-dev openssl Python3.4를 다운로드하고 컴파일하고 설치한다.Raspbian Weezy 에는 Python3.2가 있어서, 최신 3.4를 설치하려면 다운로드해서 컴파일 하면 된다. 1234$ wget https://www.python.org/ftp/python/3.4.3/Python-3.4.3.tgz$ tar xvzf Python-3.4.3.tgz$ cd Python-3.4.3/$ ./configure Raspberry Pi 2에서 빌드시 꽤 많은 시간을 사용한다. 12345$ ./configure...real 2m16.512suser 1m16.360ssys 0m20.630s 컴파일하고 빌드시 한 시간 이상 필요하다. 123456$ make # 한 시간 소요$ sudo make install...real 16m40.747suser 15m51.550ssys 0m24.030s 크로스컴파일 환경을 사용할 수 있다.","link":"/python-build-bb3a1092ebbd/"},{"title":"Nginx - HTTPS and Certificate SSL","text":"Nginx를 HTTPS를 사용할 수 있도록 사설 인증서와 그리고 공인 인증서를 이용해 SSL을 활성화 하는 과정을 정리했다. Nginx 설치와 서버, 프락시 등의 사용 방법에 대해서는 Nginx on Ubuntu/Debian 문서를 참조한다. TLSTLS는 SSL의 새로운 이름이다. SSL(Secure Socket Layer)는 대칭키 혹은 공개키 방식의 인증을 이룬후 암호화된 통신이 가능하다. TLS에 대해서는 다음 블로그에 자세히 설명되어 있다. HTTPS, SSL 설명 Nginx HTTPSNginx 에서 HTTPS를 상용하려면 인증기관을 통해 발급받은 SSL인증서가 필요하다. 여기서는 사용자 개인용 사설 인증서를 만들어 사용한다. 공인 서버 인증서에 대해서는 별도로 다룬다. [^2] 를 참조하면 사설 인증서와 공인 인증서에 대한 설명이 있다. 사설 인증서 설정SSL Certificate 파일을 생성하고 저장해 둔다. [^4] 12$ sudo mkdir /etc/nginx/ssl$ cd /etc/nginx/ssl OpenSSL을 사용해서 SSL Certificate를 생성한다. 12$ sudo openssl genrsa -out privkey.pem 2048$ sudo openssl req -new -x509 -key privkey.pem -out cacert.pem -days 1095 Generate DH params - 시간이 소요된다 (armv7 1Ghz 에서 30분 이상) 1$ sudo openssl dhparam 2048 &gt; /etc/nginx/ssl/dhparam.pem Nginx 설정에 SSL 활성화/etc/nginx/site-available/yoursite.com 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 80번 요청을 모두 443 SSL 서버로 바꾼다.server { listen 80 default_server; listen [::]:80 default_server; add_header Strict-Transport-Security max-age=2592000; rewrite ^/.*$ https://$host$request_uri? permanent;}# SSL을 이용한 444번 포트 사용 사이트 정의server { listen 443 default; server_name my-site.localhost; ssl on; ssl_certificate /etc/nginx/ssl/cacert.pem; ssl_certificate_key /etc/nginx/ssl/privkey.pem; ssl_session_timeout 5m; ssl_session_cache shared:SSL:5m; # Diffie-Hellman parameter for DHE ciphersuites, recommended 2048 bits ssl_dhparam /etc/nginx/ssl/dhparam.pem; # secure settings (A+ at SSL Labs ssltest at time of writing) # see https://wiki.mozilla.org/Security/Server_Side_TLS#Nginx ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-CAMELLIA256-SHA:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-SEED-SHA:DHE-RSA-CAMELLIA128-SHA:HIGH:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS'; ssl_prefer_server_ciphers on; proxy_set_header X-Forwarded-For $remote_addr; add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot;; proxy_buffers 16 64k; proxy_buffer_size 128k; server_tokens off; root /var/www/html; index index.html index.htm index.nginx-debian.html; location / { try_files $uri $uri/ =404; client_max_body_size 0; }} 설정 파일이 제대로 구성됐는지 테스트해본다.[^1] 1sudo nginx -t Certified SSL 작업: macbook pro의 thinkbee@ ~/Documents/SslCert$ https://jetmirshatri.com/build-nginx-with-openssl-1-1-0-on-ubuntu-16-04/ Lets’ EncryptLets’ Encrypt는 HTTPS를 사용하기 위해 SSL을 구매해야 하는 부분이 HTTPS 보급에 방해된다고 생각해서 SSL을 무료로 제공해서 HTTPS를 보급하기 위해 작년 말에 만들어졌다. 초기에는 Mozilla, Cisco, Akamai, EFF, id entrust 등이 모여서 ISRG(Internet Security Research Group)라는 새로운 SSL 인증기관을 만들어서 올해 SSL을 무료로 제공하겠다고 발표했다. 지금은 이 Lets’ Encrypt에 Facebook, 워드프레스를 만드는 Automattic, shopify 등 많은 회사가 스폰서로 참여하고 있다 https://www.nginx.com/blog/free-certificates-lets-encrypt-and-nginx/ Lets’ Ecrypt 발급Lets’ Ecrypt는 Shell 기반의 발급 방법을 권장한다. 웹을 통한 발급은 인증된 도메인 등록지에서 가능하다고 한다. 쉘 기반 발급을 위해서 ACME protocol client를 사용한다. 정식 클라이언트는 Certbot 을 사용한다. Certbot을 설치할 수 없는 상황에서는 호환 클라이언트를 사용할 수 있다. getssl1./getssl -c yourdomain.com 1234~/.getssl~/.getssl/getssl.cfg~/.getssl/yourdomain.com~/.getssl/yourdomain.com/getssl.cfg ~/.getssl/getssl.cfg 를 필요시 수정한다. ~/.getssl/yourdomain.com/getssl.cfg 을 수정한다. Recommended: Certbothttps://letsencrypt.org/docs/client-options/ 여기서 getssl bash 스크립트를 사용해 본다. openssl req -new -sha256 -key domain.key -subj “/“ -reqexts SAN -config &lt;(cat /etc/ssl/openssl.cnf &lt;(printf “[SAN]\\nsubjectAltName=DNS:thinkbee.kr,DNS:www.thinkbee.kr,DNS:blog.thinkbee.kr“)) Certbot-autohttps://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-14-04 https://www.nginx.com/blog/free-certificates-lets-encrypt-and-nginx/ 참고 TLS/SSL에 대해 알아보아요 [^2]: SSL 인증서 종류[^3]: Enabling Https with Nginx[^4]: Create Self signed SSL","link":"/2017-04-04-ubuntu-nginx-ssl-37a2ab2a1f5f/"},{"title":"Ubuntu&#x2F;Debian Basic Security settings","text":"리눅스 시스템을 설치후 기본적인 보안 설정과 도구를 사용하는 과정을 정리했다. firewall 과 sshd rootkit fail2ban Firewall과 ssh 보안 구성사용자 로그인에 제약을 두고, 원격 접속에 대해서 방화벽과 sshd 보안을 강화한다. sudoer 등록처음 로그인후 새로운 사용자 등록하고 suders에 직접 권한을 줄 수 있다. sudo 새 사용자 등록sudo 사용자를 추가해서 사용하려면, adduser 혹은 useradd 명령을 사용해서 사용자를 등록 할 수 있다. 새 사용자 등록먼저 adduser를 사용한 등록은, 1234567891011121314151617# adduser qkbooAdding user `qkboo' ...Adding new group `qkboo' (1000) ...Adding new user `qkboo' (1000) with group `qkboo' ...Creating home directory `/home/qkboo' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for qkbooEnter the new value, or press ENTER for the default Full Name []: Gangtai Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] y useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. http://www.tecmint.com/add-users-in-linux/ ‘useradd‘ 명령은 크게 두가지 일을 한다: 추가한 사용자에 대한 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 편집 사용자 홈 디렉토리 생성 1$sudo useradd -m qkboo 그리고 패스워드를 등록한다. 1234$ sudo passwd qkbooNew password:Retype new password:passwd: password updated successfully userdel 로 사용자 완전 삭제시 1$ userdel -r sambaguest visudovisudo 명령으로 sudoers 파일을 편집할 수 있다. sudoer에 있는 root는 제외하고 사용자로 등록한다. 123$ sudo visudo# User privilege specificationpi ALL=(ALL:ALL) ALL sudo 사용자를 sudo 그룹에 등록해 둔다. 1$ sudo usermod -aG sudo pi ufw를 사용한 방화벽 등록1$ sudo apt install ufw 방화벽 기본 규칙을 실행한다. 12$ sudo ufw default deny incoming$ sudo ufw default allow outgoing 리눅스 방화벽 구성에 대해서는 포스트 UFW Firewall on Ubuntu/Debian 에 자세히 설명하고 있다. 123$ sudo ufw allow ssh$ sudo ufw allow http$ sudo ufw allow https 그리고 ufw로 방화벽을 활성화 한다. 1234$ sudo ufw statusStatus: inactive$ sudo ufw enable 현재 서버의 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 1$ netstat -tlnp ping (icmp) 허용/거부UFW 기본설정은 ping 요청을 허용하도록 되어있다. 이것은 /etc/ufw/before.rules 파일에 정의되어 있는데 여기서 icmp 프로토콜 관련한 항목을 DROP으로 처리하거나 삭제하면 ping을 방지할 수 있다. 123456 # ok icmp codes-A ufw-before-input -p icmp --icmp-type destination-unreachable -j ACCEPT-A ufw-before-input -p icmp --icmp-type source-quench -j ACCEPT-A ufw-before-input -p icmp --icmp-type time-exceeded -j ACCEPT-A ufw-before-input -p icmp --icmp-type parameter-problem -j ACCEPT-A ufw-before-input -p icmp --icmp-type echo-request -j ACCEPT samba 허용 12$ sudo ufw allow Samba$ sudo ufw allow from 192.168.0.0/16 to any app Samba syslog 에 패킷 필터링 결과를 로깅 하려면, 12$ sudo ufw logging onLogging enabled 리눅스 방호벽에 ssh 허용한다. ufw를 사용한다면 다음 같이 해준다. ssh 보안 ssh Brute-force Attack 방어 1$ sudo ufw limit ssh ssh를 특정 IP 주소에만 접속을 허용한다 1sudo ufw allow from 192.168.0.100 to any port 22 1sudo ufw allow from 192.168.0.100 to any port 22 proto tcp sshd 보안 구성ssh 사용에 특정한 사용자, 호스트 등에서만 사용하도록 제한하게 구성한다. sshd_config 수정/etc/ssh/sshd_config에서 다음 내용으로 수정한다. 포트, IP, Time out 시간을 지정할 수 있다. 12345678910111213141516#sshd 포트넘버 변경 (Port)Port 2222#sshd Listen AddressListenAddress 192.168.0.200# alive 메시지 사용 결정TCPKeepAlive no # 기본 yes.# 클라이언트가 살아있는지 확인하는 간격.ClientAliveInterval 60 # 기본 0.# 클라이언트에서 응답이 없을 때 메시지를 보내는 횟수ClientAliveCountMax 3 # 확인 횟수# Login Prompt에서 사용자 입력을 기다리는 시간을 초 단위로 입력.LoginGraceTime 20 #( 1m: 기본 1분지정, 0은 시간제한없음) 사용자 계정에 대한 접근 1234567891011121314# no로 설정하면 root 계정으로 Login 불가능.PermitRootLogin no# SSH 접속을 통해 Login을 허용할 User를 지정. 지정된 User 외의 접속은 차단됨.# 여러 계정 입력시 Space로 구분.AllowUsers foo# sudo(관리자)그룹만 로그인가능( 다른 유저들도 ssh로그인을 가능하게 하려면 이부분 삭제 )AllowGroups sudo# 모두 접속이 허용, 여기에 등록된 group만 접속 거부됨#DenyGroups# 모두 접속이 허용, 여기에 등록된 계정만 접속 거부됨#DenyUsers issue 이용ssh 로그인시 Banner로 지정한 Text File의 내용을 Login Prompt에 출력한다. 시스템 접근에 대한 사전 경고이다. /etc/ssh/sshd_config 에 Banner를 추가한다. 12# 설정한 경로에 존재하는 Text File의 내용을 Login Prompt에 출력.Banner /etc/issue.net 그리고 /etc/issue.net 파일에 다음 경고를 넣어준다. 12345678910111213141516171819202122232425&gt; ***************************************************************************&gt; NOTICE TO USERS&gt;&gt; This computer system is the private property of its owner, whether&gt; individual, corporate or government. It is for authorized use only.&gt; Users (authorized or unauthorized) have no explicit or implicit&gt; expectation of privacy.&gt;&gt; Any or all uses of this system and all files on this system may be&gt; intercepted, monitored, recorded, copied, audited, inspected, and&gt; disclosed to your employer, to authorized site, government, and law&gt; enforcement personnel, as well as authorized officials of government&gt; agencies, both domestic and foreign.&gt;&gt; By using this system, the user consents to such interception, monitoring,&gt; recording, copying, auditing, inspection, and disclosure at the&gt; discretion of such personnel or officials. Unauthorized or improper use&gt; of this system may result in civil and criminal penalties and&gt; administrative or disciplinary action, as appropriate. By continuing to&gt; use this system you indicate your awareness of and consent to these terms&gt; and conditions of use. LOG OFF IMMEDIATELY if you do not agree to the&gt; conditions stated in this warning.&gt;&gt; **************************************************************************** systemd 를 사용하면, 12$ sudo systemctl restart sshd.service$ sudo systemctl status sshd.service upstart를 사용하면, 1$ sudo service ssh restart 공개키 방식을 이용일반 패스워드를 사용하는 로그인 방식보다 rsa 키를 이용한 접속이 보다 보안에 좋다. 그리고 일단 한번 설정해 놓으면 편하다. 서버에 /etc/ssh/sshd_config 설정에서 rsa키 사용에 대한 설정이 제대로인지 살펴본다. 12PubkeyAuthentication yesRSAAuthentication yes ssh 클라이언트클라이언트에서 공개키 생성을 한다. 키의 크기를 높이려면 -b 옵션으로 1024, 2048, 4096 값을 제시한다. 1234567891011121314151617181920212223(CLIENT)$ mkdir ~/.ssh(CLIENT)$ chmod 700 ~/.ssh(CLIENT)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@CLIENT_HOST&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/daddy/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /Users/daddy/.ssh/id_rsa.Your public key has been saved in /Users/daddy/.ssh/id_rsa.pub.The key fingerprint is:SHA256:nBbRg+tTnmEbyuqzb0cqeBfzuaj1XOJP3n767Xmj3s0 USER@CLIENT_HOSTThe key\\'s randomart image is:+---[RSA 4096]----+| .o || ..o || .. . || ..o= || oS= = || .B = || . ..B..o || . =.+=+= ..o*|| o+Oo.=o++=BE|+----[SHA256]-----+ 개인 비밀키와 공개키 파일이 ~/.ssh 폴더에 기본 파일이름 id_rsa.pub, id_rsa.prb 파일로 저장된다. 서버에서 할일서버에서 비밀키를 생성한다. 12(SERVER)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@SERVER&quot;(SERVER)$ chmod 700 ~/.ssh 클라이언트 공개키를 서버 배포서버로 id_rsa.pub를 scp 로 복사해서 authorized_keys 파일에 더해주면 된다. 아래 같이 할 수 있다. 1cat ~/.ssh/id_rsa.pub | ssh USER@SERVER 'cat &gt;&gt; .ssh/authorized_keys' scp로 복사하고 서버에서 authorized_keys 파일에 더해줄 수 있다. 123(CLIENT)$ scp ~/.ssh/id_rsa.pub USER@SERVER:~/client.pub(CLIENT)$ ssh userid@SERVER(SERVER)$ cat client.pub &gt;&gt; .ssh/authorized_keys; rm client.pub 이제 해당 서버로 로그인해 본다. 아래 같이 시스템 명칭을 주고 생성할 수 도 있다. 1ssh-keygen -t rsa -C &quot;Raspberry Pi #123&quot; 권한은 아래와 같이 클라이언트와 서버 모두 설정한다. 1234chmod 600 ~/.ssh/id_rsachmod 644 ~/.ssh/id_rsa.pubchmod 644 ~/.ssh/authorized_keyschmod 644 ~/.ssh/known_host 그리고 클라이언트에서 서버로 ssh 접속을 해본다. 로그인 과정 없이 로그인되면 공개키 방식의 인증이 마무리되ㅓㅇㅆ다. 1(CLIENT)$ ssh USER@SERVER 개인키 파일을 이용한 로그인-i 옵션을 이용하면 개인키를 여러개 만들어 두고 서버 마다 달리 로그인 할 수 있다. 1ssh -i .ssh/개인키 id@host-Name Root kitchkrootkit 루트킷 탐지 프로그램 일반적인 루트킷, 커널 기반 루트킷, Worm 까지도 탐지 가능 설치1$ sudo apt install chkrootkit 컴파일로 빌드 설치시 http://www.chkrootkit.org/ 에서 다운로드후 빌드한다. 123$ tar -zxvf chkrootkit.tar.gz$ cd chkrootkit-0.50$ make sense 루트킷 실행1$ sudo chkrootkit not infected, not found 가 아닌 경우 잘 살펴보자. rkhunterRootkit이 System에 설치되어 있는지 Check합니다. chkrootkit 에서 검사하지 않는 설정 파일들이나 서버 계정 등 을 검사 하기 때문에 chkrootkit 과 함께 사용하면 좋다. 1$ sudo apt install rkhunter 설치 시에 MTA(Matil Transfer Agent)인 Postfix가 의존성으로 같이 설치됩니다. RPi Jessie에서 설치시 rkhunter Invalid SCRIPTWHITELIST configuration option: Non-existent pathname: /usr/bin/lwp-request 경고 발생lwp-request는 명령행 HTTP 사용자 에이전트로 사용하지 않는다면 &gt; /etc/rkhunter.conf에 있는 SCRIPTWHITELIST /usr/bin/lwp-request 주석 처리참조: lwp-request 실행1$ sudo rkhunter -c skip 1$ sudo rkhunter -c --skip-keypress --pkgmgr dpkg 1$ sudo rkhunter -c -sk // --skip-keypress updateproperties update 1$ sudo rkhunter --propupd 업데이트 점검 1$sudo rkhunter --update cron 설정12345$ sudo vi /etc/default/rkhunterCRON_DAILY_RUN=&quot;true&quot;CRON_DB_UPDATE=&quot;true&quot;APT_AUTOGEN=&quot;true&quot; 자세한 결과가 저장된 /var/log/rkhunter.log의 내용을 토대로 Google에서 검색하거나 Rkhunter Users Mailing List를 이용한다. /var/log/rkhunter.log ## Fail2ban 로그를 검사해 의심스런 IP 를 찾아 Firewall rule에 등록해 관리하는 것은 어려운 과정이다. Fail2ban은 정규표현식을 사용해서 로그에서 의심스런 IP를 찾아 Firewall 등록 할 수 있도록 해준다. 설치fail2ban 은 iptables 패키지와 함께 설치한다. 1$ sudo apt install iptables fail2ban 그리고 systemctl 로 재대로 서비스가 시작되는지 확인해 본다. 12$ sudo systemctl restart fail2ban.service # 재시작$ sudo systemctl status fail2ban.service # running 상태 확인 설정을 위해서 fail2ban 설정 파일인 fail2ban.conf, 그리고 jail 파일 jail.conf 파일을 .local 파일로 복사한 사용자 정의 파일에서 사용한다. 123$ cd /etc/fail2ban$ sudo cp fail2ban.conf fail2ban.local # 설정파일$ sudo cp jail.conf jail.local # jail 설정 /etc/fail2ban 디렉토리주요 파일, fail2ban.local : fail2ban 주요 설정 파일 jail.local: jail 설정 파일 jail.d/defaults-debian.conf: jail enable/disable paths-common.conf: 로그 파일 경로 paths-debian.conf: 로그 파일 경로 fail2ban.localfail2ban 에서 전역 설정을 무선언해 줍니다. 예를 들어 검출된 IP중에 무시할 영역을 선언해 줍니다. 1234[DEFAULT]ignoreip = 127.0.0.1/8 192.168.0.1/24bantime = 2592000 # 금지 시간을 늘린다.maxretry = 3 # 금지된 행위 시도 횟수 jail.localjail.d/defaults-debian.conf 파일에 jail 을 활성화 혹은 비활성화 시킨다. 기본으로 sshd 만 활성화 되어 있다. 아래는 nginx 에 대해서도 활성화 했다. 12345678[sshd]enabled = true[nginx-http-auth]enabled = true[nginx-botsearch]enabled = true 시스템 서비스 포트 확인현재 시스템의 활성화되어 있는 포트는 netstat 명령으로 확인할 수 있다. 12345$ sudo netstat -tulpentcp 0 0 127.0.1.1:53 0.0.0.0:* LISTEN 0 12762 731/dnsmasqtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 0 16387 670/sshdtcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 0 10674 708/nginx -g daemon 열려 있는 포트를 fail2ban 의 jail을 활성화해서 방화벽으로 감시하면 된다. fail2ban 사용fail2ban-client, fail2ban-regex 명령을 이용해 jail의 ban 상태를 확인하거나 테스트 할 수 있다. Jail 실행 확인fail2ban-client 명령으로 해당 jail을 확인 할 수 있다. 1234$ sudo fail2ban-client statusStatus|- Number of jail: 6 - Jail list: nginx-noproxy, nginx-noscript, nginx-nohome, nginx-badbots, sshd 전체 jail 중에 특정한 것만 확인한다. 12345678Status for the jail: ssh|- filter| |- File list: /var/log/auth.log| |- Currently failed: 208| `- Total failed: 4357`- action |- Currently banned: 679 | `- IP list: 2.176.38.209 116.31.116.53 181.21.6.110 153.171.66.99 190.67.247.209 201.179.200.15 103.207... 테스트의심스런 동작을 Filter로 선언해서 사용하는데 해당 필터를 점검해야할 필요가 있다. 다음 1$ sudo fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf lastb실패한 로그인 시도View Failed Login Attempts – lastb 참조. -w 로 사용자 이름을 출력하고 첫번째 열만 자른 후 정렬한 후, uniq 명령으로 중복되는 이름을 제거한 후 출력한다. 1$ sudo lastb -w | cut -d &quot; &quot; -f 1 | sort | uniq | less 이중에서 접속한 IP와 횟수를 출력한다. 12345678$ sudo lastb -f /var/log/btmp.1 -w -i | awk '{print $3}' | sort | uniq --count | sort -nr | less[sudo] root의 암호: 2166 112.85.42.156 1945 112.85.42.193 1591 112.85.42.201 1327 112.85.42.230 1146 112.85.42.196 참조[^1]: Ubuntu Server의 보안을 위해서 해야 할 것들 (Part 1)[^2]: Ubuntu Server의 보안을 위해서 해야 할 것들 (Part 2)[^3]: How To Protect SSH with Fail2Ban on Ubuntu 14.04[^4]: 우분투 방화벽(UFW) 설정","link":"/2017-04-03-linux-basic-securities-259a0c1129cb/"},{"title":"UFW Firewall on Ubuntu&#x2F;Debian","text":"일반적인 리눅스 배포본의 방화벽인 ufw` 를 사용해서 리눅스에 방화벽을 구축하는 방법을 기술하고 있다. 2019-12-10: 정리 2017-09-10: Log, export 추가서{:.right-history} 여기서 사용, 테스트한 리눅스 배포본은 Ubuntu 14.04, 15.04, 16.04 계열에서 동작하리라 믿는다. 실제 Raspbian Weezy, Jessie, Armbian Ubuntu 16.04, Debian Jessie 에서 사용중이다. UFW - Uncomplicated FirewallUbuntu의 기본 방화벽 두고는 UFW이다. 데스크탑을 위한 GUI 버전 Gufw 도 있다. [^2] ufw 설치다음 같이 ufw 패키지를 설치한다. 내부에서 서버로 운영중인 ARM 계열의 SBC 컴퓨터인 Raspberry Pi, Odroid, OrangePi 등의 배포본에는 ufw가 빠져 있다. 1$ sudo apt install ufw 1234$ sudo systemctl status ufw* ufw.service - Uncomplicated firewall Loaded: loaded (/lib/systemd/system/ufw.service; enabled; vendor preset: enabled) Active: inactive (dead) 방화벽 서비스를 시작한다. 1234567891011$ sudo systemctl start ufw$ sudo systemctl status ufw* ufw.service - Uncomplicated firewall Loaded: loaded (/lib/systemd/system/ufw.service; enabled; vendor preset: enabled) Active: active (exited) since Tue 2019-12-10 02:21:19 UTC; 1s ago Docs: man:ufw(8) Process: 2750 ExecStart=/lib/ufw/ufw-init start quiet (code=exited, status=0/SUCCESS) Main PID: 2750 (code=exited, status=0/SUCCESS)Dec 10 02:21:19 rock64 systemd[1]: Starting Uncomplicated firewall...Dec 10 02:21:19 rock64 systemd[1]: Started Uncomplicated firewall. 이제 ufw 를 활성화 하고 구성 내용을 설정해야 한다. 방화벽 구성 설정방화벽은 다음 같이 설정한다 기본 규칙 프로토콜, 포트 규칙 추가 방화벽 활성화 방화벽 기본 설정기본 정책을 설정 한다 - (들어오는 패킷은 차단, 나가는 패킷은 허용) 12$ sudo ufw default deny incoming$ sudo ufw default allow outgoing 현재 방화벽 기본 정책을 확인한다. 1$ sudo ufw status 설정한 규칙과 이에 따른 액션을 확인해 보려면 다음과 같이 입력한다. 12345$ sudo ufw status verboseStatus: activeLogging: on (low)Default: deny (incoming), allow (outgoing)New profiles: skip Default 부분이 방화벽의 기본 규칙으로 현재 들어오는 것은 막고, 나가는 것은 열어 놓은 상태이다. iptables 명령의 상태를 확인하려면 status raw 를 사용한다. 1$ sudo ufw show raw 먼저 ufw를 활성화하고 규칙을 추가한다. UFW 활성화방화벽은 커널 수준에서 패킷을 다루기 때문에 아래 같이 활성화 명령을 통해 네트워크 패킷을 ufw가 다룰 수 있게 해준다. ufw 활성화 상태를 확인하고 inactive 상태면 활성화 한다. 12345$ sudo ufw statusStatus: inactive$ sudo ufw enableFirewall is active and enabled on system startup 방화벽을 끌 때는 아래와 같은 명령어를 입력한다 1$ sudo ufw disable 방화벽 규칙 허용서비스, 포트, 프로토콜, 프로그램등에 예외 규칙을 적용할 액션을 추가한다. ufw [allow,deny] /&lt;optional: protocal&gt; 혹은 서비스 이름으로 가능하다 ufw [allow,deny] ssh, http, https 허용ssh 포트를 변경해서 사용한다면 반드시 직접 포트를 입력하자 123$ sudo ufw allow ssh$ sudo ufw allow http$ sudo ufw allow https 새로운 설정을 적용하려면 disable &gt; enable 해도 좋고 아래와 같이 reload 가 가능하다 1$ sudo ufw reload 포트포트를 변경해 사용하거나 특정 포트를 허용 할 수 있다. ssh 프로토콜은 tcp 22번 포트를 사용한다. 12$ sudo ufw allow 8080$ sudo ufw allow 22 규칙과 액션 상태를 확인한다. 12345678910$ sudo ufw status verboseStatus: activeLogging: on (low)Default: deny (incoming), allow (outgoing)New profiles: skipTo Action From-- ------ ----22 LIMIT IN Anywhere22 LIMIT IN Anywhere (v6) ssh 허용sh 허용 123$ sudo ufw allow sshor$ sudo ufw allow 22 ssh를 특정 IP 주소에만 접속을 허용한다 1sudo ufw allow from 192.168.0.100 to any port 22 1sudo ufw allow from 192.168.0.100 to any port 22 proto tcp limitufw는 Brute-force Attack 방어를 도와주는 Brute-force Attack을 방어하기 위한다면 다음과 같이 실행한다. 1$ sudo ufw limit ssh samba 허용12$ sudo ufw allow Samba$ sudo ufw allow from 192.168.0.0/16 to any app Samba 이렇게 설정하고 실제 열린 포트는 다음 같이 netstat 명령으로 확인이 가능하다. 12345678910111213$ netstat -tlnp(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 5034/python3tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN -tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN -tcp 0 0 0.0.0.0:1883 0.0.0.0:* LISTEN -tcp6 0 0 ::1:8080 :::* LISTEN 5034/python3tcp6 0 0 :::22 :::* LISTEN -tcp6 0 0 ::1:25 :::* LISTEN -tcp6 0 0 :::1883 :::* LISTEN - IP 주소 제어특정 IP 대역에서 허용/거부 하기 ufw [allow,deny] from 특정 IP만 허용할 경우 1$ sudo ufw allow from 192.168.0.100 특정 ip 또는 특정 ip 대역에 대해 특정 포트 허용/거부하기 ufw [allow,deny] from to port 123$ sudo ufw allow from 192.168.0.100 to any port 22$ sudo ufw allow from 192.168.0.100 to any port 22 proto tcp$ sudo ufw allow from 192.168.0.100 to any port 8080 특정 IP 혹은 IP 범위에 대한 접근 제어도 가능하다. ufw allow from to port ufw allow from to port proto 포트의 범위를 규칙으로 사용할 경우 1$ sudo ufw allow 9200:9300/tcp 특정 아이피에만 일정 범위의 포트를 tcp 패킷만 허용할 경우 1$ sudo ufw allow from 192.168.0.101 to any port 9200:9300 proto tcp 서브넷을 특정 포트에 허용할 경우 1$ sudo ufw allow from 192.168.0.0/24 to any port 27017 proto tcp ping (icmp) 허용/거부UFW 기본설정은 ping 요청을 허용하도록 되어있다. 이것은 /etc/ufw/before.rules 파일에 정의되어 있는데 여기서 icmp 프로토콜 관련한 항목을 DROP으로 처리하거나 삭제하면 ping을 방지할 수 있다. 123456 # ok icmp codes-A ufw-before-input -p icmp --icmp-type destination-unreachable -j ACCEPT-A ufw-before-input -p icmp --icmp-type source-quench -j ACCEPT-A ufw-before-input -p icmp --icmp-type time-exceeded -j ACCEPT-A ufw-before-input -p icmp --icmp-type parameter-problem -j ACCEPT-A ufw-before-input -p icmp --icmp-type echo-request -j ACCEPT 방화벽 규칙 삭제등록된 규칙을 삭제할 때는 2가지 방법이 있다. 첫번째는 등록 시 사용한 규칙을 그대로 입력하는 방법 12$ sudo ufw delete allow ssh$ sudo ufw delete allow 8080 22/tcp 설정이 되어있다고 가정하고, 해당 포트/포로토콜을 삭제한다. 1$ sudo ufw delete deny 22/tcp 두번째는 각 규칙의 번호를 확인하고 번호로 지우는 방법으로 status numbered 명령으로 규칙 번호를 확인한다. 1234567891011$ sudo ufw status numberedStatus: active To Action From -- ------ ----[ 1] 22 ALLOW IN Anywhere[ 2] 80/tcp ALLOW IN Anywhere[ 3] 443/tcp ALLOW IN Anywhere[ 4] 22 (v6) ALLOW IN Anywhere (v6)[ 5] 80/tcp (v6) ALLOW IN Anywhere (v6)[ 6] 443/tcp (v6) ALLOW IN Anywhere (v6) 등록된 규칙의 번호는 줄 맨앞에 있는 [숫자]로 이 숫자를 delete 명령에 준다. 2번 규칙 80/tcp 를 지우려면 1$ sudo ufw delete 2 UFW 설정 파일/etc/ufw/ 밑에 before.rule, before6.rule 파일이 있다. 기본적으로 ufw 시작시 before.rules, that allows loopback, ping, and DHCP을 활성화 하고 또한 ufw 명령이 실행된 후에 추가되는 룰이 after.rule, IPv6용 after6.rule 파일이 있다. 그리고 /etc/default/ufw 파일은 IPv6 를 활성화 하거나 비활서화 한다. Logging12$ sudo ufw logging onLogging enabled 로그 수준은 ufw logging low|medium|high 로 지정한다. 기록되는 로그는 /var/logs/ufw 에 위치한다. 1Sep 16 15:08:14 &lt;hostname&gt; kernel: [UFW BLOCK] IN=eth0 OUT= MAC=00:00:00:00:00:00:00:00:00:00:00:00:00:00 SRC=123.45.67.89 DST=987.65.43.21 LEN=40 TOS=0x00 PREC=0x00 TTL=249 ID=8475 PROTO=TCP SPT=48247 DPT=22 WINDOW=1024 RES=0x00 SYN URGP=0 UFW BLOCK: This location is where the description of the logged event will be located. In this instance, it blocked a connection. IN: If this contains a value, then the event was incoming OUT: If this contain a value, then the event was outgoing MAC: A combination of the destination and source MAC addresses SRC: The IP of the packet source DST: The IP of the packet destination LEN: Packet length TTL: The packet TTL, or time to live. How long it will bounce between routers until it expires, if no destination is found. PROTO: The packet’s protocol SPT: The source port of the package DPT: The destination port of the package WINDOW: The size of the packet the sender can receive SYN URGP: Indicated if a three-way handshake is required. 0 means it is not. 참조How to configure ufw - Ubuntu 14.04 IP address from mac address [^2]: UFW Help[^3]: Check blocked IP in iptables","link":"/2017-04-03-ubuntu-firewall-0455c0bb68ad/"},{"title":"Python - Install virtualenv on macOS X","text":"Python 개발환경을 위해서 macOS에 설치된 python2.7 그리고 brew 같은 유틸리티로 python3.x 를 설치하고, pip를 사용해서 패키지를 관리할 수 있다. 그리고 다양한 모듈과 시스템 모듈의 분리를 위해서 버전 관리 도구인 virtualenv와 virtualenvwrapper 를 사용해 가상 개발 환경을 구성하는 방법을 설명한다. macOS에서 Python virtualenv 개발환경 구축하기macOS 에는 python2.6, python2.7이 설치되어 있다. python3를 설치하려면 HomeBrew, MacPort 같은 시스템 유틸리티 관리자를 이용한다. 여기서는 HomeBrew 를 사용했다. 1$ brew install python3 사전 준비파이썬 패키지 도구인 pip(Python Package Index, PyPI)는 파이썬 모듈을 검색, 설치, 관리 할 수 있다.설치된 python 버전에 따라 pip가 설치되어 있다. brew로 python3를 설치하면 pip3 버전이 설치된다. pip --version 버전 정보를 출력하면 버전과 site-packages 위치를 확인할 수 있다. 1234$ pip --versionpip 7.1.2 from /Library/Python/2.7/site-packages (python 2.7)$ pip3 --versionpip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6) site-packagespip 로 설치되는 패키지 모듈은 시스템의 site-packages 폴더에 설치된다. python2.7은 /usr/lib/python2.7/site-packages python3.4는 /usr/lib/python3.4/site-packages 그래서 시스템에 설치된 pip는 sudo로 설치한다. brew로 설치한 python3의 pip3는 사용자 환경에서 접근이 가능해서 sudo 없이 설치해도 된다. 12$ sudo pip install --upgrade pip$ pip3 install --upgrade pip3.6 이후는 특별히 버전을 명시하지 않으면 pip는 pip3.6을 사용한다고 가정한다. Python 가상 개발 환경 설치앞서 언급한데로 개발을 위해 site-package 모듈을 유지하고 개발을 위해 설치하는 패키지 모듈을 python 버전에 의존해 관리하는 버전 관리자로 pyenv, virtualenv 같은 버전 관리자를 사용한다. 버전 관리자는 사용자 환경에 시스템 모듈을 복사해 새로 설치되는 모듈을 기존 시스템 버전과 혼동되지 않게 해준다. virtualenv와 virtualenvwrapper여기서 pip로 virtualenv와 virtualenvwrapper를 설치한다. 12$ pip3.6 install virtualenv$ pip3.6 install virtualenvwrapper 쉘 프로파일 .bashrc, .profile 등에 다음 라인을 추가한다. 123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh 그리고 쉘 환경을 로딩하기 위해서 다시 로그인 하거나 다음 같이 source 명령을 이용하면 아래 같이 virtualenvwrapper 에서 제공하는 환경변수가 설정된다. 아래는 source 명령으로 .profile을 컴파일한 결과를 보여준다. 12345678910111213$ source .profilevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/get_env_details 다음 같이 에러가 발생하면 쉘에 VIRTUALENVWRAPPER_PYTHON 를 추가해 준다. /usr/bin/python: No module named virtualenvwrappervirtualenvwrapper.sh: There was a problem running the initialization hooks. If Python could not import the module virtualenvwrapper.hook_loader,check that virtualenvwrapper has been installed forVIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is 점검I then search for the location of virtualenv and virtualenv wrapper to confirm their locations: 12$ pip3 show virtualenvLocation: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages 12$ pip3 show virtualenvwrapperLocation: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages Quick-Start새로운 가상환경은 mkvirtualenv NAME 명령으로 만든다. 가상환경으로 전환시 프롬프트가 (NAME) $ 형태로 표시된다. 123$ mkvirtualenv django2 #기본 python 버전의 환경 생성...(django2):~$ # 실행 가상 환경 쉘 mkvirtualenv 명령은 -p 옵션으로 파이썬 버전을 명시할 수 있다. 1$ mkvirtualenv -p python3 django3 --system-site-packages 옵션은 site-package 시스템 버전을 사용하게 한다. 1$ mkvirtualenv --system-site-packages -p python3 django3 workon NAME 명령으로 설치한 가상 환경 목록을 보거나 혹은 해당 가상환경으로 전환할 수 있다. 12345$ workondjango2 django3$ workon django3...(django3):~$ 프로젝트 환경을 빠져 나오려면 deactivate를 실행한다. 1(django3):~$ deactivate","link":"/2017-04-03-virtualenv-mac-4704e6586b06/"},{"title":"Linux LVM2","text":"2018-09-19 when umount, device busy!2018-06-23 mount 명령{: history-right} LVM2Odorid C2에 USB Memory를 사용해서 리눅스의 LVM을 이용하고 있다. 여기서는 LVM 설정에 대해서만 다루고 있다. Single board computer 종류의 보드는 주 디스크로 SD Card, eMMC 를 사용하고, USB 메모리 등은 디바이스 장치로 /dev/sd* 이름으로 접근할 수 있다. 디스크 파티션시스템에 사용할 디스크 파티션을 생성한다. 그리고 사용할 디스크 파티션 종류 LVM으로 해야 한다. parted 혹은 fdisk 를 사용해서 디스크 볼륨을 생성하고 사용한다. parted대상 디스크 목록을 통해 디스크의 크기 정보를 확인한다. 1sudo parted -l parted로 lvm 볼륨 잡기 12345678910111213sudo parted /dev/sdb(parted) mklabel gptWarning: The existing disk label on /dev/sda will be destroyed and all data onthis disk will be lost. Do you want to continue?Yes/No? y(parted) unit GB(parted) mkpart primary 0 32.0GB #디스크 크기 입력(parted) set 1 lvm on(parted) printNumber Start End Size File system Name Flags 1 0.00GB 32.0GB 32.0GB primary lvm fdisk 사용대상 디스크 목록을 통해 디스크의 크기 정보를 확인한다. 1sudo fdisk -l fdisk로 파티션을 시작한다. 123456789# fdisk /dev/sdaCommand (m for help): pCommand (m for help): gCommand (m for help): nLast sector, +sectors or +size{K,M,G,T,P} (2048-125042654, default 125042654): +4GCommand (m for help): tHex code (type L to list all codes): 30Changed type of partition 'Linux filesystem' to 'Linux LVM'.Command (m for help): w 이제 새로운 파티션 ‘/dev/sda1’ 이 생성됐다. LVM 생성하기 LVM 종류로 파티션한 볼륨으로 Pysical volume 을 생성한다. Pysical volume을 Volume Group으로 등록한다. 실제 사용할 크기 만큼 Logical Volume으로 나눠 생성한다. 파일 시스템을 생성하고 마운트 한다. 시스템에 lvm2 를 설치한다. 1$ sudo apt install lvm2 Pysical Volume 만들기파티션을 Pysical volume으로 만든다. 12345$ sudo -s# pvcreate /dev/sda1 /run/lvm/lvmetad.socket: connect failed: No such file or directory WARNING: Failed to connect to lvmetad. Falling back to internal scanning. Physical volume &quot;/dev/sda1&quot; successfully created 이제 물리볼륨을 로지컬 볼륨 그룹으로 나누고 1234# vgcreate vg_usb /dev/sdb1 Volume group &quot;vg_usb&quot; successfully created# vgdisplay 볼륨그룹 지우기 12# vgremove vg_usb Volume group &quot;vg_usb&quot; successfully removed Logical Volume 만들기로지컬 볼륨을 만든다. 용량은 -L 과 -l 옵션을 사용 -L [GB/KB/B..] 단위 용량 -l PE PE 용량 단위 - vgdisplay 에 표시되는 PE 개수 여기서 두개의 로지컬 볼륨을 만든다고 가정한다. 1234# lvcreate -L +20G -n dbvol vg_usb Logical volume &quot;dbvol&quot; created.# lvcreate -L +9GB -n workvol vg_usb Logical volume &quot;workvol&quot; created. 생성한 로지컬보륨은 lvdisplay로 자세한 정보를 확인할 수 있다. 로지컬 볼륨을 지우려면 lvremove로 볼륨그룹 밑에 있는 로지컬보륨을 삭제한다. 1# lvremove /dev/vg_usb/dbvol 이제 로지컬볼륨이 준비됐고, 실제 파일 시스템을 생성한다. 파일시스템 생성mkfs 명령으로 파일 시스템을 생성한다. 12# mkfs.ext4 /dev/vg_usb/dbvol# mkfs.ext4 /dev/vg_usb/workvol 부팅시 항상 마운트하기 위해서 fstab에 등록해야 하는데, fstab에 아운트 지점을 지정하는 방법은 디바이스 드라이브의 경로 혹은 UUID를 명시하는 것이다. LVM도 다르지 않는데 먼저 fstab에 등록해서 마운트 하기 위해서 lvdisplay 명령으로 LV path 를 확인한다. 123456# lvdisplay --- Logical volume --- LV Path /dev/vg_usb/dbvol --- Logical volume --- LV Path /dev/vg_usb/workvol /etc/fstab에 LV Path 경로를 추가 한다. 12/dev/vg_usb/dbvol /data ext4 defaults 0 1/dev/vg_usb/workvol /home/pi/work ext4 defaults 0 1 UUID를 사용하려면 위에 찾은 LV Path에 해당하는 UUID를 찾아야 한다.^1 먼저 LV path 경로를 보면 12$ ll /dev/vg_usb/dbvollrwxrwxrwx 1 root root 7 May 2 18:18 /dev/vg_usb/dbvol -&gt; ../dm-0 같이 링크로 나온다. 이 링크 파일의 UUID를 찾으면 된다. 12$ ls -l /dev/disk/by-uuid/lrwxrwxrwx 1 root root 10 May 2 18:18 a7bb8085-0e50-845a-b65b-a6b7e8c86dc9 -&gt; ../../dm-0 찾은 UUID를 fstab에 마운트 지점과 함께 기록한다. 1UUID=a7bb8085-0e50-845a-b65b-a6b7e8c86dc9 /data ext4 defaults 0 0 UUID=”680C0FE30C0FAAE0” /jgdata ntfs user,auto,rw 0 0 LVM 사이즈 키우기1# lvextend -L +10M /dev/um_vg/xfs_lv -r ### LVM 을 새 시스템에 장착하기 LVM으로 생성한 볼륨그룹을 다른 시스템에서 사용하려면 Volume group을 이용한다. volume group 비활성화 volume group 추출 새 시스템에서 volume group 가져오기 새 시스템에서 volume group 활성화 새 시스템에서 마운트 1. vgscan으로 확인123# vgscan Reading all physical volumes. This may take a while... Found volume group &quot;vg_usb&quot; using metadata type lvm2 2. vg 추출12# vgexport vg_usb Volume group &quot;vg_usb&quot; successfully exported 이제 새 시스템에서 추출한 volume group을 활성화 한다. 3. PV 파티션 확인pvscan으로 파티션을 확인한다. 비활성화하고 추출한 파티션을 확인할 수 있다. 123# pvscan PV /dev/sda2 is in exported VG vg_usb [55.62 GiB / 25.62 GiB free] Total: 1 [55.62 GiB] / in use: 1 [55.62 GiB] / in no VG: 0 [0 ] vbimport 로 volume group을 가져온다. 12# vgimport vg_usb Volume group &quot;vg_usb&quot; successfully imported 4. VG 활성화12# vgchange -ay vg_usb 1 logical volume(s) in volume group &quot;vg_usb&quot; now active 마운트 하기 위해서 볼륨그룹은 장치는 dev 밑에 보륨그룹 이름 /dev/vg_usb 같이 생성되므로 ls 명령으로 확인 가능 12# ls /dev/vg_usb/mongovol workvol 혹은 lvdisplay 명령으로 LV path 를 확인한다. 1234567891011121314151617# lvdisplay --- Logical volume --- LV Path /dev/vg_usb/dbvol LV Name dbvol VG Name vg_usb LV UUID hTnMaP-6rgM-ePOi-HXs4-X0Ia-h4mP-gpT1JM LV Write Access read/write LV Creation host, time odroid64, 2016-12-02 15:05:45 +0900 LV Status available # open 0 LV Size 30.00 GiB Current LE 7680 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 mount 명령으로 LV path를 마운트 한다. 12345# mount /dev/vg_usb/dbvol mongodata/...# mount.../dev/mapper/vg_usb-dbvol on /data type ext4 (rw,relatime,data=ordered) 재시동 후 마운트를 유지하기 위해 마운트한 경로를 /etc/fstab에 추가한다. LVM error기존 LVM 디스크를 사용하던 OS에 타 시스템에서 생성한 LVM을 옮겨와 사용하려면 다음 같이 lvmetad 에러가 난다. /run/lvm/lvmetad.socket: connect failed: No such file or directory lvm2 서비스를 활성화하고 시작해 주면 된다. 1234sudo systemctl enable lvm2-lvmetad.servicesudo systemctl enable lvm2-lvmetad.socketsudo systemctl start lvm2-lvmetad.servicesudo systemctl start lvm2-lvmetad.socket ### Unmount - It's busy LVM 볼륨을 사용중 마운트를 해제하려고 할 때 다음 같은 경고가 난다. 1234sudo umount /dataumount: /data: target is busy (In some cases useful info about processes that use the device is found by lsof(8) or fuser(1).) fuser 명령 lsof 명령으로 해당 디렉토리를 사용중인 파일, 프로세스를 확인할 수 있다. 1234$ sudo fuser -vm /data USER PID ACCESS COMMAND/data: root kernel swap /data/.swap4G root kernel mount /data lsof로 어떤 프로세스가 디렉토리를 사용하는지 출력해 볼 수 있다. 123$ sudo lsof +D /dataCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbash 23617 qkboo cwd DIR 179,1 4096 129793 . xfs 파일시스템 주의: USB 메모리를 사용한 디스크에서 mongodb에 사용하기 위해서 시작했는데, 최신 mongodb의 storage engine인 WiredTiger는 xfs를 요구한다. 다만 Odroid C2 의 Ubuntu, Ambian 에서 xfsprogs 설치후 xfs 파일 시스템 생성시 문제가 있다. 1# apt install xfsprogs 디스크 볼륨을 xfs file system 생성한다. 1# mkfs.xfs /dev/usb64_vg/db_xfs ## 참조 Create xfs filesystem based LVM [LVM Resize](&gt; https://www.rootusers.com/lvm-resize-how-to-decrease-an-lvm-partition/)","link":"/2017-04-03-odroid-lvm2-0844c68ac111/"},{"title":"Nginx - Install, WebDAV, Proxy on Ubuntu&#x2F;Debian","text":"nginx를 사용해서 일반 웹 서비스, SSL, WebDav 서비스와 다른 외부 웹 서비스와 연동하는 설정을 해보자. 여기서 node.js 애플리케이션을 연동한다. ## Nginx 설치와 구성 우분투/데비안 계열에서 apt-get install 명령으로 설치한다. Nginx 설치1$ sudo apt-get install nginx 우분투/데비안 계열은 /etc/nginx 밑에 nginx 설정 파일이 위치한다. 123456789nginx/├── conf.d/├── htpasswd├── nginx.conf├── sites-available/│ └── default├── sites-enabled/│ └── default -&gt; /etc/nginx/sites-available/default└── ssl/ htpasswd: apache-utils의 htpasswd 유틸리티로 생성한 Basic auth 계정 파일 ssl/ : SSL 인증서 파일 nginx.conf : nginx의 전역 설정 파일, 사이트 설정 및 가상 호스트 설정은 sites-available 에 선언. sits-available: 웹 사이트 설정 파일 sites-enabled: 새 사이트 정의가장 좋은 방법은 기존 default 설정 파일을 복사해 수정한 후 사용한다. 12$ cd /etc/nginx/$ cp site-available/default cp site-available/my-site my-site가상 호스트 파일을 /etc/nginx/sites-available/ 폴더에 추가하고 site-enabled에 링크를 해주면 된다. 아래 내용으로 /etc/nginx/sites-available/my-site 파일을 다음 같이 추가해 준다. 1234567891011121314server { listen 80 default_server; listen [::]:80 default_server; root /home/qkboo/my-site; index index.html index.htm index.nginx-debian.html; server_name my-site.localhost; location / { try_files $uri $uri/ =404; }} 사이트 활성화는 /etc/nginx/site-enabled 폴더에 소프트 링크를 걸어준ㄷ. 12$ sudo ln -s /etc/nginx/sites-available/my-site /etc/nginx/sites-enabled/my-site$ sudo service nginx reload # 설정 다시 가져오기 Debian, Ubuntu 계열은 Ubuntu 15.x, Debian Wizzy 이후? 시스템 서비스를 systemd 로 다룬다. nginx도 systemd 스크립트로 관리할 수 있다. systemd 관련 내용 참조 - [^6] 12$ sudo systemctl reload nginx.service$ sudo systemctl status nginx.service 만약 설정 파일에 문제가 있으면 systemctl status nginx.service 결과에 어느 줄에서 문제가 있는지 확인할 수 있다. Nginx for Node.jsNginx를 메인 웹 서버로 사용하고 여기에 연결되는 URL, Location에 따라 nginx 외부의 다른 서비스에서 처리하게 하는 방법을 proxy 를 연결하는 것이다. 즉, nginx에서 Node.js, Django, Tomcat 같은 웹 서비스의 통로로 사용한다. http://www.albertauyeung.com/post/setup-jupyter-nginx-supervisor/ proxy1234567891011121314151617181920212223242526server { listen 80; server_name test.example.com; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:52222/; proxy_redirect off; } log_not_found off; gzip on; gzip_comp_level 2; gzip_proxied any; gzip_min_length 1000; gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript text/x-js; } 설정 파일이 제대로 구성됐는지 테스트해본다. sudo nginx -t [^1] ## WebDAV Nginx에서 WebDAV는 nginx-extras 패키지를 설치한다. 123$ sudo apt-get install nginx nginx-extras$ sudo mkdir /home/qkboo/WebDav$ sudo chown www-data /home/qkboo/WebDav 혹은 chgrp로 그룹만 변경할 수 있다. 1$ chgrp www-data /home/qkboo/WebDav Basic AuthHTTP Auth 는 htpasswd 유틸리티로 사용자 이름과 아이디를 등록해서 사용한다. [^5] 12$ sudo apt-get install apache2-utils$ sudo htpasswd -c /etc/nginx/htpasswd exampleuser WebDav용 설정위에서 사용한 my-site 설정에 다음 같이 WebDav 디렉토리 위치를 추가한다. 123456789101112131415161718192021222324252627282930313233343536server { # SSL configuration listen 443 ssl http2 default_server; listen [::]:443 ssl http2 default_server; ssl on; #... 생략 # WebDav directory and URL location /myfiles { alias /home/qkboo/WebDav; #root /home/qkboo/; #client_body_temp_path /var/dav/temp; dav_methods PUT DELETE MKCOL COPY MOVE; dav_ext_methods PROPFIND OPTIONS; create_full_put_path on; dav_access user:rw group:rw all:rw; autoindex on; # Basic auth auth_basic &quot;restricted&quot;; auth_basic_user_file /etc/nginx/htpasswd; send_timeout 36000s; proxy_connect_timeout 36000s; proxy_read_timeout 36000s; proxy_send_timeout 36000s; # large file uploads proxy_request_buffering off; }} more configureshttp://nginx.org/en/docs/http 에 있는 세부 설정중 사용한 것. Upload sizePOST로 multi-part 업로드시에 다음 에러가 보이면 nginx의 기본 업로드 크기를 2M 이하로 설정되어 그렇다. 1[error] 31354#0: *10899 client intended to send too large body: 1198151 bytes, client: &lt;IP address&gt;, server: example.com, request: “POST /wp-admin/async-upload.php HTTP/1.1”, host: “example.com”, referrer: “http://example.com/wp-admin/post.php?post=&lt;post id&gt;&amp;action=edit” client_max_body_size 속성을 server, location 에 설정해 준다: 1client_max_body_size 20M; limit_ratelimit_rate, limit_rate_after 는 함께 사용 12345location /flv/ { flv; limit_rate_after 500k; limit_rate 50k;} ## 참조 [^1]: nginx command[^5]: Http Auth[^6]: 서버 프로세스 관리에 대해","link":"/2017-04-03-ubuntu-nginx-72805493fb26/"},{"title":"Python - Install virtualenv on Linux","text":"Python 개발환경을 위해서 시스템에 설치된 python2.7, python3.x 에서 사용하는 패키지 모듈을 pip를 사용해서 패키지를 관리할 수 있다. 그리고 시스템 모듈과 별도의 버전 환경으로 버전 관리 도구인 virtualenv와 virtualenvwrapper 를 사용해 파이썬 가상 개발 환경을 구성하는 방법을 설명한다. Python virtualenv 개발환경 구축하기최근 리눅스 배포본은 python2.7, python3.x 버전이 내장되어 있다. raspbian-wheezy에는 Python 2.7과 Python 3.2가 설치되어 있다 raspbian jessie에는 Python 2.7과 Python 3.3이 설치되어 있다. armbian Debian Jessie, Ubuntu Xenial 에도 Python 2.7과 Python3.3 이 설치되어 있다. 파이썬 개발환경은 virtualenv 를 기반으로 사용하는 것을 권장한다. 그리고 가상 개발 환경은, 시스템 개발자 모듈 설치 시스템 Python pip 설치 pip에서 시스템 Python virtualenv, virtualenvwrapper 설치 가상환경 만들기 순서로 구성할 수 있다. Python 가상 개발 환경 설치다양한 파이썬 버전을 위해 환경 구성을 해주는 유틸리티. pyenv : “Simple Python Version Management”, 로컬에 다양한 파이썬 버전을 설치하고 사용할 수 있도록 한다. pyenv를 사용함으로써 파이썬 버전에 대한 의존성을 해결할 수 있다. virtualenv : “Virtual Python Environment builder”, 로컬에 다양한 파이썬 환경을 구축하고 사용할 수 있도록 한다. 일반적으로 Python Packages라고 부르는 ( pip install을 통해서 설치하는 ) 패키지들에 대한 의존성을 해결할 수 있다. autoenv : 만약 pyenv와 virtualenv를 통해서 의존성을 해결한다고 하더라도 작업할때마다 설정해주는 것은 귀찮은 작업이다. 특정 프로젝트 폴더로 들어가면 자동으로 개발 환경을 설정해주는 autoenv라는 스크립트를 활용할 수 있다. pyenvhttp://pythonstudy.xyz/python/article/506-파이썬-가상환경 여기서는 virtualenv와 virtualenvwrapper를 사용해서 모듈을 설치하고 관리한다. pip 모듈을 사용해서 virtualenv 와 virtualenvwrapper 를 설치한다. virtualenv 단독 사용다음 참조. http://dgkim5360.tistory.com/entry/python-virtualenv-on-linux-ubuntu-and-windows virtualenv는 가상환경이 설치된 위치로 이동해서, 설치한 폴더에서 source 명령을 통해 환경을 활성화해야 한다. 이런 점을 보완해 쉘 명령을 제공하는 virtualenvwrapper와 함께 쓰는 것을 권한다. 여기서는 pip로 virtualenv와 virtualenvwrapper를 설치해서 사용한다. virtualenv와 virtualenvwrappervirtualenv는 가상의 파이썬 작업환경을 만들어 준다. 작업환경을 따로따로 만들어, 시스템 파이썬 모듈이나 다른 가상의 작업환경에게 영향을 주지 않는다. 또한 pip는 시스템의 site-packages 폴더 /usr/lib/python2.7/site-packages에 모듈을 설치하는데 virtualenv를 이용하면 분리할 수 있다. 이제 pip로 virtualenv와 virtualenvwrapper를 설치한다. 12$ pip3 install virtualenv$ pip3 install virtualenvwrapper virtualenvwrapper는 virtualenv 통합 환경을 쉽게 다룰 수 있게 해준다. 쉘 프로파일 .bashrc, .profile 등에 다음 라인을 추가한다. 123export WORKON_HOME=$HOME/.virtualenvsexport PROJECT_HOME=$HOME/Develsource /usr/local/bin/virtualenvwrapper.sh 그리고 쉘 환경을 로딩하기 위해서 다시 로그인 하거나 다음 같이 source 명령을 이용해도 좋다. 12345678910111213141516$ source .profileebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extentpermitted by applicable law.Last login: Fri Oct 23 18:17:41 2015 from 192.168.219.103virtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkprojectvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/initializevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/premkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postmkvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/prermvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postrmvirtualenvvirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/predeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postdeactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/preactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/postactivatevirtualenvwrapper.user_scripts creating /home/pi/.virtualenvs/get_env_details 다음 에러가 발생하면 쉘에 VIRTUALENVWRAPPER_PYTHON 를 추가해 준다. /usr/bin/python: No module named virtualenvwrappervirtualenvwrapper.sh: There was a problem running the initialization hooks. If Python could not import the module virtualenvwrapper.hook_loader,check that virtualenvwrapper has been installed forVIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is Quick-Start새로운 가상환경은 mkvirtualenv 명령으로 만든다. 가상환경으로 전환시 프롬프트가 (NAME) $ 형태로 표시된다. 123$ mkvirtualenv django2 #기본 python 버전의 환경 생성...(django2):~$ # 실행 가상 환경 쉘 mkvirtualenv 명령은 -p 옵션으로 파이썬 버전을 명시할 수 있다. 1$ mkvirtualenv -p python3 django3 --system-site-packages 옵션은 site-package 시스템 버전을 사용하게 한다. 1$ mkvirtualenv --system-site-packages -p python3 django3 workon 명령으로 설치한 가상 환경 목록을 보거나 혹은 해당 가상환경으로 전환할 수 있다. 12345$ workondjango2 django3$ workon django3...(django3):~$ 프로젝트 환경을 빠져 나오려면 deactivate를 실행한다. 1(django3):~$ deactivate 가상환경 복사하기12$ cpvirtualenv django3 new_djang4$ rmvirtualenv django3 pyvenv3.3에서부터 pyvenv에 기본으로 설치되어 있다. 다만 3.3에서는 pip를 가상 환경을 만들 때마다 설치해주어야 한다. 3.4에서는 pip까지 기본으로 설치되어 있다. 12345$ mkdir django_tests$ cd django_tests$ pyvenv-3.4 env$ source env/bin/activate # env의 파이썬 활성화(env)$ deactivate # 시스템 파이썬으로 복귀 System serviceVirtualevn 환경을 시스템 시작 스크립, 크론, 파이썬 스크립에서 사용하려면 해당 가상 환경 위치의 python 혹은 가상환경의 jupyter-notebook 같은 명령 위치를 지정하면 된다. https://serverfault.com/questions/821575/systemd-run-a-python-script-at-startup-virtualenv 참조virtualenvwrapper","link":"/2017-04-03-virtualenv-linux-8431e8cf44ac/"},{"title":"Rasbian Wheezy 설치후 작업","text":"upgrade1# apt update &amp;&amp; apt dist-upgrade &amp;&amp; apt upgrade 업그레이드 중 1The following packages have been kept back: linux-image-c2 기존 리눅스 이미지를 지우고 업그리이드 중 에러가 나서 이미지 업그레이드가 안되었으므로, 이전 버전 이미지를 찾아 삭제해 주면 다시 업그레이드가 된다. 1234567# apt --installed list |grep linuxlinux-image-3.14.65-73/unknown,now 20160802 arm64 [installed,automatic]linux-image-3.14.79-94/unknown,now 20161121 arm64 [installed,automatic]linux-image-c2/now 73-1 arm64 [installed,upgradable to: 94-1]linux-libc-dev/xenial-updates,xenial-security,now 4.4.0-51.72 arm64 [installed]util-linux/xenial-updates,now 2.27.1-6ubuntu3.1 arm64 [installed] 이전 버전 이미지를 지운다. 업그레이드 후 uname 확인 12345678root@odroid64:~# apt autoremove linux-image-3.14.65-73...Preparing to unpack .../linux-image-c2_94-1_arm64.deb ...Unpacking linux-image-c2 (94-1) over (73-1) ...Setting up linux-image-c2 (94-1) ...# uname -aLinux odroid64 3.14.79-94 #1 SMP PREEMPT Mon Nov 21 17:13:27 BRST 2016 aarch64 aarch64 aarch64 GNU/Linux 설정hostnamedebian 계열에서 hostname을 변경하려면 hostnamectl 을 사용한다. 1234567891011121314$ sudo -s# hostnamectl set-hostname dlp# show settingsroot@debian:~# hostnamectl Static hostname: dlp Icon name: computer-vm Chassis: vm Machine ID: 5f47b11299ed4689a48a7f78197e452a Boot ID: bdeed3b6c079405bb45d79eff3e870a5 Virtualization: vmware Operating System: Debian GNU/Linux 8 (jessie) Kernel: Linux 3.16.0-4-amd64 Architecture: x86-64 TimezoneCLI에서 설정을 할 수 있다. 1# dpkg-reconfigure tzdata timedatectl timedatectl 명령으로 123456$ timedatectl list-timezones...Asia/Seoul...$ sudo timedatectl set-timezone Asia/Seoul 혹은 손으로 직접 수정한다면, Timezone은 /etc/localtime 이라는 바이너리로 저장되므로명령행에서 지원하는 timezone을 복사할 수 도 있다. 1$ sudo cp /usr/share/zoneinfo/Europe/London /etc/localtime 기본 에디터 변경odroid의 ubuntu 16.04는 기본에디터로 joe가 설치되어 있다. vim 으로 변경한다. 1234567891011121314# update-alternatives --config editorThere are 6 choices for the alternative editor (providing /usr/bin/editor). Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/joe 70 auto mode 1 /usr/bin/jmacs 50 manual mode 2 /usr/bin/joe 70 manual mode 3 /usr/bin/jpico 50 manual mode 4 /usr/bin/jstar 50 manual mode 5 /usr/bin/rjoe 25 manual mode 6 /usr/bin/vim.tiny 10 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 6 apt autocompetionbash-completion 이 빠져 있으면 1$ sudo apt install bash-completion apt-get 명령은 자동완성이 되지만 apt 명령은 안된다면 1$ sudo apt install --reinstall bash-completion Dnsutilsdig, nslookup 같은 명령이 있는 패키지. 1$ sudo apt install dnsutils 디스크tune2fsfsck로 마지막 체크한 시간 확인은 tune2fs 명령을 이용 12$sudo tune2fs -l /dev/sdbX | grep Last\\ cLast checked: Sun Dec 13 09:14:22 2015 마운트 횟수 12tune2fs -l /dev/sdbX | grep MountMount count: 157 12tune2fs -l /dev/sdbX | grep MaxMaximum mount count: -1 참조: https://linuxconfig.org/how-to-force-fsck-to-check-filesystem-after-system-reboot-on-linux fsck루트 파티션을 강제로 fsck 하게 하려면 루트 파티션에 forcefsck 파일을 생성해 둔다. 1$sudo touch /forcefsck forcefsck 파일은 단 한번만 부팅시 루트 파일시스템을 체크한다. 만약 지속적으로 파일 시스템을 체크하도록 하려면 tune2fs 를 사용해서 ‘Maximum mount count’ 파라미터를 사용하도록 한다. 아래 명령은 부팅시마다 루트 파티션을 체크하게 된다. 1tune2fs -c 10 /dev/sdb1 이렇게 하면 fsck Maxium mount 값을 양의 값으로 지정하게 된다. 그리고 10번째 부팅시 체크하도록 하려면 -c 10 을 준다. 1tune2fs -c 10 /dev/sdb1 SWAPswap 파일로 만들려면 12345$ sudo dd if=/dev/zero of=/data/swap4G bs=1G count=4sudo chmod 600 /swapfilesudo mkswap /swapfilesudo swapon /swapfilesudo swapon -s 123sudo mkswap /dev/sda1sudo swapon /dev/sda1sudo swapon -s grc터미널 컬러 처리 https://github.com/garabik/grc 1234grc netstatgrc ping hostnamegrc tail /var/log/sysloggrc ps aux lastblastb 명령은 /var/log/wtmp, /var/log/btmp 에 있는 로그인 기록에서 최근 로그인한 모든 목록을 출력한다. 다음은 최근 20개 목록을 출력한다. 12345$ sudo lastb -n 20root ssh:notty 112.85.42.230 Fri Jul 20 17:25 - 17:25 (00:00)root ssh:notty 112.85.42.230 Fri Jul 20 17:25 - 17:25 (00:00)oracle ssh:notty 210.182.116.102 Mon Jul 16 23:36 - 23:36 (00:00)cumulus ssh:notty 36.248.211.16 Mon Jul 16 20:59 - 20:59 (00:00) 실패한 로그인 시도https://www.guyrutenberg.com/2014/09/26/view-failed-login-attempts-lastb/ -w 로 사용자 이름을 출력하고 첫번째 열만 자른 후 정렬한 후, uniq 명령으로 중복되는 이름을 제거한 후 출력한다. 1$ sudo lastb -w | cut -d &quot; &quot; -f 1 | sort | uniq | less 이중에서 접속한 IP와 횟수를 출력한다. 12345678$ sudo lastb -f /var/log/btmp.1 -w -i | awk '{print $3}' | sort | uniq --count | sort -nr | less[sudo] root의 암호: 2166 112.85.42.156 1945 112.85.42.193 1591 112.85.42.201 1327 112.85.42.230 1146 112.85.42.196 기본 Python 만들기사용자 파이썬 앨리어스 만들기사용자 홈 디렉토리에 ~/.bashrc 파일에 앨리어스를 만든다. 1alias python='/usr/bin/python3.4' 다시 로그인 하거나 .bashrc를 컴파일해서 사용한다. 1$ . ~/.bashrc 시스템 전체로 파이썬 구성하기12$ update-alternatives --list pythonupdate-alternatives: error: no alternatives for python 여기서 python2.7과 python3.5 를 update-alternative 로 1$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1 12$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2update-alternatives: using /usr/bin/python3.4 to provide /usr/bin/python (python) in auto mode 파이썬 관련 대체 프로그램 목록을 보면, 123$ update-alternatives --list python/usr/bin/python2.7/usr/bin/python3.5 삭제를 하려면 1$sudo update-alternatives --remove python /usr/bin/python2.7","link":"/raspbian_wheezy-after-install-6746a9b1bc0c/"},{"title":"Odroid - Install Linux","text":"2018-07-10: UART 정보 추가2017-07-24: exFAT 추가{:.right-history} Odroid C2 - Install Armbian{: width=”600”} [그림. armv8 Odroid C2] 다음은 Odroid C2에 Ubuntu 16.04 minimal 버전, 그리고 Ambian Jessie를 설치하고, 처음 설정에 대한 것이다. Odroid에서 제공하는 64bit Ubuntu 설치 Ambian 64bit Debian jessi 설치 sudoer 사용자 사용 hostname 설정 swap 사용 Ambian for OdroidArmbian에서 데스크탑 버전으로 Ubuntu 와 서버 버전으로 Debian Jessie를 다운로드 가능하다. {: width=”600”} 여기서는 Debian Jessie 버전을 사용한다. 준비사항Micro SD Card를 사용하면 가능하면 UHX-1 Class 10 를 사용하도록 한다. Odroid C2는 Micro SD Card 혹은 eMMC Card로 부팅 디스크를 구성할 수 있다. Micro SD Card: UHX-1 Class 10 이상 SDHX Class 8에서 사용중인데, 큰 문제는 없지만 SD Card에 영향을 받는 듯 하다. DownloadAmbian Download 에서 Odroid C2 이미지 에서 Debian server를 다운 받는다. 서버는 7z 파일로 되어 있어서 Windows에서는 7-Zip 프로그램, macOS에서는 Keka Linux에서 7z linux 7z은 apt-get install p7zip-full 으로 설치한다. 모든 플랫폼에서 사용 가능한 저수준 이미지 쓰기 프로그램 **Etcher**도 권장한다. Etcher 사용모든 플랫폼에서 이미지 쓰기가 가능한 Etcher 사용을 권장한다. 다운로드한 Debian_jessie_default.7z 이미지 파일을 선택하고 선택한 SD Card에 이미지를 쓴다. {: width=”600”} dd 사용다운로드한 Debian_jessie_default.7z 이미지를 압축 해제하고, SD Card를 슬롯에 넣고, SD Card의 디스크 번호를 확인하고, 마운트를 해제한다. 여기서 macOS를 사용하고 Disk Utility 를 이용한다. 12$ diskutil list #디스크 번호 확인$ diskutil unmountDisk /dev/disk1 #마운트 해제 dd를 사용해 오에스이미지를 쓴다. 1$ sudo dd if=Debian_jessie_default.img of=/dev/rdisk1 bs=1M conv=fsync Verifying the burned image with Linux오에스 이미지 파일의 md5 값과 디스크에 쓴 이미지의 해시 값을 비교할 수 있다. 1234567891011$ sudo dd if=&lt;/dev/path/of/card&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.153662 s, 559 MB/s9b085251a00ad7ae16fe42fbfb25c042 -$$ dd if=&lt;my/odroid/image.img&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.140843 s, 610 MB/s9b085251a00ad7ae16fe42fbfb25c042 - 두 값이 일치해야 한다. OS를 쓴 SD Card 로 부팅하고 시스템 구성과 설정을 할 수 있다. 사용자 인터페이스로 사용하기 위해 HDMI, Keyboard 그리고 마우스가 필요하다. 만약 GUI 인터페이스 사용이 여의치 않으면 다음 같이 Serial Console을 이용해 접근할 수 있다. Serial Console 이용Odroid C2는 아래 같이 Serial Port 를 제공하고 있다. ^1 {: width=”6400”} [그림. Odroid C2 의 UART (그림. wiki.odroid.com)] 시스템 설정기본 아이디 root / 1234 로 로그인 가능하고 즉시 비밀번호를 변경해야 한다. 또한 사용자 계정을 만들어 사용해야 한다. 1234567891011121314151617181920212223242526272829303132333435Welcome to ARMBIAN Ubuntu 16.04 LTS 3.4.112-sun8iSystem load: 1.17 Up time: 2 minIP: 192.168.11.122CPU temp: 51°CUsage of /: 17% of 7.3GChanging password for root.(current) UNIX password:Enter new UNIX password:Retype new UNIX password:Thank you for choosing Armbian! Support: www.armbian.comCreating new account. Please provide a username (eg. your forename): qkbooAdding user `qkboo' ...Adding new group `qkboo' (1000) ...Adding new user `qkboo' (1000) with group `qkboo' ...Creating home directory `/home/qkboo' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for qkbooEnter the new value, or press ENTER for the default Full Name []: Qkboo Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] yDear Qkboo, your account qkboo has been created and is sudo enabled.Please use this account for your daily work from now on. upgrade1# apt update &amp;&amp; apt dist-upgrade &amp;&amp; apt upgrade 업그레이드 중 1The following packages have been kept back: linux-image-c2 기존 리눅스 이미지를 지우고 업그리이드 중 에러가 나서 이미지 업그레이드가 안되었으므로, 이전 버전 이미지를 찾아 삭제해 주면 다시 업그레이드가 된다. 1234567# apt --installed list |grep linuxlinux-image-3.14.65-73/unknown,now 20160802 arm64 [installed,automatic]linux-image-3.14.79-94/unknown,now 20161121 arm64 [installed,automatic]linux-image-c2/now 73-1 arm64 [installed,upgradable to: 94-1]linux-libc-dev/xenial-updates,xenial-security,now 4.4.0-51.72 arm64 [installed]util-linux/xenial-updates,now 2.27.1-6ubuntu3.1 arm64 [installed] 이전 버전 이미지를 지운다. 업그레이드 후 uname 확인 12345678root@odroid64:~# apt autoremove linux-image-3.14.65-73...Preparing to unpack .../linux-image-c2_94-1_arm64.deb ...Unpacking linux-image-c2 (94-1) over (73-1) ...Setting up linux-image-c2 (94-1) ...# uname -aLinux odroid64 3.14.79-94 #1 SMP PREEMPT Mon Nov 21 17:13:27 BRST 2016 aarch64 aarch64 aarch64 GNU/Linux hostnamedebian 계열에서 hostname을 변경하려면 hostnamectl 을 사용한다. 1234567891011121314$ sudo -s# hostnamectl set-hostname dlp# show settingsroot@debian:~# hostnamectl Static hostname: dlp Icon name: computer-vm Chassis: vm Machine ID: 5f47b11299ed4689a48a7f78197e452a Boot ID: bdeed3b6c079405bb45d79eff3e870a5 Virtualization: vmware Operating System: Debian GNU/Linux 8 (jessie) Kernel: Linux 3.16.0-4-amd64 Architecture: x86-64 Timezone1# dpkg-reconfigure tzdata bash-completionminimal 버전에는 bash-completion 을 다시 설치해 준다. 1$ sudo apt install bash-completion --reinstall Swap 추가여유 디스크에 swap을 추가하려면 123$ sudo mkswap /dev/sda1$ sudo swapon /dev/sda1$ sudo swapon -s swap 파일로 만들려면 12345$ sudo dd if=/dev/zero of=/data/swap4G bs=1G count=4$ sudo chmod 600 /swapfile$ sudo mkswap /swapfile$ sudo swapon /swapfile$ sudo swapon -s swapoffswap 을 지우려면 12swapoff /swapfilerm /swapfile ## Ubuntu 16.04 설치 Micro SD Card를 사용하면 가능하면 UHX-1 Class 10 를 사용하도록 한다. 준비사항Odroid C2는 Micro SD Card 혹은 eMMC Card로 부팅 디스크를 구성할 수 있다. Micro SD Card: UHX-1 Class 10 이상 SDHX Class 8에서 사용중인데, 큰 문제는 없지만 SD Card에 영향을 받는 듯 하다. 다운로드 사이트에서 Download 한다. Write a imagemacOS를 사용하고 있어서 macOS의 diskutil 명령을 사용해 SD Card에 접근했다. 1diskutil list # 디스크 목록에서 SD Card의 디바이스 파일 찾는다. 그리고 쓸려는 SD Card를 Unmount 해준다. 1diskutil unmountDisk /dev/disk1 다운받은 xz 파일을 dd 명령으로 SD Card 메모리 디스크에 쓴다. 1xzcat ubuntu64-16.04-minimal-odroid-c2-20160815.img.xz | sudo dd of=/dev/rdisk1 bs=1M conv=fsync macOS는 /dev/disk[1,2..] 의 디바이스 파일과 /dev/rdisk[1,2…]의 raw disk 디바이스 파일이 있다. 실제 쓸때 rdisk 파일을 사용하도록 권장하고 있다. Verifying the burned image with Linux12345678910$ sudo dd if=&lt;/dev/path/of/card&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.153662 s, 559 MB/s9b085251a00ad7ae16fe42fbfb25c042 -$ dd if=&lt;my/odroid/image.img&gt; bs=512 count=$((`stat -c%s &lt;my/odroid/image.img&gt;`/512)) | md5sum167742+0 records in167742+0 records out85883904 bytes (86 MB, 82 MiB) copied, 0.140843 s, 610 MB/s9b085251a00ad7ae16fe42fbfb25c042 - 첫번째 부팅기본 유저는 root/odroid 로 설정되어 있다. root의 기본 패스워드를 변경하고, sudo 사용자를 추가해 사용하도록 하자. upgradeupgrade시 dist-upgrade 는 꼭 해주도록 하자. kernel 관련 업그레이드를 완성시켜 준다. 1# apt update &amp;&amp; apt dist-upgrade &amp;&amp; apt upgrade 업그레이드 하는 도중 아래 같은 에러가 발생하면, The following packages have been kept back: linux-image-c2 기존 리눅스 이미지를 지우고 업그리이드 중 에러가 나서 이미지 업그레이드가 중단되어서 그렇다. 이전 버전 이미지를 찾아 삭제해 주면 다시 업그레이드가 된다. 1234567# apt --installed list |grep linuxlinux-image-3.14.65-73/unknown,now 20160802 arm64 [installed,automatic]linux-image-3.14.79-94/unknown,now 20161121 arm64 [installed,automatic]linux-image-c2/now 73-1 arm64 [installed,upgradable to: 94-1]linux-libc-dev/xenial-updates,xenial-security,now 4.4.0-51.72 arm64 [installed]util-linux/xenial-updates,now 2.27.1-6ubuntu3.1 arm64 [installed] 이전 버전 이미지를 지운다. 업그레이드 후 uname 확인 12345678root@odroid64:~# apt autoremove linux-image-3.14.65-73...Preparing to unpack .../linux-image-c2_94-1_arm64.deb ...Unpacking linux-image-c2 (94-1) over (73-1) ...Setting up linux-image-c2 (94-1) ...# uname -aLinux odroid64 3.14.79-94 #1 SMP PREEMPT Mon Nov 21 17:13:27 BRST 2016 aarch64 aarch64 aarch64 GNU/Linux Odroid의 Ubuntu는 root 계정을 기본으로 제공하고 있다. 일반 사용자를 등록해 sudoer로 사용하도록 한다. sudo 새 사용자 등록sudo 사용자를 추가해서 사용하려면, adduser 혹은 useradd 명령을 사용해서 사용자를 등록 할 수 있다. 새 사용자 등록먼저 adduser는 추가할 사용자에 대한 정보를 하나씩 물어 가며 등록이 진행되고, 사용자 홈을 생성해 준다. 1234567891011121314151617$ sudo adduser qkbooAdding user `qkboo' ...Adding new group `qkboo' (1000) ...Adding new user `qkboo' (1000) with group `qkboo' ...Creating home directory `/home/qkboo' ...Copying files from `/etc/skel' ...Enter new UNIX password:Retype new UNIX password:passwd: password updated successfullyChanging the user information for qkbooEnter the new value, or press ENTER for the default Full Name []: Gangtai Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] y useradd 는 홈 디렉토리, 쉘 등에 대한 옵션을 주고 사용자를 등록한다. http://www.tecmint.com/add-users-in-linux/ ‘useradd‘ 명령은 크게 두가지 일을 한다: 추가한 사용자에 대한 /etc/passwd, /etc/shadow, /etc/group and /etc/gshadow 편집 사용자 홈 디렉토리 생성 1$sudo useradd -m qkboo 그리고 패스워드를 등록한다. 1234$ sudo passwd qkbooNew password:Retype new password:passwd: password updated successfully sudoer 등록처음 로그인후 새로운 사용자 등록하고 suders에 직접 권한을 줄 수 있다.새로 등록한 혹은 사용자를 sudo 그룹에 등록해 둔다. 1# usermod -aG sudo USERNAME 혹은 visudo 명령으로 sudoers 파일을 편집할 수 있습니다. sudoer에 있는 root는 제외하고 사용자로 등록한다. 1234$ sudo visudo# User privilege specificationroot ALL=(ALL:ALL) ALLpi ALL=(ALL:ALL) ALL 기본 에디터 변경odroid의 ubuntu 16.04는 기본에디터로 joe가 설치되어 있다. vim 으로 변경한다. 1234567891011121314# update-alternatives --config editorThere are 6 choices for the alternative editor (providing /usr/bin/editor). Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/joe 70 auto mode 1 /usr/bin/jmacs 50 manual mode 2 /usr/bin/joe 70 manual mode 3 /usr/bin/jpico 50 manual mode 4 /usr/bin/jstar 50 manual mode 5 /usr/bin/rjoe 25 manual mode 6 /usr/bin/vim.tiny 10 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 6 exFAT리눅스테어 외부 USB 디스크를 exFAT로 포맷하고 사용한다면, exfat-fuse와 exfat-utils를 설치해 준다. 1$ sudo apt install exfat-fuse exfat-utils 그리고 대부분 최신 리눅스 데스크탑은 USB 디스크를 더블클릭하면 자동마운트 해준다. 터미널에서는 123$ sudo mkdir /media/my_usb$ sudo mount -t exfat /dev/sdb1 /media/my_usb$ sudo umount /dev/sdb1 VNC server1sudo apt install tightvncserver 그리고 vncserver 명령으로 기본 패스워드를 생성한다. 1vncserver grc터미널 컬러 처리 https://github.com/garabik/grc 참조 [sudo user create](&gt; https://www.digitalocean.com/community/tutorials/how-to-create-a-sudo-user-on-ubuntu-quickstart) armbian docs","link":"/2017-04-02-odroid-install-linux-b4fd508bf4e3/"},{"title":"NodeJS와 Nginx 웹 서버","text":"Nginx with nodejsnginx를 사용해서 일반 웹 서비스와 node.js 애플리케이션을 연동하는 방법을 살펴보자. http://blog.argteam.com/coding/hardening-node-js-for-production-part-2-using-nginx-to-avoid-node-js-load/ Nginx 구성Nginx 설치가 되었다고 가정한다. nginx 구성 파일/etc/nginx 밑에 가상 호스트 환경에 맞게 파일을 구성한다. /etc/nginx/site-available/myhome.conf 1234567891011121314151617181920212223242526272829server { listen 80 default_server; server_name _; index index.html index.htm index.nginx-debian.html; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:50000/; proxy_redirect off; try_files $uri $uri/ =404; } log_not_found off; gzip on; gzip_comp_level 2; gzip_proxied any; gzip_min_length 1000; gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript text/x-js; } http 에 대한 구성 12345678910111213141516171819202122232425 http { upstream my_node_app { server 127.0.0.1:8000; server { listen 80; server_name localhost domain.com; access_log /var/log/nginx/my_node_app.log; location ~ /static/ { root /home/node/my_node_app; if (!-f $request_filename) { return 404; } } location / { proxy_pass http://my_node_app; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; } }} nginx 구성을 재시작한다 123$ cd /etc/nginx/sites-enabled$ sudo ln -s /etc/nginx/sites-available/test.conf test.conf$ sudo service nginx reload Nginx with Node.jsnodejs 를 연동하기 위한 Proxy 구성을 추가한다. 1234567891011121314151617181920212223242526server { listen 80; server_name test.example.com; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:52222/; proxy_redirect off; } log_not_found off; gzip on; gzip_comp_level 2; gzip_proxied any; gzip_min_length 1000; gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript text/x-js; } SSLNginx를 이용해 SSL 제공을 해주자. Private SSL 설정1234567$ sudo mkdir /etc/nginx/ssl$ cd /etc/nginx/ssl$ sudo openssl genrsa -des3 -passout pass:x -out server.pass.key 2048$ sudo openssl rsa -passin pass:x -in server.pass.key -out server.key$ sudo rm server.pass.key$ sudo openssl req -new -key server.key -out server.csr$ sudo openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt Nginx 설정/etc/nginx/site-available/yoursite.com 123456789101112131415161718192021222324252627282930313233343536373839404142434445server { listen 443 default; server_name erp.yclean.co.kr; access_log /var/log/nginx/oddo.access.log; error_log /var/log/nginx/oddo.error.log; ssl on; ssl_certificate /etc/nginx/ssl/server.crt; ssl_certificate_key /etc/nginx/ssl/server.key; keepalive_timeout 60; ssl_ciphers HIGH:!ADH:!MD5; ssl_protocols SSLv3 TLSv1; ssl_prefer_server_ciphers on; proxy_buffers 16 64k; proxy_buffer_size 128k; location / { proxy_pass http://127.0.0.1:8069; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; } location ~* /web/static/ { proxy_cache_valid 200 60m; proxy_buffering on; expires 864000; proxy_pass http://127.0.0.1:8069; }}server { listen 80; server_name erp.yclean.co.kr; add_header Strict-Transport-Security max-age=2592000; rewrite ^/.*$ https://$host$request_uri? permanent;} http 리다이렉트 http://serverfault.com/questions/250476/how-to-force-or-redirect-to-ssl-in-nginx 12345server { listen 80; server_name signup.mysite.com; rewrite ^ https://$server_name$request_uri? permanent;} The best way as it described in the official how-to is by using the return directive: 12345server { listen 80; server_name signup.mysite.com; return 301 https://$server_name$request_uri;} site file 활셩화123$ sudo ln -s /etc/nginx/sites-available/yourOdooSite.com /etc/nginx/sites-enabled/yourOdooSite.com$ sudo /etc/init.d/nginx restart CORSCORS(Cross-Origin resource sharing)은 웹 페이지 도메인 밖의 다른 도메인에서 제한된 웹 페이지를 자원을 허용하도록 하는 메커니즘이다.[^2] You need to enable CORS on the server (localhost:8080). Check out this site: http://enable-cors.org/ All you need to do is add an HTTP header to the server: 1Access-Control-Allow-Origin: http://localhost:3000 전체적으로 열어 주려 1Access-Control-Allow-Origin: * 다음 같이 nginx 설정을 사용한다. https://gist.github.com/prophittcorey/8205248 123456789101112131415161718192021et $cors '';if ($http_origin ~ '^https?://(localhost|www\\.yourdomain\\.com|www\\.yourotherdomain\\.com)') { set $cors 'true';}if ($cors = 'true') { add_header 'Access-Control-Allow-Origin' &quot;$http_origin&quot; always; add_header 'Access-Control-Allow-Credentials' 'true' always; add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always; add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Requested-With' always; # required to be able to read Authorization header in frontend #add_header 'Access-Control-Expose-Headers' 'Authorization' always;}if ($request_method = 'OPTIONS') { # Tell client that this pre-flight info is valid for 20 days add_header 'Access-Control-Max-Age' 1728000; add_header 'Content-Type' 'text/plain charset=UTF-8'; add_header 'Content-Length' 0; return 204;} Nginx와 Proxy 서비스Nginx를 앞단에 두고 Proxy를 이용해 nodeJS, Djang, Angular 등의 서비스를 이용할 때, nginx나 backend 둘 중 한 곳에서 CORS를 활성화 해주면 된다. Nginx에서 CORSNginx에서 CORS를 허용하려면 아래 설정을 사용할 수 있다. [^1] 1234567891011121314151617181920212223242526272829location / { if ($request_method = 'OPTIONS') { add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; # # Custom headers and headers various browsers *should* be OK with but aren't # add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; # # Tell client that this pre-flight info is valid for 20 days # add_header 'Access-Control-Max-Age' 1728000; add_header 'Content-Type' 'text/plain; charset=utf-8'; add_header 'Content-Length' 0; return 204; } if ($request_method = 'POST') { add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Expose-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; } if ($request_method = 'GET') { add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; add_header 'Access-Control-Expose-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range'; }} 이와 비슷한 방법으로 https://gist.github.com/m4ttbrock/7337183 CORS node.jshttps://enable-cors.org/server_expressjs.html if your app is created with simple node.js set it in your response headers like 12345678910var http = require('http');http.createServer(function (request, response) {response.writeHead(200, { 'Content-Type': 'text/plain', 'Access-Control-Allow-Origin' : '*', 'Access-Control-Allow-Methods': 'GET,PUT,POST,DELETE'});response.end('Hello World\\n');}).listen(3000); if your app is created with express frameworkuse a CORS middleware like 123456var allowCrossDomain = function(req, res, next) { res.header('Access-Control-Allow-Origin', &quot;*&quot;); res.header('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE'); res.header('Access-Control-Allow-Headers', 'Content-Type'); next();} cors modulecors 모듈을 이용할 수 있다. https://github.com/expressjs/cors Enable All CORS requets123var cors = require(&quot;cors&quot;);app.use(cors()); Enable CORS for a Single Route123app.get(&quot;/products/:id&quot;, cors(), function (req, res, next) { res.json({ msg: &quot;This is CORS-enabled for a Single Route&quot; });}); Configuring CORS12345678var corsOptions = { origin: &quot;http://example.com&quot;, optionsSuccessStatus: 200, // some legacy browsers (IE11, various SmartTVs) choke on 204};app.get(&quot;/products/:id&quot;, cors(corsOptions), function (req, res, next) { res.json({ msg: &quot;This is CORS-enabled for only example.com.&quot; });}); 참조 Using Nginx with Odoo HTTPS, SSL 설명 SSL 인증서 종류 [^1]: CORS on Nginx[^2]: Cross-origin resource sharing","link":"/nodejs-nginx-38d522a8db27/"},{"title":"NodeJS &#x2F; nvm 기반 개발환경 설치","text":"Node.js를 설치하고 관리할 수 있는 Node Version Manager를 사용한 개발환경 구성에 대해 살펴본다. 2018-6 npm i 관련 설명 추가{:.right-history} 버전관리자를 통한 Node.js 개발환경Node.js는 커뮤니티 개발을 위주로 업그레이드가 자주 된다. 개발중인 관련 모듈이 업그레이드를 따라가지 못할 경우가 자주 발생할 수 있다. 그래서 실제 개발하는 경우에 Node.js 버전의 변경을 자유롭게 하기 위해서 버전관리자(Node Version Manager) 환경에서 개발을 권장한다. 주요한 버전관리자에는 Nvm, Nodist 등 여러 종류가 있는데, 대부분 리눅스와 맥에서 사용 가능하다. 그리고 윈도우 환경에서는 nvm-windows, nodist를 사용할 수 있다. Linux/macOS: https://github.com/creationix/nvm Windows: https://github.com/marcelklehr/nodist 버전관리자를 설치후 사용 방법은 대동소이 하다. 여기서는 nvm을 다룬다. Shell 은 쉘 프롬프트로 사용자 권한 및 현재 위치를 표시하는데 보통 권한별로 아래 기호를 사용한다. $ : 사용자 프롬프트 # : root 프롬프트 ~ : 사용자 홈 디렉토리 / : 루트 디렉토리 . : 현재 디렉토리 .. : 이전 디렉토리 nvm 설치Linux / MacOS는 다음 쉘 스크립을 실행해 설치한다. curl 이용: 1curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.4/install.sh | bash wget 이용: 1wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.4/install.sh | bash install.sh 스크립이 설치하는 nvm은 사용자 홈디렉토리 ~/.nvm 에 설치된다. (이후 $NVM_HOME이라 하겠다) $NVM_HOME/install.sh 를 실행하면 업그레이드가 진행된다. 설치후 ~/.bash_profile, ~/.profile 등의 프로파일에 nvm.sh 가 실행되도록 아래 스크립이 추가된다. 12export NVM_DIR=&quot;$HOME/.nvm&quot;[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; . &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm Node.js 설치원격 저장소의 node 목록 12nvm ls-remotenvm ls-remote v6 #v6.x 버전만 검색 nvm install 은 해당 node version를 다운로드하고 설치한다. 1nvm install v5 # node version v5.x 버전중 최종버전 nvm ls 설치된 node 버전을 확인한다 12345$ nvm ls v0.9.12 v0.11.0 v6.9.1current: v6.9.1 nvm use로 사용할 node version을 지정한다 - 이것은 사용자의 $PATH 환경변수에 node 경로를 추가해준다. 12nvm use 6.9.1 #v6 버전을 사용한다.nvm use v7 #v7 버전중 최종 버번을 선택한다. node 경로를 제거하려면, 1nvm deactivate 로그인후 기본 node 환경으로 지정하려면 1nvm alias default 6.9.1 lts 버전Node.js 는 가용 버전이 장기지원을 위해서 LTS(Long Term Support) 프로그램을 진행하고 있다. 실제 운영 서버는 이런 LTS 버전을 중심으로 가동될 것이다. nvm 도 lts 만을 선별해서 설치하고 관리할 수 있다. 현재 LTS 버전중 최신버전만을 출력하려면, 1nvm ls-remote --lts |grep Latest 전역 패키지 통합nvm에서 새로운 node 버전을 설치하면서 기존 node 버전에서 사용중인 패키지를 통합해서 설치 할 수 있다. 예를 들어 최신 8 버전을 설치하며 사용중인 기존 6버전 패키지를 함께 설치하려면, 1nvm install v8 --reinstall-packages-from=v8.0.1 Default alias 잘 못 된 경우새로 로그인 혹은 버전 변경시 다음 메시지 출력, 1N/A: version &quot;N/A -&gt; N/A&quot; is not yet installed. 이 경우 가능성은 제거한 버전이 default 로 지정되서 그런듯 하다, 아래의 경우 default가 v8.7 인데 삭제해서 없기 때문이다. 12345678910$ nvm ls-&gt; v6.11.5 v7.10.1default -&gt; v8.7.0 (-&gt; N/A)node -&gt; stable (-&gt; v7.10.1) (default)stable -&gt; 7.10 (-&gt; v7.10.1) (default)iojs -&gt; N/A (default)lts/* -&gt; lts/boron (-&gt; v6.11.5)lts/argon -&gt; v4.8.5 (-&gt; N/A)lts/boron -&gt; v6.11.5 그래서 default 를 설치된 버전으로 변경해서 지정해 주면 위 메시지가 나오지 않는다. ### nodist Nodist 는 윈도우즈 환경에서 Nvm과 비슷하게 nodejs의 버전을 관리할 수 있다. https://github.com/marcelklehr/nodist 윈도우즈 인스톨러로 다운로드 가능. git 혹은 zip 으로 다운로드 가능. 인스톨러로 설치시nodist releases 에서 nodist 인스톨러를 다운받아 설치한다. git으로 설치윈도우즈 git으로 clone을 해오고, 윈도우의 환경설정 변수를 설정한다. 123C:\\&gt;git clone git://github.com/marcelklehr/nodist.gitC:\\&gt;setx /M PATH &quot;C:\\users\\thinkbee\\nodist\\bin;%PATH%&quot;C:\\&gt;setx /M NODIST_PREFIX &quot;C:\\users\\thinkbee\\nodist&quot; 이제 cmd에서 nodist의 업데이트를 실행해주고 사용한다. 1C:\\&gt;nodist selfupdate 기타 다른 환경에서 설치 및 사용법은 nodist 에서 확인한다. /usr/local/lib└── configurable-http-proxy@4.5.3=&gt; If you wish to uninstall them at a later point (or re-install them under your=&gt; nvm Nodes), you can remove them from the system Node as follows: $ nvm use system $ npm uninstall -g a_module npmnpm 은 nodejs 패키지 관리자로 선택한 모듈을 설치, 갱신 및 삭제할 수 있고, 스크립팅을 통해 프로세스 관리까지 할 수 있다. npm init1npm init -y[--yes] 이렇게 생성된 package.json 은, 1234567891011{ &quot;name&quot;: &quot;myproject&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;} npm 으로 추가하는 모듈은 package.json에 의존성을 추가할 수 있다. npm install --save 별도의 플래그를 사용한다. 그리고 --dev 플래그를 주면 developer dependency에 추가해 준다. savenpm &lt; 5 이하 버전은 -S 혹은 --save 옵션으로 모듈 의존성을 package.json 에 추가한다. node를 설치후 npm을 업그레이드 해준다. npm 자체는 다음 같이 업그레이드 한다. 12npm i -g npmnpm install npm@latest -g Outdated module현재 package.json 에 설치된 버전과 명시된 버전 그리고 최신 버전과 차이를 알 수 있다. 1234npm outdatedPackage Current Wanted Latest Locationbody-parser 1.15.2 1.15.2 1.18.2 application-namedebug 0.7.4 0.7.4 3.1.0 application-name 최신 버전으로 설치를 하려면 package.json을 버전코드로 변경하고 업데이트를 진행한다. 모든 패키지를 업데이트할 수 있다. 123npm update+ mongoose@4.13.1added 1 package, removed 4 packages and updated 2 packages in 32.975s 특정 모듈만 업데이트하려면 패키지를 명시하면 된다. 1npm update debug npm upgradenode를 설치후 npm을 업그레이드 해준다. npm 자체는 다음 같이 업그레이드 한다. 12npm i -g npmnpm install npm@latest -g Outdated module현재 package.json 에 설치된 버전과 명시된 버전 그리고 최신 버전과 차이를 알 수 있다. 1234npm outdatedPackage Current Wanted Latest Locationbody-parser 1.15.2 1.15.2 1.18.2 application-namedebug 0.7.4 0.7.4 3.1.0 application-name 최신 버전으로 설치를 하려면 package.json을 버전코드로 변경하고 업데이트를 진행한다.혹은 모든 패키지를 업데이트할 수 있다. 123npm update+ mongoose@4.13.1added 1 package, removed 4 packages and updated 2 packages in 32.975s npm in vs. npm upinstall 과 update는 package.json 에 명시된 버전에 대응해 실행된다. npm install installs all modules that are listed on package.json file and their dependencies. npm update updates all packages in the node_modules directory and their dependencies. npm install express installs only the express module and its dependencies. npm update express updates the express module and its dependencies. stackoverflow: npm install vs update 에 따르면 버전 관리에 따른 차이를 보인다. 개별 모듈만 업그레이드 하려면 install @latest 같이 사용한다. 다음 같이 npm outdated 로 프로젝트 버전 상태를 확인해 보면 12345678910111213141516171819$ npm outdatedPackage Current Wanted Latest Locationagenda 0.9.0 0.9.1 1.0.3 www_appbody-parser 1.15.2 1.15.2 1.18.2 www_appcharset 1.0.0 1.0.1 1.0.1 www_appcheerio 0.22.0 0.22.0 1.0.0-rc.2 www_appcookie-parser 1.3.5 1.3.5 1.4.3 www_appdebug 2.2.0 2.2.0 3.1.0 www_appejs 2.5.7 2.5.8 2.5.8 www_appexpress 4.14.1 4.14.1 4.16.3 www_appiconv 2.2.1 2.3.0 2.3.0 www_appmongoose 4.13.2 4.13.12 5.0.13 www_appmorgan 1.7.0 1.7.0 1.9.0 www_appmulter 1.2.0 1.3.0 1.3.0 www_apppassport 0.2.2 0.2.2 0.4.0 www_apppassport-local-mongoose 1.3.0 1.3.0 5.0.0 www_apppug 2.0.0-rc.4 2.0.3 2.0.3 www_apprequest 2.83.0 2.85.0 2.85.0 www_appserve-favicon 2.3.0 2.3.2 2.5.0 www_app i 명령으로 현재 package.json에 명시된 버전이 설치된다. 123$ npm i mongoose+ mongoose@4.13.12updated 7 packages in 17.037s @latest 제한자로 최신 버전으로 업그레이드 할 수 있다. 12$ npm i mongoose@latest+ mongoose@5.0.13 어쨌든 버전 갱신을 목적으로 하면 npm i 를 일반적으로 써도 무방하다. Process management다음 글로 좀더 깊은 내용으로 옮겼다.","link":"/2017-04-01-nodejs-install-nvm-dbf81fcc0896/"},{"title":"NodeJS - Patterns","text":"원문 https://darrenderidder.github.io/talks/ModulePatterns/ 요약 Node.js Module Patterns이것은 같단한 모듈을 hello-module.js 소스에 선언한 것이다. 12// hello-module.jsconsole.log(&quot;Hello World&quot;); 선언된 소스는 require() 로 들여올 수 있다: 1require(&quot;hello-module.js&quot;); Define a global모듈 foo.js 를 글로벌 1234// foo.jsfoo = function () { console.log(&quot;Im foo&quot;);}; 모듈 foo.js를 들여와 전역에 선언된 함수 foo()를 사용한다. 12require(&quot;foo.js&quot;);foo(); 그러나 글로벌 영역을 오염 시키지 않는다. export an anonymous functionmodule 객체에 export 한다. 1234// bar.jsmodule.exports = function () { console.log(&quot;Im bar&quot;);}; 모듈 bar.js를 들여와 전역에 선언된 함수 foo()를 사용한다. 12var bar = require(&quot;./bar.js&quot;);bar(); export a named functionmodule 객체의 이름 속성으로 export 한다. 1234// bar.jsmodule.fiz = function () { console.log(&quot;fiz&quot;);}; 모듈 bar.js를 들여와 전역에 선언된 함수 foo()를 사용한다. 12var fiz = require(&quot;./fiz.js&quot;).fiz;fiz(); export an anonymous object1234567// buz.jsvar Buz = function() {};Buz.prototype.log = function() { console.log('buz');}export.modules = new Buz(); 모듈 buz.js를 들여와 객체의 메서드를 호출한다. 12var buz = require(&quot;./buz&quot;);buz.log(); export a named object1234567// buz.jsvar Baz = function() {};Baz.prototype.log = function() { console.log('baz');}export.Baz = new Baz(); 모듈 baz.js를 들여와 속성 메서드를 호출한다. 12var baz = require(&quot;./baz.js&quot;).Baz;baz.log(); export an anonymous prototypemodule.exports 에 객체를 노출한다. 1234567// doo.jsvar Doo = function() {};Doo.prototype.log = function() { console.log('doo!');}export.exports = new Doo(); 모듈 doo.js를 들여와 객체의 메서드를 호출한다. 123var Doo = require(&quot;./doo.js&quot;);var doo = new Doo();doo.log(); export a named prototypemodule 에 이름 속성을 노출한다. 1234567// qux.jsvar Qux = function() {};Qux.prototype.log = function() { console.log('qux!');}export.Qux = Qux; 모듈 qux.js를 들여와 객체의 메서드를 호출한다. 123var Qux = require(&quot;./qux.js&quot;).Qux;var qux = new Qux();qux.log(); module.exportsmodules.exports는 exports로 가명을 가지고 있다. 이름 있는 속성을 사용할 때 아래 같이 선언한다. 1234&gt; module.exports.fiz = 'Fiz';&gt; exports.buz = 'buz';&gt; module.exports === exports;true exports 에 직접 대입하면 exports alias를 덮어 쓰게 된다. 1234567891011121314&gt; module.exports.qux = &quot;qux&quot;;&gt; exports{ qux: &quot;qux&quot; }&gt; exports === module.exportstrue&gt; exports = &quot;wobble wibble wubble!&quot;;&gt; exports === module.exportsfalse&gt; exports&quot;wobble wibble wubble!&quot;&gt; module.exports{ qux: &quot;qux&quot; }// module.exports is canonical pros, cons Named exports: 한 모듈에 여러 개체 및 속성을 노출할 수 있다. Anonymouse exports: 간단한 클라이언트 인터페이스로 적합","link":"/nodejs-patterns-b4b5804878bf/"},{"title":"MySQL 5.x 시작 (3)","text":"MySQL사용자 관리mysql-server 를 설치하며 만든 root 사용자 패스워드를 사용해서 데이터베이스에 접속한다. 1$ mysql -u root -p 사용자 데이터베이스사용자가 사용할 데이터베이스를 만든다. 12mysql&gt;create database mydb;Query OK, 1 row affected (0.00 sec) 그리고 CREATE USER, INSERT 로 새 사용자를 추가할 수 있다. create user userid@HOST identified by ‘PASSWORD’; 사용자 foo 를 localhost 와 모든 것을 의미하는 패턴 %로 추가하면: 12mysql &gt; create user foo@localhost identified by 'password';mysql &gt; create user 'foo'@'%' identified by 'password'; 혹은 1insert into user (host, user, password) values ('localhost', 'hiru', 'password('hirururu')); 사용자 제거mysql &gt; drop user ‘hiru’;mysql &gt; delete from user where user =’hiru’ 사용자 생성시 다음같이 1396 에러는 CREATE USER/GRANT 명령으로 사용자와 권한을 추가/관리해야 하는데 mysql.db, mysql.user 테이블을 직접 조작하다가 일관성이 깨졌기 때문 12mysql&gt; create user 'shopuser'@'localhost' identified by ')12345';ERROR 1396 (HY000): Operation CREATE USER failed for 'shopuser'@'localhost' 제대로 사용자를 삭제하고 drop user shopuser@localhost flush privileges; 로 갱신해 준다. 권한 주기권한을 추가하고 삭제하기 위해서, GRANT와 REVOKE의 명령을 사용한다. GRANT 명령 등으로 데이터베이스 사용자가 데이터베이스 자원에 접근하는 권한을 만들 수 있다. GRANT ALL privileges ON DB_NAME.TABLE TO USER_ID@[HOST] IDENTIFIED BY ‘PASSWORD’GRANT [SELECT,DELETE,INSERT,UPDATE,] ON DB_NAME.TABLE TO USER_ID@[HOST] IDENTIFIED BY ‘PASSWORD’ DB_NAME,TABLE 등에 * 패턴을 사용할 수 있다. HOST: 접근하는 소스 호스트 PASSWORD: 패스워드 http://www.w3big.com/ko/mysql/mysql-administration.html 현재 머신에서만 접속할 수 있는 사용자 계정, 외부, 원격에서 접속할 수 있는 사용자 계정을 추가해 준다. 123mysql&gt; use mysql; # mysql system dbmysql&gt; GRANT ALL privileges ON mydb.* TO foo@localhost IDENTIFIED BY '*****';mysql&gt; GRANT ALL privileges ON mydb.* TO foo@'%' IDENTIFIED BY '*****'; 혹은 12grant select, insert, update, delete on mydb.* to foo@host identified by 'password';mysql &gt; grant select, insert, update, delete on dbname.table to userid@'192.168.%' identified by 'password'; 권한을 확인하는 방법 12mysql &gt; show grants for foo@localhostmysql &gt; show grants for 'foo'@'%'; 변경된 권한을 적용하기 1mysql &gt; flush privileges; 권한을 삭제하는 방법 1mysql &gt; revoke all on dbname.table from username@host 추가한 사용자는 SELECT로 확인할 수 있다. 1mysql&gt; select host,authentication_string from user where user='foo'; 사용자 데이터베이스 사용새로 생성한 사용자 ID로 로그인을 해서 데이터베이스 정보를 확인해 보자. 12345678910$ mysql -u foo -pEnter password:mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mydb |+--------------------+ 그리고 데이터베이스를 사용하려면 use [DATABASE] 로 변경한다. 1mysql&gt; use mydb; Character Setmysql에서 한글이 ?로 표시되는 경우. 12345678mysql&gt; SELECT * FROM department;+----+------+| id | name |+----+------+| 1 | ??? || 2 | ??? |+----+------+2 rows in set (0.00 sec) my.cnf의 문자셋과 터미널 문자셋이 일치하지 않아서 그렇다. MySQL은 설치시 지정하지 않았다면 기본적으로 문자셋이 ‘latin1’으로 설정되어 있다. 123456789101112131415161718192021mysql&gt; show variables like 'c%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ || collation_connection | latin1_swedish_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci || completion_type | NO_CHAIN || concurrent_insert | AUTO || connect_timeout | 10 || core_file | OFF |+--------------------------+----------------------------+15 rows in set (0.00 sec) MySQL 설정 파일에서 문자셋을 변경할 수 있다. 다믕 같이 자신의 my.cnf 파일을 작성한다. client, mysqld, mysql 에 대해서 utf8 사용을 선언해 준다. 1234567891011121314151617[client]..default-character-set=utf8[mysqld]character-set-client-handshake=FALSEinit_connect=&quot;SET collation_connection = utf8_general_ci&quot;init_connect=&quot;SET NAMES utf8&quot;character-set-server=utf8collation-server=utf8_general_ci[mysqldump]default-character-set=utf8[mysql]default-character-set=utf8 mysql&gt; show variables like ‘char%’;+————————–+—————————-+| Variable_name | Value |+————————–+—————————-+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+————————–+—————————-+8 rows in set (0.00 sec) 사용자 관리GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP-&gt; ON TUTORIALS.*-&gt; TO ‘zara‘@’localhost’-&gt; IDENTIFIED BY ‘zara123’; SQLStructural Query Language로 튜플 간의 관계를 계산해서 결과를 도촐한다. SEQUEL: Structured English QUEry Language; part of SYSTEM R, 1974 SQL/86: ANSI &amp; ISO standard SQL/89: ANSI &amp; ISO standard SQL/92 or SQL2: ANSI &amp; ISO standard SQL3: in the works… SQL2 supported by ORACLE, SYBASE, INFORMIX, IBM DB2, SQL SERVER, OPENINGRES,… SQL의 구성 SQL consists of the following parts: Data Definition Language (DDL) Interactive Data Manipulation Language (Interactive DML) Embedded Data Manipulation Language (Embedded DML) Views Integrity Transaction Control Authorization Catalog and Dictionary Facilities 교수 학습 연습데이터 유형 http://www.w3big.com/ko/mysql/mysql-data-types.html table professor 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 scode varchar(4) 학번, 기본키 sname varchar(20) 이름 sdept varchar(20) 학과 sphone varchar(15) 전화번호 123456CREATE TABLE professor ( pcode varchar(4) NOT NULL PRIMARY KEY, pname varchar(10), pdept varchar(12), pphone varchar(8)); table student 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 scode varchar(4) 학번, 기본키 sname varchar(20) 이름 sdept varchar(20) 학과 sphone varchar(15) 전화번호 create student table 123456CREATE TABLE student ( scode char(4) NOT NULL PRIMARY KEY, sname char(10), sdept char(12), sphone char(8)); table course 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 ccode varchar(4) 과목코드, 기본키 cname varchar(20) 과목명 ctime int 강의 시수 croom varchar(15) 강의실 create course table 123456CREATE TABLE course ( ccode varchar(4) NOT NULL PRIMARY KEY, cname varchar(10), ctime integer, croom varchar(8)); table lecture 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 lpcode varchar(4) 교수코드, 기본키 lccode varchar(4) 과목코드, 기본키 create lecture table 12345CREATE TABLE lecture ( lpcode char(4) NOT NULL, lccode char(4) NOT NULL, PRIMARY KEY (lpcode, lccode)); table advice 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 apcode varchar(4) 교수코드, 기본키 asccode varchar(4) 학번, 기본키 create advice table 12345CREATE TABLE advise ( apcode char(4) NOT NULL, ascode char(4) NOT NULL, PRIMARY KEY (apcode, ascode)); table register 파일 Python-Database-class-student.sql 컬럼명 테이터 타입 비고 rscode varchar(4) 학번, 기본키 rcccode varchar(4) 과목코드, 기본키 create register table 12345CREATE TABLE register ( rscode char(4) NOT NULL, rccode char(4) NOT NULL, PRIMARY KEY (rscode, rccode)); 데이터 입력123456789101112INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P001','김 구','컴퓨터공학과','0001');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P002','안창호','컴퓨터공학과','0002');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P003','이육사','국문학과','0003');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P004','박종화','국문학과','0004');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P005','심 훈','사학과','0005');INSERT INTO professor (pcode, pname, pdept, pphone)\\ VALUES ('P006','한용운','사학과','0006'); 외부 데이터 파일 이용파일에 필드 간의 ‘,’로 구분한 데이터 파일이 있다. 물론 필드 구별 문자는 데이터의 내용에 따라 사용자가 임의로 정 할 수 있다.파일: studens.txt 123456S001, 박소명, 컴퓨터공학과, 123-4567S002, 최민국, 컴퓨터공학과, 234-5678S003, 이승호, 국문학과, 345-6789S004, 정수봉, 국문학과, 456-7890S005, 김상진, 사학과, 567-8901S006, 황정숙, 사학과, 678-9012 studnets.txt 파일을 읽어들이는 것은 스크립트 파일을 작성하거나 mysql에서 직접 실행할 수 있다.먼저 스크립트 파일 students.sql은 다음과 같다. 123use mydb;load data local infile &quot;student.txt&quot; into table studentfields terminated by ',' ; 이제 mysql 클라이언트에서 데이터를 읽어 들인다. 12mysql&gt;source students.sql; 데이터 조회 SELECT [DISTINCT] select _expr essi onFROM table_listWHERE where_definitionORDER BY col_name [ASC|DESC]GROUP BY col _name_listLIMIT [offset ], rows 예제-1) 전체 교수 리스트를 출력하는 SQL 검색 문을 작성하라.mysql &gt; sel ect * fromprof; 예제-2) 전체 교수 리스트를 이름순서로 출력하는 검색 문을 작성하라.mysql &gt; sel ect * fromprof order by pname; 예제-5) 전체 교수 리스트를 이름 역순으로 출력하는 검색 문을 작성하라.mysql &gt; sel ect * fromprof order by pname desc; 전체 교수 리스트를 학과별로 출력하는 검색 문을 작성하라.mysql &gt; sel ect * fromprof order by pdept, pname; 예제-4) 국문학과 교수 리스트를 이름순서로 출력하는 검색 문을 작성하라.mysql&gt; select * from professor where pdept =’국문학과’; JOIN“FROM 테이블명 AS 별명” 구문은 SQL 문장에서 별명으로 테이블을 참조하 는 역할은 한다. 예제-6) MySQL 과목을 강의하는 교수님의 이름, 전화번호와 강의실을 검색 하는 문장을 작성하라.mysql&gt; select p.pname, p.pphone, c.croom from professor p, course c, lecture lwhere c.cname=’MySQL’ and c.ccode=l.lccodeand l.lpcode=p.pcode; 예제-7) ‘김구’ 교수님이 강의하는 과목명, 강의 시수와 강의실을 검색하는 문장을 작성하라. 1234select c.cname, c.ctime, c.croomfrom professor as p, course as c, lecture as lwhere p.pname = '김 구' and p.pcode = l.lpcode and l.lccode = c.ccode; 예제-8) 각 학생이 수강 신청한 과목에 대해서 학생이름, 전화번호, 과목명, 강의실, 강의 시수를 검색하는 문장을 작성하라. 1234select s.sname, s.sphone, c.cname, c.ctime, c.croomfrom student as s , course as c, register as rwhere s.scode = r.rscode and r.rccode = c.ccodeorder by s.sname, c.cname; sub-query예제-9) 각 학생이 신청한 총 학점을 구하는 검색식을 작성하라. 1234select s.sname, s.sdept, s.sphone, sum(c.ctime)from student as s , course as c, register as rwhere s.scode = r.rscode and r.rccode = c.ccodegroup by s.sname; WHERE 조건절에 해당하는 결과를 GROUP BY 구절에 명시된 s.sname 필드에 따라 그룹으로 결과를 분류하고 난 후, SELECT 필드에 SUM(c.cti me) 함수를 사용해서 c.cti me 필드에 대한 합을 구함으로써 각 학 생이 신청한 총 학점를 구할 수 있다. 예제-10) 각 학과별 교수님은 몇 분인지 구하는 검색식을 작성하라. 123select pdept, count(*)from professorgroup by pdept; LIMIT 구절예제-11) 페이지 크기가 2 일 때, (예제-8)의 결과에서 두 번째 페이지를 검색하는 SQL문장은 작성하라.select s.sname, s.sphone, c.cname, c.ctime, c.croom fromstudent as s , course as c, regi ster as rwhere s.scode = r.rscode and r.rccode = c.ccode order by s.sname, c.cname￼￼limit 2, 2; 마지막 행의 limit 2, 2구절에서, 첫 번째 인자는 오프셋(offset)으로 검 색 결과 레코드들의 순번을 의미한다. 오프셋 값은 0 부터 지정하기 때문에 오프셋값2는전체레코드중에서세번째레코드를가리킨다. 두번째는 인자는 출력하는 레코드 수(rows)를 의미한다. 따라서, 레코드 수 2 는 2 개 의 레코드를 출력하라는 의미가 된다. Update UPDATE tbl_nameSET col_name1 = expr1, col_name2 = expr2, …[WHERE where_definition] [LIMIT rows]; 예제-12) 교수테이블에서 ‘김 구’ 선생님의 이름을 ‘하은용’ 교수님으로 변 경하는 문장을 작성하라.update prof set pname =’하은용’ where pname =’김구’; 예제-13) 지도 테이블의 교수코드가 ‘P007’ 인 레코드들을 모두 ‘P005’ 로 변경하라.update advise set apcode =’P005’ where apcode =’P007’; 예제-14) 강의 시수가 2인 과목들의 강의 시수를 하나 증가 시키고, 강의실 을 Lab1로 변경하라.update course set ctime=ctime + 1, croom=’Lab1’ where ctime=2; Delete DELETE FROM tbl_name[WHERE where_definition] [LIMIT rows] 예제-15 ) 국문학과 학생 레코드를 삭제하는 문장을 작성하라.delete fromstudent where sdept =’국문학과’; PyMySQL 튜토리얼PyMySQL 설치 1$ pip install PyMySQL 만약 pip 로 설치가 안되면 다음 같이 setup.py를 이용해 직접 설치 할 수 있다.$ # X.X is the desired PyMySQL version (e.g. 0.5 or 0.6).$ curl -L https://github.com/PyMySQL/PyMySQL/tarball/pymysql-X.X | tar xz$ cd PyMySQL*$ python setup.py install$ # The folder PyMySQL* can be safely removed now. 123456CREATE TABLE users ( 'id' int(11) NOT NULL AUTO_INCREMENT, 'email' varchar(255) COLLATE utf8_bin NOT NULL, 'password' varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY ('id')) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ; 데이터베이스 삭제 1mysql&gt; drop database mydb; 사용자 비밀번호 변경1mysql&gt; set password for ''myid''@''localhost'' = password(''password''); 테이블 생성show 명령으로 데이터베이스 자원 현환을 볼 수 있다. mysql&gt; help show 다음은 데이터베이스 목록을 보고, ‘mydb’를 사용합니다. 12345678910111213mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mydb || mysql || performance_schema |+--------------------+4 rows in set (0.00 sec)mysql&gt;use mydb... 테이블 현황 1234567mysql&gt; show tables;+----------------+| Tables_in_mydb |+----------------+| test |+----------------+1 row in set (0.00 sec) 테이블 만들기 12345678mysql&gt;CREATE TABLE users (\\ id int(11) NOT NULL AUTO_INCREMENT,\\ email varchar(255) COLLATE utf8_bin NOT NULL,\\ password varchar(255) COLLATE utf8_bin NOT NULL,\\ PRIMARY KEY (id)\\) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin\\AUTO_INCREMENT=1 ; mysql&gt; 터미널에서 여러 줄의 명령을 입력하기 위해서 줄의 끝에 ‘'를 사용해서 여러줄을 입력했다. 이럴게 만들어진 테이블은 show 명령으로 작성 스크립트를 확인할 수 있다. 123456789mysql&gt; show create table users;| Table | Create Table | users | CREATE TABLE `users` ( `id` int(11) NOT NULL AUTO_INCREMENT, `email` varchar(255) COLLATE utf8_bin NOT NULL, `password` varchar(255) COLLATE utf8_bin NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin |1 row in set (0.00 sec) 테이블의 구성 요소는 desc 명령을 확인할 수 있다. 123456789mysql&gt; desc users;+----------+--------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+--------------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || email | varchar(255) | NO | | NULL | || password | varchar(255) | NO | | NULL | |+----------+--------------+------+-----+---------+----------------+3 rows in set (0.00 sec) 데이터 입력1234mysql&gt; insert into users values (0, 'aaa@example.com', 'sldfjslfj');mysql&gt; insert into users values (0, 'bbb@example.com', 'sldfjslfj');mysql&gt; insert into users values (0, 'ccc@example.com', 'sldfjslfj');mysql&gt; insert into users values (0, 'ddd@example.com', 'sldfjslfj'); Alter12345678mysql&gt; #컬럼 추가mysql&gt; alter table users add first_name varchar(10);mysql&gt; alter table users add last_name char(10);mysql&gt; alter table users add point int(5);mysql&gt; alter table users add gener int(5);mysql&gt; #컬럼 삭제mysql&gt; alter table users drop gener; 참조 https://pythonschool.net/category/databases.html","link":"/mysql5-3-start-2b49208d5af4/"},{"title":"MySQL 5.x 소스 빌드 (2)","text":"MySQL소스 빌드mysql 계정 생성 groupadd mysql // 시스템에 mysql 그룹 생성useradd -g mysql -M -s /bin/false mysql // 시스템 로그인이 불가하며 홈디렉터리를 제외하여 mysql 계정을 생성mysql 소스 파일 다운로드 및 압축 해제 mysql 설치에 필요한 필수 패키지 사전 설치 1yum install -y cmake bison gcc gcc-c++ ncurses-devel mysql 데이터베이스 서버를 구축하기 위하여 mysql 최신 버전의 소스를 다운로드 받아 압축을 해제. 1234$ wget http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.28.tar.gz$ tar xzvf mysql-5.6.28.tar.gz$ cd mysql-5.6.28 mysql db 설치에 필요한 사전 작업이 완료되면 설치를 진행할 수 있다. Mysql 은 5.5 버전 이후의 버전은 configure 명령어가 아닌 아래와 같이 cmake 명령어를 이용하여 configure 를 진행. mysql cmake command 정리 1$ cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql - DENABLED_LOCAL_INFILE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 - DWITH_EXTRA_CHARSETS=all -DDEFAULT_CHARSET=utf8 - DDEFAULT_COLLATION=utf8_general_ci -Dwith_ZLIB=system - DENABLE_DTRACE=0 mysql 환경 설정파일 및 mysql 초기화mysql 설치작업이 끝나면 데몬을 구동하기 위한 초기화 작업이 필요하다. 다음과 같이 작업이 완료되면 최초 설치 작업은 마무리 된다. mysql 환경설정 기본 파일 복사 1$ cp ./support-files/my-default.cnf /etc/my.cnf mysql 초기화 12$ cd /usr/local/mysql$ /usr/local/mysql/scripts/mysql_install_db –user=mysql mysql 서비스 스크립트 및 서비스 설정Mysql 설정이 완료되면 부가적으로 서비스의 스크립트와, 부팅 시 자동으로 서비스가 올라오도록 아래와 같은 기본 설정을 추가한다. mysql 서비스 스크립트 및 서비스 runlevel 등재 12$ cd /usr/local/mysql$ cp -a support-files/mysql.server /etc/init.d/mysqld # ln -s /etc/init.d/mysqld /etc/rc3.d/S90mysqld Startmysql-server 를 설치하며 만든 root 사용자 패스워드를 사용해서 데이터베이스에 접속한다. 12345678910111213141516171819$ mysql -u root -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 1Server version: 5.6.26 MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema |+--------------------+3 rows in set (0.00 sec) 사용자가 사용할 데이터베이스를 만든다. 12mysql&gt;create database mydb;Query OK, 1 row affected (0.00 sec) 계속해서 새로운 사용자를 만든다. 1234# 현재 머신에서만 접속할 수 있는 사용자 계정mysql&gt; GRANT ALL privileges ON *.* TO ID@localhost IDENTIFIED BY '*****';# 외부, 원격에서 접속할 수 있는 사용자 계정mysql&gt; GRANT ALL privileges ON *.* TO ID@'%' IDENTIFIED BY '*****'; localhost 머신의 MySQL 데이터베이스에 myid라는 이름의 아이디를 만들고, 패스워드는 password로 설정 사용자 데이터베이스 사용새로 생성한 사용자 ID로 로그인을 해서 데이터베이스를 만든다. 123root@a5d2a69fa410:/# mysql -u qkboo -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\\\g. MySQL 설정MySQL에서 설정파일을 읽는 순서는 다음과 같다. /etc/my.cnf/etc/mysql/my.cnf/usr/local/mysql/etc/my.cnf~/.my.cnf /etc/my.cnfutf-u 문자셋을 기본으로 설정하기 위해서 my.cnf 파일을 다음 같이 사용한다. MySQL 설정 파일에서 문자셋을 변경할 수 있다. 다믕 같이 자신의 my.cnf 파일을 작성한다. client, mysqld, mysql 에 대해서 utf8 사용을 선언해 준다. 1234567891011121314151617[client]..default-character-set=utf8[mysqld]character-set-client-handshake=FALSEinit_connect=&quot;SET collation_connection = utf8_general_ci&quot;init_connect=&quot;SET NAMES utf8&quot;character-set-server=utf8collation-server=utf8_general_ci[mysqldump]default-character-set=utf8[mysql]default-character-set=utf8 참조 https://pythonschool.net/category/databases.html","link":"/mysql5-2-install-src-293ff6413213/"},{"title":"MySQL 5.x 설치 (1)","text":"MySQLInstallUbuntu 16 x64, armhf 등에서 패키지로 설치 1 Startmysql-server 를 설치하며 만든 root 사용자 패스워드를 사용해서 데이터베이스에 접속한다. 123456789$ mysql -u root -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 1Server version: 5.6.26 MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. 데이터베이스 보기 123456789mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+ mysql shell 에서 root 패스워드 변경 12mysql&gt; update user set password=password('PASSWORD') where user = ‘root’;mysql&gt; flush privileges; MySQL 설정MySQL에서 설정파일을 읽는 순서는 다음과 같다. /etc/my.cnf/etc/mysql/my.cnf/usr/local/mysql/etc/my.cnf~/.my.cnf /etc/my.cnfutf-u 문자셋을 기본으로 설정하기 위해서 my.cnf 파일을 다음 같이 사용한다. 만약 외부에서 데이터베이스를 접속하면 설정의 bind-address 막아 주어야 한다. 그렇지 않으면 클라이언트에서 접속 시도시 다음 2003 에러가 난다.[^2] 1ERROR 2003 (HY000): Can't connect to MySQL server on MySQL 설정 파일에서 문자셋을 변경할 수 있다. 다믕 같이 자신의 my.cnf 파일을 작성한다. client, mysqld, mysql 에 대해서 utf8 사용을 선언해 준다. 1234567891011[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock[mysql.server]user=mysqlbasedir=/var/lib[safe_mysqld]err-log=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid 1234567891011121314151617[client]..default-character-set=utf8[mysqld]character-set-client-handshake=FALSEinit_connect=&quot;SET collation_connection = utf8_general_ci&quot;init_connect=&quot;SET NAMES utf8&quot;character-set-server=utf8collation-server=utf8_general_ci[mysqldump]default-character-set=utf8[mysql]default-character-set=utf8 Mysql Secure Installation1# mysql_secure_installation SSLSSL을 통한 암호화 접속을 허용하려면 서버측과 클라이언트 측 모두 인증 파일을 만들어야 한다. https://dev.mysql.com/doc/refman/5.7/en/using-encrypted-connections.html 서버측 인증인증 --ssl 옵션으로 파일은, –ssl-ca identifies the Certificate Authority (CA) certificate. –ssl-cert identifies the server public key certificate. This can be sent to the client and authenticated against the CA certificate that it has. –ssl-key identifies the server private key. mysql_ssl_rsa_setup 유틸리티를 실행하면 data 디렉토리 밑에 생성해 준다.[^5] ca.pemserver-cert.pemserver-key.pem 파일을 생성해 준다. 12345[mysqld]ssl-ca=/var/mysql/ca.pemssl-cert=/var/mysql/server-cert.pemssl-key=/var/mysql/server-key.pem openssl 이용openssl을 이용해 수동으로 키를 생성한다. [^6] 123#cd /etc/mysql#openssl genrsa 2048 &gt; ca-key.pem ca certificate 생성 1openssl req -new -x509 -nodes -days 1000 -key ca-key.pem &gt; ca-cert.pem 1openssl req -newkey rsa:2048 -days 1000 -nodes -keyout server-key.pem &gt; server-req.pem private key를 생성합니다. [root@EDYDR51P0 newcerts]# openssl x509 -req -in server-req.pem -days 1000 -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 &gt; server-cert.pem 증서를 가지고 SSL 로 접속할려면 요런 옵션으로 접속하면 된다. mysql -u root -p –ssl –ssl-ca=c:\\cert\\cert.pem 참조https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-16-04 https://pythonschool.net/category/databases.htmlERROR 2003 (HY000) [^5]: Creating SSL &amp; RSA Certificates and keys[^6]: [Creating SSL Certificates and keys Using openssl](6.4.3.2 Creating SSL Certificates and Keys Using openssl)","link":"/mysql5-1-install-62fc29f0d175/"},{"title":"SD Card 포맷 및 디스크 이미지 사용하기","text":"SBC, PC 등의 머신에서 SD Card 사용에 필요한 사항을 정리했다. 2018-08-30: 전체 내용 편집2017-10-30: swap 추가, timezone 수정{:.right-history} ## SD Card 와 디스크 이미지 사용하기 SD Card는 Secure Digital의 약자로 Flash memory(비휘발성) 카드 포맷이다. 자세한 내용은 Wikipedia: SD Card 를 확인하자. SD Card format Windows Disk Utility를 이용한다. SD Association의 SD Formatter 를 이용한다. macOS Diskutility 앱을 이용한다. SD Association의 SD Formatter 를 이용한다. Linux fdisk, parted 명령으로 포맷할 수 있다. dd 명령으로 macOSmacOS는 Disk Utility 프로그램을 명령줄에서 diskutil 명령으로 디스크에 대한 파티션, 포맷 및 점검을 할 수 있다. GUI 윈도우를 제공하지만 명령줄에서 diskutil 명령으로 파티션, 마운트 및 포맷을 할 수 있다. 명령줄에서 diskutil 명령으로 목록과 파티션 마운트를 해제하고 123$ diskutil list$ diskutil unmountDisk /dev/diskX 역시 dd 명령을 이용해 /dev/zero, /dev/urandom 을 디스크 전체에 써서 지울 수 있다. 1$ sudo dd if=/dev/urandom of=/dev/diskX bs=1000000 디스크 파티션은 partitionDisk 를 사용해서 파티션할 수 있다. 1$ sudo diskutil partitionDisk &lt;Disk&gt; GPT| FAT|exFAT|JHFS+ NAME SIZE SIZE: 0b 전체. zeros$ diskutil reformat /dev/rdisk3 LinuxUbuntu 등은 SD Card 슬롯에 삽입된 장치는 /dev/mmcblkX 같이 장치 이름을 붙인다. USB Stick 으로 SD Card 혹은 Micro SD Card를 사용하면 /dev/sdX 디스크 이름을 사용한다. lsblk 명령은 디바이스 장치가 마운트 된 곳을 출력해 준다. 123456789$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 119.2G 0 disk├─sda1 8:1 0 84.5G 0 part└─sda6 8:6 0 28.9G 0 part /mmcblk0 179:0 0 7.5G 0 disk├─mmcblk0p2 179:2 0 6.8G 0 part /media/qkboo/ROOT├─mmcblk0p3 179:3 0 486.1M 0 part└─mmcblk0p1 179:1 0 200M 0 part /media/qkboo/EFI 파티션 및 포맷을 위해 마운트된 파티션을 언마운트 한다. 12$ sudo umount /dev/mmcblk0p2$ sudo umount /dev/mmcblk0p1 parted 유틸리티로 파티션을 삭제, 생성할 수 있다. 다음은 명령라인에서 옵션을 주어 사용하는 방법이다 123$ sudo parted /dev/mmcblk0 rm 1$ sudo parted /dev/mmcblk0 rm 2$ sudo parted /dev/sdc mkpart primary ext3 4MiB 100% 결과로 mmcblk0 디스크 드라이브에 mmcblk0p1 파티션이 생성된다. 다음은 위와 같은 내용으로 fat32 파티션을 parted 를 Shell로 사용하는 예이다. 12345sudo parted /dev/mmcblk0(parted) mklabel msdos(parted) mkpart primary fat32 1MiB 100%(parted) set 1 boot on(parted) quit 마지막으로 파티션을 파일시스템으로 포맷해 준다. 1$ sudo mkfs -V -t vfat /dev/mmcblk0p1 역시 dd 명령을 이용해 /dev/zero, /dev/urandom 을 디스크 전체에 써서 지울 수 있다. 1$ sudo dd if=/dev/zero of=/dev/diskX bs=4M Disk cloneLinux, macOS 에서 파티션 도구, dd 를 사용해서 디스크 전체, 혹은 파티션을 이미지로 추출해 생성하는 과정을 정리했다. dd 이용하기dd 로 디스크의 전체를 이미지 파일로 생성할 수 있다. 다만 디스크 전체 섹터를 추출하므로 디스크 용량과 같은 크기를 가진 이미지 파일이 생성된다. 1dd bs=4M if=/dev/sdX of=image.gz conv=fsync Ubuntu gparted우분투 Live CD에서 gparted는 가능한 사용하지 않는 공간은 빼고 최소 크기로 줄여 줄 수 있다. 압축 이용하기전체 디스크 크기의 이미지 파일이 너무 크면, 압축유틸리티를 이용해 저장할 수 있다. 12dd bs=4M count=&lt;size_in_MBs&gt; if=/dev/sdX | gzip -c --fast| dd of=image.gzdd bs=4M count=&lt;size_in_MBs&gt; if=/dev/sdX | xz -c --fast| dd of=image.xz 반대로 압축한 이미지 파일을 디스크로 복원하기 위해서 unzip, gunzip, xz -d 압축을 해제한 결과를 파이프로 dd로 전달한다. 12dd if=/path/to/image.gz | gunzip -c | dd bs=1M of=/dev/sdYdd if=/path/to/image.xz | xzcat | dd bs=1M of=/dev/sdY macOS의 Disk Utility 이용GUI인 Disk Utility에서 SD Card 디스크를 선택하고 macOS의 .dmg 이미지 파일로 저장할 수 있고, 저장시 압축 선택이 가능하다. ### Disk Image를 SD Card에 쓰기 각 OS에서 dd 같은 Disk clone 도구를 사용해서 디스크 이미지를 SD Card에 쓸 수 있다. Etcher모든 OS 플랫폼을 지원하는 Etcher 사용을 권장한다. Etcher 을 다운받아 이미지 파일 선택해 대상 SD Card 에 GUI로 쓸 수 있다. {:width=”640”} dd를 사용한다면 이러지는 macOS, Linux 섹션을 참조한다. dd로 이미지 쓰기디스크 내용을 dd 명령으로 디스크 이미지 형태로 저장할 수 있다. 1$ sudo dd if=opensuse_jeos-20171030.img of=/dev/mmcblk0 bs=4m 압축 이미지로 제공하는 이미지 파일은 zcat, xzcat, gzcat 같은 표출 출력 유틸리티를 사용해, dd 명령에 파이프로 처리할 수 있다. 1$ xzcat openSUSE-Leap42.2-ARM-JeOS-raspberrypi3.aarch64.raw.xz | sudo dd of=/dev/rdisk1 bs=4m; sync 이제 이미지 SD Card를 보드에 넣고 부팅한 후 시스템 설정을 시작하면 된다. 시스템 구성을 하고, 여러 설정을 한 후 백업, 복사 등을 위해, 설정한 OS 를 디스크 이미지로 복제하는 경우가 많아 이때는 dd 명령을 사용할 수 있다. ### 이미지 파일 다루기 백업한 디스크 이미지 파티션을 확인하고 폴더에 마운트해서 내용을 확인할 할 수 있다. 이미지 파일의 파티션 정보를 fdisk, parted 명령으로 확인할 수 있다. fdisk 이용123456789101112$ fdisk -lu opensuse-e20.imgDisk opensuse-e20.img: 14.9 GiB, 16022241280 bytes, 31293440 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0xe0e3966bDevice Boot Start End Sectors Size Id Typeopensuse-e20.img1 2048 411651 409604 200M c W95 FAT32 (LBA)opensuse-e20.img2 413696 30282525 29868830 14.2G 83 Linuxopensuse-e20.img3 30283776 31278554 994779 485.7M 82 Linux swap / Solaris parted 이용123456789101112131415$ parted opensuse-42.3-homepi_16GB-firewalld.imgGNU Parted 3.2Using opensuse-42.3-homepi_16GB-firewalld.imgWelcome to GNU Parted! Type 'help' to view a list of commands.(parted) pModel: (file)Disk opensuse-42.3-homepi_16GB-firewalld.img: 16.0GBSector size (logical/physical): 512B/512BPartition Table: msdosDisk Flags:Number Start End Size Type File system Flags 1 1049kB 211MB 210MB primary fat16 lba 2 212MB 15.5GB 15.3GB primary ext4 3 15.5GB 16.0GB 509MB primary linux-swap(v1) Byte 단위로 보려면 1234567(parted) unitUnit? [compact]? B(parted) pNumber Start End Size Type File system Flags 1 1048576B 210765823B 209717248B primary fat16 lba 2 211812352B 15504653311B 15292840960B primary ext4 3 15505293312B 16014620159B 509326848B primary linux-swap(v1) 이미지 마운트디스크 이미지는 리눅스에서 mount 명령으로 마운트 할 수 있다. mount 명령으로 실제 파티션이 시작하는 위치를 offset으로 지정해서 마운트 한다. 앞서 사용한 opensuse-42.3-homepi_16GB.img 이미지의 파티션 정보가 다음 같다고 하자. 1234Number Start End Size Type File system Flags 1 1048576B 210765823B 209717248B primary fat16 lba 2 211812352B 15504653311B 15292840960B primary ext4 3 15505293312B 16014620159B 509326848B primary linux-swap(v1) 첫번째 파티션 시작 위치 1048576B 를 오프셋으로 삼아서 root 권한으로 mount 명령을 사용한다. 섹터 정보를 Byte 단위로 변경하려면, 파티션 정보에서 1 sector 크기가 512 를 확인하고, 이미피 파일의 파티션 시작 섹터를 곱해서 offset 범위를 계산한다. 1Sector size * Start = (in the case) 512 * 8192 = 4194304 (Byte) 이제 마운트 명령 mount -o loop,ro,offset 옵션을 주고, boot와 ROOT 파티션을 마운트 해보자, Now we have the offsets and we can use those to mount the filesystems using the loopback device: 12$ sudo mount -o loop,ro,offset=1048576 opensuse-42.3-homepi_16GB.img ~/mnt/boot/$ sudo mount -o loop,ro,offset=211812352 opensuse-42.3-homepi_16GB.img ~/mnt/ROOT/ 마운트가 성공하면 df 명령 혹은 mount 명령으로 마운트한 위치를 확인할 수 있다; 12345678910$ df -hFilesystem Size Used Avail Use% Mounted onudev 1.5G 0 1.5G 0% /devtmpfs 300M 5.1M 295M 2% /run/dev/sda6 29G 7.3G 20G 28% /tmpfs 1.5G 188K 1.5G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 1.5G 0 1.5G 0% /sys/fs/cgroup/dev/loop0 200M 4.4M 196M 3% /home/qkboo/mnt/boot/dev/loop1 200M 4.4M 196M 3% /home/qkboo/mnt/ROOT /dev/loop0 파일 시스템이 지정한 마운트 위치에 마운트했다는 것을 알 수 있다. 또한 -t [fs_type] 옵션으로 파티션의 파일 시스템을 명시할 수 있다. 이미지에서 한 파티션만 마운트 하기이미지에 있는 하나의 파티션만 마운트 할 수 있다. [^3] 앞의 이미지 파일 정보를 /dev/loop0 에 offset을 주고 1sudo losetup -o 4194304 /dev/loop0 sda.img Now the partition resides on /dev/loop0. You can fsck it, mount it etc 12sudo fsck -fv /dev/loop0sudo mount /dev/loop0 /mnt Unmount 12sudo umount /mntsudo losetup -d /dev/loop0 Truncate질문, 원래 2GB 데비안 이미지를 16GB SD Card에 썼다. 나머지 14GB 공간을 별도로 파티션 나눌 수 있나? 먼저 이미지 파티션 정보를 얻는다. 123456789$ fdisk -lu image.imgDisk image.img: 4096 MB, 4096000000 bytes, 8000000 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000a1bc7 Device Boot Start End Blocks Id Systemimage.img1 2048 5872026 5869978 b W95 FAT32 이미지 파티션의 끝 부분이 5872026 으로 5872026 * 512 = 2,8Gb 이고, 나머지는 안쓰는 공간이다. truncate 도구로 현재 파티션에서 빈공간을 잘라낸다. 다만 블럭 수가 0에서 시작하므로 섹터 수에 1을 더해준다.[^2] 1$ truncate --size=$[(5872026+1)*512] image.img Repair &amp; Corruption프롬프트에서 다음 명령으로 해당 파티션을 점검한다. 12# fsck -fy /dev/mmcblk0p2# reboo 혹은 다음 부팅시 처리할 수 있도록 한다. 12# touch /forcefsck# reboot Check Bad sector터미널에서 SD Card 삽입/추출 및 점검시 섹터 에러를 확인하기 위해 dmesg 로 감시할 수 있다. 다음 명령은 dmesg 가 발생하면, 내용 중 마지막 15줄을 터미널로 출력해 준다. 1$ watch &quot;dmesg | tail -15&quot; hdparamhdparam 1234$ sudo hdparm -t /dev/mmcblk0/dev/mmcblk0: Timing buffered disk reads: 58 MB in 3.09 seconds = 18.80 MB/sec badblocks1$ sudo badblocks -n -v /dev/mmcblk0 RecoveringGNU ddrescue is a data recovery tool. It copies data from one file or block device (hard disc, cdrom, etc) to another, trying to rescue the good parts first in case of read errors. https://www.gnu.org/software/ddrescue/ 참조[^2]: Truncate free space at disk image[^3]: Mount single partition from image of entire disk(device) Raspberry Pi:mmcblk, qkboo parted로 Partition, Foramt하기, qkboo Linux LVM2,qkboo","link":"/sdcard-usage-f12e3af3c903/"},{"title":"Cloud Drives 마운트 사용하기","text":"리눅스 ( 아마 Armbian 서버에서 사용하려고 했었던 것 같다?!)에서 Cloud drive를 사용하고자 한다. Odroid C2 그리고 Orange-pi 시스템에서 사용할, 데스크탑 환경의 Armbian Xenial에서 사용하기 위해 클라우드 드라이브를 사용할 목적으로 사용했었다. Google DriveGoogle drive는 grive 패키지로 제공되고 있다. 최근 (아마 2016년 이후) Google의 REST API가 바뀌어 grive2 패키지를 사용해야 한다. 패키지 제공이 되지 않으면 소스 빌드해서 사용했다. grive2 소스 기반 설치Debian/Ubuntu/Linux Mint 에서 다음 라이브러리가 필요하다: yajl 2.x libcurl libstdc++ libgcrypt Boost (Boost filesystem, program_options, regex, unit_test_framework and system are required) expat 다음 같이 cmake 와 필요한 라이브러리를 apt로 설치한다. 12sudo apt-get install git cmake build-essential libgcrypt11-dev libyajl-dev \\ libboost-all-dev libcurl4-openssl-dev libexpat1-dev libcppunit-dev binutils-dev pkg-config 빌드소스 다운로드: 12git clone https://github.com/vitalif/grive2cd grive2 CMake 로는 다음 같이 빌드 환경을 구성한다 123mkdir buildcd buildcmake .. 그리고 Make 로 다음 같이 빌드한다: 1make -j4 그리고 설치한다: 1sudo make install Updates소스는 git pull 로 최신 소스를 얻고 다시 빌드한다: 123456cd /path/to/yourGriveSourceCodeDir/grive2git pullcd buildcmake ..make -j4sudo make install Usage인증 12345678910$ grive -a-----------------------Please go to this URL and get an authentication code:https://accounts.google.com/o/oauth2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%....client_id=22314510474.apps.googleusercontent.com-----------------------Please input the authentication code here:5/dTdVFy9xBd2cKLYvkcvJlYhwfht4IPuyJdri2Vv3sKAReading local directoriesReading remote server file list 참조 Grive2 ## OneDrive, for Linux OneDrive, for Linux를 설치해서 사용한다. 설치https://github.com/skilion/onedrive 와 같이 다운로드해서 설치하거나 apt로 unstable apt로 설치할 수 있다. source 설치git-hub 가이드에 따라, 12345sudo apt-get install libcurl-devsudo apt-get install libsqlite3-devsudo wget http://master.dl.sourceforge.net/project/d-apt/files/d-apt.list -O /etc/apt/sources.list.d/d-apt.listwget -qO - http://dlang.org/d-keyring.gpg | sudo apt-key add -sudo apt-get update &amp;&amp; sudo apt-get install dmd-bin 그런데 Armbian 에서 llibcurl-dev 패키지를 요구해서, 1234567$ sudo apt-get install libcurl-devReading state information... DonePackage libcurl-dev is a virtual package provided by: libcurl4-openssl-dev 7.38.0-4+deb8u5 libcurl4-nss-dev 7.38.0-4+deb8u5 libcurl4-gnutls-dev 7.38.0-4+deb8u5You should explicitly select one to install. 그래서 libcurl-dev을 설치했다 12$ sudo apt-get install libcurl4-openssl-dev$ sudo apt-get install libsqlite3-dev 설정1234$ cat ~/.config/onedrive/configsync_dir = &quot;~/OneDrive&quot;skip_file = &quot;.*|~*|thumbs.db|Games/*.iso&quot;skip_dir = &quot;.*|Music|Movies/FullHD&quot; 사용은 1234567$ onedrive -hUsage: onedrive [OPTION]...no option Sync and exit.-m --monitor Keep monitoring for local and remote changes.--resync Forget the last saved state, perform a full sync.-v --verbose Print more details, useful for debugging.-h --help This help information. 참조 onedrive for Linux","link":"/linux-cloud-drives-a4494fd3046f/"},{"title":"Cheat Linux System","text":"Linux 에서 짬짬히 자주 쓰이는 명령을 설정을 정리. timezone Disk GRUB, fsck, dd rsync Timezone 관련CLI에서 설정을 할 수 있다. timedatectl timedatectl 명령으로 123456$ timedatectl list-timezones...Asia/Seoul...$ sudo timedatectl set-timezone Asia/Seoul 만약 손으로 수정을 한다면, timedatectl 로 지정되는 설정 Timezone은 /etc/localtime 이라는 바이너리로 저장되므로명령행에서 지원하는 timezone을 복사할 수 도 있다고 한다.. 1$ sudo cp /usr/share/zoneinfo/Europe/London /etc/localtime GRUB 복구우분투 부트로더인 GRUB가 잘못되어 복구하려면 해당 배포본의 Live CD, Live USb 등으로 부팅해서 ‘Try Ubuntu’ 에서 터미널을 통해 복구 절차를 시작한다. https://askubuntu.com/questions/88384/how-can-i-repair-grub-how-to-get-ubuntu-back-after-installing-windows https://help.ubuntu.com/community/Grub2 https://wiki.ubuntu.com/Grub2#Recover KeyboardCapslock과 Control key 교체하기 키맵 이용해서 다음 명령: 1$setxkbmap -layout us -option ctrl:nocaps 123sudo vi /etc/default/keyboardXKBOPTIONS=&quot;ctrl:nocaps&quot; 1sudo dpkg-reconfigure keyboard-configuration dd블록 크기디스크에 데이터를 쓸려면 디스크의 기본 블록 크기인 512B 보다 큰게 좋다. 또한 쓰기 속도를 증가시키기 위해서 디스크의 물리적 지형에 맞는 크기를 사용하는 것이 좋다. fdisk 같은 유틸리티로 정보를 확인할 수 있고 혹은 sysfs 정보를 확인할 수 있다. 123456/sys/block/sdX/size/sys/block/sdX/queue/physical_block_size/sys/block/sdX/queue/logical_block_size/sys/block/sdX/sdXY/alignment_offset/sys/block/sdX/sdXY/start/sys/block/sdX/sdXY/size 디스크 지우기dd에 데이터를 쓸려면 디스크의 기본 블록 크기인 512B 보다 커야 한다. 또한 쓰기 속도를 증가시키기 위해서 디스크의 물리적 지형에 맞는 크기를 사용하는 것이 좋다. 1$ sudo dd bs=8k if=/dev/urandom of=/dev/rdisk2 fdisk 정보로 확인 1234567891011$ sudo fdisk -l /dev/sdbDisk /dev/sdb: 59.6 GiB, 64021856256 bytes, 125042688 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: 441CD64A-70D1-4A40-ACA8-05CAB62C5C89Device Start End Sectors Size Type/dev/sdb1 2048 8390655 8388608 4G Linux swap/dev/sdb2 8390656 125042654 116651999 55.6G Linux LVM fdisk 결과의 Sector size는 전체 용량과 섹터 크기를 계산하면 논릭적인 섹터의 크기를 확인할 수 있다. 12echo $((64021856256/125042688))512 Sector size (logical/physical): 512 bytes / 512 bytes 에서 물리 크기를 확인할 수 있다. 성능dd 를 사용해서 1024 바이트를 1000000 블록에 걸쳐 쓰기를 수행한다 - 1GB 1$ time sudo dd bs=1024 count=1000000 if=/dev/zero of=1GB_file dd 를 사용해서 1GB 크기 파일을 1024 바이트씩 읽기를 한다. 1$ time sudo dd bs=1024 if=1GB_file of=/dev/null Verbose outputSending an INFO signal to a running dd process makes it print I/O statistics to standard error and then resume copying. In the example below, dd is run in the background to copy 10 million blocks. The kill command makes it output intermediate I/O statistics, and when dd completes normally or is killed by the SIGINT signal, it outputs the final statistics. 12345678$ dd if=/dev/zero of=/dev/null count=10MB &amp; pid=$!$ kill -s INFO $pid; wait $pid3385223+0 records in3385223+0 records out1733234176 bytes (1.7 GB) copied, 6.42173 seconds, 270 MB/s10000000+0 records in10000000+0 records out5120000000 bytes (5.1 GB) copied, 18.913 seconds, 271 MB/s On systems lacking the INFO signal dd responds to the USR1 signal instead, unless the POSIXLY_CORRECT environment variable is set. You can also try the status=progress option: 123456[~]$ dd if=/dev/zero of=/dev/null count=10MB status=progress4708234752 bytes (4.7 GB, 4.4 GiB) copied, 4 s, 1.2 GB/s10000000+0 records in10000000+0 records out5120000000 bytes (5.1 GB, 4.8 GiB) copied, 4.3516 s, 1.2 GB/s[~]$ 참조 http://askubuntu.com/questions/511467/how-can-i-completely-erase-all-data-on-a-micro-sd-card Terminal Reset실수로 바이너리 파일을 cat 하거나 하여 글자들이 깨질때.. 터미널 리셋하는 방법 12345$ reset$ tput sgr0$ setterm -reset$ setterm -initialize$ Ctrl + V, Ctrl + O System Info123cat /etc/os-release # Raspbianuname -acat /etc/issue Hardware Info123456lscpulshwlspcilsusblsblk // block deviceslspcmcia 1cat /proc/cpuinfo // BIOS안의 시스템 정보//dmidecode //memory$free -m Architecture1$cat /etc/issue Ubuntu 에서 1$subo lsb_release -a 12$ dpkg --print-architecture //armhf 123$ uname -ai686, i386은 32bit, x86_64는 64bit. armv7은 32bit, armv8은 64bit$ uname -m // machine inf $ uname -i // hw platform$ uname -p // processor $ arch // uname -m 과 동일 32bit 64bit 체크$ getconf LONG_BIT // 시스템 구성 질의 $ file /bin/lsELF 32-bit LSB executable, ARM, EABI5 version 1 .. ARMarm 7 is 32 bit.ARMv8-A, October 2011, 64-bit address space and 64-bit arithmetic 지원$ uname -m // machine infi686 // 32bitx86_64 // 64bitarmv7l // 32bitarmv8 // 64bit 설정// Time zone 1$ sudo dpkg-reconfigure tzdata rsynchttp://www.joinc.co.kr/w/Site/Tip/Rsync rsync -avzh source destination-a : 심볼릭 링크, 속성, 퍼미션, 소유권 등 보존-v : 자세한 정보출력-z : 전송시 압축-r : 하위디렉토리포함-e ssh : ssh를 이용한 rsync 동기화–stats : 결과출력 기본 옵션1rsync -av source/ destination/ include와 exclude이 옵션을 이용해서 대상 파일을 추가하거나 제외 할 수 있다. 1$ rsync -avz --exclude 'data' id@192.168.56.101:/home/backups ./ 별표(*)도 사용할 수 있다. 1$ rsync -avz --exclude '*.cache' id@192.168.56.101:/home/backups ./ 증분 백업수정/변경된 내용만 동기화한다. rsync -avzh moniwiki/ /tmp/backups/-h, –human-readable : output numbers in a human-readable format-u : –update update only (don’t overwrite newer files)–delete : 서버동기화후 원본에서 파일이 삭제되면 백업에서도 파일을 삭제–remove-source-files : 12$ rsync -av /home/ /backup/home/ # 원본 증분 백업$ rsync -av --delete /home/ /backup/home/ #원본 증분 백업, 원본 파일 삭제시 사본에서도 삭제 동기화 옵션delete 옵션목적지에 파일이나 디렉토리가 존재할 경우 삭제하고 싶을 때 --delete 옵션을 사용한다. 1rsync -avz --delete id@192.168.56.101:/home/backups ./ 원본 삭제 옵션--remove-source-files를 이용하면, 전송이 끝난 후 원본파일을 삭제한다. 1$rsync --remove-source-files -zvh backup.tar /tmp/backups/ ssh 통한 백업rsync 에는 ssh 를 이용하여 원격서버에 접속하여 동기화를 하는 기능이 있습니다. 1rsync -azrtv --delete --stats -e &quot;ssh -i /root/.ssh/개인키&quot; 원본서버계정@원본서버주소:원본경로/ /백업경로/ find와 결합1find . -type f -mtime -3 | rsync -avz --files-from=- /soucepc /data/backup faillog/var/log/faillog 는 계정의 로그인 실폐 횟수 정보를 바이너리 파일로 저장한다. 다음 C struct 구조의 정보가 바이너리로 저장되고 있다: 1234567struct faillog { short fail_cnt; short fail_max; char fail_line[12]; time_t fail_time; long fail_locktime;}; 직접 읽을 수 없기 때문에 faillog 명령을 사용한다. 123456$ faillog -u pi # pi 계정$ faillog -aLogin Failures Maximum Latest Onroot 0 0 01/01/70 00:00:00 +0000daemon 0 0 01/01/70 00:00:00 +0000 최근 3일의 로그인 실패를 찾으려면 : 1$ faillog -t 3 -u pi fsckfsck(for file system consistency check) 명령은 파일 시스템을 조사하여 손상된 파일을 출력해 주며 사용자에게 그것을 복구할 것인지를 질의fsck 수행은 시스템마다 약간의 차이가 있지만 대부분 다음과 같은 5개 항목에 대하여 검사Blocks and sizes, Pathname, Connectivity, Reference count, Free List 1$ sudo fsck –t ext2 /dev/hdb Attempt to repair damaged blocks1$ sudo fsck –a Repair damaged blocks interactively1$ sudo fsck -r &lt;drive&gt; forceForcing the checkYou can also force fsck at boot time by passing fsck.mode=force, as a kernel parameter. This will check every filesystem you have on the machine. /forcefsckCreate a file called forcefsck: 1# touch /forcefsck Now, reboot the system: 1# reboot Frce fsck on next boot using shutdown command (may not work on many modern distros) The -F option force fsck on reboot, login as root and type the following command to reboot and run fsck: 1# shutdown -rF now 링크 Changing the check frequencyBy default, fsck checks a filesystem every 30 boots (counted individually for each partition). To change the frequency of checking, run: 1$ sudo tune2fs -c 20 /dev/sda1 exFAT리눅스테어 외부 USB 디스크를 exFAT로 포맷하고 사용한다면, exfat-fuse와 exfat-utils를 설치해 준다. 1$ sudo apt install exfat-fuse exfat-utils 그리고 대부분 최신 리눅스 데스크탑은 USB 디스크를 더블클릭하면 자동마운트 해준다. 터미널에서는 123$ sudo mkdir /media/my_usb$ sudo mount -t exfat /dev/sdb1 /media/my_usb$ sudo umount /dev/sdb1 vnc serverhttps://www.digitalocean.com/community/tutorials/how-to-install-and-configure-vnc-on-ubuntu-14-04 http://www.whatwant.com/840 $ sudo apt-get install gnome-panel tightvncserver 첫 실행을 해서 기본 Config 등의 구성을 하도록 하면 되는데, sudo 없이 계정 권한으로 실행하여도 된다. 계정 권한으로 실행을 하면 해당 계정으로 환경 설정을 한다. 1$ vncserver 실행할 때에 해상도를 미리 정해줘야 한다. $ vncserver -geometry 1024x768 기본 창 관리자 변경 기본 생성된 xstartup 파일에는 내가 원하는 대로 환경 설정이 되어 있지 않다. 가장 먼저 실행된 vnc4server를 종료부터 하고 xstartup 파일을 수정하자. 1234$ vncserver -kill :1$ cp ~/.vnc/xstartup ~/.vnc/xstartup.old$ nano ~/.vnc/xstartup 참조https://wiki.archlinux.org/index.php/fsck","link":"/linux-system-cheat-2be979083953/"},{"title":"Linux - X Forwarding","text":"SBC 보드 (raspberry pi, odroid c2 등)를 Terminal 기반으로 사용하려고 할 때 GUI에서 Programming을 확인해야 할 경우 X11, VNC 등을 이용할 수 있다. 여기서는 X Forwarding 기법을 정리하고 있다. [^1]: Single Board Computer X11 ForwardingX11은 유닉스/리눅스의 전통적 데스크탑 프로토콜로 GUI 데스크탑 환경을 X11 Protocol을 사용해서 로컬 혹은 원격지 컴퓨터에서 이용할 수 있게 설계되어 있다. X Windows: X ming윈도우즈에서 X ming 환경을 구축하면 X window system을 사용할 수 있다. X client: MobaXterm윈도우 플랫폼은 다양한 X window 제품들이 있다. 최근 재미있게 사용해본 것으로 MobaXterm이 있는데, 이 제품은 유료 제품으로 Trial 을 제공하고 있다. 특징적으로 Xserver와 SSH client를 내장하고 있어서 손쉽게 리눅스 제품과 연결해 사용할 수 있다. [그림. MobaXterm 이미지] ssh를 이용해 X server에 접속하는 것 만으로도 X client 동작을 수행하고, 탭으로 구분한 ssh client 관리가 장점이며, sftp 를 이용해 서버측 파일을 브라우징 할 수 있는 장점이 있다. 단, 기업용은 유료이므로 주의가 필요하다. ### macOS/Linux 데스크탑 X Window를 지원하는 리눅스 데스크탑 혹은 맥오에스에서 ssh로 X11 Forwarding 사용할 수 있다. [그림. SSH와 X11 Tunnel 구조] X forwarding을 활성화 해서 ssh를 연결하려면 ssh -X 옵션을 추가해서 접속한다. Mac에서 X11설정Mac OS X는 OX X 10.5 이후 부터 X11을 포함하고 있지 않는다. Apple은 OS X의 X11을 더 개발하고 지원하기 위한 조직적인 노력으로 XQuartz 프로젝트를 만들었습니다. https://support.apple.com/ko-kr/HT201341 http://xquartz.macosforge.org XQuartz 를 설치해서 지원을 받아야 한다. xquartz 사이트에서 다운받아 설치한다. [그림. macOS X: Download Xquartz] 설치후 맥에서 로그아웃후 로그인 하면 X11 관련 설정과 응용프로그램을 XQuartz 기반으로 사용할 수 있다. X11 Forwarding 설정맥에서는 sshd 설정이 /private/etc/ssh/sshd_config 파일에 있다. 여기에 X11 client 요청을 허용하도록 X11Forwarding을 허용해야 한다. 1user@mac~$ sudo vi /private/etc/sshd_config 내용중에서 X11Forwarding를 찾아 다음 같이 허용으로 저장한다 1X11Forwarding yes 마지막으로 Mac에서 외부에서 요청한 X11 연결을 허용해 준다. 12user@mac~$ xhost +access control disabled, clients can connect from any host X11 이용이제 리눅스/맥 클라이언트에서 원격 서버에 -X 옵션을 이용해서 로그인 한다. 1user@mac~$ ssh -X pi@192.168.1.10 이제 원격지에서 X11 응용 프로그램을 실행해 보겠습니다. 다음은 X11 terminal 프로그램을 실행하면 Mac의 화면에 X11 terminal이 실행됩니다. 123pi@raspberrypi ~ $ netsurf-gtk ORpi@raspberrypi ~ $ lxterminal 라즈베리파이의 xterminal 프로그램이 Mac 실행됩니다. [그림. Ssh와 X Forwarding] 만약 다음 에러를 만나면 접속을 종료하고 Mac의 xhost 접속 허용을 다시 해주어야 한다. (lxterminal:20700): Gtk-WARNING **: cannot open display: localhost:10.0 혹은 원격 서버에 로그인 없이 직접 실행할 수 있습니다 12user@mac~$ ssh -X -f pi@192.168.1.205 lxterminalpi@192.168.1.205's password: 기타 X11 Appxterminal 이외의 X11 앱을 사용하려면 다음 패키지를 설치해 준다. 12~ $ sudo apt install libnss3~ $ sudo apt install x11-apps","link":"/2016-02-10-linux-x-forwarding-bb480df32ccc/"},{"title":"Linux - ssh-sshfs","text":"ssh 사용 팁과 sshfs 이용 방법에 대해서 정리한다. ssh터미널에서 ssh를 사용하는데 이용하는 구성과 설정을 정리했다. 비밀키 이용ssh를 사용하는 클라이언트에서 ssh-keygen 으로 비밀키와 공개키를 생성하고, 접속하는 서버 계정 밑에 클라이언트 공개키를 저장하면 ssh 접속시 비밀번호 응답 없이 처리되어 로그인 할 수 있다. 1. ssh 클라이언트클라이언트에서 개인 비밀키를 생성한다. ssh-keygen 명령은 기본적으로 비밀키와 공개키 파일을 사용자 홈디렉토리 ~/.ssh 폴더에, 기본 파일이름 id_rsa.pub, id_rsa.prb 파일로 저장한다. 1(CLIENT)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@localhost&quot; 2. ssh 서버서버에도 클라이언트와 동일하게 ssh-keygen 명령으로 비밀키와 공개키를 생성한다. 1(SERVER)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@server&quot; 서버에 공개키 배포클라이언트에 생성한 공개키 id_rsa.pub 파일을 업로드해서 ./ssh/authorized_keys 파일에 추가해야 한다. 보통 scp 명령으로 복사해서 authorized_keys 파일에 더해주면 된다. 일반적으로 scp 명령으로 복사하고, 서버에 ssh 접속해서 업로드한 공개키 파일을 authorized_keys 파일에 더해준다. 1. 클라이언트에서 복사하기: 1scp ~/.ssh/id_rsa.pub USER_ID@HOST_NAME:~/client.pub ssh로 서버에 로그인한다. 2.서버 authorized_keys 붙여넣기: 12ssh userid@SERVER(SERVER) $ cat client.pub &gt;&gt; .ssh/authorized_keys; rm client.pub 위 2 과정을 아래 명령 한 줄로 복사-&gt;붙여넣기를 동시에 할 수 있다. 클라이언트: 1cat ~/.ssh/id_rsa.pub | ssh &lt;USERNAME&gt;@&lt;IP-ADDRESS&gt; 'cat &gt;&gt; .ssh/authorized_keys' 이제 해당 서버로 로그인해 본다. ssh config 사용하기사용자를 위한 ssh 구성을 하려면 ~.ssh/config 설정 파일을 이용한다. keep alive sessionssh 접속시 옵션을 주어 세션 유지 시간을 지정할 수 있다. ServerAliveInterval 사용접속시 ServerAliveInterval=TICK를 사용하면 TICK초 마다 한번씩 ServerAliveInterval를 보낸다. 옵션을 직접 사용하거나 ~/.ssh/config 설정 파일에 지정해 둘 수 있다. ssh 접속시 -o 옵션으로 지정한다. 1ssh -o ServerAliveInterval=10 192.168.0.1 ~/.ssh/config 이용사용자의 ssh 설정 파일은 ~/.ssh/config 이다. 12345# For all hostsServerAliveInterval 20# For a selection of hostsHost 192.168.0.1 192.168.1.1 ServerAliveInterval 20 시스템 전체에 적용한다면 /etc/ssh_config 에 (혹은 데비안 계열은 /etc/ssh/ssh_config) 지정해도 된다. ## sshfs 원격 호스트에서 작업중인 소스등을 편집하는데 터미널로 접속해 vim, nano 같은 편집 도구를 이용할 수 있지만, 개발 컴퓨터에서 손에 익은 GUI 개발 도구를에서 개발하고 편집해서, 원격 호스트에서 실행하는 방법을 선호해서 sshfs를 이용하고 있다. 보통 Sublime Text, TextMate 등의 에디터에서 파이썬 등의 프로그래밍 코드를을 작성하고 sshfs를 이용해 원격 디렉토리에 저장하는 방법을 사한다. 설치Ubuntu/Debian1$sudo apt install sshfs Mac OS XMac OS X Fuse 설치 http://osxfuse.github.io sshfs 설치후 재시동 필요. Window다음 설치 파일을 받아 설치한다.https://win-sshfs.googlecode.com/files/win-sshfs-0.0.1.5-setup.exe Mac OS X 사용Mac OS X에서는 OSXFuse를 사용해서 사용자 계정에서 sshfs를 이용한다. 그래서 sudo 명령을 사용하지 않는다. 1$ sshfs USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote sudo 명령을 이용해서 마운트할 경우 마운트 포인트를 찾지 못해서 다음 같은 에러가 난다. 12$ lsls: odoomodules: No such file or directory Ubunto/Debian1sudo sshfs USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote 사용후 언마운트는 다음과 같다. 1$sudo umount /Volume/remote 마운트 고정: Mac OS Xhttps://amaral.northwestern.edu/resources/guides/mounting-remote-folder-os-x-over-ssh 파일 /etc/fstab 1sshfs#USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote DS_Store 파일OS X는 파일을 다룰 때 .DS_Store 파일로 폴더를 지저분하게 한다. 이것을 비활성화 할 수 있다.마운트할 때 noappledouble 옵션을 사용한다. 12$ mkdir ~/example$ sshfs user@host:/example ~/example -oauto_cache,reconnect,defer_permissions,negative_vncache,noappledouble,volname=Example Mounting an OSX SSH Volume using FUSE and SSHFS ssh authentication1sudo sshfs -o IdentityFile=~/.ssh/id_rsa USER_ID@xxx.xxx.xxx.xxx:/ /Volume/remote 자주사용하는 sshfs 명령12$ mkdir ~/example$ sshfs user@host:/example ~/example -oauto_cache,reconnect,defer_permissions,negative_vncache,noappledouble,volname=Example sshfs optionssshfs 구현마다 조금 다르지만 https://linux.die.net/man/1/sshfs 에서 옵션 내용을 조금 살펴보자: -o reconnect : reconnect to server -o delay_connect : delay connection to server o sshfs_sync: synchronous writes -o no_readahead: synchronous reads (no speculative readahead) -o sshfs_debug: print some debugging information -o cache=BOOL: enable caching {yes,no} (default: yes) -o cache_timeout=N: sets timeout for caches in seconds (default: 20) -o cache_X_timeout=N: sets timeout for {stat,dir,link} cache -o workaround=LIST: colon separated list of workarounds none: no workarounds enabled all: all workarounds enabled cache느린 네트워크에서는 캐시를 끄고 사용하는게 좋겠다. -o cache=YESNO: enable caching {yes,no} (default: yes) -o cache_timeout=N : sets timeout for caches in seconds (default: 20) -o cache_X_timeout=N : sets timeout for {stat,dir,link} cache 보증된 네트워크에서 암호화 없이 mount sshd 가 암호화를 지원하는 상황에서 안된다. 안전한 네트워크에서는 Ciphers, Compression 옵션을 사용 ^Blazingly fast sshfs 하면 빠른 속도를 얻을 수 있다. 1sshfs -o Ciphers=arcfour -o Compression=no server://some/folder /mnt/some_local_folder Ciphers=arcfour : 빠른 암호화 메서드, 다만 안전하지 않다. Compression : ssh 내장 압축 사용하지 않는다. rsync 에도 사용할 수 있다. 1rsync -e&quot;ssh -c arcfour -o Compression=no&quot; ...rest of rsync cmd... TCP OptimizationMTU(Maximum Transmission Unit)네트워크 인터페이스에서 세그먼트 없이 보낼수 있는 최대 데이터그램 크기 값입니다. 만약 데이터가 MTU 값 이상이라면 여러개의 패킷으로 분할이 될 것입니다. 간단하게 보자면 MTU 는 패킷이 한번에 보낼 수 있는 최대 크기라고 볼 수 있습니다. 이더넷의 MTU 값은 일반적으로 1500 바이트이며 옛날에 모뎀을 통해 접속하던 PPPoE 연결은 1492 바이트를 가지고 있습니다. MTU 는 각 패킷 프레임안에 최대 전송할 수 있는 값 MSS(Maximum segment size) 가 정의되어 있습니다. 그렇다면 MTU는 MSS + TCP/IP 헤더 크기가 될 것이고 반대로 MSS 는 MTU - 40 바이트가 됩니다. 40 바이트는 IP 와 TCP 헤더 20 바이트씩을 뜻합니다. Linux리눅스에서 MTU 값은 ifconfig 명령으로 확인할 수 있다. 123456789$ ifconfig eth0eth0 Link encap:Ethernet HWaddr b8:27:eb:c8:5f:4b inet addr:220.121.140.239 Bcast:220.121.140.255 Mask:255.255.255.0 inet6 addr: fe80::ba27:ebff:fec8:5f4b/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1633606 errors:0 dropped:44758 overruns:0 frame:0 TX packets:73808 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:85875027 (81.8 MiB) TX bytes:22615535 (21.5 MiB) 기본 MTU가 1500인데 이 값을 조정하려면 sudo ifconfig 명령으로 할 수 있다. 1$ sudo ifconfig eth0 mtu 9000 재시동 후에도 지속적으로 MTU 값을 유지하고 싶으면 /etc/network/interfaces 에 명시하면 된다. 12345auto eth0iface eth0 inet static address 192.168.0.2 netmask 255.255.255.0 mtu 9000 링크MTU SSHFS-MUXhttp://www.linux-magazine.com/Issues/2014/165/SSHFS-MUX Error에러 mount_osxfuse: the file system is not available (255) There appears to be a problem loading the KEXT installed by the regular osxfuse Homebrew package. You can use brew cask to install the official FUSE for OS X build from their own DMG: 123brew rm osxfusebrew install caskroom/cask/brew-caskbrew cask install osxfuse 참조 SSHFS – Installation and Performance SSHFS-MUX Protocol Not Supported Error Mac OS X sshfs Mounting an OSX SSH Volume using FUSE and SSHFS","link":"/ssh-sshfs-3916cf1ca544/"},{"title":"ssh 관련 사용 옵션","text":"SSH UsagesSsh timeoutssh를 사용시 접속 시간이 지나면 자동 끎김을 막아주는 옵션들이 있다. 운영하는 서버는 보안상 alive 메시지를 모두 막아 두었다.다만, ssh 접속시 ServerAliveInterval 을 사용해서 클라이언트가 alive 메시지를 서버에 있다. sshdsshd 데몬은 클라이언트 접속후 sshd_config에 구성한 설정데로 alive 메시지를 클라이언트에 주고 받아 접속 시간을 연장할 수 있다. 아래 그림 [^1] 1234567891011# alive 메시지 사용 결정#TCPKeepAlive yes # 기본 yes.# 클라이언트가 살아있는지 확인하는 간격.ClientAliveInterval 60 # 기본 0.# 클라이언트에서 응답이 없을 때 메시지를 보내는 횟수ClientAliveCountMax 3 # 확인 횟수# Login Prompt에서 사용자 입력을 기다리는 시간을 초 단위로 입력.LoginGraceTime 20 #( 1m: 기본 1분지정, 0은 시간제한없음) ssh 옵션ssh 사용시 /etc/ssh/ssh_config 구성 파일에 있는 ServerAliveInterval 옵션을 사용하면 ssh 접속시 alive 메시지를 서버가 클라이인트에게 주어진 시간 간격으로 보낸다. [그림. ServerAliveInterval] ssh_config 파일에 구성하거나 ssh 사용시 -o ServerAliveInterval 옵션을 사용하는 방법 두 가지가 있다. ssh -oServerAliveInterval option every time you’re connecting to a server by using the -o ServerAliveInterval= prefix as the following example; 1ssh -o ServerAliveInterval=300 user@example.com key파일 사용키파일 이용 키파일을 원하는 위치에 복사하고 퍼미션을 400으로 조정합니다. (저는 ~/Desktop/key/로 정했습니다.) 1$ chmod 400 ~/Desktop/key/keyfile.pem 터미널에서 키파일 옵션을 추가한 명령으로 ssh 접속 1$ ssh -i ~/Desktop/key/keyfile.pem ec2-user@[서버 아이피 또는 도메인] 포트가 다르다면 1$ ssh -i ~/Docments/cloud-server.pem root@220.11.11.173 -p 8888 서버 키 생성 서버에도 클라이언트와 동일하게 ssh-keygen 명령으로 비밀키와 공개키를 생성한다. 1(SERVER)$ ssh-keygen -t rsa -b 4096 -C &quot;USER@server&quot; scp -i /Documents/ncloud-key/qkbooo-ncloud.pem ~/.ssh/id_rsa.pub root@210.89.190.173:/ -p 2525 12ssh userid@SERVER(SERVER) $ cat client.pub &gt;&gt; .ssh/authorized_keys; rm client.pub 포트변경 사용rsync 포트 사용rsync에서 다른 ssh 포트를 사용하고 있을 경우 아래와 같이 옵션을 붙여준다. 1$ rsync -e 'ssh -p 0000' 혹은 1rsnyc --rsh'=ssh -p0000' 참조 sshd_config ssh_config [^1]: How to keep your ssh connection","link":"/ssh-usages-00fede663686/"},{"title":"Build ffmpeg - macOS","text":"Mac OS X 에서 ffmpeg 빌드Android OS에 사용할 ffmpeg를 macOS에서 크로스컴파일러로 빌드해서 포팅하는 과정을 담고 있다.필요한 것은 homebrew xcode command line Android NDK stanalone toolchain 준비할 것Homebrew 를 이용한 빌드를 위해서 xcode와 homebrew 설치가 필요하다. Homebrew 설치 http://goo.gl/Uu7p8 Xcode command line tool이 필요하다. Xcode 최신버전들은 Command line tool을 수동으로 설치해야 한다. Xcode를 실행하여 ‘Preferences &gt; Downloads &gt; Command Line Tools’ 항목을 설치 homebrew 설치1ruby &lt;(curl -fsSkL raw.github.com/mxcl/homebrew/go) 그리고 homebrew doctor 명령을 실행해 설치 환경과 내용이 이상 없는지 확인한다. 1homebrew doctor update로 포뮬라들을 최신으로 갱신해 준다. 1brew update homebrew에서 설치하는 개체를 Ruby script로 패키지에 대해 선언한 명세서를 Formula라고 하고 install 명령에 의해 /usr/local/Library/Formula 에 설치한다. homebrew에서 패키지를 하나 설치한다. 1$ brew install wget 그리고 패키지의 업그레이드, 제거는 다음과 같다. 12brew upgrade [foo]brew uninstall [foo] 의존성 패키지 설치ffmpeg 에 필요한 의존선 패키지를 설치한다. 1234brew install automake celt faac fdk-aac git \\lame libass libtool libvorbis libvpx libvo-aacenc \\opencore-amr openjpeg opus sdl schroedinger shtool \\speex texi2html theora wget x264 xvid yasm Install libaacplus (atm. there is no recipe for it) 컴파일 환경에 대해 [^1]를 참조했다. http://tipok.org.ua/node/17 123wget http://217.20.164.161/~tipok/aacplus/libaacplus-2.0.2.tar.gztar xzf libaacplus-2.0.2.tar.gzcd libaacplus-2.0.2 libtool on osx is quite different from the gnu libtool, which is called glibtool on osx 1234567cat autogen.sh | sed 's/libtool/glibtool/' &gt; autogen2.shsed -i '.bck' -e 's/libtool/glibtool/' autogen.sh./autogen.shmake &amp;&amp; make installcd .. Standalone toolchainhttp://goo.gl/P20dD Standalone toolchain은 Android NDK 최근 버전부터 추가된 기능입니다. 이걸 사용하면 ndk-build 명령을 쓰지 않고 기존의 configure -&gt; make를 사용하던 컴파일 과정을 그대로 사용해서 라이브러리를 컴파일 할 수 있습니다. ndk를 통해서 toolchain을 빌드한다. 자세한 사항은 STANDALONE-TOOLCHAIN 참조한다. 1234$ {NDK}/build/tools/make-standalone-toolchain.sh \\--platform=android-8 \\–install-dir=/MYDEV/android=9-toolchain$ export PATH=/MYDEV/android=9-toolchain/bin:$PATH 샘플 코드 컴파일 방법test.cpp 가 있다고 가정하고 1$ arm-linux-androideabi-g++ -o test_arm test.cpp Makefile 을 다음과 같이 만든다. 12345678910ARM_COMPILE = arm-linux-androideabi-CC = g++ARM_CC = $(ARM_COMPILE)g++ARM_INCLUDES = -I /MYDEV/android=9-toolchain/sysroot/usr/includeCFLAGS = -O2 -Wall -D_LINUX -fno-strict-aliasing -D_COLOR_LOGBINS = testarm: $(ARM_CC) $(CFLAGS) -o test_arm test.cpp $(ARM_INCLUDES) ffmpeg buildstandalone toolchain을 사용한다. ffmpeg configuration 1export ANDROID_ROOT=/cygdrive/c/my-android-toolchain 1234567891011121314151617ANDROID_ROOT=/home/qkboo/my-android-toolchain \\./configure --target-os=linux \\--arch=arm \\--enable-cross-compile \\--cc=$ANDROID_ROOT/bin/arm-linux-androideabi-gcc \\--cross-prefix=$ANDROID_ROOT/bin/arm-linux-androideabi- \\--extra-cflags=&quot;-marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon&quot; \\--extra-ldflags=&quot;-Wl,--fix-cortex-a8&quot; \\--disable-doc \\--disable-ffmpeg \\--disable-ffplay \\--disable-ffprobe \\--disable-ffserver \\--disable-avdevice \\--disable-network \\--disable-devices \\--disable-filters 맨 첫 줄의 ANDROID_ROOT 값은 자신이 standalone toolchain을 설치한 폴더로 수정합니다. 참고로 “–arch=arm”과 “–enable-cross-compile”: arm CPU 용으로 cross compile 하겠다는 옵션입니다. “–cc”나 “–cross-prefix”: cross compile 할 때 사용할 compiler에 관한 정보를 줍니다. “–extra-cflags”나 “–extra-ldflags”는 neon 사용할 때 쓰는 옵션입니다. (c:/android-ndk-r5b/docs/STANDALONE-TOOLCHAIN.html 참조) 나머지는 ffmpeg에서 이러이러한 기능은 빼고 컴파일 하겠다는 뜻입니다. 예를들어 network 이런 기능은 필요없겠지요? 생성된 config.h 파일을 열어봅니다. 1234567891011#define ARCH_ARM 1#define HAVE_ARMV5TE 1#define HAVE_ARMV6 1#define HAVE_ARMV6T2 1#define HAVE_ARMVFP 1#define HAVE_NEON 1 위와 같은 설정들이 잘 되어 있음을 확인할 수 있으실 겁니다. config.h 파일에서 #define restrict restrict 부분을 찾아 다음과 같이 바꾼다. 1#define restrict X264 컴파일http://bongjaemoon.wordpress.com/2012/05/25/ffmpeg-x264-compile-for-using-with-android-ndk-on-mac-osx/ Application.mk 작성g:/Root/FFmpegBasic/jni 폴더에 Application.mk 파일을 만듭니다.내용은 간단히 아래와 같이 한 줄만 작성합니다. APP_ABI := armeabi-v7a 참고:arm architecture ARMv7-A 이상을 타겟으로 컴파일 하겠다는 옵션입니다.arm CoretexA8 이상의 core가 이에 해당됩니다.앞서 말씀드린대로 arm11 코어를 사용한 Optimus One, Galaxy Neo 같은 폰에서는 안 돌아가겠지요. Android.mk 작성 http://www.viper.pe.kr/docs/make-ko/make-ko_toc.html (한글)http://sunsite.ualberta.ca/Documentation/Gnu/make-3.79/html_chapter/make_toc.html (영문) Android.mk 는 폴더마다 여러개를 작성해야 합니다.공통으로 사용할 common.mk 파일을 먼저 작성한 후, 각각 폴더마다 설명하겠습니다. common.mk g:/Root/FFmpegBasic/jni/ffmpeg 폴더에 common.mk 파일을 만듭니다.모든 Android.mk에서 공통으로 include 해서 사용할 파일입니다. common.mk에서는 크게 두가지 일을 할 것입니다.1) 공통으로 사용할 컴파일 옵션을 정의합니다.2) configure를 통해 생성된 파일에서 컴파일 할 소스 파일 이름들을 읽어 저장합니다. 컴파일 옵션은 다음과 같이 한 줄이면 됩니다. 1.COMMON_CFLAGS := -DHAVE_AV_CONFIG_H -D_ISOC99_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_POSIX_C_SOURCE=200112 -D_XOPEN_SOURCE=600 -DPIC -std=c99 -fomit-frame-pointer -fPIC -fno-math-errno -fno-signed-zeros -fno-tree-vectorize참고:컴파일 옵션이 복잡해 보이지만 그냥 configure에서 생성된 컴파일 옵션을 그대로 정리해 준 것 뿐입니다. ffmpeg 폴더의 common.mak 파일을 열어보시면아래와 같은 부분이 있습니다.1.%.o: %.c 2.$(CCDEP)3.$(CC) $(CPPFLAGS) $(CFLAGS) $(CC_DEPFLAGS) -c $(CC_O) $&lt;FFmpeg 컴파일 할 때, $(CPPFLAGS) $(CFLAGS) $(CC_DEPFLAGS) 이 세 개의 매크로에 정의된 옵션들을 사용하는 것을 알 수 있습니다. ffmpeg 폴더의 config.mak 파일을 열어보시면 이 값들이 정의되어 있습니다. CPPFLAGS는 아래와 같습니다.1.CPPFLAGS= -D_ISOC99_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_POSIX_C_SOURCE=200112 -D_XOPEN_SOURCE=600 -DPIC이 값들은 다 사용해 줍니다. CFLAGS는 엄청 깁니다.1.CFLAGS= -marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon -std=c99 -fomit-frame-pointer -fPIC -marm -g -Wdeclaration-after-statement -Wall -Wno-parentheses -Wno-switch -Wdisabled-optimization -Wpointer-arith -Wredundant-decls -Wno-pointer-sign -Wcast-qual -Wwrite-strings -Wtype-limits -Wundef -Wmissing-prototypes -Wno-pointer-to-int-cast -O3 -fno-math-errno -fno-signed-zeros -fno-tree-vectorize -Werror=implicit-function-declaration -Werror=missing-prototypes복잡해 보이지만 하나씩 차근히 보면 정리가 됩니다.여기서 -marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon -g -O3 옵션들은 다 뺍니다.우리는 Android ndk-build를 사용할 것이기 때문에 -O3 같은 최적화 관련 옵션은 지정하지 않습니다.(이것은 android build system이 알아서 해줍니다)-marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon 이와 같은 cross compile관련, neon 관련 옵션도 빼줍니다.(이것은 나중에 Android.mk의 옵션으로 지정해 줄 것입니다)마지막으로 -W 로 시작하는 옵션은 warning 관련 옵션이니 그냥 다 뺍니다. CC_DEPFLAGS는 별 것 없고 상관없는 값들입니다. 무시합니다. 추가로 subdir.mak 파일을 보시면 아래와 같은 부분이 있습니다. 1.$(OBJS) $(SUBDIR)%.ho $(SUBDIR)%-test.o $(TESTOBJS): CPPFLAGS += -DHAVE_AV_CONFIG_H$(OBJS) 에 정의된 모든 파일에 위 조건이 해당되므로 -DHAVE_AV_CONFIG_H 도 포함합니다. 이렇게 정리하면 위에서 한 줄로 정리한 COMMON_CFLAGS 컴파일 옵션들이 나옵니다. 컴파일 할 소스 파일들을 정의 이 부분은 소스가 좀 길고 복잡하게 느껴질 수 있습니다. 하지만 역시 핵심은 간단합니다. 먼저 FFmpeg의 Makefile을 하나만 분석해 보겠습니다.ffmpeg 폴더의 common.mak 파일을 열어보면 아래와 같은 부분이 있습니다.1.OBJS += $(OBJS-yes)컴파일에 사용할 소스 파일은 OBJS 매크로와 OBJS-yes 매크로에 정의되어 있다는 것을 알 수 있습니다.우리도 이 소스들을 컴파일 하면 되므로 똑같이 적어줍니다. 이제 OBJS 매크로에는 xxxxx.o 와 같은 object 파일들이 쭉 저장되게 됩니다.이걸 그냥 간단히 전부 xxxxx.c로 변환해서 쓰면 가장 쉽겠지만 그렇게 간단하지는 않습니다.우선 c 파일 외에도 xxxxx.S 와 같은 어셈블리 코드들이 포함되어 있고,neon 컴파일 해야하는 소스들은 xxxxx.c.neon 또는 xxxxx.S.neon 과 같이 neon 접미사를 붙여줘야 하기 때문입니다. 다행인 것은, FFmpeg 소스들을 보면 neon 컴파일 해야 하는 소스들은 모두_neon.c 와 같이 _neon 접미사가 붙어 있어서 이것으로 구분이 가능합니다.(ffmpeg/libavcodec/arm 폴더의 파일들을 훑어 보시기 바랍니다)따라서 _neon 접미사를 검색해서 해당 접미사가 있는 소스에만 .neon을 마지막에 추가해 주면 됩니다. 위와 같은 과정을 수동으로 일일이 진행하셔도 좋지만 번거로우니 Makefile 문법을 사용해 작성해 주면 됩니다.최종적으로 컴파일 할 소스 파일들은 각각 다음 매크로에 저장할 것입니다. C_FILES: 컴파일 할 c 파일S_FILES: 컴파일 할 S 파일NEON_C_FILES: neon 컴파일 할 c 파일NEON_S_FILES: neon 컴파일 할 S 파일FFFILES: 컴파일 할 모든 소스 파일 전부 정의 이제까지 설명한 것을 종합해서 common.mk의 전체 소스를 보여드리면 아래와 같습니다.common.mk 파일을 다음과 같이 작성해줍니다. 01.COMMON_CFLAGS := -DHAVE_AV_CONFIG_H -D_ISOC99_SOURCE -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -D_POSIX_C_SOURCE=200112 -D_XOPEN_SOURCE=600 -DPIC -std=c99 -fomit-frame-pointer -fPIC -fno-math-errno -fno-signed-zeros -fno-tree-vectorize02. 03.OBJS += $(OBJS-yes)04. 05.ALL_S_FILES := $(wildcard $(LOCAL_PATH)/$(ARCH)/.S)06.ALL_S_FILES := $(addprefix $(ARCH)/,$(notdir $(ALL_S_FILES)))07. 08.NEON_S_FILES := $(wildcard $(LOCAL_PATH)/$(ARCH)/_neon.S)09.NEON_S_FILES := $(addprefix $(ARCH)/,$(notdir $(NEON_S_FILES)))10. 11.NEON_C_FILES := $(wildcard $(LOCAL_PATH)/$(ARCH)/*_neon.c)12.NEON_C_FILES := $(addprefix $(ARCH)/,$(notdir $(NEON_C_FILES)))13. 14.S_FILES := $(filter-out $(NEON_S_FILES),$(ALL_S_FILES))15. 16.C_OBJS := $(OBJS)17.ifneq ($(S_FILES),)18.S_OBJS := $(S_FILES:.S=.o)19.S_OBJS := $(filter $(S_OBJS),$(C_OBJS))20.C_OBJS := $(filter-out $(S_OBJS),$(C_OBJS))21.else22.S_OBJS :=23.endif24. 25.ifneq ($(NEON_S_FILES),)26.NEON_S_OBJS := $(NEON_S_FILES:.S=.o)27.NEON_S_OBJS := $(filter $(NEON_S_OBJS),$(C_OBJS))28.C_OBJS := $(filter-out $(NEON_S_OBJS),$(C_OBJS))29.else30.NEON_S_OBJS :=31.endif32. 33.ifneq ($(NEON_C_FILES),)34.NEON_C_OBJS := $(NEON_C_FILES:.c=.o)35.NEON_C_OBJS := $(filter $(NEON_C_OBJS),$(C_OBJS))36.C_OBJS := $(filter-out $(NEON_C_OBJS),$(C_OBJS))37.else38.NEON_C_OBJS :=39.endif40. 41.C_FILES := $(C_OBJS:.o=.c)42.S_FILES := $(S_OBJS:.o=.S)43.NEON_C_FILES := $(NEON_C_OBJS:.o=.c.neon)44.NEON_S_FILES := $(NEON_S_OBJS:.o=.S.neon)45. 46.FFFILES := $(sort $(NEON_S_FILES)) $(sort $(NEON_C_FILES)) $(sort $(S_FILES)) $(sort $(C_FILES)) 참고:OBJS 와 OBJS-yes 매크로가 어떻게 생성되는지 보겠습니다. ffmpeg/libavcodec 폴더의 Makefile을 열어 봅니다.1.OBJS = allcodecs.o 2.audioconvert.o 3.avpacket.o 4.bitstream.o 5.bitstream_filter.o 6.dsputil.o 위와 같은 소스를 볼 수 있습니다.이는 다시 말하면 allcodecs.c, audioconvert.c … 와 같은 소스들은 컴파일 옵션과 상관없이 무조건 컴파일 하겠다는 뜻입니다. 다음으로 아래와 같은 코드들이 이어집니다.1.OBJS-$(CONFIG_AANDCT) += aandcttab.o2.OBJS-$(CONFIG_AC3DSP) += ac3dsp.o3.OBJS-$(CONFIG_CRYSTALHD) += crystalhd.offmpeg 폴더의 config.mak 파일을 열어서 CONFIG_AANDCT, CONFIG_CRYSTALHD 등을 찾아 보시면 이게 어떻게 돌아가는지 알 수 있습니다.config.mak 파일을 열어 보면 아래와 같이 되어 있습니다.1.CONFIG_AANDCT=yes2.!CONFIG_CRYSTALHD=yes즉, “OBJS-$(CONFIG_AANDCT)”는 “OBJS-yes”로 변환되어 aandcttab.c 는 컴파일할 것이고,”OBJS-$(CONFIG_CRYSTALHD)”는 그렇지 않으니 crystalhd.c 는 컴파일 하지 않을 것 입니다. 이런 방법은 거의 모든 open source library에서 사용하고 있는 표준적인 방법이니 익숙해지는 것이 좋습니다. 참조[^1]: Compiling ffmeg on macOS ffmpeg on Mac","link":"/ffmpeg-build-macos-288c84d81d85/"}],"tags":[{"name":"WSL2","slug":"WSL2","link":"/tags/WSL2/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"grub","slug":"grub","link":"/tags/grub/"},{"name":"exfat","slug":"exfat","link":"/tags/exfat/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"pip","slug":"pip","link":"/tags/pip/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"CUDA","slug":"CUDA","link":"/tags/CUDA/"},{"name":"NVIDIA","slug":"NVIDIA","link":"/tags/NVIDIA/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"macos","slug":"macos","link":"/tags/macos/"},{"name":"machinelearning","slug":"machinelearning","link":"/tags/machinelearning/"},{"name":"초거대AI","slug":"초거대AI","link":"/tags/%EC%B4%88%EA%B1%B0%EB%8C%80AI/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"Coco","slug":"Coco","link":"/tags/Coco/"},{"name":"Open image","slug":"Open-image","link":"/tags/Open-image/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","link":"/tags/Semantic-Segmentation/"},{"name":"kitti","slug":"kitti","link":"/tags/kitti/"},{"name":"godel","slug":"godel","link":"/tags/godel/"},{"name":"foundation model","slug":"foundation-model","link":"/tags/foundation-model/"},{"name":"Synthetic data","slug":"Synthetic-data","link":"/tags/Synthetic-data/"},{"name":"mongodb","slug":"mongodb","link":"/tags/mongodb/"},{"name":"armbian","slug":"armbian","link":"/tags/armbian/"},{"name":"odroid-c2","slug":"odroid-c2","link":"/tags/odroid-c2/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"debian","slug":"debian","link":"/tags/debian/"},{"name":"arm64","slug":"arm64","link":"/tags/arm64/"},{"name":"amd64","slug":"amd64","link":"/tags/amd64/"},{"name":"우분투","slug":"우분투","link":"/tags/%EC%9A%B0%EB%B6%84%ED%88%AC/"},{"name":"데비안","slug":"데비안","link":"/tags/%EB%8D%B0%EB%B9%84%EC%95%88/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"content","slug":"content","link":"/tags/content/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"formatting","slug":"formatting","link":"/tags/formatting/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"markup","slug":"markup","link":"/tags/markup/"},{"name":"R","slug":"R","link":"/tags/R/"},{"name":"R Studio","slug":"R-Studio","link":"/tags/R-Studio/"},{"name":"Bigdata","slug":"Bigdata","link":"/tags/Bigdata/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Springboot","slug":"Springboot","link":"/tags/Springboot/"},{"name":"nodejs","slug":"nodejs","link":"/tags/nodejs/"},{"name":"angularjs","slug":"angularjs","link":"/tags/angularjs/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"Coordinate System","slug":"Coordinate-System","link":"/tags/Coordinate-System/"},{"name":"Cartesian Coordinate","slug":"Cartesian-Coordinate","link":"/tags/Cartesian-Coordinate/"},{"name":"Polar Coordinate","slug":"Polar-Coordinate","link":"/tags/Polar-Coordinate/"},{"name":"cross compiler","slug":"cross-compiler","link":"/tags/cross-compiler/"},{"name":"ffmpeg","slug":"ffmpeg","link":"/tags/ffmpeg/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"HTTPS","slug":"HTTPS","link":"/tags/HTTPS/"},{"name":"Open API","slug":"Open-API","link":"/tags/Open-API/"},{"name":"NodeJS","slug":"NodeJS","link":"/tags/NodeJS/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"anaconda","slug":"anaconda","link":"/tags/anaconda/"},{"name":"virtualenv","slug":"virtualenv","link":"/tags/virtualenv/"},{"name":"Data science","slug":"Data-science","link":"/tags/Data-science/"},{"name":"jekyll","slug":"jekyll","link":"/tags/jekyll/"},{"name":"installation","slug":"installation","link":"/tags/installation/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"install","slug":"install","link":"/tags/install/"},{"name":"bootstrap 4","slug":"bootstrap-4","link":"/tags/bootstrap-4/"},{"name":"brew","slug":"brew","link":"/tags/brew/"},{"name":"맥오에스","slug":"맥오에스","link":"/tags/%EB%A7%A5%EC%98%A4%EC%97%90%EC%8A%A4/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"마크다운","slug":"마크다운","link":"/tags/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"odroid","slug":"odroid","link":"/tags/odroid/"},{"name":"raspberry pi","slug":"raspberry-pi","link":"/tags/raspberry-pi/"},{"name":"라즈베리파이","slug":"라즈베리파이","link":"/tags/%EB%9D%BC%EC%A6%88%EB%B2%A0%EB%A6%AC%ED%8C%8C%EC%9D%B4/"},{"name":"orange pi","slug":"orange-pi","link":"/tags/orange-pi/"},{"name":"오렌지파이","slug":"오렌지파이","link":"/tags/%EC%98%A4%EB%A0%8C%EC%A7%80%ED%8C%8C%EC%9D%B4/"},{"name":"banana pi","slug":"banana-pi","link":"/tags/banana-pi/"},{"name":"바나나파이","slug":"바나나파이","link":"/tags/%EB%B0%94%EB%82%98%EB%82%98%ED%8C%8C%EC%9D%B4/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"X11","slug":"X11","link":"/tags/X11/"},{"name":"Debian","slug":"Debian","link":"/tags/Debian/"},{"name":"Debian Strech","slug":"Debian-Strech","link":"/tags/Debian-Strech/"},{"name":"lvm","slug":"lvm","link":"/tags/lvm/"},{"name":"lvm2","slug":"lvm2","link":"/tags/lvm2/"},{"name":"Odroid","slug":"Odroid","link":"/tags/Odroid/"},{"name":"firewall","slug":"firewall","link":"/tags/firewall/"},{"name":"security","slug":"security","link":"/tags/security/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"webdav","slug":"webdav","link":"/tags/webdav/"},{"name":"리눅스","slug":"리눅스","link":"/tags/%EB%A6%AC%EB%88%85%EC%8A%A4/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/tags/Raspberry-Pi/"},{"name":"Orange Pi","slug":"Orange-Pi","link":"/tags/Orange-Pi/"},{"name":"ARM","slug":"ARM","link":"/tags/ARM/"},{"name":"tmux","slug":"tmux","link":"/tags/tmux/"},{"name":"terminal","slug":"terminal","link":"/tags/terminal/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"apache","slug":"apache","link":"/tags/apache/"},{"name":"google drive","slug":"google-drive","link":"/tags/google-drive/"},{"name":"onedrive for linux","slug":"onedrive-for-linux","link":"/tags/onedrive-for-linux/"},{"name":"Odroid c2","slug":"Odroid-c2","link":"/tags/Odroid-c2/"},{"name":"find","slug":"find","link":"/tags/find/"},{"name":"compiler","slug":"compiler","link":"/tags/compiler/"},{"name":"sshfs","slug":"sshfs","link":"/tags/sshfs/"},{"name":"nodejs tutorials","slug":"nodejs-tutorials","link":"/tags/nodejs-tutorials/"},{"name":"nvm","slug":"nvm","link":"/tags/nvm/"},{"name":"TypeScript Tutorials","slug":"TypeScript-Tutorials","link":"/tags/TypeScript-Tutorials/"},{"name":"TypeScript","slug":"TypeScript","link":"/tags/TypeScript/"},{"name":"angular4","slug":"angular4","link":"/tags/angular4/"},{"name":"웹토큰","slug":"웹토큰","link":"/tags/%EC%9B%B9%ED%86%A0%ED%81%B0/"},{"name":"JWT Toekn","slug":"JWT-Toekn","link":"/tags/JWT-Toekn/"},{"name":"JSON Web Token","slug":"JSON-Web-Token","link":"/tags/JSON-Web-Token/"},{"name":"npm","slug":"npm","link":"/tags/npm/"},{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"gulp","slug":"gulp","link":"/tags/gulp/"},{"name":"bower","slug":"bower","link":"/tags/bower/"},{"name":"webpack","slug":"webpack","link":"/tags/webpack/"},{"name":"express","slug":"express","link":"/tags/express/"},{"name":"server","slug":"server","link":"/tags/server/"},{"name":"nodemon","slug":"nodemon","link":"/tags/nodemon/"},{"name":"pm2","slug":"pm2","link":"/tags/pm2/"},{"name":"yarn","slug":"yarn","link":"/tags/yarn/"},{"name":"photoshop","slug":"photoshop","link":"/tags/photoshop/"},{"name":"clipping-mask","slug":"clipping-mask","link":"/tags/clipping-mask/"},{"name":"collages","slug":"collages","link":"/tags/collages/"},{"name":"miniconda","slug":"miniconda","link":"/tags/miniconda/"},{"name":"pyenv","slug":"pyenv","link":"/tags/pyenv/"},{"name":"HTS","slug":"HTS","link":"/tags/HTS/"},{"name":"주식","slug":"주식","link":"/tags/%EC%A3%BC%EC%8B%9D/"},{"name":"virtualenvwrapper","slug":"virtualenvwrapper","link":"/tags/virtualenvwrapper/"},{"name":"powershell","slug":"powershell","link":"/tags/powershell/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"Anaconda","slug":"Anaconda","link":"/tags/Anaconda/"},{"name":"pyenv-windows","slug":"pyenv-windows","link":"/tags/pyenv-windows/"},{"name":"venv","slug":"venv","link":"/tags/venv/"},{"name":"conda","slug":"conda","link":"/tags/conda/"},{"name":"Raspbian","slug":"Raspbian","link":"/tags/Raspbian/"},{"name":"라즈비안","slug":"라즈비안","link":"/tags/%EB%9D%BC%EC%A6%88%EB%B9%84%EC%95%88/"},{"name":"Raspberry Pi 3","slug":"Raspberry-Pi-3","link":"/tags/Raspberry-Pi-3/"},{"name":"openSUSE","slug":"openSUSE","link":"/tags/openSUSE/"},{"name":"LEAP 15.0","slug":"LEAP-15-0","link":"/tags/LEAP-15-0/"},{"name":"LEAP 42.3","slug":"LEAP-42-3","link":"/tags/LEAP-42-3/"},{"name":"Installation","slug":"Installation","link":"/tags/Installation/"},{"name":"Pi Camera","slug":"Pi-Camera","link":"/tags/Pi-Camera/"},{"name":"jupyter notebook","slug":"jupyter-notebook","link":"/tags/jupyter-notebook/"},{"name":"WiFi","slug":"WiFi","link":"/tags/WiFi/"},{"name":"LiFi","slug":"LiFi","link":"/tags/LiFi/"},{"name":"Wireless","slug":"Wireless","link":"/tags/Wireless/"},{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","link":"/tags/Artificial-Intelligence/"},{"name":"인공지능","slug":"인공지능","link":"/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"},{"name":"TensorFlow","slug":"TensorFlow","link":"/tags/TensorFlow/"},{"name":"certificate ssl","slug":"certificate-ssl","link":"/tags/certificate-ssl/"},{"name":"synergy","slug":"synergy","link":"/tags/synergy/"},{"name":"Firewall","slug":"Firewall","link":"/tags/Firewall/"},{"name":"방화벽","slug":"방화벽","link":"/tags/%EB%B0%A9%ED%99%94%EB%B2%BD/"},{"name":"fail2ban","slug":"fail2ban","link":"/tags/fail2ban/"},{"name":"Security","slug":"Security","link":"/tags/Security/"},{"name":"mongoose","slug":"mongoose","link":"/tags/mongoose/"},{"name":"middleware","slug":"middleware","link":"/tags/middleware/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"jupyter","slug":"jupyter","link":"/tags/jupyter/"},{"name":"jupyter-notebook","slug":"jupyter-notebook","link":"/tags/jupyter-notebook/"},{"name":"파이썬","slug":"파이썬","link":"/tags/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"opensuse","slug":"opensuse","link":"/tags/opensuse/"},{"name":"leap 42.3","slug":"leap-42-3","link":"/tags/leap-42-3/"},{"name":"leap 15","slug":"leap-15","link":"/tags/leap-15/"},{"name":"odroid c2","slug":"odroid-c2","link":"/tags/odroid-c2/"},{"name":"Scientific","slug":"Scientific","link":"/tags/Scientific/"},{"name":"Numpy","slug":"Numpy","link":"/tags/Numpy/"},{"name":"opensuse leap 15","slug":"opensuse-leap-15","link":"/tags/opensuse-leap-15/"},{"name":"EEG","slug":"EEG","link":"/tags/EEG/"},{"name":"Armbian","slug":"Armbian","link":"/tags/Armbian/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"firewalld","slug":"firewalld","link":"/tags/firewalld/"},{"name":"파이어월","slug":"파이어월","link":"/tags/%ED%8C%8C%EC%9D%B4%EC%96%B4%EC%9B%94/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"SD Card","slug":"SD-Card","link":"/tags/SD-Card/"},{"name":"micro SD Card","slug":"micro-SD-Card","link":"/tags/micro-SD-Card/"},{"name":"Kotlin","slug":"Kotlin","link":"/tags/Kotlin/"},{"name":"Gradle","slug":"Gradle","link":"/tags/Gradle/"},{"name":"Dependency","slug":"Dependency","link":"/tags/Dependency/"},{"name":"rsync","slug":"rsync","link":"/tags/rsync/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"openssl","slug":"openssl","link":"/tags/openssl/"},{"name":"jupyterlab","slug":"jupyterlab","link":"/tags/jupyterlab/"},{"name":"systemd","slug":"systemd","link":"/tags/systemd/"},{"name":"parted","slug":"parted","link":"/tags/parted/"},{"name":"fdisk","slug":"fdisk","link":"/tags/fdisk/"},{"name":"SDCard","slug":"SDCard","link":"/tags/SDCard/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"증권","slug":"증권","link":"/tags/%EC%A6%9D%EA%B6%8C/"},{"name":"json","slug":"json","link":"/tags/json/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"sed","slug":"sed","link":"/tags/sed/"},{"name":"awk","slug":"awk","link":"/tags/awk/"},{"name":"Hosting","slug":"Hosting","link":"/tags/Hosting/"},{"name":"sensor","slug":"sensor","link":"/tags/sensor/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"ClI","slug":"ClI","link":"/tags/ClI/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"CLI","slug":"CLI","link":"/tags/CLI/"},{"name":"Nodejs","slug":"Nodejs","link":"/tags/Nodejs/"},{"name":"Miniconda","slug":"Miniconda","link":"/tags/Miniconda/"},{"name":"PowerShell","slug":"PowerShell","link":"/tags/PowerShell/"},{"name":"bitbucket","slug":"bitbucket","link":"/tags/bitbucket/"},{"name":"ssh-key","slug":"ssh-key","link":"/tags/ssh-key/"},{"name":"openssh","slug":"openssh","link":"/tags/openssh/"},{"name":"setuptools","slug":"setuptools","link":"/tags/setuptools/"},{"name":"build","slug":"build","link":"/tags/build/"},{"name":"설치","slug":"설치","link":"/tags/%EC%84%A4%EC%B9%98/"},{"name":"PyPi","slug":"PyPi","link":"/tags/PyPi/"},{"name":"pull request","slug":"pull-request","link":"/tags/pull-request/"},{"name":"포트폴리오","slug":"포트폴리오","link":"/tags/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4/"},{"name":"icarus theme","slug":"icarus-theme","link":"/tags/icarus-theme/"},{"name":"UFW","slug":"UFW","link":"/tags/UFW/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"fsck","slug":"fsck","link":"/tags/fsck/"},{"name":"Windows Terminal","slug":"Windows-Terminal","link":"/tags/Windows-Terminal/"},{"name":"Multiprocess","slug":"Multiprocess","link":"/tags/Multiprocess/"},{"name":"TLS","slug":"TLS","link":"/tags/TLS/"},{"name":"SSL","slug":"SSL","link":"/tags/SSL/"},{"name":"mariadb","slug":"mariadb","link":"/tags/mariadb/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"SSH Tunneling","slug":"SSH-Tunneling","link":"/tags/SSH-Tunneling/"},{"name":"bulma","slug":"bulma","link":"/tags/bulma/"}],"categories":[{"name":"OS","slug":"OS","link":"/categories/OS/"},{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"Windows","slug":"OS/Windows","link":"/categories/OS/Windows/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"R","slug":"Programming/R","link":"/categories/Programming/R/"},{"name":"Angularjs","slug":"Programming/Angularjs","link":"/categories/Programming/Angularjs/"},{"name":"C&#x2F;C++","slug":"Programming/C-C","link":"/categories/Programming/C-C/"},{"name":"github","slug":"github","link":"/categories/github/"},{"name":"Nodejs","slug":"Programming/Nodejs","link":"/categories/Programming/Nodejs/"},{"name":"Python","slug":"Programming/Python","link":"/categories/Programming/Python/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/categories/Raspberry-Pi/"},{"name":"IT","slug":"IT","link":"/categories/IT/"},{"name":"Android","slug":"Programming/Android","link":"/categories/Programming/Android/"},{"name":"git","slug":"Programming/git","link":"/categories/Programming/git/"},{"name":"Database","slug":"Programming/Database","link":"/categories/Programming/Database/"},{"name":"Linux","slug":"OS/Linux","link":"/categories/OS/Linux/"},{"name":"ETC","slug":"ETC","link":"/categories/ETC/"}],"pages":[{"title":"About Me","text":"Announce Just re-arranging old blogging articles, 2023-01 I am","link":"/about/index.html"},{"title":"Firebase - Cloud Message","text":"Firebase 에서 Cloud Messaging을 사용해서 앱의 재사용을 촉진하는 과정을 알게된다. Firebase Cloud MessageFCM을 사용해 앱 사용자에게 기능 소개, 동기화 요구 등의 알림 메시지를 전송할 수 있다. 메시지는 4KB 크기 페이로드를 전송할 수 있다. 주요기능 알림 메시지 또는 데이터 메시지 전송 다양한 메시지 타겟팅 클라이언트 앱에서 메시지 전송 이들은 아래 같이 메시지 전송 체계를 제공하고 있다. Cloud Messaging파이어베이스 콘솔에서 Notification을 활성화 시킨다. 왼쪽 메뉴에서 GLOW-&gt;Notification 를 선택하거나, {:width=”500”} 제품 목록에서 Notification 를 선택한다. {:width=”500”} 메시지 작성Cloud Messaging -&gt; Notificatios 화면에서 즉시 발송할 메시지를 작성을 시작한다 {:width=”500”} 메시지 내용을 작성한다. {:width=”500”} 메시지 수신앱이 화면에 실행중이 아니면 Notification Manager로 메시지가 전달되어, 단말의 Notification 에서 확인이 가능하다. {:width=”350”} 참조첫 페이지","link":"/documents/android/2018-04-20-firebase-cloud_message.html"},{"title":"Firebase - Database","text":"Firebase console에서 데이터베이스를 다루는 과정을 살펴본다. Database채팅 메시지를 읽고 보내기 위해 인증을 추가해 보자 실시간 데이터 베이스파이어베이스 실시간 데이터 베이스는 JSON 설정을 구성할 수 있다. 파이어베이스 프로젝트에 들어가 Database 를 선택하고 {:width=”500”} *Realtime Database 탭을 시작해서 {:width=”500”} 규칙을 선언한다. {:width=”500”} 인증후 사용할 수 있도록 아래 같이 구성한다. {:width=”500”} 참조첫 페이지","link":"/documents/android/2018-04-20-firebase-database.html"},{"title":"Firebase - Getting Started","text":"Firebase는 고품질 앱을 개발하는 기본적인 도구를 제공해서 앱 개발에 필요한 기초적인 기능을 쉽게 추가할 수 있기 때문에 앱 개발자는 비즈니스 로직에 더 집중할 수 있게 된다. Firebase앱 개발 및 테스트를 위해 다음 같은 Firebase 제품을 즉시 사용할 수 있다: gmp_database: 실시간 데이터베이스 gmp_firestore: Cloud Firestore gmp_auth: 인증 gmp_storage: Cloud Storage gmp_test_lab: Test Lab gmp_performance: 성능 모니터링 gmp_crashlytics: Crashlytics gmp_crash: 오류 보고 gmp_functions: Cloud 함수 gmp_hosting: 호스팅 앱에 Firebase 기능 추가: 애널리틱스로 사용자 행동을 파악합니다. 인증으로 사용자 인증을 설정합니다. 실시간 데이터베이스로 사용자 정보를 저장하거나 Cloud Storage로 BLOB 데이터를 저장합니다. 클라우드 메시징으로 사용자에게 알림을 보냅니다. 오류 보고로 앱이 다운된 시점과 이유를 조사합니다. Firebase요금제 https://firebase.google.com/pricing/?authuser=1 Android 프로젝트에 Firebase 추가사용 조건: Android 4.0(Ice Cream Sandwich) 이상 및 Google Play 서비스 11.8.0 이상을 실행하는 기기 Android Studio 최신 버전 이런 서비스를 console 에서 프로젝트를 생성하고 프로젝트의 그래들에 SDK를 추가하면 된다. SDK 추가프로젝트 루트 build.gradle 에 google-services 플러그인 과 Google maven 저장소를 추가한다. 12345678910111213buildscript { // ... dependencies { classpath 'com.google.gms:google-services:3.2.0' // google-services plugin }}allprojects { repositories { google() jcenter() }} 앱 모듈의 build.gradle 에 apply plugin 으로 Firebase 제품 플러그인을 활성화 한다. 123456789101112apply plugin: 'com.android.application'android { // ...}dependencies { // ...}// ADD THIS AT THE BOTTOMapply plugin: 'com.google.gms.google-services' 이제 파이어베이스 의존성 라이브러리를 추가하고 사용하면 된다. 파이어베이스 라이브러리다양한 Firebase에서 라이브러리를 사용해서 앱에 필요한 기능을 추가 할 수 있다. com.google.firebase:firebase-core 애널리틱스 com.google.firebase:firebase-database : 실시간 데이터베이스 com.google.firebase:firebase-firestore: Cloud Firestore com.google.firebase:firebase-storage: 저장소 com.google.firebase:firebase-crash: 오류 보고 com.google.firebase:firebase-auth: 인증 com.google.firebase:firebase-messaging: 클라우드 메시징 com.google.firebase:firebase-config: 원격 구성 com.google.firebase:firebase-invites: 초대 및 동적 링크 com.google.firebase:firebase-ads: AdMob com.google.firebase:firebase-appindexing: 앱 색인 생성 com.google.firebase:firebase-perf: 성능 모니터링 파이어베이스 라이브러리는 앞서 선언한 그래들 파일에 사용하려는 파이어베이스 라이브러리를 그래들 의존성 dependencies에 추가해 주면 된다. 123456789101112131415apply plugin: 'com.android.application'android { // ...}dependencies { // ... implementation 'com.google.firebase:firebase-core:15.0.0' implementation 'com.google.firebase:firebase-auth:15.0.0' implementation 'com.google.firebase:firebase-storage:15.0.0'}// ADD THIS AT THE BOTTOMapply plugin: 'com.google.gms.google-services' 참조첫 페이지","link":"/documents/android/2018-04-20-firebase-start.html"},{"title":"Firebase - Storage","text":"Firebase console에서 Storage를 다루는 과정을 살펴본다. StorageFireage Storage는 사진, 동영상 등의 사용자 제작 콘텐츠 제공해야 하는 앱에서 쉽게 접근하는 서비스를 제공한다. 이것은 Cloud Storage용 Firebase SDK를 사용하여 클라이언트에서 직접 파일을 업로드하고 다운로드할 수 있다. Storage 시작하기스토리지는 파이어베이스 콘솔의 Storage에서 시작한다. {:width=”500”} 스토리지에 버킷을 추가한다. {:width=”500”} 참조 Firebase 저장소","link":"/documents/android/2018-04-20-firebase-storage.html"},{"title":"Firebase - Android Codelab (1): 프로젝트 시작","text":"Firebase Android Codelab 에 있는 2~4번 과정을 정리한 것이다. Android 프로젝트에서 Codelab제공하는 코드랩 코드 friendlychat-android 저장소는 프로젝트 두개로 구성되 있다: android-start: 코드랩을 따라할 수 있는 샘플 코드. android: 코드랩을 완료한 완성한 코드. 다운로드12$ mkdir firebase-codelab$ cd firebase-codelab/ 깃헙에서 코드랩 샘플 코드를 다운로드 한다: 12$ git clone https://github.com/firebase/friendlychat-androidCloning into 'friendlychat-android'... 프로젝트 가져오기Android Studio에서 다운로드한 android-start 프로젝트를 들여온다. [그림. 코드랩 소스 들여오기] 이 프로젝트에서 파이어베이스 코드랩을 따라갈 때 사용할 클래스 파일은 MainActivity, MyFirebaseInstanceIdService, MyFirebaseMessagingService 이다. 이 프로젝트에 구성되 있는 파이어베이스 의존성은 Firebase 시작하기 를 참조해서 그래들 파일 build.gradle 내용을 살펴보기 바란다. 참조","link":"/documents/android/2018-05-01-android_codelab01-start.html"},{"title":"Firebase - Android Codelab (2): Firebase console","text":"Firebase Android Codelab 에 있는 Start와 Authentication을 정리했다. Firebase console ProjectFirebase console 에서 프로젝트를 생성한다. 앱의 해시 값을 Firebase project에 등록해 준 후에, 생성한 google-service.json 파일을 다운로드해서 앱 프로젝트의 모듈에 복사한다. Android 프로젝트에서 Firebase 추가Firebase consoleconsole 에서 프로젝트를 생성하고 프로젝트의 그래들에 SDK를 추가하면 된다. 새 프로젝트를 생성하고 안드로이드 앱 등록 : 패키지 이름 및 SHA1 hash 등록 구성 파일 다운로드: google-service.json Firebase SDK 추가 Firebase 프로젝트 생성Firebase console 로 들어간다. {:width=”500”} 새 프로젝트를 생성한다. {:width=”400”} 안드로이드 앱 등록앱을 추가한다. {:width=”500”} 안드로이드 앱 프로젝트 정보를 등록한다. {:width=”500”} SHA1 해시 값을 얻는다. 기본 debug.keystore 를 사용하면 다음 같다. 1$ keytool -exportcert -alias androiddebugkey -keystore ~/.android/debug.keystore -list -v -storepass android google-service.json서비스 파일을 다운로드해서 앱에 등록한다. {:width=”500”} Firebase SDK 추가안드로이드 앱 프로젝트의 그래들에 Firebase SDK plugin을 추가한다. 프로젝트 수준의 build.gradle (/build.gradle): 123456buildscript { dependencies { // Add this line classpath 'com.google.gms:google-services:3.2.0' }} 앱 수준의 build.gradle (//build.gradle): 12345678dependencies { // Add this line compile 'com.google.firebase:firebase-core:15.0.0'}// Add to the bottom of the fileapply plugin: 'com.google.gms.google-services' 마지막으로 IDE의 표시줄에 있는 ‘지금 동기화’를 누르세요. 앱 실행콘솔에서 Firebase SDK 추가 단계 다음을 진행하면 안드로이드 앱을 실행하기를 요구한다. {:width=”250”} 앱이 실행되고 제대로 Firebase 프로젝트가 등록되면 성공 메시지가 나온다. {:width=”500”} Google play service 업그레이드com.google.gms:google-services 를 사용할 때 단말의 구글 플레이 버전이 낮다면, 앱 실행시 아래 같은 Google play service upgrade 요청 메시지를 보게 된다. {:width=”500”} 그리고 Authentication 등의 서비스 이용을 요청시 Notification으로 업그레이드 실행을 요청받는다. {:width=”500”} 업그레이드를 실행하면 서비스 앱을 업그레이드한다. {:width=”500”} 참조첫 페이지","link":"/documents/android/2018-05-01-android_codelab02.html"},{"title":"Firebase - Android Codelab (3): Auth","text":"Firebase Android Codelab 에 있는 Authentication을 정리했다. 인증 활성화채팅 메시지를 읽고 보내기 위해 인증을 추가해 보자 실시간 데이터 베이스파이어베이스 실시간 데이터 베이스는 JSON 설정을 구성할 수 있다. 파이어베이스 프로젝트에 들어가 Database 를 선택하고 {:width=”500”} *Realtime Database 탭을 시작해서 {:width=”500”} 규칙을 선언한다. {:width=”500”} 인증후 사용할 수 있도록 아래 같이 구성한다. {:width=”500”} Authentication API파이어베이스 인증은 Navigate to the Firebase console and select your project Select Authentication Select the Sign In Method tab Toggle the Google switch to enabled (blue) Press Save on the resulting dialog 파이어베이스 콘솔에서 프로젝트를 선택한 후에 Authentication 으로 들어간다. {:width=”500”} 여기서 가능한 인증 방법은 이메일/비밀번호, 전화, Google, Play gmae, facebook, twitter, github, anonymous 가 제공된다. Google 인증으로 시작해 보자 {:width=”500”} Auth dependency 추가하기앱 모듈의 build.gradle에 firebase-auth 플러그인을 추가한다. app/build.gradle 파일: 1implementation 'com.google.firebase:firebase-auth:15.0.0' Add the Auth instance variables in the MainActivity class: MainActivity.java 파일 123// Firebase instance variablesprivate FirebaseAuth mFirebaseAuth;private FirebaseUser mFirebaseUser; 사용자 확인하기로그인 화면을 표시하기 위해 onCreate 에 아래 코드를 추가하자 1234567891011121314151617// Set default username is anonymous.mUsername = ANONYMOUS;// Initialize Firebase AuthmFirebaseAuth = FirebaseAuth.getInstance();mFirebaseUser = mFirebaseAuth.getCurrentUser();if (mFirebaseUser == null) { // Not signed in, launch the Sign In activity startActivity(new Intent(this, SignInActivity.class)); finish(); return;} else { mUsername = mFirebaseUser.getDisplayName(); if (mFirebaseUser.getPhotoUrl() != null) { mPhotoUrl = mFirebaseUser.getPhotoUrl().toString(); }} 로그아웃을 메뉴 아이템으로 추가해 보자, 1234567891011121314@Overridepublic boolean onOptionsItemSelected(MenuItem item) { switch (item.getItemId()) { case R.id.sign_out_menu: mFirebaseAuth.signOut(); Auth.GoogleSignInApi.signOut(mGoogleApiClient); mUsername = ANONYMOUS; startActivity(new Intent(this, SignInActivity.class)); finish(); return true; default: return super.onOptionsItemSelected(item); }} 로그인 화면 구현SignInActivity 클래스를 열고 구글 계정으로 로그인할 수 있도록 코드를 추가해 보자, SignInActivity.java 123// Firebase instance variablesprivate FirebaseAuth mFirebaseAuth;Then, edit the onCreate() method to initialize Firebase in the same way you did in MainActivity: SignInActivity.java의 onCreate에 12// Initialize FirebaseAuthmFirebaseAuth = FirebaseAuth.getInstance(); 로그인 버튼을 클릭하면 인증화면이 호출되도록 해보자, SignInActivity.java 12345678@Overridepublic void onClick(View v) { switch (v.getId()) { case R.id.sign_in_button: signIn(); break; }} Add the required signIn method that actually presents the user with the Google Sign-In UI. SignInActivity.java 1234private void signIn() { Intent signInIntent = Auth.GoogleSignInApi.getSignInIntent(mGoogleApiClient); startActivityForResult(signInIntent, RC_SIGN_IN); } onActivityResult() 에 결과를 처리하는 코드를 추가해 보자, 12345678910111213141516@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) { super.onActivityResult(requestCode, resultCode, data); // Result returned from launching the Intent from GoogleSignInApi.getSignInIntent(...); if (requestCode == RC_SIGN_IN) { GoogleSignInResult result = Auth.GoogleSignInApi.getSignInResultFromIntent(data); if (result.isSuccess()) { // Google Sign-In was successful, authenticate with Firebase GoogleSignInAccount account = result.getSignInAccount(); firebaseAuthWithGoogle(account); } else { // Google Sign-In failed Log.e(TAG, &quot;Google Sign-In failed.&quot;); } }} 앱을 실행하면 구글 로그인 화면을 볼 수 있다. {:width=”500”} 로그인을 진행하면서 구글 서비스 이용에 대한 동의 절차가 진행된다. 로그인 후 채칭 화면의 옵션 메뉴에서 Logout 도 정상적으로 동작하는지 확인해 보자. 참조첫 페이지]","link":"/documents/android/2018-05-01-android_codelab03-auth.html"},{"title":"Firebase - Android Codelab (4): Read messages","text":"Firebase Android Codelab 에서 제공하는 튜토리얼을 한국어로 정리/요약 한 것. 메시지 읽기채팅 메시지를 포함하고 있는 Codelab 샘플 앱에 포함되 있는 initial_messages.json 파일을 파이어베이스 데이터베이스로 가져와온다. 메시지 가져오기 파이어베이스 콘솔에서 Database를 실행해 Realtime Database로 들어간다. 마우스 오른쪽 클릭으로 Import JSON을 실행한다. {:width=”500”} initial_messages.json 파일을 선택한다. {:width=”500”} 메시지는 아래 같은 구조를 가지고 있다. {:width=”500”} 실시간 데이터베이스와 스토리지 의존성 추가앱 프로젝트의 모듈 build.gradle 에 다음 의존성을 추가 12implementation 'com.google.firebase:firebase-database:15.0.0'implementation 'com.google.firebase:firebase-storage:15.0.0' 메시지 동기화파이어베이스 데이터베이스를 초기화 하고 데이터의 변경을 감지하는 핸들에 리스너를 추가해 준면 리사이클러 뷰에 메시지가 표시된다. MainActivity.java 에 선언를 한다. 123// Firebase instance variablesprivate DatabaseReference mFirebaseDatabaseReference;private FirebaseRecyclerAdapter&lt;FriendlyMessage, MessageViewHolder&gt; mFirebaseAdapter; MainActivity.java 의 onCreate() 에서 mProgressBar.setVisibility(ProgressBar.INVISIBLE); 를 아래 코드로 대체한다.이 코드는 초기 있는 메시지를 추가하고 파이어베이스 데이터베이스에서 새 메시지를 대기한다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596// New child entriesmFirebaseDatabaseReference = FirebaseDatabase.getInstance().getReference();SnapshotParser&lt;FriendlyMessage&gt; parser = new SnapshotParser&lt;FriendlyMessage&gt;() { @Override public FriendlyMessage parseSnapshot(DataSnapshot dataSnapshot) { FriendlyMessage friendlyMessage = dataSnapshot.getValue(FriendlyMessage.class); if (friendlyMessage != null) { friendlyMessage.setId(dataSnapshot.getKey()); } return friendlyMessage; } };DatabaseReference messagesRef = mFirebaseDatabaseReference.child(MESSAGES_CHILD); FirebaseRecyclerOptions&lt;FriendlyMessage&gt; options = new FirebaseRecyclerOptions.Builder&lt;FriendlyMessage&gt;() .setQuery(messagesRef, parser) .build();mFirebaseAdapter = new FirebaseRecyclerAdapter&lt;FriendlyMessage, MessageViewHolder&gt;(options) { @Override public MessageViewHolder onCreateViewHolder(ViewGroup viewGroup, int i) { LayoutInflater inflater = LayoutInflater.from(viewGroup.getContext()); return new MessageViewHolder(inflater.inflate(R.layout.item_message, viewGroup, false)); } @Override protected void onBindViewHolder(final MessageViewHolder viewHolder, int position, FriendlyMessage friendlyMessage) { mProgressBar.setVisibility(ProgressBar.INVISIBLE); if (friendlyMessage.getText() != null) { viewHolder.messageTextView.setText(friendlyMessage.getText()); viewHolder.messageTextView.setVisibility(TextView.VISIBLE); viewHolder.messageImageView.setVisibility(ImageView.GONE); } else { String imageUrl = friendlyMessage.getImageUrl(); if (imageUrl.startsWith(&quot;gs://&quot;)) { StorageReference storageReference = FirebaseStorage.getInstance() .getReferenceFromUrl(imageUrl); storageReference.getDownloadUrl().addOnCompleteListener( new OnCompleteListener&lt;Uri&gt;() { @Override public void onComplete(@NonNull Task&lt;Uri&gt; task) { if (task.isSuccessful()) { String downloadUrl = task.getResult().toString(); Glide.with(viewHolder.messageImageView.getContext()) .load(downloadUrl) .into(viewHolder.messageImageView); } else { Log.w(TAG, &quot;Getting download url was not successful.&quot;, task.getException()); } } }); } else { Glide.with(viewHolder.messageImageView.getContext()) .load(friendlyMessage.getImageUrl()) .into(viewHolder.messageImageView); } viewHolder.messageImageView.setVisibility(ImageView.VISIBLE); viewHolder.messageTextView.setVisibility(TextView.GONE); } viewHolder.messengerTextView.setText(friendlyMessage.getName()); if (friendlyMessage.getPhotoUrl() == null) { viewHolder.messengerImageView.setImageDrawable(ContextCompat.getDrawable(MainActivity.this, R.drawable.ic_account_circle_black_36dp)); } else { Glide.with(MainActivity.this) .load(friendlyMessage.getPhotoUrl()) .into(viewHolder.messengerImageView); } } }; mFirebaseAdapter.registerAdapterDataObserver(new RecyclerView.AdapterDataObserver() { @Override public void onItemRangeInserted(int positionStart, int itemCount) { super.onItemRangeInserted(positionStart, itemCount); int friendlyMessageCount = mFirebaseAdapter.getItemCount(); int lastVisiblePosition = mLinearLayoutManager.findLastCompletelyVisibleItemPosition(); // If the recycler view is initially being loaded or the // user is at the bottom of the list, scroll to the bottom // of the list to show the newly added message. if (lastVisiblePosition == -1 || (positionStart &gt;= (friendlyMessageCount - 1) &amp;&amp; lastVisiblePosition == (positionStart - 1))) { mMessageRecyclerView.scrollToPosition(positionStart); } } }); mMessageRecyclerView.setAdapter(mFirebaseAdapter); 이어서 파이어베이스 데이터베이스에서 갱신하기 위해서 onPause() 와 onResume() 메서드를 갱신한다. MainActivity.java 1234567891011@Overridepublic void onPause() { mFirebaseAdapter.stopListening(); super.onPause();}@Overridepublic void onResume() { super.onResume(); mFirebaseAdapter.startListening();} Test message sync파이어베이스 데이터베이스에 새 메시지를 추가해서 클라이언트와 동기화가 되는지 확인해 보자, 앱을 시작하자, 파이어베이스 콘솔의 데이터베이스에서 새 메시지를 넣자, {:width=”500”} 앱에서 추가된 메시지가 확인된다. 참조첫 페이지","link":"/documents/android/2018-05-01-android_codelab04-message.html"},{"title":"Firebase - Android Codelab (5): Send messages","text":"Firebase Android Codelab 에서 제공하는 튜토리얼을 한국어로 정리/요약 했다. 메시지 보내기채팅 메시지 전송을 추가해 보자,텍스트를 입력하고 전송 버튼을 누르면 메시지가 보내는 과정을 처리해 보자, 메시지 보내기전송버튼을 누르면 FriendlyMessage 객체가 생성되고 파이어베이스 실시간 데이터베이스(RTDB)에 넣어진다. 이 객체를 DatabaseReference 객체의 push() 메서드로 전달하면, 객체의 경로에 자동 생성한 ID를 추가하게 된다. 아이디는 새 메시지가 목록에 추가될 때마다 순차적으로 증가하게 된다. MainActivity.java 의 mSendButton.onClick() 메서드에서 메시지 전송을 추가해 보자, 1234567891011121314mSendButton = (Button) findViewById(R.id.sendButton);mSendButton.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { FriendlyMessage friendlyMessage = new FriendlyMessage(mMessageEditText.getText().toString(), mUsername, mPhotoUrl, null /* no image */); mFirebaseDatabaseReference.child(MESSAGES_CHILD) .push().setValue(friendlyMessage); mMessageEditText.setText(&quot;&quot;); }}); 이미지 메시지 보내기이미지를 포함한 메시지를 전송하려면 이미지를 선택 선택 이미지 처리 RTDB에 임시 이미지 메시지를 쓴다 이미지를 업로드한다 업로드 완료되면 업로드한 이미지의 메시지 URL을 갱신한다. 1. 이미지를 선택mAddMessageImageView.onClick() 메서드에서 Intent.ACTION_OPEN_DOCUMENT 인텐트 액션으로 내장 메모로 혹은 구글 드라이브에서 이미지 형식의 파일을 선택할 수 있다. 1234567891011MainActivity.javamAddMessageImageView = (ImageView) findViewById(R.id.addMessageImageView);mAddMessageImageView.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { Intent intent = new Intent(Intent.ACTION_OPEN_DOCUMENT); intent.addCategory(Intent.CATEGORY_OPENABLE); intent.setType(&quot;image/*&quot;); startActivityForResult(intent, REQUEST_IMAGE); }}); 앱을 실행하고 메시지 입력창 왼쪽의 + 버튼이 이미지 메시지 선택 버튼이다. {:width=”500”} 버튼을 실행하면 도큐멘트 선택 앱이 실행된다. {:width=”500”} 선택한 이미지는 onActiivtyResult() 에서 처리한다. 2. 선택 이미지 처리1234567891011121314151617181920212223242526272829303132333435363738MainActivity.java@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) { super.onActivityResult(requestCode, resultCode, data); Log.d(TAG, &quot;onActivityResult: requestCode=&quot; + requestCode + &quot;, resultCode=&quot; + resultCode); if (requestCode == REQUEST_IMAGE) { if (resultCode == RESULT_OK) { if (data != null) { final Uri uri = data.getData(); Log.d(TAG, &quot;Uri: &quot; + uri.toString()); FriendlyMessage tempMessage = new FriendlyMessage(null, mUsername, mPhotoUrl, LOADING_IMAGE_URL); mFirebaseDatabaseReference.child(MESSAGES_CHILD).push() .setValue(tempMessage, new DatabaseReference.CompletionListener() { @Override public void onComplete(DatabaseError databaseError, DatabaseReference databaseReference) { if (databaseError == null) { String key = databaseReference.getKey(); StorageReference storageReference = FirebaseStorage.getInstance() .getReference(mFirebaseUser.getUid()) .child(key) .child(uri.getLastPathSegment()); putImageInStorage(storageReference, uri, key); } else { Log.w(TAG, &quot;Unable to write message to database.&quot;, databaseError.toException()); } } }); } } }} 실제 이미지 Uri 를 업로드하는 putImageInStorage() 메서드를 구현한다. 12345678910111213141516171819private void putImageInStorage(StorageReference storageReference, Uri uri, final String key) { storageReference.putFile(uri).addOnCompleteListener(MainActivity.this, new OnCompleteListener&lt;UploadTask.TaskSnapshot&gt;() { @Override public void onComplete(@NonNull Task&lt;UploadTask.TaskSnapshot&gt; task) { if (task.isSuccessful()) { FriendlyMessage friendlyMessage = new FriendlyMessage(null, mUsername, mPhotoUrl, task.getResult().getMetadata().getDownloadUrl() .toString()); mFirebaseDatabaseReference.child(MESSAGES_CHILD).child(key) .setValue(friendlyMessage); } else { Log.w(TAG, &quot;Image upload task was not successful.&quot;, task.getException()); } } });} 스토리지 허용하기Firebase Storage를 콘솔에서 생성해야 클라이언트에서 사용할 수 있다. Firebase Storage 사용하기 를 참조해서 생성한다. 이미지 전송앱을 실행하고 메시지 입력창 왼쪽의 + 버튼을 클릭해 이미지를 선택한다. {:width=”500”} Note: 여기서 메시지 글자수가 10자로 제한하고 있다. 다음 11단계의 Remote Config 단락에서 제한을 푸는 것을 알게된다. 참조첫 페이지","link":"/documents/android/2018-05-02-android_codelab05-message.html"},{"title":"Firebase - Android Codelab (6): Logging Action","text":"Firebase Android Codelab 에서 제공하는 튜토리얼을 한국어로 정리/요약 했다. 단말 인덱스에 메시지 넣기파이어베이스 앱 인덱싱을 사용하면 단말에 개인 콘텐츠를 인덱스할 수 있다. 단말 인덱스가 활성화 되면 검색 쿼리로 콘텐츠를 찾을 수 있다. 여기서 앱 메시지 작성시 인덱스하고 구글 앱에서 발견할 수 있도록 한다. 인덱스 의존성 추가파이어베이스 인덱싱 의존성은 메시지 작성시과 사용자 행위 기록을 단말에서 인덱스 하도록 한다. 앱 모듈의 build.gradle에 다음을 추가한다. 1implementation 'com.google.firebase:firebase-appindexing:15.0.0' 인텐츠 필터 추가AndroidManifest.xml 에 필터를 추가해 준다. 12345678910111213141516&lt;activity android:name=&quot;com.google.firebase.codelab.friendlychat.MainActivity&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;android.intent.action.MAIN&quot;/&gt; &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot;/&gt; &lt;/intent-filter&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;android.intent.action.VIEW&quot;/&gt; &lt;category android:name=&quot;android.intent.category.DEFAULT&quot;/&gt; &lt;category android:name=&quot;android.intent.category.BROWSABLE&quot;/&gt; &lt;data android:host=&quot;friendlychat.firebase.google.com&quot; android:scheme=&quot;http&quot; android:pathPrefix=&quot;/message&quot;/&gt; &lt;/intent-filter&gt;&lt;/activity&gt; 개인 콘텐츠를 인덱스단말에서 언제든 메시지를 전송할 때 이 메시지를 단말 인덱스에 추가할 수 있어서 구글 앱을 통해 발견할 수 있다. 아래 코드는 메시지를 단말 인덱스에 새 메시지를 생성하는 코드이다. MainActivity.java 12345678910111213141516171819private Indexable getMessageIndexable(FriendlyMessage friendlyMessage) { PersonBuilder sender = Indexables.personBuilder() .setIsSelf(mUsername.equals(friendlyMessage.getName())) .setName(friendlyMessage.getName()) .setUrl(MESSAGE_URL.concat(friendlyMessage.getId() + &quot;/sender&quot;)); PersonBuilder recipient = Indexables.personBuilder() .setName(mUsername) .setUrl(MESSAGE_URL.concat(friendlyMessage.getId() + &quot;/recipient&quot;)); Indexable messageToIndex = Indexables.messageBuilder() .setName(friendlyMessage.getText()) .setUrl(MESSAGE_URL.concat(friendlyMessage.getId())) .setSender(sender) .setRecipient(recipient) .build(); return messageToIndex;} 새 메시지가 있으면 viewHolder에 indexMessage() 호출하는 코드를 추가한다. MainActivity.java 123456789@Overrideprotected void onBindViewHolder(final MessageViewHolder viewHolder, FriendlyMessage friendlyMessage, int position) { //... if (friendlyMessage.getText() != null) { // write this message to the on-device index FirebaseAppIndex.getInstance() .update(getMessageIndexable(friendlyMessage)); }} Note: It helps to add an IntentService that establishes a base index of all messages for you initially. See details in the App Indexing documentation. 사용자 행위 기록앱 안에서 사용자 행위 기록은 구글 앱에서 앱 컨텐츠에 대한 사용자 경험을 개선하는데 도움을 준다. 메시지를 보는 것 같은 개인적 내용에 대한 사용자 행위를 기록하기 위해서는 Action 객체의 Metadata 에서 업로드 속성을 false 로 해주어야 단말에 기록이 남고 구글 서버에 업로드 되지 않는다. MainActivity.java 123456private Action getMessageViewAction(FriendlyMessage friendlyMessage) {return new Action.Builder(Action.Builder.VIEW_ACTION) .setObject(friendlyMessage.getName(), MESSAGE_URL.concat(friendlyMessage.getId())) .setMetadata(new Action.Metadata.Builder().setUpload(false)) .build();} 기록이 끝나면 FirebaseUserActions.getInstance().end(...) 메서드에 getMessageViewAction() 에서 번환하는 Action 객체를 넘겨주면서 호출해 준다. MainActivity.java 123456789101112131415...@Overrideprotected void onBindViewHolder(final MessageViewHolder viewHolder, FriendlyMessage friendlyMessage, int position) {...if (friendlyMessage.getText() != null) { // write this message to the on-device index FirebaseAppIndex.getInstance() .update(getMessageIndexable(friendlyMessage));}// log a view action on itFirebaseUserActions.getInstance().end(getMessageViewAction(friendlyMessage));} 행위 기록 테스트 앱을 실행하고 메시지 Hi world 메시지를 전송한다 Google app에서 Hi world 메시지를 검색하고, 결과는 Personnel tab에서 확인할 수 있다. {:width=”500”} 참조첫 페이지","link":"/documents/android/2018-05-02-android_codelab06-logging.html"},{"title":"Firebase - Android Codelab (7): Notifications","text":"Firebase Android Codelab 에서 제공하는 10. Receive Reengagement Notifications 튜토리얼을 한국어로 정리/요약 했다. 노티피케이션 받기Firebase Cloud Messaging (FCM)은 앱 사용자에게 알림을 보낼 수 있다. 여기서 Firebase console에서 FCM을 보내고 앱에서 확인 알림을 받는 구성을 해보겠다. FCM 의존성 추가앱 모듈 그래들 app/build.gradle 파일에 의존성을 추가한다. 1implementation 'com.google.firebase:firebase-messaging:15.0.0' FCM 서비스앱에서 FCM 서비스를 사용하기 위해서 토픽 가입에 RegistrationIntentService 클래스, 메시지 처리에 MyFirebaseMessagingService 백그라우드 서비스 클래스로 사용한다. RegistrationIntentService 클래스는 백그라운드 서비스로 InstanceID 를 사용해서 FCM 서버에 앱을 식별시켜준다. 이것은 토픽 메시징을 통해 확인 메시지를 전송하는데 사용하는 토픽에 가입한다. MyFirebaseMessagingService 클래스는 수신하는 FCM 메시지를 처리하는 백그라운드 서비스이다. 이것은 의존성으로 추가한 firebase-fcm library에 있는 FirebaseMessagingService를 상속한다. MyFirebaseMessagingService 클래스MyFirebaseMessagingService 클래스는 onMessageReceived 를 재정의해서 알림을 처리한다. MyFirebaseMessagingService.java 12345678910111213public class MyFirebaseMessagingService extends FirebaseMessagingService { private static final String TAG = &quot;MyFMService&quot;; @Override public void onMessageReceived(RemoteMessage remoteMessage) { // Handle data payload of FCM messages. Log.d(TAG, &quot;FCM Message Id: &quot; + remoteMessage.getMessageId()); Log.d(TAG, &quot;FCM Notification Message: &quot; + remoteMessage.getNotification()); Log.d(TAG, &quot;FCM Data Message: &quot; + remoteMessage.getData()); }} MyFirebaseInstanceIdService 클래스MyFirebaseInstanceIdService 는 FCM 로직을 다루를 서비스로 InstanceID 토큰이 발생하면 앱을 갱신하는데 사용한다. 그러기 위해서 FirebaseInstanceIdService를 상속받아 onTokenRefresh 메서드를 재정의한다. MyFirebaseInstanceIdService.java 123456789101112131415161718192021public class MyFirebaseInstanceIdService extends FirebaseInstanceIdService { private static final String TAG = &quot;MyFirebaseIIDService&quot;; private static final String FRIENDLY_ENGAGE_TOPIC = &quot;friendly_engage&quot;; /** * The Application's current Instance ID token is no longer valid * and thus a new one must be requested. */ @Override public void onTokenRefresh() { // If you need to handle the generation of a token, initially or // after a refresh this is where you should do that. String token = FirebaseInstanceId.getInstance().getToken(); Log.d(TAG, &quot;FCM Token: &quot; + token); // Once a token is generated, we subscribe to topic. FirebaseMessaging.getInstance() .subscribeToTopic(FRIENDLY_ENGAGE_TOPIC); }} AndroidManifest.xml 클래스 등록MyFirebaseMessagingService과 MyFirebaseInstanceIdService 클래스를 서비스로 등록한다. AndroidManifest.xml 123456789101112131415&lt;service android:name=&quot;.MyFirebaseMessagingService&quot; android:exported=&quot;false&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;com.google.firebase.MESSAGING_EVENT&quot; /&gt; &lt;/intent-filter&gt;&lt;/service&gt;&lt;service android:name=&quot;.MyFirebaseInstanceIdService&quot; android:exported=&quot;false&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;com.google.firebase.INSTANCE_ID_EVENT&quot; /&gt; &lt;/intent-filter&gt;&lt;/service&gt; 실행앱을 실행하고 Home 버튼을 눌러 현재 화면에 실행을 백그라운드로 보낸다. 파이어베이스 콘솔에서 알림을 작성한다.파이어베이스 콘솔에서 Notification을 활성화 시킨다. 왼쪽 메뉴에서 GLOW-&gt;Notification 를 선택하거나, {:width=”500”} 제품 목록에서 Notification 를 선택한다. {:width=”500”} 메시지 작성Cloud Messaging -&gt; Notificatios 화면에서 즉시 발송할 메시지를 작성을 시작한다 {:width=”500”} 메시지 내용을 작성한다. {:width=”500”} 알림 수신 확인앱이 전면에 실행중에 로그캣에 출력하므로 로그캣을 확인해 보면 된다. {:width=”500”} 앱 실행이 중단되면 Notification manager로 알림이 수신되어 Notifications에서 확인이 가능하다. {:width=”350”} 참조첫 페이지","link":"/documents/android/2018-05-02-android_codelab07.html"},{"title":"Firebase - Android Codelab (8): 원격지 설정 - 메시지 크기","text":"Firebase Android Codelab 에서 제공하는 11. Remotely Configure Friendly Message Length 튜토리얼을 한국어로 정리/요약 했다. 파이어베이스의 Remote Config는 원격에서 앱을 설정할 수 있게 해준다. Remotely configureFirebase Cloud Messaging (FCM)은 앱 사용자에게 알림을 보낼 수 있다. 여기서 Firebase console에서 FCM을 보내고 앱에서 확인 알림을 받는 구성을 해보겠다. 여기서 Friendly Messages 는 메시지 크기가 제한되 있는데 파이어베이스 콘솔에서 이것을 변경해 보겠다. 콘솔에서 구성 규칙을 추가하기파이어베이스 콘솔의 Remote Config 에서 Add Parameter 를 클릭한다. {:width=”500”} 그리고 파라미터 키로 friendly_msg_length 를 주고 값으로 10 정도를 입력한 후에 Add Parameter 버튼을 눌러 완료한다. {:width=”500”} 변경사항 게시 버튼을 눌러 공개한다. 앱에 Remote config 활성화 하기앱 모듈의 app/build.gradle 파일에 firebase-config 의존성을 추가한다: app/build.gradle 1implementation 'com.google.firebase:firebase-config:15.0.0' 액티비티액티비티에 Remote Config 객체를 선언한다. MainActivity.java (instance variable) 12// Firebase instance variablesprivate FirebaseRemoteConfig mFirebaseRemoteConfig; 요청과 설정 사용MainActivity의 oncreate() 내부에 데이터베이스 초기화 코드 위에 FirebaseRemoteConfig 를 초기화 하고 fetchConfig() 메서드를 호출한다. MainActivity.java 1234567891011121314151617181920// Initialize Firebase Remote Config.mFirebaseRemoteConfig = FirebaseRemoteConfig.getInstance();// Define Firebase Remote Config Settings.FirebaseRemoteConfigSettings firebaseRemoteConfigSettings = new FirebaseRemoteConfigSettings.Builder() .setDeveloperModeEnabled(true) .build();// Define default config values. Defaults are used when fetched config values are not// available. Eg: if an error occurred fetching values from the server.Map&lt;String, Object&gt; defaultConfigMap = new HashMap&lt;&gt;();defaultConfigMap.put(&quot;friendly_msg_length&quot;, 10L);// Apply config settings and default values.mFirebaseRemoteConfig.setConfigSettings(firebaseRemoteConfigSettings);mFirebaseRemoteConfig.setDefaults(defaultConfigMap);// Fetch remote config.fetchConfig(); fetchConfig() 메서드는 Remote Config API를 사용해서 설정을 받아온다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Fetch the config to determine the allowed length of messages.public void fetchConfig() { long cacheExpiration = 3600; // 1 hour in seconds // If developer mode is enabled reduce cacheExpiration to 0 so that // each fetch goes to the server. This should not be used in release // builds. if (mFirebaseRemoteConfig.getInfo().getConfigSettings() .isDeveloperModeEnabled()) { cacheExpiration = 0; } mFirebaseRemoteConfig.fetch(cacheExpiration) .addOnSuccessListener(new OnSuccessListener&lt;Void&gt;() { @Override public void onSuccess(Void aVoid) { // Make the fetched config available via // FirebaseRemoteConfig get&lt;type&gt; calls. mFirebaseRemoteConfig.activateFetched(); applyRetrievedLengthLimit(); } }) .addOnFailureListener(new OnFailureListener() { @Override public void onFailure(@NonNull Exception e) { // There has been an error fetching the config Log.w(TAG, &quot;Error fetching config: &quot; + e.getMessage()); applyRetrievedLengthLimit(); } });}/** * Apply retrieved length limit to edit text field. * This result may be fresh from the server or it may be from cached * values. */private void applyRetrievedLengthLimit() { Long friendly_msg_length = mFirebaseRemoteConfig.getLong(&quot;friendly_msg_length&quot;); mMessageEditText.setFilters(new InputFilter[]{new InputFilter.LengthFilter(friendly_msg_length.intValue())}); Log.d(TAG, &quot;FML is: &quot; + friendly_msg_length);} 또한 메뉴에서 설정을 다시 받아 오게끔 옵션 메뉴에 추가한다. MainActivity.java 123456789101112131415@Overridepublic boolean onOptionsItemSelected(MenuItem item) { switch (item.getItemId()) { case R.id.fresh_config_menu: fetchConfig(); return true; case R.id.sign_out_menu: mFirebaseAuth.signOut(); mUsername = ANONYMOUS; startActivity(new Intent(this, SignInActivity.class)); return true; default: return super.onOptionsItemSelected(item); }} 앱 실행 앱을 실행해서 메시지를 작성하면 10자로 제한된다. 파이어베이스 콘솔에서 friendly_msg_length를 15 정도로 늘려서 테스트 해본다. 변경된 값을 수신하면 로그캣에 아래 같이 찍힌다. {:width=”500”} NOTE: Fresh config requests (requests from Remote Config server) are limited to 5 per hour. If this limit is exceeded requests will be throttled and cached values will be returned till the end of the hour. 참조첫 페이지","link":"/documents/android/2018-05-03-android_codelab08.html"},{"title":"Firebase - Android Codelab (9): 초대 설치하기","text":"Firebase Android Codelab 튜토리얼 중에서 12. Send Install Invites 을 한국어로 정리/요약 했다. 설치 초대하기파이어베이스 앱 초대하기 서비스는, 앱 사용자에게 이메일, 문자를 통해 앱을 공유하도록 할 수 있다. AppInvite 추가하기앱 모듈의 그래들 파일에 appinvite 의존성을 추가한다. app/build.gradle 1implementation 'com.google.android.gms:play-services-appinvite:15.0.0' GoogleApiClient 구성하기액티비티에 GoogleApiClient.OnConnectionFailedListener 인터페이스를 구현한다. 12345678public class MainActivity extends AppCompatActivity implements GoogleApiClient.OnConnectionFailedListener { //... @Override public void onConnectionFailed(ConnectionResult connectionResult) { Log.d(TAG, &quot;onConnectionFailed:&quot; + connectionResult); }} AppInvites는 startActivityForResult 를 호출해서 개시된다. 이것은 AppInvites UI 가 초대장을 생성하고 onActivityResult 를 통해 활동을 호출하는 완성된 상태를 반환하는 것을 처리한다. oncrete에서 GoogleApiClient를 초기화 한다. MainActivity.java 1234mGoogleApiClient = new GoogleApiClient.Builder(this) .enableAutoManage(this, this) .addApi(Auth.GOOGLE_SIGN_IN_API) .build(); 초대 보내기액티비티에서 AppInviteInvitation.IntentBuilder로 인텐트를 구성해 startActivityForResult로 AppInvites를 호출하는 sendInvitation() 메서를 구현한다 MainActivity.java 1234567private void sendInvitation() { Intent intent = new AppInviteInvitation.IntentBuilder(getString(R.string.invitation_title)) .setMessage(getString(R.string.invitation_message)) .setCallToActionText(getString(R.string.invitation_cta)) .build(); startActivityForResult(intent, REQUEST_INVITE);} AppInvites 의 결과는 onActivityResult()에서 요청한 REQUEST_INVITE 식별자를 이용해 다룬다. MainActivity.java 12345678910111213141516171819202122@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) { super.onActivityResult(requestCode, resultCode, data); Log.d(TAG, &quot;onActivityResult: requestCode=&quot; + requestCode + &quot;, resultCode=&quot; + resultCode); if (requestCode == REQUEST_IMAGE) { if (resultCode == RESULT_OK) { //... } } else if (requestCode == REQUEST_INVITE) { if (resultCode == RESULT_OK) { // Check how many invitations were sent and log. String[] ids = AppInviteInvitation.getInvitationIds(resultCode, data); Log.d(TAG, &quot;Invitations sent: &quot; + ids.length); } else { // Sending failed or it was canceled, show failure message to the user Log.d(TAG, &quot;Failed to send invitation.&quot;); } }} 초대는 메뉴 아이템으로 구성해서 sendInvitation을 호출한다. MainActivity.java 123456789101112131415161718@Overridepublic boolean onOptionsItemSelected(MenuItem item) { switch (item.getItemId()) { case R.id.invite_menu: sendInvitation(); return true; case R.id.fresh_config_menu: fetchConfig(); return true; case R.id.sign_out_menu: mFirebaseAuth.signOut(); mUsername = ANONYMOUS; startActivity(new Intent(this, SignInActivity.class)); return true; default: return super.onOptionsItemSelected(item); }} 초대 실행앱을 실행하고 메뉴 항목에서 Invite를 실행하면 App Intites가 실행되어 현재 단말의 주소록에서 이메일 혹은 SMS 사용자가 표시된다. 모든 사용자에게 보내거나 사용자를 선택해서 작성한 메시지와 앱 주소를 보내게 된다. [그림.] 참조첫 페이지","link":"/documents/android/2018-05-03-android_codelab09-invite.html"},{"title":"Firebase - Android Codelab (10): 사용자 추적","text":"Firebase Android Codelab 튜토리얼 중에서 13. Track User Flows 을 한국어로 정리/요약 했다. 파이어베이스를 통해 구글 애널리틱스에 사용자가 앱에서 행한 행위에 대한 기록을 전달해 분석하고 보고할 수 있어서 앱 개선에 도움을 줄 수 있다. 사용자 흐름 추적하기파이어베이스 구글 애널리틱 firebase-analytics은 앱 사용 행위를 통한 사용자들의 행동을 이해하는 방법을 제공한다. 파이어베이스 애널리틱스 의존성 추가앱의 모듈 app/build.gradle 파일에 firebase-analytics 의존성을 추가한다. app/build.gradle 파일: 1implementation 'com.google.firebase:firebase-analytics:15.0.0' 애널리틱스 초기화멤버 변수로 FirebaseAnalytics 객체를 선언한다. MainActiivty.java 1private FirebaseAnalytics mFirebaseAnalytics; mFirebaseAnalytics 객체를 onCreate() 안에서 초기화 한다. 1mFirebaseAnalytics = FirebaseAnalytics.getInstance(this); 파이어베이스 구글 애널리틱스를 초기화 하면 앱 설치, 세션 생명주기 같은 기본 매트릭스를 제공하게 초기화 한다. 사용자 이벤트 전송파이어베이스 구글 애널리틱스의 기본 매트릭스 보다 사용자 정의 기록을 처리하기 위해서, 주문형 이벤트 정보를 기록할 수 있다. 이런 주문형 이벤트 기록은 mFirebaseAnalytics.logEvent() 를 호출한다. onActivityResult 에서 초대 이벤트를 로그한다. REQUEST_INVITE 요청 코드를 처리하는데 SHARE 이벤트를 성공 혹은 실패에 대해서 인자로 보낸다. 12345678910111213141516171819202122232425262728@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) { super.onActivityResult(requestCode, resultCode, data); Log.d(TAG, &quot;onActivityResult: requestCode=&quot; + requestCode + &quot;, resultCode=&quot; + resultCode); If (requestCode == REQUEST_IMAGE) { // ... } else if (requestCode == REQUEST_INVITE) { if (resultCode == RESULT_OK) { Bundle payload = new Bundle(); payload.putString(FirebaseAnalytics.Param.VALUE, &quot;sent&quot;); mFirebaseAnalytics.logEvent(FirebaseAnalytics.Event.SHARE, payload); // Check how many invitations were sent and log. String[] ids = AppInviteInvitation.getInvitationIds(resultCode, data); Log.d(TAG, &quot;Invitations sent: &quot; + ids.length); } else { Bundle payload = new Bundle(); payload.putString(FirebaseAnalytics.Param.VALUE, &quot;not sent&quot;); mFirebaseAnalytics.logEvent(FirebaseAnalytics.Event.SHARE, payload); // Sending failed or it was canceled, show failure message to // the user Log.d(TAG, &quot;Failed to send invitation.&quot;); } }} 파이어베이스에서 구글 애널리틱으로 기록한 이벤트는 모으고, 익명처리되어 24시간 사이에 콘솔에 보고된다. Any events you log to Google Analytics for Firebase will be aggregated, anonymized, and reported in the Firebase console within 24 hours. 참조첫 페이지","link":"/documents/android/2018-05-04-android_codelab10.html"},{"title":"Firebase - Android Codelab (11): 수익과 광고","text":"Firebase Android Codelab 튜토리얼 중에서 14. 광고 수익 을 한국어로 정리/요약 했다. 광고 수익파이어베이스 구글 애널리틱은 사용자 앱 통한 사용자들의 이동을 이해하는 방법을 제공한다. 파이어베이스 애널리틱스 의존성 추가앱의 모듈 app/build.gradle 파일에 play-services-ads 의존성을 추가한다. app/build.gradle 파일: 1implementation 'com.google.android.gms:play-services-ads:15.0.0' 이름 공간 추가activity_main.xml 파일의 최상위 RelativeLayout에 xmlns:ads을 추가한다. activity_main.xml 1234567891011&lt;RelativeLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:tools=&quot;http://schemas.android.com/tools&quot; xmlns:ads=&quot;http://schemas.android.com/apk/res-auto&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:paddingBottom=&quot;@dimen/activity_vertical_margin&quot; android:paddingLeft=&quot;@dimen/activity_horizontal_margin&quot; android:paddingRight=&quot;@dimen/activity_horizontal_margin&quot; android:paddingTop=&quot;@dimen/activity_vertical_margin&quot; tools:context=&quot;com.google.firebase.codelab.friendlychat.MainActivity&quot;&gt; 그리고 activity_main.xml의 RelativeLayout의 맨 위에 ad view를 추가한다. activity_main.xml 123456789&lt;com.google.android.gms.ads.AdView android:id=&quot;@+id/adView&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_centerHorizontal=&quot;true&quot; android:layout_alignParentTop=&quot;true&quot; ads:adSize=&quot;BANNER&quot; ads:adUnitId=&quot;@string/banner_ad_unit_id&quot;&gt;&lt;/com.google.android.gms.ads.AdView&gt; RecyclerView를 adView 밑에 배치하기 위해 android:layout_below=&quot;@+id/adView&quot; 로 배치해 준다.한다. activity_main.xml 123456&lt;android.support.v7.widget.RecyclerView android:id=&quot;@+id/messageRecyclerView&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:layout_below=&quot;@+id/adView&quot; android:layout_above=&quot;@+id/linearLayout&quot;/&gt; AdView 객체In the MainActivity add an instance variable that represents the AdView: MainActivity.java 12private AdView mAdView;Request Ad MainActivity.java 안의 onCreate() 메서드에 ad 요청을 추가한다: MainActivity.java 123mAdView = (AdView) findViewById(R.id.adView);AdRequest adRequest = new AdRequest.Builder().build();mAdView.loadAd(adRequest); Handle lifecycle eventsMainActivity에 액티비티 생명주기 이벤트, 정지, 재시작 그리고 종료에 대한 처리를 추가한다. MainActivity.java 123456789101112131415161718192021222324252627@Overridepublic void onPause() { if (mAdView != null) { mAdView.pause(); } mFirebaseAdapter.stopListening(); super.onPause();}/** Called when returning to the activity */@Overridepublic void onResume() { super.onResume(); mFirebaseAdapter.startListening(); if (mAdView != null) { mAdView.resume(); }}/** Called before the activity is destroyed */@Overridepublic void onDestroy() { if (mAdView != null) { mAdView.destroy(); } super.onDestroy();} Test AdMob 실행을 한다. 광고가 보이즌지 확인한다. {:width=”350”} [그림. 앱 광고 화면] 참조첫 페이지","link":"/documents/android/2018-05-04-android_codelab11-ads.html"},{"title":"Firebase - Android Codelab (12): 크래시 보고","text":"Firebase Android Codelab 튜토리얼 중에서 15. Report Crashes 을 한국어로 정리/요약 했다. 크래시 보고Firebase Crashlytics는 앱이 크래시 발생과 크래시를 이끈 이벤트 로그를 보고할 수 있도록 한다. 파이어베이스 크래시 의존성 추가앱의 모듈 app/build.gradle 파일에 crashlytics 의존성을 추가한다. app/build.gradle 파일: 1234567apply plugin: 'com.android.application'apply plugin: 'io.fabric'dependencies { // ... implementation 'com.crashlytics.sdk.android:crashlytics:2.7.1'} 그리고 Fabric maven repository 의존성이 프로젝트 build.gradle에 있는지 확인한다.. project/build.gradle 123456789101112buildscript { repositories { // ... maven { url 'https://maven.fabric.io/public' } } dependencies { // ... classpath 'io.fabric.tools:gradle:1.24.4' }} 초기화메뉴에 Cause Crash 메뉴를 추가하고, 메뉴 처리시 크래시를 발생하도록 해보자,onOptionsItemSelected 메서드에 crash_menu를 다루도록 추가한다. MainActivity.java 12345678910111213141516171819202122@Overridepublic boolean onOptionsItemSelected(MenuItem item) { switch (item.getItemId()) { case R.id.crash_menu: Log.w(&quot;Crashlytics&quot;, &quot;Crash button clicked&quot;); causeCrash(); return true; case R.id.invite_menu: sendInvitation(); return true; case R.id.fresh_config_menu: fetchConfig(); return true; case R.id.sign_out_menu: mFirebaseAuth.signOut(); mUsername = ANONYMOUS; startActivity(new Intent(this, SignInActivity.class)); return true; default: return super.onOptionsItemSelected(item); }} causeCrash methodMainActivity안에 다음 causeCrash method 를 추가해 주자: MainActivity.java 123private void causeCrash() { throw new NullPointerException(&quot;Fake null pointer exception&quot;);} Test AdMob To activate the app with Firebase Crashlytics, go to the Firebase Dashboard and click ‘Crashlytics’, select ‘Yes, this app is new to Crashlytics.’ {:width=”500”} [그림. 새 크래시리틱 생성하기] 앱 화면의 메뉴에서 Cause Crash 를 실행한다. 크래시 보고가 업로드 성공하면 로그캣에서 확인할 수 있다. (크래시 보고 업로드가 안 보이면 로그캣 필터를 No Filters로 한다.) {:width=”500”} [그림. 크래시 보고 로그캣 메시지] 크래시가 보고된 후에 5분 후 파이어베이스 콘솔에서 확인이 가능하다. 파이어베이스 콘솔에서 Crashlytics 에서 보고서를 확인할 수 있다. {:width=”500”} [그림. 크래시리틱 보고] 참조첫 페이지","link":"/documents/android/2018-05-04-android_codelab12-crash.html"},{"title":"Firebase - Android Codelab (13): 테스트","text":"Firebase Android Codelab 튜토리얼 중에서 16. 앱 테스트(클라우드) 을 한국어로 정리/요약 했다. Firebase Test Lab파이어베이스 테스트 랩은 앱을 여러 종류의 안드로이드 단말을 여러 API 수준과 지역화를 가로질러 테스트할 수 있도록 해준다. 이 테스트들은 모두 클라우드에서 자동으로 이루어진다. Android Test Lab 은 세 가지 테스트 기반을 제공한다. Test Dimensions × Test Executions = Test Matrix Test Dimensions: 앱을 테스트할 장치 유형으로, 장치 모델, 오에스 버전, 지역 그리고 화면 방향 등이다. Test Executions: 개별 실행 가능한 테스트로 Test dimensions의 조합을 선택해 테스트한다. Test Matrix: Test dimensions에서 실행한 테스트 결과. Espresso instrument 의존성 확인앱의 모듈 app/build.gradle 에 androidTestImplementation이 있는지 확인한다. app/build.gradle 파일: 1androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.1' 로그온 및 Firebase Test plugin 활성화 확인먼저 Android Studio 의 preference 에서 Firebase Test lab plugin이 활성화 되도록 한다. {:width=”500”} [그림. Firebase Test Lab Plugin] 그리고 Google Cloud 계정에 로그인 해주어야 한다. {:width=”500”} [그림. Android Studio에서 Google Cloud 로그인] Instrumentation test case 추가파이어베이스 테스트 랩에서 실행할 기구 테스트를 MainActivityEspressoTest.java 파일에 {:width=”350”} [그림. 테스트 케이스 파일] 테스트 케이스 메서드를 추가한다. MainActivityEspressoTest.java 1234@Testpublic void verifySignUpButtonDisplayed() { onView(ViewMatchers.withId(R.id.sign_in_button)).check(matches(isDisplayed()));} 테스트 위한 구성을 실행Android Studio 프로젝트 뷰에서 app &gt; Edit Configurations… 을 실행한다. {:width=”500”} [그림. Edit Configurations... ] Configuration 화면이 열리면 (+) 버튼을 눌러 Android Instrumented Tests를 선택해서 새 테스트 구성을 생성한다: Name: FriendlyChat Test Module: app Test: Class Class: com.google.firebase.codelab.friendlychat.MainActivityEspressoTest {:width=”500”} [그림. Android Instrumented 구성하기 ] Target Options: 타겟 메뉴에서 Firebase Test Lab Device Matrix 를 선택한다. {:width=”500”} [그림. 타겟 선택하기 ] 파이어베이스 프로젝트 선택하기 {:width=”500”} [그림. 파이어베이스 프로젝트 선택 ] Test Lab 구성을 실행한 결과는 콘솔에서 확인할 수 있다. {:width=”500”} [그림. 콘솔에서 결과 화면] 파이어베이스 콘솔에서 테스트 랩 사용하기여기서는 Android Studio 에서 Test Lab을 사용하는 사례를 보고 있다. 완성된 앱의 APK 를 직접 콘솔의 테스트 랩에서 Test Matrix를 실행할 수 있다. {:width=”500”} [그림. 파이어베이스 콘솔 - 프로젝트 오버뷰 화면] 안드로이드 앱 테스트에 대해 더 자세히 알고 싶다면 Android Testing Codelab을 살펴보면 좋겠다. 참조첫 페이지","link":"/documents/android/2018-05-04-android_codelab13-test.html"},{"title":"","text":"Android Studio 시작하기1. Installation : Android StudioDownload &amp; Installation Android Studio Android Studio 설치와 AVD 사용 2. Start A new project and to LinearLayouthttps://imgur.com/gallery/pyMiwB6 Firebase Android codelab 시리즈: 2018-04월 자료 Android Codelab: 프로젝트 시작 Android Codelab: Firebase console Android Codelab: Authentication Android Codelab: Read A message Android Codelab: Send A message Android Codelab: Logging User action Android Codelab: Cloud Messaging Android Codelab: Remote Config Android Codelab: App Invites Android Codelab: Track User Flows Android Codelab: Ads Android Codelab: Crash Android Codelab: Test Lab Firebase 소개: Firebase 시작하기 Firebase Storage 사용하기 Firebase Database 사용하기 Firebase Cloud Messaging 사용하기","link":"/documents/android/index.html"},{"title":"","text":"Ducumentations PythonAI: Python 개발 AndroidAndroid 개발 DatabaseDatabase 관련 LinuxLinux 문서 정리 macOS Advanced macOS Command-Line Tools Mooc / OCW / Open Lab https://www.edwith.org/ 스탠포드의 “엔지니어들을 위한 개인 재무 관리” 강의 요약/cs007.blog https://cs007.blog/2022/10/13/cs-007-course-material-2022/ 모두의 연구소 Computer Science 폰노이만 아키텍처,blog 컴파일 단계 활용분야 CRM: https://cdnsite.agilecrm.com/img/info-graphic.svg SCM: https://st4.depositphotos.com/13159112/21885/v/1600/depositphotos_218853972-stock-illustration-scm-supply-chain-management-concep.jpg ERP: https://leadersmt.net/wp-content/uploads/2021/09/erp-system.png Big Data https://www.selecthub.com/wp-content/uploads/2020/03/BA-Life-Cycle-1024x1024.png https://www.saytekinc.com/img/big-data.png","link":"/documents/index.html"},{"title":"","text":"git git 입문 git 발전 git 발전: reset 한글 pro git A Visual Git reference, 한국어 github 가입과 프로파일 Github README 프로파일, qkboo 깃허브 프로필 꾸미기 github-Desktop 이용Github Desktop 이용 배포하는 방법을 살펴본다. Github-desktop 이용,qkboo github 팀 레포지토리 생성 팀 레포지토리 Fork, Pull request &amp; Merge, qkboo (old)github 웹 Pull request &amp; merge, qkboo 맨땅에서 시작하는 협업을 위한Github 사용법 github 활용 취업 깃허브(GitHub)로 취업하기 (특강) 깃허브로 취업하기 주니어 개발자를 위한 취업 정보","link":"/documents/git/index.html"},{"title":"","text":"Profile README깃헙 레포지토리를 깃헙 사용자 이름과 동일하게 생성하고 README.md 를 추가하면 프로필 리드미로 사용할 수 있다. https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-profile/customizing-your-profile/managing-your-profile-readme 사용자 이름과 같은 레포지토리를 생성하고 README.md 를 추가 github 사용자 이름과 같은 레포지토리를 생성한다 README.md 파일을 추가한다. 사용자에 대한 설명을 적은 README.md 이렇게 추가한 프로필 README 는 Overview 에 나타나게 된다.","link":"/documents/git/github_profile.html"},{"title":"","text":"Github Desktop 이용 배포하는 방법을 살펴본다. github 가입 github-desktop 설치 새 로컬 레포지토리 생성 로컬에서 원격 레포지토리에 Publish 로컬 파일 생성/추가/수정/삭제 github 원격 레포지토리에서 새 파일 생성 원격 레포지토리 클론 github 에 새 원격 레포지토리 생성 https://blog.thinkbee.kr/1. github 가입2. github-desktop 설치Github Desktop 설치: https://desktop.github.com/ GitHub Desktop 설명서: https://docs.github.com/ko/desktop 다운로드 다운로드한 github-desktop을 설치한다. 처음 시작 Sign in to Github.com Completes Sign in to Github.com 3. 새 로컬 레포지토리 생성새 로컬 레포지토리 생성 새 로컬 레포지토리 정보 입력 새 로컬 레포지토리 4. 로컬을 원격 레포지토리에 Publish로컬 레포지토리를 직접 원격 레포지토리로 생성하고 업로드한다. 원격에서 레포지토리를 생성해야 하므로 이름을 입력 5. 로컬 파일 생성/추가/수정/삭제 github-desktop 에서 로컬 레포지토리에 생성/추가/수정/삭제한 파일을 확인하고 Commit 해야 한다. 로컬 레포지토리 변경되면 Commit 하고 원격지에 Push 로 업로드한다. 로컬 레포지토리 변경되면 Commit 하고 원격지에 Push 로 업로드한다. 6. github 원격 레포지토리에서 새 파일 생성github 레포지토리에서 add file 을 사용해서 파일, 디렉토리를 만들수 있다. 원격 레포지토리에 변경이 발생하면 로컬에서 Fetch 를 통해 변경 사항을 확인한다. 원격 레포지토리 변경 사항을 로컬과 동기화를 하려면 Pull 을 실행한다. 원격 레포지토리 Pull 결과 1 7. 원격 레포지토리를 로컬에 클론예를 들어 https://github.com/tensorflow/examples 를 클론한다면 github-desktop 직접 열기 github-desktop 직접 열기 8. 원격 레포지토리 Forkgithub 의 다른 레포지토리를 Fork 한다. 9. github 에 새 원격 레포지토리 생성 1","link":"/documents/git/gettting-start-github_desktop.html"},{"title":"","text":"github 에서 팀 프로젝트를 위해서 팀장이 레포지토리를 생성하고 팀원을 참여자로 추가한다. 그리고 팀원은 fork 를 통해서 클론해서 프로젝트에 참여 작업을 이어 나갈 수 있다. 레포지토리 생성 (팀장) 참여자 관리 (팀장)프로젝트 레포지토리에 팀원을 추가해 준다. 레포지토리 Settings 에서 Collaborators 페이지에서 참여자를 관리할 수 있다. Collaborator 에 추가할 github 사용자를 검색 Collaborators 추가 사용자 목록 참여자 알림 확인사용자는 알림에 Collaborator 에 추가되어 허용할지를 등록 요청받은 collaborator 을 받아들인다 Fork &amp; Pull Request, Merge깃헙을 통해 프로젝트를 수행한다면 레포지토리 fork, pull-request, commit 을 통해서 여러 참여자/기여자의 코드를 동기화 할 수 있다. https://www.tomasbeuzen.com/post/git-fork-branch-pull/ 팀장이 공유할 레포지토리를 만든다 팀원이 프로젝트 레포지토리를 fork 한다 fork 하는 레포지토리 정보를 입력한다 포크한 레포지토리에 새 파일을 추가한다.팀원 레포지토리로 포크한 프로젝트 레포지토리에 새 파일을 추가한다. github desktop으로 하는 예제는 마지막에 있다. 팀원, 포크한 레포지토리에 새 파일이 추가되었다 팀원, 변경 사항을 Open Pull Request 한다 팀원, Pull Request 내용을 적는다 팀원, 변경 사항을 Open Pull Request 한다 팀장, Pull Request 를 확인한다. 팀장, Pull Request 를 확인한다. 팀장, Merge 한다. 프로젝트 레포지토리에 팀원이 추가한 파일이 추가 되었다. 포크한 레포지토리를 Sync 해서 동기화를 한다. Sync 해서 동기화로 upstream 과 commit 을 일치시킨다 클라이언트에서 fork 레포지토리 작업팀 레포지토리에 참여한 사용자가 원격 레포지토리를 클론해서 로컬에서 작업을 할 수 있다. 작업한 결과는 Push를 통해서 원격레포지토리에 동기화를 한다. fork한 레포지토리를 로컬에 클론한다Github desktop을 이용해서 레포지토리를 선택해서 클론을 수행한다. 클론 레포지토리를 저장할 위치를 정한다. Git desktop은 직접 Upstream에 pull request 를 할 수 있도록 지원하고 있지만 여기서는 Push 를 사용하겠다. 클론한 로컬 레포지토리에서 새파일 작업을 한다 레포지토리에 변경 사항을 커밋을 한다. 로컬의 커밋 변경을 PUSH 한다 github upstream에 pull request 한다","link":"/documents/git/github-fork_pull_request.html"},{"title":"","text":"github 사이트에서 프로젝트에서 사용하는 레포지토리를 생성하고 레포지토리에 새 참여자를 추가해서 브랜치를 생성해서 관리하는 과정을 설명한다. fork 가 아닌 github 웹을 사용하고 있다. 참여자 관리레포지토리 Settings 에서 Collaborators 페이지에서 참여자를 관리할 수 있다. Collaborator 에 추가할 github 사용자를 검색 Collaborators 추가 사용자 목록 사용자는 알림에 Collaborator 에 추가되어 허용할지를 등록 요청받은 collaborator 을 받아들인다 Collaborator 사용자가 새로운 파일을 추가한다. 레포지토리 브랜치의 새로운 변경/추가/삭제가 발생하면 Pull request 를 요청해야 한다. Collaborator로 참가한 사용자는 pull request 하고 merge도 할 수 있지만 정책으로 main 관리자가 하도록 하자. 새 브랜치 사용pull request 와 merge 를 위한 정책 구성. Collaborator도 merge 할 수 있지만 팀장/관리자가 merge 하도록 정책을 정한다. Pull request 와 merge 새 브랜치를 생성한다 새 브랜치에서 작업을 수행한다. 새 브랜치에 변경된 내용을 pull request 할 수 있다. 새 브랜치에 변경된 내용을 pull request 할 수 있다. 사용자/관리자는 새 브랜치에 변경된 내용을 pull request 할 수 있다. 관리자/팀장은 새 브랜치에 변경된 내용을 merge 한다. 관리자/팀장은 새 브랜치에 변경된 내용을 merge 한다. 관리자/팀장은 사용한 브랜치는 제거해 레포지토리를 정리한다.","link":"/documents/git/old-github-fork_pull.html"},{"title":"","text":"Android Studio 설치와 사용 AVD 사용 1. Android Studio 설치와 사용Android Studio 2021 특징https://developer.android.com/studio#downloads 페이지의 특징 숏켯 보기 Android Studio 2021 설치 시스템 요구사항 설치다운로드 선택: macOS 설치 인텔 혹은 애플 CPU 구분해 다운로드한 dmg 를 실행한다. Android Studio 를 Application 폴더로 드래그한다. 2. AVD 사용Android Studio 에서 AVD 를 생성시 HAXM 사용을 권장한다. HAXM 설치 확인emulator -accel-check 명령으로 확인할 수 있다. 12345~$ emulator -accel-checkaccel:8HAXM is not installed on this machine (/dev/HAX is missing).accel Windows 에서 VM 가속기 설치Windows에서 VM 가속 구성Windows의 VM 가속은 다음 세 가지 하이퍼바이저 Intel Hardware Accelerated Execution Manager(HAXM) Android Emulator Hypervisor Driver for AMD Processors Windows Hypervisor Platform(WHPX) 선택 기준: Hyper-V 사용중지Intel HAXM / Android Emulator Hypervisor Driver for AMD Processors를 사용시 Hyper-V 꺼야 한다. &lt;윈도우 키&gt;+&lt;S&gt; 를 누른 후 **”Windows 기능”**을 입력해서 [Windows 기능 켜기/끄기] 를 실행 [Windows 기능 켜기/끄기] 창에서 [Hyper-V], [Windows 샌드박스], [Windows 하이퍼바이저 플랫폼] 이 모두 꺼져 있어야 한다. 인텔 CPU / HAXM 설치 https://github.com/intel/haxm/releases/ 최신 버전의 Windows용 Intel HAXM 압축 파일 다운로드 다운로드한 haxm-windows_버전.zip 파일의 압축 풀기 haxm-버전-setup.exe 파일 실행 후 설치 진행초기 화면에서 와 클릭 설치가 완료되면 를 클릭하여 설치 종료 AMD CPU https://github.com/google/android-emulator-hypervisor-driverfor-amd-processors/releases/ 최신 버전의 [Android Emulator Hypervisor Driver for AMD Processors] 파일(gvm-windows_버전.zip) 다운로드 다운로드한 gvm-windows_버전.zip 파일의 압축을 풀고, 압축을 푼 폴더의 silent_install.bat 파일을 실행하여 설치를 진행 Windows Hypervisor Platform(WHPX) 설치Windows Hypervisor Platform(WHPX) 요구사항 Intel 프로세서: 가상화 기술(VT-x), 확장 페이지 테이블(EPT), 무제한 게스트(UG) 기능을 지원. 컴퓨터의 BIOS 설정에서 VT-x가 사용 설정. AMD 프로세서: AMD Ryzen 프로세서가 권장. 컴퓨터의 BIOS 설정에서 가상화 또는 SVM이 사용 설정되어 있다. Android 스튜디오 3.2 베타 1 이상 (developer.android.com에서 다운로드). Android Emulator 버전 27.3.8 이상 (SDK Manager를 사용하여 다운로드). Windows 10이 2018년 4월 업데이트 이상이어야 한다. Windows Hypervisor Platform(WHPX) 사용 VM 가속 구성 설정 &gt; Apps and features(앱 및 기능)를 선택합니다. Related settings(관련 설정)에서 Programs and Features(프로그램 및 기능)를 클릭합니다. Turns Windows Features on or off를 클릭합니다. Windows Hypervisor Platform을 선택합니다. macOS 에서 VM 가속기 구성Mac OS X v10.10 Yosemite 이상에서 Android Emulator는 기본적으로 내장된 Hypervisor.Framework를 사용하고 Hypervisor.Framework가 초기화에 실패할 경우에는 다시 Intel HAXM을 사용하게 됩니다. Hypervisor.Framework를 사용할 수 없을 때 macOS에서 VM 가속을 사용하려면 Intel HAXM 커널 확장 프로그램을 설치해야 합니다. Intel HAXM 커널 확장 프로그램을 설치 SDK Manager SDK Update Sites 탭을 클릭한 다음 Intel HAXM을 선택. 다운로드가 완료되면 설치 프로그램을 실행합니다. 일반적으로 sdk/extras/intel/Hardware_Accelerated_ExecutionManager/IntelHAXMversion.dmg 위치에서 설치 프로그램을 찾을 수 있다. 화면에 표시된 안내에 따라 설치를 완료합니다. 다음 명령어를 실행하여 새 커널 확장 프로그램이 올바르게 작동하는지 확인. 12$ kextstat | grep intelcom.intel.kext.intelhaxm","link":"/documents/android/2023-android_studio_new_project.html"},{"title":"리눅스 문서 정리","text":"이 문서 타래는 리눅스에 대한 글을 모아 두었다. 시스템 일반 Raspberry Pi: mmcblk 블럭장치 SD Card 포맷 및 디스크 이미지 사용하기 Docker CLI 요약 HTTPS 를 위한 Private SSL find 명령 usages Linux cheat : dd, fsck, grub, rync, timezone, failog systemd 서비스 systemd 에 jupyterlab 등록하기 systemd 서비스 관리 Firewall Linux설치후 - Basic Security, UFW Linux설치후 - firewalld openSUSE openSUSE - openSUSE LEAP 15: Install, Raspberry Pi openSUSE - Installation, Raspberry Pi Opensuse LEAP 설치후 10가지 작업, Raspberry Pi openSUSE - Basic Security openSUSE - nginx, nodejs 등 서버 openSUSE - 서비스 관리 openSUSE - Network 관리 openSUSE - firewalld Upgrade OpenSUSE LEAP 42.2 to 42.3, Raspberry Pi 64bit OS openSUSE: Build MongoDB 3.4, Raspberry Pi","link":"/documents/linux.html"},{"title":"","text":"AI with PythonPython 회오리바람을 탄 파이썬 데이터 과학/파이썬, 동국대학교 왕초보를 위한 Python: 쉽게 풀어 쓴 기초 문법과 실습 초보자를 위한 파이썬 300제 개발도구 Windows Command 명령어 pyenv 버전 관리자 개발환경 Jupyter-lab 개발환경 이해 Google Colab,202209 git과 github 사용 WBS 작성법, 브런치 Docker CLI 요약 인공지능 수학 인공지능을 위한 기초수학 통계 파이썬 통계 상관계수 HTML &amp; CSS https://www.w3schools.com/html/default.asp https://www.w3schools.com/css/default.asp 이미지 구조 색상 이론 초보자 가이드 Data structure파이썬 엑셀 CSV 파일 읽고/쓰기: https://docs.python.org/ko/3/library/csv.html https://wikidocs.net/80822 Sample file: https://github.com/UCLSPP/datasets/blob/master/data/Credit.csv JSON 파일 읽고/쓰기: https://wikidocs.net/67980 json 쓰기: https://wikidocs.net/126088","link":"/documents/python.html"},{"title":"Database 관련 요약","text":"이 문서 타래는 데이터베이스 관련 자료 링크를 정리한다. MariaDB / MySQL MySql CLI 주요 명령 mysqlclient 에서 CLI 로 사용할 수 있는 명령 요약 mysqladmin CLI 주요 사용법 mysqladmin 명령 요약 MySQL/MariaDB Server SSH Over Tunneling SSH Tunneling 을 구성하고 사용 MariaDB/MySQL 클라언트-서버 TLS/SSL 암호화 연결 TLS/SSL을 이용한 데이터베이스 클라이언트-서버 접속에 대한 요약. MariaDB 클라언트-서버 TLS/SSL 암호화 연결(1) MariaDB 클라언트-서버 TLS/SSL 암호화 연결(2) MariaDB 클라언트-서버 TLS/SSL 암호화 연결(3) MariaDb 10/ MySQL 8 - data 디렉토리 변경 (Ubuntu) MySQL 8 / MariaDB 의 기본 data 디렉토리를 이동하는 과정을 요약 설치 Rock64에서 MySQL Server APT 이용 설치 MySQL 5.x 설치 (1) MySQL 5.x 소스 빌드 (2) MySQL 5.x 시작 (3) MongoDB Community Edition Installations 시리즈 설치 MongoDB Community Edition 4.2 설치 - ARM64 Ubuntu/Debian Armbian MongoDB Community Edition 4.2: 구성 설정과 사용자 인증 사용 MongoDB 4.2 설치 on Armbian 64bit OS openSUSE: Build MongoDB 3.4, Raspberry Pi Raspberry Pi 에서 mongodb 3.4 를 빌드하는 과정. Docker 기반 mongodb Mongodb를 Docker 를 이용 구동하고 실행한다. MongoDB Community Edition 3.6 on Ubuntu,2018 mongodb 3.4 on Armbian","link":"/documents/database.html"}]}